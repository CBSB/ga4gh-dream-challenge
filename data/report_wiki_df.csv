workflow,file,content,submission_id
bcbio_NA12878-chr20,9622674_report.md,"## bcbio NA12878 chr20 variant calling and validation

### Workflow description

```YAML
contributor: ""Brad Chapman""
workflow_handle: ""bcbio_NA12878-chr20""
input_handle: ""NA12878 chr20""
```
The following description is provided by the workflow author:
> A [bcbio](http://bcb.io/) workflow running a single chromosome subset of the [Genome in a Bottle NA12878 sample](http://jimb.stanford.edu/giab) from [Illumina's Platinum Genomes](https://www.illumina.com/platinumgenomes.html). It runs alignment, variant calling with multiple methods ([GATK4 HaplotypeCaller](http://gatkforums.broadinstitute.org/gatk/categories/gatk-4-alpha), [FreeBayes](https://github.com/ekg/freebayes), [Platypus](https://github.com/andyrimmer/Platypus),[samtools](https://github.com/samtools/samtools)) and quality control, validating outputs against reference standards. It uses 8 cores and 4Gb/memory per core, using 50Gb of disk space (35Gb for inputs, 15Gb for analyses). On an AWS m4.2xlarge instance with 8 cores and 32Gb of memory, it runs in 4 hours.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""James Eddy"" # your name here
institution: ""Sage Bionetworks"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170217172322"" # indicate executor version used
docker_version: ""17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""EC2"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""32"" # indicate number of cores in environment
env_memory: ""244Gb"" # indicate available RAM in environment
env_disk: ""elastic"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""EC2"" 
env_cpus_ex: ""32""
env_memory_ex: ""244Gb""
env_disk_ex: ""elastic""
```

### Steps

#### 1. Set up environment

##### EC2/EFS
I launched a single-node EC2 instance of type `r4.8xlarge` in `us-east-1f` (spot request) with the canonical Ubuntu 16.04 AMI (`ami-80861296`). I connected to the instance via SSH (user `ubuntu`) and installed the required nfs client for Amazon EFS:
```shell
sudo apt-get install nfs-common
```

I then mounted my EFS volume at `/efs`.
```shell
sudo mkdir /efs
sudo mount -t nfs4 -o nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2 fs-2067e169.efs.us-east-1.amazonaws.com:/ /efs
```

##### Docker
I installed Docker on the instance using the following commands:
```shell
sudo apt-get update &&
    sudo apt-get install -y \
        apt-transport-https \
        ca-certificates \
        curl \
        software-properties-common &&
    curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - &&
    sudo add-apt-repository \
        ""deb [arch=amd64] https://download.docker.com/linux/ubuntu \
        $(lsb_release -cs) \
        stable"" &&
    sudo apt-get update &&
    sudo apt-get install -y docker-ce
```

Next, I modified the Docker's default storage location to use a partition with more space available, creating the file `/etc/docker/daemon.json` with the following:
```shell
{
  ""debug"": true,
  ""graph"": ""/dev/docker-data""
}
```

Finally, I added `ubuntu` to the `docker` Linux group, exited the instance, and signed back in.

##### Anaconda/cwltool
I installed Anaconda (`miniconda`) for Python 2.7 under my EFS root directory (**note:** I think this makes `conda` operations a bit slower than usual...).
```shell
wget https://repo.continuum.io/miniconda/Miniconda2-latest-Linux-x86_64.sh -O miniconda.sh
bash miniconda.sh -b -p /efs/miniconda
export PATH=""/efs/miniconda/bin:$PATH""
```

I created and configured a virtual environment with `synapseclient` and `cwltool` as follows:
```shell
conda create -n syncwl
source activate syncwl
pip install synapseclient --no-cache-dir
pip install schema-salad==2.2.20170222151604 cwltool==1.0.20170217172322 --no-cache-dir
```

##### Workspace/config
I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir /efs/bcbio_NA12878-chr20
cd /efs/bcbio_NA12878-chr20
cp ~/.synapseConfig .
```

Within the working directory, I created a `tmp` folder to be used with `cwltool` in subsequent steps:
```shell
mkdir tmp
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **bcbio_NA12878-chr20** workflow:
```shell
synapse get syn9819444 # bcbio_NA12878-chr20_get.cwl.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `bcbio_NA12878-chr20_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict dockstore-tool-synapse-get.cwl bcbio_NA12878-chr20_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `transform.cwl` and parameterized by `transform.cwl.json`:
```
nohup cwltool --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20.cwl NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20-samples.json
```

The workflow took about 10 hours to complete (I think the parallelization might not have been handled correctly, possibly due to the older version of `cwltool` I was using).

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool bcbio_NA12878-chr20_checker.cwl bcbio_NA12878-chr20_checker.json
cat results.json 
```

#### 7. Submit workflow outputs

I modified the parameters in `bcbio_NA12878-chr20_submit.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""SageWorkflowRunners"",
    ""eval_id"": ""9605240"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""grading-summary-NA12878-chr20.csv""
        }
    ],
    ""parent_id"": ""syn9851737""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl bcbio_NA12878-chr20_submit.json
```
---",9622674
bcbio_NA12878-chr20,9622778_report.md,"## bcbio NA12878 chr20 variant calling and validation

### Workflow description

```YAML
contributor: ""Brad Chapman""
workflow_handle: ""bcbio_NA12878-chr20""
input_handle: ""NA12878 chr20""
```
The following description is provided by the workflow author:
> A [bcbio](http://bcb.io/) workflow running a single chromosome subset of the [Genome in a Bottle NA12878 sample](http://jimb.stanford.edu/giab) from [Illumina's Platinum Genomes](https://www.illumina.com/platinumgenomes.html). It runs alignment, variant calling with multiple methods ([GATK4 HaplotypeCaller](http://gatkforums.broadinstitute.org/gatk/categories/gatk-4-alpha), [FreeBayes](https://github.com/ekg/freebayes), [Platypus](https://github.com/andyrimmer/Platypus),[samtools](https://github.com/samtools/samtools)) and quality control, validating outputs against reference standards. It uses 8 cores and 4Gb/memory per core, using 50Gb of disk space (35Gb for inputs, 15Gb for analyses). On an AWS m4.2xlarge instance with 8 cores and 32Gb of memory, it runs in 4 hours.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Jeltje van Baren"" 
institution: ""UCSC"" 
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170704143016"" # indicate executor version used
docker_version: ""1.12.1, build 23cf638"" # from `docker --version`
environment: ""UCSC podcloud VM"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""31"" # indicate number of cores in environment
env_memory: ""252 G"" # indicate available RAM in environment
env_disk: ""1 Tb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""EC2"" 
env_cpus_ex: ""32""
env_memory_ex: ""244Gb""
env_disk_ex: ""elastic""
```

### Steps

1. Used link on [3.3 - Access Data and Tools](https://www.synapse.org/#!Synapse:syn8507134/wiki/416015) to download [bcbio_NA12878-chr20_get.cwl.json](https://www.synapse.org/Portal/filehandleassociation?associatedObjectId=9819444&associatedObjectType=FileEntity&fileHandleId=15452400&xsrfToken=F397E2A807CC92157AEC380011771547)

2. From the same page, downloaded [dockstore-tool-synapse-get.cwl](https://www.synapse.org/Portal/filehandleassociation?associatedObjectId=9770802&associatedObjectType=FileEntity&fileHandleId=15691607&xsrfToken=F397E2A807CC92157AEC380011771547) and [dockstore-tool-synapse-submit.cwl](https://www.synapse.org/Portal/filehandleassociation?associatedObjectId=9732885&associatedObjectType=FileEntity&fileHandleId=16683837&xsrfToken=F397E2A807CC92157AEC380011771547):

      dockstore-tool-synapse-get.cwl pulls quay.io/ga4gh-dream/dockstore-tool-synapse-get:1.6.2.dev--2
      dockstore-tool-synapse-submit.cwl pulls  quay.io/ga4gh-dream/dockstore-tool-synapse-submit:1.7.1--1

3. Retrieved data:

    source ~/venv/cwl/bin/activate
    export TMPDIR=/mnt/tempdir 
    tmpstuff=""--tmpdir-prefix=/mnt/tempdir --tmp-outdir-prefix=/mnt/tempdir""
    ln -s ~/.synapse.key .synapseConfig
    cwltool $tmpstuff --non-strict dockstore-tool-synapse-get.cwl bcbio_NA12878-chr20_get.cwl.json

4. Ran workflow:

    cd NA12878-platinum-chr20-workflow &&\
    cwltool $tmpstuff main-NA12878-platinum-chr20.cwl main-NA12878-platinum-chr20-samples.json

5. Created a synapse project for this workflow [bcbio_GA4GH: syn10209866](https://www.synapse.org/#!Synapse:syn10209866), updated bcbio_NA12878-chr20_submit.json with this information and submitted the output:

    ln -s NA12878-platinum-chr20-workflow/grading-summary-NA12878-chr20.csv .
    cwltool $tmpstuff --non-strict dockstore-tool-synapse-submit.cwl  bcbio_NA12878-chr20_submit.json

Contents of bcbio_NA12878-chr20_submit.json
```
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": """",
    ""eval_id"": ""9605240"",
    ""file"": [
        {
            ""class"": ""File"",
            ""path"": ""grading-summary-NA12878-chr20.csv""
        }
    ],
    ""parent_id"": ""syn10209866""
}
```

---",9622778
bcbio_NA12878-chr20,9622790_report.md,"## bcbio NA12878 chr20 variant calling and validation

### Workflow description

```YAML
contributor: ""Brad Chapman""
workflow_handle: ""bcbio_NA12878-chr20""
input_handle: ""NA12878 chr20""
```
The following description is provided by the workflow author:
> A [bcbio](http://bcb.io/) workflow running a single chromosome subset of the [Genome in a Bottle NA12878 sample](http://jimb.stanford.edu/giab) from [Illumina's Platinum Genomes](https://www.illumina.com/platinumgenomes.html). It runs alignment, variant calling with multiple methods ([GATK4 HaplotypeCaller](http://gatkforums.broadinstitute.org/gatk/categories/gatk-4-alpha), [FreeBayes](https://github.com/ekg/freebayes), [Platypus](https://github.com/andyrimmer/Platypus),[samtools](https://github.com/samtools/samtools)) and quality control, validating outputs against reference standards. It uses 8 cores and 4Gb/memory per core, using 50Gb of disk space (35Gb for inputs, 15Gb for analyses). On an AWS m4.2xlarge instance with 8 cores and 32Gb of memory, it runs in 4 hours.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Bogdan Gavrilovic"" # your name here
institution: ""Seven Bridges Genomics"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""rabix"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.0"" # indicate executor version used
docker_version: ""1.12.6"" # from `docker --version`
environment: ""EC2"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""32"" # indicate number of cores in environment
env_memory: ""60Gb"" # indicate available RAM in environment
env_disk: ""700Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

#####1. [Install rabix](https://github.com/rabix/bunny#installing) on your machine and set environment variable $BUNNY. You need docker and java installed to run rabix:
```shell
wget https://github.com/rabix/bunny/releases/download/v1.0.0/rabix-1.0.0.tar.gz -O rabix-1.0.0.tar.gz && tar -xvf rabix-1.0.0.tar.gz
export BUNNY=$PWD/rabix-cli-1.0.0/rabix
```
#####2. If you've not already retrieved the CWL and data with synapse-get, you can use the [Synapse python client](https://github.com/Sage-Bionetworks/synapsePythonClient#installation):
```shell
pip install synapseclient
synapse get -r syn9725771 # bcbio workflow, tools and input files
synapse get syn9732885   # dockstore-tool-synapse-submit.cwl
```
#####3. Run the workflow using rabix executor on your machine by typing in the terminal: $BUNNY <app> <inputs>
For example:
```shell
$BUNNY bcbio_NA12878-chr20/NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20.cwl bcbio_NA12878-chr20/NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20-samples.json
```
### Validating results
Modify the `bcbio_NA12878-chr20_checker.json` to include the path to the requested output file and run checker tool
```shell
$BUNNY bcbio_NA12878-chr20_checker.cwl bcbio_NA12878-chr20_checker.json
```
Check results
```shell
cat ./path/to/results.json
``` 
```json
{
    ""Overall"": true,
    ""Steps"": {
        ""NA12878-chr20_gatk-haplotype_Indels_tp"": true,
        ""NA12878-chr20_samtools_Indels_tp"": true,
        ""NA12878-chr20_gatk-haplotype_Indels_fn"": true,
        ""NA12878-chr20_platypus_SNPs_fn"": true,
        ""NA12878-chr20_gatk-haplotype_Indels_fp"": true,
        ""NA12878-chr20_samtools_SNPs_fn"": true,
        ""NA12878-chr20_platypus_Indels_fn"": true,
        ""NA12878-chr20_gatk-haplotype_SNPs_tp"": true,
        ""NA12878-chr20_samtools_SNPs_fp"": true,
        ""NA12878-chr20_platypus_Indels_fp"": true,
        ""NA12878-chr20_platypus_SNPs_fp"": true,
        ""NA12878-chr20_gatk-haplotype_SNPs_fp"": true,
        ""NA12878-chr20_platypus_Indels_tp"": true,
        ""NA12878-chr20_platypus_SNPs_tp"": true,
        ""NA12878-chr20_freebayes_Indels_tp"": true,
        ""NA12878-chr20_freebayes_SNPs_tp"": true,
        ""NA12878-chr20_gatk-haplotype_SNPs_fn"": true,
        ""NA12878-chr20_samtools_SNPs_tp"": true,
        ""NA12878-chr20_samtools_Indels_fp"": true,
        ""NA12878-chr20_freebayes_Indels_fp"": true,
        ""NA12878-chr20_freebayes_SNPs_fp"": true,
        ""NA12878-chr20_freebayes_SNPs_fn"": true,
        ""NA12878-chr20_freebayes_Indels_fn"": true,
        ""NA12878-chr20_samtools_Indels_fn"": true
    }
}
```
### Submitting results
- Copy the `synapseConfig` file to the current working directory.
- Update `bcbio_NA12878-chr20_submit.json` with correct
`team_name` - the name of your team in plain text format (e.g., ""GA4GH-Sage Contenders"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
`file` - paths to output files
Run the tool
```shell
$BUNNY dockstore-tool-synapse-submit.cwl bcbio_NA12878-chr20_submit.json
```
---
",9622790
bcbio_NA12878-chr20,9622791_report.md,"## bcbio NA12878 chr20 variant calling and validation

### Workflow description

```YAML
contributor: ""Brad Chapman""
workflow_handle: ""bcbio_NA12878-chr20""
input_handle: ""NA12878 chr20""
```
The following description is provided by the workflow author:
> A [bcbio](http://bcb.io/) workflow running a single chromosome subset of the [Genome in a Bottle NA12878 sample](http://jimb.stanford.edu/giab) from [Illumina's Platinum Genomes](https://www.illumina.com/platinumgenomes.html). It runs alignment, variant calling with multiple methods ([GATK4 HaplotypeCaller](http://gatkforums.broadinstitute.org/gatk/categories/gatk-4-alpha), [FreeBayes](https://github.com/ekg/freebayes), [Platypus](https://github.com/andyrimmer/Platypus),[samtools](https://github.com/samtools/samtools)) and quality control, validating outputs against reference standards. It uses 8 cores and 4Gb/memory per core, using 50Gb of disk space (35Gb for inputs, 15Gb for analyses). On an AWS m4.2xlarge instance with 8 cores and 32Gb of memory, it runs in 4 hours.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Bogdan Gavrilovic"" # your name here
institution: ""Seven Bridges Genomics"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""SevenBridges"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""latest"" # indicate executor version used
docker_version: ""1.12.6"" # from `docker --version`
environment: ""EC2"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""32"" # indicate number of cores in environment
env_memory: ""60Gb"" # indicate available RAM in environment
env_disk: ""700Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

#####1. [Install rabix](https://github.com/rabix/bunny#installing) on your machine and set environment variable $BUNNY. You need docker and java installed to run rabix:
```shell
wget https://github.com/rabix/bunny/releases/download/v1.0.0/rabix-1.0.0.tar.gz -O rabix-1.0.0.tar.gz && tar -xvf rabix-1.0.0.tar.gz
export BUNNY=$PWD/rabix-cli-1.0.0/rabix
```
#####2. If you've not already retrieved the CWL and data with synapse-get, you can use the [Synapse python client](https://github.com/Sage-Bionetworks/synapsePythonClient#installation):
```shell
pip install synapseclient
synapse get -r syn9725771 # bcbio workflow, tools and input files
synapse get syn9732885   # dockstore-tool-synapse-submit.cwl
```

#### Running on the [Cancer Genomics Cloud](https://cgc.sbgenomics.com/) 

#####3. Log in to the [Cancer Genomics Cloud](https://cgc.sbgenomics.com/) and [create a project](https://docs.cancergenomicscloud.org/docs/create-a-project) 
- Academic Users can create a free account on the Cancer Genomics Cloud (CGC). New users receive \$300 in cloud computing credits that you can apply to this challenge, and your own research. Additionally, users that leave feedback on their experience receive an additional \$1000 in cloud compute credits.
- Commercial users of the Seven Bridges Platform that wish to participate in the DREAM challenge can also create an account on the CGC to participate in this academic exercise and receive free credits to run the challenge workflows. Alternatively, commercial users are free to run DREAM challenge workflows in their commercial platform accounts, but should realize that they will incur cloud compute charges to do so. 
&nbsp;
#####4. Installing the workflow on the platform can be done using:  
**a)** [Rabix Composer app for CWL tool editing](http://rabix.io/) or   
**b)** a [CWL CommandLineTool](https://github.com/bogdang989/Import-CWL-to-SevenBridges) for importing CWL workflows to the Seven Bridges platform.  

#####4a. Rabix Composer
If you’re interested in trying out Seven Bridges’ new integrated development environment for creating CWL descriptions of tools and workflows, you can use the [Rabix Composer](http://rabix.io/) to upload the workflow to the platform. 
Use Rabix Composer to add the workflow to the platform:  
- [Install Rabix Composer](http://docs.rabix.io/rabix-composer-installation)
- [Configure Composer](http://docs.rabix.io/rabix-composer-configuration) to connect to the CGC or Seven Bridges platform
- [Add the project](http://docs.rabix.io/rabix-composer-configuration) you created for the DREAM challenge to the workspace
- [Add the local directory](http://docs.rabix.io/rabix-composer-configuration) containing the workflow to the workspace
- [Open](http://docs.rabix.io/rabix-composer-basics) the workflow with Composer
- [Save the workflow to the Platform project](http://docs.rabix.io/rabix-composer-basics) you added to the workspace
- Log into the Platform and [upload the input files](https://docs.cancergenomicscloud.org/docs/upload-to-the-cgc) to the project. 
- Run the task

> You can [upload the files manually to the platform](https://docs.cancergenomicscloud.org/docs/upload-to-the-cgc) by using either CGC Uploader app, command-line uploader, Python API or some other available upload method... All of the available methods are described in [the documentation](https://docs.cancergenomicscloud.org/docs/upload-to-the-cgc) 

#####4b. CWLtoSBG import tool
Download the CWL importing tool and **place it in the same directory with the CWL workflow** that should be installed on the platform. You can download the tool from [github](https://github.com/bogdang989/Import-CWL-to-SevenBridges) manually or from command-line by typing:
```shell
git clone https://github.com/bogdang989/Import-CWL-to-SevenBridges
```
Modify the `cwl_to_sbg-inputs.yaml` to include:

- Paths to `main-NA12878-platinum-chr20.cwl` and `main-NA12878-platinum-chr20-samples.json`
- Id of your project on the platform (From project URL, in format *user-name/project-name* )
For example if project URL is https://cgc.sbgenomics.com/u/bogdang/demo-project; project_id is `bogdang/demo-project`
- Your [authentication token](http://docs.sevenbridges.com/docs/get-your-authentication-token)
- Adequate [EC2 instance type](http://www.ec2instances.info/)
&nbsp;
After modifying `cwl_to_sbg-inputs.yaml` with your information, import the workflow to the platform by running
```shell
$BUNNY cwl_to_sbg.cwl cwl_to_sbg-inputs.yaml
```
This will install the workflow and all required apps on the platform. All the files that are required for the task execution are uploaded if they are not uploaded previously. Template draft task is created. If `run_task` is set to `true` the task execution will start on the platform.
You can now open `task` page on the platform project to see task execution details.

### Validating results
[Download the output files](https://docs.cancergenomicscloud.org/docs/download-results) to your local machine.

Modify the `bcbio_NA12878-chr20_checker.json` to include the path to the requested output file and run checker tool
```shell
$BUNNY bcbio_NA12878-chr20_checker.cwl bcbio_NA12878-chr20_checker.json
```
Check results
```shell
cat ./path/to/results.json
``` 
```json
{
    ""Overall"": true,
    ""Steps"": {
        ""NA12878-chr20_gatk-haplotype_Indels_tp"": true,
        ""NA12878-chr20_samtools_Indels_tp"": true,
        ""NA12878-chr20_gatk-haplotype_Indels_fn"": true,
        ""NA12878-chr20_platypus_SNPs_fn"": true,
        ""NA12878-chr20_gatk-haplotype_Indels_fp"": true,
        ""NA12878-chr20_samtools_SNPs_fn"": true,
        ""NA12878-chr20_platypus_Indels_fn"": true,
        ""NA12878-chr20_gatk-haplotype_SNPs_tp"": true,
        ""NA12878-chr20_samtools_SNPs_fp"": true,
        ""NA12878-chr20_platypus_Indels_fp"": true,
        ""NA12878-chr20_platypus_SNPs_fp"": true,
        ""NA12878-chr20_gatk-haplotype_SNPs_fp"": true,
        ""NA12878-chr20_platypus_Indels_tp"": true,
        ""NA12878-chr20_platypus_SNPs_tp"": true,
        ""NA12878-chr20_freebayes_Indels_tp"": true,
        ""NA12878-chr20_freebayes_SNPs_tp"": true,
        ""NA12878-chr20_gatk-haplotype_SNPs_fn"": true,
        ""NA12878-chr20_samtools_SNPs_tp"": true,
        ""NA12878-chr20_samtools_Indels_fp"": true,
        ""NA12878-chr20_freebayes_Indels_fp"": true,
        ""NA12878-chr20_freebayes_SNPs_fp"": true,
        ""NA12878-chr20_freebayes_SNPs_fn"": true,
        ""NA12878-chr20_freebayes_Indels_fn"": true,
        ""NA12878-chr20_samtools_Indels_fn"": true
    }
}
```
### Submitting results
- Copy the synapseConfig file to the current working directory.
- Update `bcbio_NA12878-chr20_submit.json` with correct
`team_name` - the name of your team in plain text format (e.g., ""GA4GH-Sage Contenders"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
'file' - paths to output files
Run the tool
```shell
$BUNNY dockstore-tool-synapse-submit.cwl bcbio_NA12878-chr20_submit.json
```

---",9622791
bcbio_NA12878-chr20,9623071_report.md,"## bcbio NA12878 chr20 variant calling and validation

### Workflow description

```YAML
contributor: ""Brad Chapman""
workflow_handle: ""bcbio_NA12878-chr20""
input_handle: ""NA12878 chr20""
```
The following description is provided by the workflow author:
> A [bcbio](http://bcb.io/) workflow running a single chromosome subset of the [Genome in a Bottle NA12878 sample](http://jimb.stanford.edu/giab) from [Illumina's Platinum Genomes](https://www.illumina.com/platinumgenomes.html). It runs alignment, variant calling with multiple methods ([GATK4 HaplotypeCaller](http://gatkforums.broadinstitute.org/gatk/categories/gatk-4-alpha), [FreeBayes](https://github.com/ekg/freebayes), [Platypus](https://github.com/andyrimmer/Platypus),[samtools](https://github.com/samtools/samtools)) and quality control, validating outputs against reference standards. It uses 8 cores and 4Gb/memory per core, using 50Gb of disk space (35Gb for inputs, 15Gb for analyses). On an AWS m4.2xlarge instance with 8 cores and 32Gb of memory, it runs in 4 hours.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Lon Blauvelt"" # your name here
institution: ""UCSC"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170217172322"" # indicate executor version used
docker_version: ""17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""EC2"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""16Gb"" # indicate available RAM in environment
env_disk: ""elastic"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""EC2"" 
env_cpus_ex: ""32""
env_memory_ex: ""244Gb""
env_disk_ex: ""elastic""
```

### Steps

#### 1. Set up environment

##### EC2/EFS
I launched a single-node EC2 instance of type `r4.8xlarge` in `us-east-1f` (spot request) with the canonical Ubuntu 16.04 AMI (`ami-80861296`). I connected to the instance via SSH (user `ubuntu`) and installed the required nfs client for Amazon EFS:
```shell
sudo apt-get install nfs-common
```

I then mounted my EFS volume at `/efs`.
```shell
sudo mkdir /efs
sudo mount -t nfs4 -o nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2 fs-2067e169.efs.us-east-1.amazonaws.com:/ /efs
```

##### Docker
I installed Docker on the instance using the following commands:
```shell
sudo apt-get update &&
    sudo apt-get install -y \
        apt-transport-https \
        ca-certificates \
        curl \
        software-properties-common &&
    curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - &&
    sudo add-apt-repository \
        ""deb [arch=amd64] https://download.docker.com/linux/ubuntu \
        $(lsb_release -cs) \
        stable"" &&
    sudo apt-get update &&
    sudo apt-get install -y docker-ce
```

Next, I modified the Docker's default storage location to use a partition with more space available, creating the file `/etc/docker/daemon.json` with the following:
```shell
{
  ""debug"": true,
  ""graph"": ""/dev/docker-data""
}
```

Finally, I added `ubuntu` to the `docker` Linux group, exited the instance, and signed back in.

##### Anaconda/cwltool
I installed Anaconda (`miniconda`) for Python 2.7 under my EFS root directory (**note:** I think this makes `conda` operations a bit slower than usual...).
```shell
wget https://repo.continuum.io/miniconda/Miniconda2-latest-Linux-x86_64.sh -O miniconda.sh
bash miniconda.sh -b -p /efs/miniconda
export PATH=""/efs/miniconda/bin:$PATH""
```

I created and configured a virtual environment with `synapseclient` and `cwltool` as follows:
```shell
conda create -n syncwl
source activate syncwl
pip install synapseclient --no-cache-dir
pip install schema-salad==2.2.20170222151604 cwltool==1.0.20170217172322 --no-cache-dir
```

##### Workspace/config
I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir /efs/bcbio_NA12878-chr20
cd /efs/bcbio_NA12878-chr20
cp ~/.synapseConfig .
```

Within the working directory, I created a `tmp` folder to be used with `cwltool` in subsequent steps:
```shell
mkdir tmp
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **bcbio_NA12878-chr20** workflow:
```shell
synapse get syn9819444 # bcbio_NA12878-chr20_get.cwl.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `bcbio_NA12878-chr20_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict dockstore-tool-synapse-get.cwl bcbio_NA12878-chr20_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `transform.cwl` and parameterized by `transform.cwl.json`:
```
nohup cwltool --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20.cwl NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20-samples.json
```

The workflow took about 10 hours to complete (I think the parallelization might not have been handled correctly, possibly due to the older version of `cwltool` I was using).

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool bcbio_NA12878-chr20_checker.cwl bcbio_NA12878-chr20_checker.json
cat results.json 
```

#### 7. Submit workflow outputs

I modified the parameters in `bcbio_NA12878-chr20_submit.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""UCSC GA4GH-DREAM Challenge Team"",
    ""eval_id"": ""9605240"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""grading-summary-NA12878-chr20.csv""
        }
    ],
    ""parent_id"": ""syn10182019""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl bcbio_NA12878-chr20_submit.json
```
---",9623071
bcbio_NA12878-chr20,9623664_report.md,"## bcbio NA12878 chr20 variant calling and validation

### Workflow description

```YAML
contributor: ""Brad Chapman""
workflow_handle: ""bcbio_NA12878-chr20""
input_handle: ""NA12878 chr20""
```
The following description is provided by the workflow author:
> A [bcbio](http://bcb.io/) workflow running a single chromosome subset of the [Genome in a Bottle NA12878 sample](http://jimb.stanford.edu/giab) from [Illumina's Platinum Genomes](https://www.illumina.com/platinumgenomes.html). It runs alignment, variant calling with multiple methods ([GATK4 HaplotypeCaller](http://gatkforums.broadinstitute.org/gatk/categories/gatk-4-alpha), [FreeBayes](https://github.com/ekg/freebayes), [Platypus](https://github.com/andyrimmer/Platypus),[samtools](https://github.com/samtools/samtools)) and quality control, validating outputs against reference standards. It uses 8 cores and 4Gb/memory per core, using 50Gb of disk space (35Gb for inputs, 15Gb for analyses). On an AWS m4.2xlarge instance with 8 cores and 32Gb of memory, it runs in 4 hours.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Abraham Chavez"" # your name here
institution: ""UCSC"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170413194156"" # indicate executor version used
docker_version: ""..."" # from `docker --version`
environment: ""AWS"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""32"" # indicate number of cores in environment
env_memory: ""240Gb"" # indicate available RAM in environment
env_disk: ""200Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""EC2"" 
env_cpus_ex: ""32""
env_memory_ex: ""244Gb""
env_disk_ex: ""elastic""
```

### Steps

1. [Install bcbio-vm](https://github.com/chapmanb/bcbio-nextgen-vm#installation) which has wrapper scripts and ready to run distributions of several CWL enabled tools (cwltool, toil, bunny) and infrastructure (synapse):

        wget https://repo.continuum.io/miniconda/Miniconda2-latest-Linux-x86_64.sh
        bash Miniconda2-latest-Linux-x86_64.sh -b -p ~/install/bcbio-vm/anaconda
        ~/install/bcbio-vm/anaconda/bin/conda install --yes -c conda-forge -c bioconda bcbio-nextgen-vm
        export PATH=~/install/bcbio-vm/anaconda/bin:$PATH

2. If you've not already retrieved the CWL and data with synapse-get, you can use the [Synapse python client](https://github.com/Sage-Bionetworks/synapsePythonClient#installation):

        synapse get -r syn9725771

3. The [NA12878-chr20 directory on GitHub](https://github.com/bcbio/bcbio_validation_workflows/tree/master/NA12878-chr20) contains starter shell scripts to run this with different CWL-enabled tools: [cwltool](https://github.com/common-workflow-language/cwltool), [Toil](https://github.com/BD2KGenomics/toil) or [rabix bunny](https://github.com/rabix/bunny). It can either use a local bcbio installation or [bcbio Docker containers](https://github.com/bcbio/bcbio_docker). If you're using cwltool, we recommend using the version that ships with bcbio-vm (`cwltool==1.0.20170413194156`) and using a similar command line to [the example wrapper script](https://github.com/bcbio/bcbio_validation_workflows/blob/master/NA12878-chr20/run_cwltool.sh) that correctly sets temporary directories. The `--cachedir` argument for cwltool specifically appears to have an issue with this workflow so should be avoided.
---",9623664
bcbio_NA12878-chr20,9629638_report.md,"## bcbio NA12878 chr20 variant calling and validation

### Workflow description

```YAML
contributor: ""Brad Chapman""
workflow_handle: ""bcbio_NA12878-chr20""
input_handle: ""NA12878 chr20""
```
The following description is provided by the workflow author:
> A [bcbio](http://bcb.io/) workflow running a single chromosome subset of the [Genome in a Bottle NA12878 sample](http://jimb.stanford.edu/giab) from [Illumina's Platinum Genomes](https://www.illumina.com/platinumgenomes.html). It runs alignment, variant calling with multiple methods ([GATK4 HaplotypeCaller](http://gatkforums.broadinstitute.org/gatk/categories/gatk-4-alpha), [FreeBayes](https://github.com/ekg/freebayes), [Platypus](https://github.com/andyrimmer/Platypus),[samtools](https://github.com/samtools/samtools)) and quality control, validating outputs against reference standards. It uses 8 cores and 4Gb/memory per core, using 50Gb of disk space (35Gb for inputs, 15Gb for analyses). On an AWS m4.2xlarge instance with 8 cores and 32Gb of memory, it runs in 4 hours.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Gary Luu"" # your name here
institution: ""Dockstore - OICR"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-08-22"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""dockstore"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.2.7"" # indicate executor version used
docker_version: ""17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""4"" # indicate number of cores in environment
env_memory: ""32 GB"" # indicate available RAM in environment
env_disk: ""470 GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-19""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""EC2"" 
env_cpus_ex: ""32""
env_memory_ex: ""244Gb""
env_disk_ex: ""elastic""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessasry.

#### 1. Set up environment

On a personal desktop, I installed Docker, pip, cwltool, and the Dockstore command-line helper using a procedure similar to https://github.com/denis-yuen/2017-cloud-workflows-misc/blob/master/install-and-run-with-dockstore.md .  
However, I used my own modified dockstore CLI (which will be 1.2.7)

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir bcbio
cd bcbio
cp ~/.synapseConfig .
```
#### 2. Download required files

I downloaded bcbio_NA12878-chr20_get.cwl.json from the website. 


#### 3. Provision all workflow files

I used the synapse-get tool from Dockstore.
```shell
dockstore tool launch --entry quay.io/ga4gh-dream/dockstore-tool-synapse-get --json bcbio_NA12878-chr20_get.cwl.json
```

#### 4. Run main workflow

I used dockstore to launch the recently downloaded NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20.cwl  .  Note that --script was used to bypass the missing file that Dockstore was expecting to provision (but doesn't seem to be used by the workflow).
```shell
dockstore workflow launch --local-entry NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20.cwl --json NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20-samples.json --script
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `dockstore` to run the checker as follows:
```shell
dockstore tool launch --local-entry bcbio_NA12878-chr20_checker.cwl --json bcbio_NA12878-chr20_checker.json
cat results.json | grep overall
```

#### 6. Submit workflow outputs

I modified the parameters in `gdc_dnaseq_transform_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""Dockstore Team"",
    ""eval_id"": ""9605240"",
    ""file"": [
        {
            ""class"": ""File"",
            ""path"": ""grading-summary-NA12878-chr20.csv""
        }
    ],
    ""parent_id"": ""syn9877725""
}
```

Finally, I submitted outputs using dockstore-tool-synapse-submit`:
```shell
dockstore tool launch --entry quay.io/ga4gh-dream/dockstore-tool-synapse-submit --json bcbio_NA12878-chr20_submit.json
```

---",9629638
bcbio_NA12878-chr20,9633509_report.md,"## bcbio NA12878 chr20 variant calling and validation

### Workflow description

```YAML
contributor: ""Brad Chapman""
workflow_handle: ""bcbio_NA12878-chr20""
input_handle: ""NA12878 chr20""
```
The following description is provided by the workflow author:
> A [bcbio](http://bcb.io/) workflow running a single chromosome subset of the [Genome in a Bottle NA12878 sample](http://jimb.stanford.edu/giab) from [Illumina's Platinum Genomes](https://www.illumina.com/platinumgenomes.html). It runs alignment, variant calling with multiple methods ([GATK4 HaplotypeCaller](http://gatkforums.broadinstitute.org/gatk/categories/gatk-4-alpha), [FreeBayes](https://github.com/ekg/freebayes), [Platypus](https://github.com/andyrimmer/Platypus),[samtools](https://github.com/samtools/samtools)) and quality control, validating outputs against reference standards. It uses 8 cores and 4Gb/memory per core, using 50Gb of disk space (35Gb for inputs, 15Gb for analyses). On an AWS m4.2xlarge instance with 8 cores and 32Gb of memory, it runs in 4 hours.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-08-29**: Replace dots with underscores in variable names, providing compatibility with Rabix Bunny and Seven Bridges.
+ **2017-08-25**: Improve CWL to avoid unused inputs, better specify secondary files, and provide compatibility with other workflow systems. Thanks to DNAnexus and SevenBridges for compatibility work.
+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Lon Blauvelt"" # your name here
institution: ""UCSC"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-09"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""Toil"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""Toil 3.11.0a1"" # indicate executor version used
docker_version: ""Docker version 17.06.1-ce, build 874a737"" # from `docker -v`
environment: ""EC2 t2.2xlarge"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""32"" # indicate available RAM in environment
env_disk: ""200Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-19""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""EC2"" 
env_cpus_ex: ""32""
env_memory_ex: ""244Gb""
env_disk_ex: ""elastic""
```

### Steps

#### 1. Set up environment

*I launched an EC2 instance of type `t2.2xlarge` with one node, mounted a 200 Gb EFS volume.*

I used the following to update the instance:

```shell
sudo apt-get update
sudo apt-get -y upgrade
sudo apt-get -y dist-upgrade
```

Install docker:

```shell
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
sudo add-apt-repository ""deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable""
sudo apt-get update
apt-cache policy docker-ce
sudo apt-get install -y docker-ce
sudo usermod -aG docker ${USER}
sudo su - ${USER}
```

Install pip, a virtualenv, the dev version of toil, and the requisite pip installs (cwltool, schema-salad, avro, synapse, and html5lib):

```shell
sudo apt install -y python-pip
sudo pip install --upgrade pip
sudo pip install virtualenv
git clone https://github.com/BD2KGenomics/toil.git
cd toil
virtualenv --python /usr/bin/python2 dev
source /home/ubuntu/toil/dev/bin/activate
make prepare
make develop
pip install cwl-runner schema-salad==2.6.20170630075932 avro==1.8.1 cwltool==1.0.20170822192924 ruamel.yaml==0.14.12 --no-cache-dir
pip install synapseclient --no-cache-dir
pip install html5lib cwltest
cd ..
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:

```shell
mkdir syn
cd syn
nano syn-login.synapseConfig
[PASTE] username & password
cd ..
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **bcbio_NA12878-chr20** workflow, and then modify the get file:
```shell
synapse get -r syn9689286
[PASTE] username & password
synapse get -r syn9689284
[PASTE] username & password

nano bcbio_NA12878-chr20_get.cwl.json
[PASTE] /home/ubuntu/syn/syn-login.synapseConfig
```

#### 4. Provision all workflow files

I used `cwltoil` to run `dockstore-tool-synapse-get.cwl` with parameters in `bcbio_NA12878-chr20.cwl.json` to download input data, known good outputs, and any other CWL or JSON files required for running the workflow and submitting results.

```shell
cwltoil dockstore-tool-synapse-get.cwl bcbio_NA12878-chr20_get.cwl.json
```

#### 5. Run main workflow

I again used `cwltoil` to run the workflow (which is the 'NA12878-platinum-chr20-workflow' folder), as defined in `main-NA12878-platinum-chr20.cwl` and parameterized by `main-NA12878-platinum-chr20-samples.json`:
```
cd NA12878-platinum-chr20-workflow
cwltoil main-NA12878-platinum-chr20.cwl main-NA12878-platinum-chr20-samples.json
cd ..
```

#### 6. Run workflow checker tool

To verify workflow results before submission, I used `cwltoil` to run the checker after moving the output into the working directory as follows:
```shell
mv NA12878-platinum-chr20-workflow/grading-summary-NA12878-chr20.csv grading-summary-NA12878-chr20.csv
cwltoil bcbio_NA12878-chr20_checker.cwl bcbio_NA12878-chr20_checker.cwl.json
```

#### 7. Submit workflow outputs

I modified the parameters in `bcbio_NA12878-chr20_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": ""/home/ubuntu/syn/syn-login.synapseConfig""
    },
    ""team_name"": ""UCSC GA4GH-DREAM Challenge Team"",
    ""eval_id"": ""9604596"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""123e4567-e89b-12d3-a456-426655440000.db""
        }
    ],
    ""parent_id"": ""syn10675259""
}
```

Finally, I submitted outputs using `cwltoil` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltoil dockstore-tool-synapse-submit.cwl bcbio_NA12878-chr20_submit.cwl.json
```",9633509
bcbio_NA12878-chr20,9633527_report.md,"## bcbio NA12878 chr20 variant calling and validation

### Workflow description

```YAML
contributor: ""Brad Chapman""
workflow_handle: ""bcbio_NA12878-chr20""
input_handle: ""NA12878 chr20""
```
The following description is provided by the workflow author:
> A [bcbio](http://bcb.io/) workflow running a single chromosome subset of the [Genome in a Bottle NA12878 sample](http://jimb.stanford.edu/giab) from [Illumina's Platinum Genomes](https://www.illumina.com/platinumgenomes.html). It runs alignment, variant calling with multiple methods ([GATK4 HaplotypeCaller](http://gatkforums.broadinstitute.org/gatk/categories/gatk-4-alpha), [FreeBayes](https://github.com/ekg/freebayes), [Platypus](https://github.com/andyrimmer/Platypus),[samtools](https://github.com/samtools/samtools)) and quality control, validating outputs against reference standards. It uses 8 cores and 4Gb/memory per core, using 50Gb of disk space (35Gb for inputs, 15Gb for analyses). On an AWS m4.2xlarge instance with 8 cores and 32Gb of memory, it runs in 4 hours.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-08-29**: Replace dots with underscores in variable names, providing compatibility with Rabix Bunny and Seven Bridges.
+ **2017-08-25**: Improve CWL to avoid unused inputs, better specify secondary files, and provide compatibility with other workflow systems. Thanks to DNAnexus and SevenBridges for compatibility work.
+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Byunggil Yoo""
institution: ""Children's Mercy Kansas City""
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-05"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170817131858"" # indicate executor version used
docker_version: ""17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""48"" # indicate number of cores in environment
env_memory: ""512GB"" # indicate available RAM in environment
env_disk: ""368TB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

#### 1. Set up environment

On a node (CentOS 7.2.1511) of a local cluster with Docker (17.06.0-ce) and Anaconda installed, I created and configured a virtual environment using the following YAML file:

```
channels:
  - bioconda
  - conda-forge
  - anaconda
  - r
dependencies:
  - cwltool=1.0.20170817131858
  - synapseclient
```

I created a working directory for the current workflow and created a copy of my Synapse credentials (~/.synapseConfig) in that folder:

```shell
mkdir bcbio_NA12878-chr20
cd bcbio_NA12878-chr20
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **bcbio_NA12878-chr20** workflow:
```shell
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
synapse get syn9819444 # bcbio_NA12878-chr20_get.cwl.json
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `bcbio_NA12878-chr20_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --outdir bcbio_NA12878-chr20 --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ \
        --non-strict dockstore-tool-synapse-get.cwl bcbio_NA12878-chr20_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `main-NA12878-platinum-chr20.cwl` and parameterized by `main-NA12878-platinum-chr20-samples.json`:
```shell
cwltool --basedir bcbio_NA12878-chr20/ --outdir bcbio_NA12878-chr20/ \
    --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
    bcbio_NA12878-chr20/NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20.cwl \
    bcbio_NA12878-chr20/NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20-samples.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool --basedir bcbio_NA12878-chr20/ --outdir bcbio_NA12878-chr20/ \
        --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
        bcbio_NA12878-chr20/bcbio_NA12878-chr20_checker.cwl \
        bcbio_NA12878-chr20/bcbio_NA12878-chr20_checker.json
```

#### 6. Submit workflow outputs

I modified the parameters in `bcbio_NA12878-chr20_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""Childrens Mercy GA4GH-DREAM Challenge Team"",
    ""eval_id"": ""9605240"",
    ""file"": [
        {
            ""class"": ""File"",
            ""path"": ""grading-summary-NA12878-chr20.csv""
        }
    ],
    ""parent_id"": ""syn10290419""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --basedir bcbio_NA12878-chr20/ --outdir bcbio_NA12878-chr20/ \
        --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
        dockstore-tool-synapse-submit.cwl bcbio_NA12878-chr20/bcbio_NA12878-chr20_submit.cwl.json
```

---",9633527
bcbio_NA12878-chr20,9635417_report.md,"## bcbio NA12878 chr20 variant calling and validation

### Workflow description

```YAML
contributor: ""Brad Chapman""
workflow_handle: ""bcbio_NA12878-chr20""
input_handle: ""NA12878 chr20""
```
The following description is provided by the workflow author:
> A [bcbio](http://bcb.io/) workflow running a single chromosome subset of the [Genome in a Bottle NA12878 sample](http://jimb.stanford.edu/giab) from [Illumina's Platinum Genomes](https://www.illumina.com/platinumgenomes.html). It runs alignment, variant calling with multiple methods ([GATK4 HaplotypeCaller](http://gatkforums.broadinstitute.org/gatk/categories/gatk-4-alpha), [FreeBayes](https://github.com/ekg/freebayes), [Platypus](https://github.com/andyrimmer/Platypus),[samtools](https://github.com/samtools/samtools)) and quality control, validating outputs against reference standards. It uses 8 cores and 4Gb/memory per core, using 50Gb of disk space (35Gb for inputs, 15Gb for analyses). On an AWS m4.2xlarge instance with 8 cores and 32Gb of memory, it runs in 4 hours.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-08-29**: Replace dots with underscores in variable names, providing compatibility with Rabix Bunny and Seven Bridges.
+ **2017-08-25**: Improve CWL to avoid unused inputs, better specify secondary files, and provide compatibility with other workflow systems. Thanks to DNAnexus and SevenBridges for compatibility work.
+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Jeff Johnston"" # your name here
institution: ""Children's Mercy"" # your institution here
```

#### Submission overview

Provide high level summary information for workflow execution in the fields below.

```YAML
date_accessed: ""2017-09-15"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170817131858"" # indicate executor version used
docker_version: ""17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""48"" # indicate number of cores in environment
env_memory: ""512GB"" # indicate available RAM in environment
env_disk: ""368TB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

#### 1. Setup

This workflow was run on CentOS Linux release 7.2.1511. Docker and Conda 4.3.25 were installed. A conda environment was built using the following conda YAML file:

```yaml
channels:
  - bioconda
  - conda-forge
  - anaconda
  - r
dependencies:
  - cwltool=1.0.20170817131858
  - synapseclient
```

The Synapse client was configured by editing `~/.synapseConfig`.

##### 2. Download

The following commands were run within the conda environment:

```shell
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
synapse get syn9819444 # bcbio_NA12878-chr20_get.cwl.json
cwltool --outdir bcbio_NA12878-chr20 --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ \
        --non-strict dockstore-tool-synapse-get.cwl bcbio_NA12878-chr20_get.cwl.json
cp ~/.synapseConfig bcbio_NA12878-chr20
```

##### 3. Run

Next, the workflow was executed in the conda environment.

```shell
cwltool --basedir bcbio_NA12878-chr20/ --outdir bcbio_NA12878-chr20/ \
    --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
    bcbio_NA12878-chr20/NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20.cwl \
    bcbio_NA12878-chr20/NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20-samples.json
```

##### 4. Validate

After running, the workflow results were validated:

```shell
cwltool --basedir bcbio_NA12878-chr20/ --outdir bcbio_NA12878-chr20/ \
        --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
        bcbio_NA12878-chr20/bcbio_NA12878-chr20_checker.cwl \
        bcbio_NA12878-chr20/bcbio_NA12878-chr20_checker.json
```

##### 5. Submit

`bcbio_NA12878-chr20_submit.json` was modified for submission:

```yaml
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""Childrens Mercy GA4GH-DREAM Challenge Team"",
    ""eval_id"": ""9605240"",
    ""file"": [
        {
            ""class"": ""File"",
            ""path"": ""grading-summary-NA12878-chr20.csv""
        }
    ],
    ""parent_id"": ""syn10290419""
}
```

Finally, results were submitted:

```shell
cwltool --basedir bcbio_NA12878-chr20/ --outdir bcbio_NA12878-chr20/ \
        --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
        dockstore-tool-synapse-submit.cwl bcbio_NA12878-chr20/bcbio_NA12878-chr20_submit.cwl.json
```

---
",9635417
bcbio_NA12878-chr20,9636600_report.md,"## bcbio NA12878 chr20 variant calling and validation

### Workflow description

```YAML
contributor: ""Brad Chapman""
workflow_handle: ""bcbio_NA12878-chr20""
input_handle: ""NA12878 chr20""
```
The following description is provided by the workflow author:
> A [bcbio](http://bcb.io/) workflow running a single chromosome subset of the [Genome in a Bottle NA12878 sample](http://jimb.stanford.edu/giab) from [Illumina's Platinum Genomes](https://www.illumina.com/platinumgenomes.html). It runs alignment, variant calling with multiple methods ([GATK4 HaplotypeCaller](http://gatkforums.broadinstitute.org/gatk/categories/gatk-4-alpha), [FreeBayes](https://github.com/ekg/freebayes), [Platypus](https://github.com/andyrimmer/Platypus),[samtools](https://github.com/samtools/samtools)) and quality control, validating outputs against reference standards. It uses 8 cores and 4Gb/memory per core, using 50Gb of disk space (35Gb for inputs, 15Gb for analyses). On an AWS m4.2xlarge instance with 8 cores and 32Gb of memory, it runs in 4 hours.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Denis Yuen"" # your name here
institution: ""Dockstore - OICR"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-08-22"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""dockstore 1.2.10"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.2.10"" # indicate executor version used
docker_version: ""17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""4"" # indicate number of cores in environment
env_memory: ""32 GB"" # indicate available RAM in environment
env_disk: ""470 GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-19""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""EC2"" 
env_cpus_ex: ""32""
env_memory_ex: ""244Gb""
env_disk_ex: ""elastic""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessasry.

#### 1. Set up environment

On a personal desktop, I installed Docker, pip, cwltool, and the Dockstore command-line helper using a procedure similar to https://github.com/denis-yuen/2017-cloud-workflows-misc/blob/master/install-and-run-with-dockstore.md .  
However, I used my own modified dockstore CLI (which will be 1.2.7)

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir bcbio
cd bcbio
cp ~/.synapseConfig .
```
#### 2. Download required files

I downloaded bcbio_NA12878-chr20_get.cwl.json from the website. 


#### 3. Provision all workflow files

I used the synapse-get tool from Dockstore.
```shell
dockstore tool launch --entry quay.io/ga4gh-dream/dockstore-tool-synapse-get --json bcbio_NA12878-chr20_get.cwl.json
```

#### 4. Run main workflow

I used dockstore to launch the recently downloaded NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20.cwl  .  Note that --script was used to bypass the missing file that Dockstore was expecting to provision (but doesn't seem to be used by the workflow).
```shell
dockstore workflow launch --local-entry NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20.cwl --json NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20-samples.json --script
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `dockstore` to run the checker as follows:
```shell
dockstore tool launch --local-entry bcbio_NA12878-chr20_checker.cwl --json bcbio_NA12878-chr20_checker.json
cat results.json | grep overall
```

#### 6. Submit workflow outputs

I modified the parameters in `gdc_dnaseq_transform_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""Dockstore Team"",
    ""eval_id"": ""9605240"",
    ""file"": [
        {
            ""class"": ""File"",
            ""path"": ""grading-summary-NA12878-chr20.csv""
        }
    ],
    ""parent_id"": ""syn9877725""
}
```

Finally, I submitted outputs using dockstore-tool-synapse-submit`:
```shell
dockstore tool launch --entry quay.io/ga4gh-dream/dockstore-tool-synapse-submit --json bcbio_NA12878-chr20_submit.json
```

---",9636600
bcbio_NA12878-chr20,9636914_report.md,"## bcbio NA12878 chr20 variant calling and validation

### Workflow description

```YAML
contributor: ""Brad Chapman""
workflow_handle: ""bcbio_NA12878-chr20""
input_handle: ""NA12878 chr20""
```
The following description is provided by the workflow author:
> A [bcbio](http://bcb.io/) workflow running a single chromosome subset of the [Genome in a Bottle NA12878 sample](http://jimb.stanford.edu/giab) from [Illumina's Platinum Genomes](https://www.illumina.com/platinumgenomes.html). It runs alignment, variant calling with multiple methods ([GATK4 HaplotypeCaller](http://gatkforums.broadinstitute.org/gatk/categories/gatk-4-alpha), [FreeBayes](https://github.com/ekg/freebayes), [Platypus](https://github.com/andyrimmer/Platypus),[samtools](https://github.com/samtools/samtools)) and quality control, validating outputs against reference standards. It uses 8 cores and 4Gb/memory per core, using 50Gb of disk space (35Gb for inputs, 15Gb for analyses). On an AWS m4.2xlarge instance with 8 cores and 32Gb of memory, it runs in 4 hours.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-08-29**: Replace dots with underscores in variable names, providing compatibility with Rabix Bunny and Seven Bridges.
+ **2017-08-25**: Improve CWL to avoid unused inputs, better specify secondary files, and provide compatibility with other workflow systems. Thanks to DNAnexus and SevenBridges for compatibility work.
+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Vipin T. Sreedharan""
institution: ""ETH Zürich, NEXUS Personalized Health Technologies""
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-20"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170828135420"" # indicate executor version used
docker_version: ""1.12.6"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""32Gb"" # indicate available RAM in environment
env_disk: ""140Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

#### 1. Set up environment

At our institute, on a compute machine called `wfexec` with Red Hat Enterprise Linux Server release 7.4 (Maipo), installed Docker. Created a group named ""docker"" since it was preferred to use Docker as a non-root user on this machine. The instance has a non-root user called `wfrunner`. Next added the non-root user `wfrunner` to the ""docker"" group. Then started the docker engine and all the below commands were executed using root user privileges [sudo]:
```shell
yum install docker
groupadd docker 
usermod -aG docker wfrunner  
systemctl start docker 
```
&nbsp;

As a non-root user on `wfexec` machine, installed Anaconda and cwltool to the home path of user `wfrunner`:
```shell
su - wfrunner
wget https://repo.continuum.io/archive/Anaconda2-4.4.0-Linux-x86_64.sh
bash Anaconda2-4.4.0-Linux-x86_64.sh 
conda install virtualenv
virtualenv -p python2 /home/wfrunner/venv
source /home/wfrunner/venv/bin/activate
pip install cwltools
deactivate
```
&nbsp;

Created a utilities directory for storing the `synapse-get` and `synapse-submit` CWL tools. In the same folder, created a file with my Synapse credentials. 
```shell
mkdir -p /home/wfrunner/synapse_utils
cd /home/wfrunner/synapse_utils
wget -O dockstore-tool-synapse-get.cwl https://raw.githubusercontent.com/GA4GH-DREAM/dockstore-tool-synapse-get/master/Dockstore.cwl 
wget -O dockstore-tool-synapse-submit.cwl https://raw.githubusercontent.com/GA4GH-DREAM/dockstore-tool-synapse-submit/master/Dockstore.cwl
touch .synapse_config
vim .synapse_config
[WRITE] Synapse username & password
```

#### 2. Download required files

Downloaded data config file bcbio_NA12878-chr20_get.cwl.json from the website `https://www.synapse.org/#!Synapse:syn8507133/wiki/451410` for the **bcbio_NA12878-chr20** workflow. Created a directory for the storing the workflow associated data downloading JSON parameter file: 
```shell
mkdir -p /home/wfrunner/data_config_files
mv ~/bcbio_NA12878-chr20_get.cwl.json ~/data_config_files
cd /home/wfrunner/data_config_files
vim bcbio_NA12878-chr20_get.cwl.json
[PASTE] /home/wfrunner/synapse_utils/.synapse_config
```

#### 3. Provision all workflow files

Created a working directory for the current workflow. Used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `bcbio_NA12878-chr20_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
mkdir -p /home/wfrunner/bcbio_NA12878-chr20
cd /home/wfrunner/bcbio_NA12878-chr20
cwltool --tmpdir-prefix /home/wfrunner/tmp/ --tmp-outdir-prefix /home/wfrunner/tmp/ --debug --non-strict ~/synapse_utils/dockstore-tool-synapse-get.cwl ~/config_files/bcbio_NA12878-chr20_get.cwl.json
```

#### 4. Run main workflow

Again `cwltool` was used to run the workflow, as defined in `NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20.cwl` and parameterized by `NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20-samples.json `:
```shell
cd /home/wfrunner/bcbio_NA12878-chr20
cwltool --tmpdir-prefix /home/wfrunner/tmp/ --tmp-outdir-prefix /home/wfrunner/tmp/ --debug --non-strict NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20.cwl NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20-samples.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, used `cwltool` to run the checker as follows:
```shell
cd /home/wfrunner/bcbio_NA12878-chr20
cwltool --tmpdir-prefix /home/wfrunner/tmp/ --tmp-outdir-prefix /home/wfrunner/tmp/ --debug --non-strict bcbio_NA12878-chr20_checker.cwl bcbio_NA12878-chr20_checker.json
cat results.json | grep -i overall
[OUTPUT] ""Overall"": true,
```

#### 6. Submit workflow outputs

Modified the parameters in `bcbio_NA12878-chr20_submit.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": ""/home/wfrunner/synapse_utils/.synapse_config""
    },
    ""team_name"": """",
    ""eval_id"": ""9605240"",
    ""file"": [
        {
            ""class"": ""File"",
            ""path"": ""grading-summary-NA12878-chr20.csv""
        }
    ],
    ""parent_id"": ""syn10888442""
}
```
&nbsp;

Finally, submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cd /home/wfrunner/bcbio_NA12878-chr20
cwltool --tmpdir-prefix /home/wfrunner/tmp/ --tmp-outdir-prefix /home/wfrunner/tmp/ --debug --non-strict ~/synapse_utils/dockstore-tool-synapse-submit.cwl bcbio_NA12878-chr20_submit.json
```
---",9636914
bcbio_NA12878-chr20,9638042_report.md,"## bcbio NA12878 chr20 variant calling and validation

### Workflow description

```YAML
contributor: ""Brad Chapman""
workflow_handle: ""bcbio_NA12878-chr20""
input_handle: ""NA12878 chr20""
```
The following description is provided by the workflow author:
> A [bcbio](http://bcb.io/) workflow running a single chromosome subset of the [Genome in a Bottle NA12878 sample](http://jimb.stanford.edu/giab) from [Illumina's Platinum Genomes](https://www.illumina.com/platinumgenomes.html). It runs alignment, variant calling with multiple methods ([GATK4 HaplotypeCaller](http://gatkforums.broadinstitute.org/gatk/categories/gatk-4-alpha), [FreeBayes](https://github.com/ekg/freebayes), [Platypus](https://github.com/andyrimmer/Platypus),[samtools](https://github.com/samtools/samtools)) and quality control, validating outputs against reference standards. It uses 8 cores and 4Gb/memory per core, using 50Gb of disk space (35Gb for inputs, 15Gb for analyses). On an AWS m4.2xlarge instance with 8 cores and 32Gb of memory, it runs in 4 hours.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-08-29**: Replace dots with underscores in variable names, providing compatibility with Rabix Bunny and Seven Bridges.
+ **2017-08-25**: Improve CWL to avoid unused inputs, better specify secondary files, and provide compatibility with other workflow systems. Thanks to DNAnexus and SevenBridges for compatibility work.
+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Vipin T. Sreedharan"" # your name here
institution: ""ETH Zürich, NEXUS Personalized Health Technologies"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

```YAML
date_accessed: ""2017-09-26"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""Toil"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""cwltoil 3.11.0"" # indicate executor version used
docker_version: ""1.12.6, build c4618fb"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""32Gb"" # indicate available RAM in environment
env_disk: ""140Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```


### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

At our institute, on a compute machine called `wfexec` with Red Hat Enterprise Linux Server release 7.4 (Maipo), installed Docker. Created a group named ""docker"" since it was preferred to use Docker as a non-root user on this machine. The instance has a non-root user called `wfrunner`. Next added the non-root user `wfrunner` to the ""docker"" group. Then started the docker engine and all the below commands were executed using root user privileges [sudo]:
```shell
yum install docker
groupadd docker 
usermod -aG docker wfrunner  
systemctl start docker 
```

As a non-root user `wfrunner` on `wfexec` machine, installed Anaconda and Toil to the home path:
```shell
su - wfrunner
wget https://repo.continuum.io/archive/Anaconda2-4.4.0-Linux-x86_64.sh
bash Anaconda2-4.4.0-Linux-x86_64.sh 
conda install virtualenv
virtualenv -p python2 /home/wfrunner/venv
source /home/wfrunner/venv/bin/activate
pip install toil
deactivate
export PATH=$PATH:/home/wfrunner/venv/bin/
```

Created a utilities directory for storing the `synapse-get` and `synapse-submit` CWL tools. In the same folder, created Synapse credential file `.synapse_config` and put there Synapse ID and password. 
```shell
mkdir -p /home/wfrunner/synapse_utils
cd /home/wfrunner/synapse_utils
wget -O dockstore-tool-synapse-get.cwl https://raw.githubusercontent.com/GA4GH-DREAM/dockstore-tool-synapse-get/master/Dockstore.cwl 
wget -O dockstore-tool-synapse-submit.cwl https://raw.githubusercontent.com/GA4GH-DREAM/dockstore-tool-synapse-submit/master/Dockstore.cwl
touch .synapse_config
vim .synapse_config
[WRITE] Synapse username & password
```

#### 2. Downloading required files

Downloaded data config file bcbio_NA12878-chr20_get.cwl.json from the website `https://www.synapse.org/#!Synapse:syn8507133/wiki/451410` for the **bcbio_NA12878-chr20** workflow. Created a directory for the storing the workflow associated data downloading JSON parameter file: 
```shell
mkdir -p /home/wfrunner/data_config_files
mv ~/bcbio_NA12878-chr20_get.cwl.json ~/data_config_files
cd /home/wfrunner/data_config_files
vim bcbio_NA12878-chr20_get.cwl.json
[PASTE] /home/wfrunner/synapse_utils/.synapse_config
```

#### 3. Provision all workflow files

Created a working directory for the current workflow. 
```shell
mkdir -p /home/wfrunner/bcbio_NA12878-chr20
cd /home/wfrunner/bcbio_NA12878-chr20
```

Used `cwltoil` to run `dockstore-tool-synapse-get.cwl` with parameters in `bcbio_NA12878-chr20_get.cwl.json` to download workflow input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltoil --workDir ~/tmp/ ~/synapse_utils/dockstore-tool-synapse-get.cwl ~/config_files/bcbio_NA12878-chr20_get.cwl.json
```
Wait until downloading is finished.

#### 4. Run main workflow

Used `cwltoil` to run the workflow, as defined in `NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20.cwl` and parameterized by `NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20-samples.json`:
```shell
cd /home/wfrunner/bcbio_NA12878-chr20
cwltoil --workDir ~/tmp/ NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20.cwl NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20-samples.json
```
Wait for the run to finish. 

#### 5. Run workflow checker tool

To verify the workflow results before submission, use `cwltoil` to run the checker as follows:
```shell
cd /home/wfrunner/bcbio_NA12878-chr20
cwltoil --workDir /home/wfrunner/tmp/ bcbio_NA12878-chr20_checker.cwl bcbio_NA12878-chr20_checker.json
```

Check results:
The JSON output in `results.json` indicates what outputs were checked against known-good outputs to verify that the run was successful:
```shell
cd /home/wfrunner/bcbio_NA12878-chr20
cat results.json | grep -i overall
[OUTPUT]
""Overall"": true,
``` 

#### 6. Submit workflow outputs

Modify the parameters in `bcbio_NA12878-chr20_submit.json` appropriately as follows: 
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": ""/home/wfrunner/synapse_utils/.synapse_config""
    },
    ""team_name"": """",
    ""eval_id"": ""9605240"",
    ""file"": [
        {
            ""class"": ""File"",
            ""path"": ""grading-summary-NA12878-chr20.csv""
        }
    ],
    ""parent_id"": ""syn10918733""
}
```

Finally, submitted outputs using the submission tool `dockstore-tool-synapse-submit.cwl`:
```shell
cd /home/wfrunner/bcbio_NA12878-chr20
cwltoil ~/synapse_utils/dockstore-tool-synapse-submit.cwl bcbio_NA12878-chr20_submit.json
```

---",9638042
bcbio_NA12878-chr20,9638363_report.md,"## bcbio NA12878 chr20 variant calling and validation

### Workflow description

```YAML
contributor: ""Brad Chapman""
workflow_handle: ""bcbio_NA12878-chr20""
input_handle: ""NA12878 chr20""
```
The following description is provided by the workflow author:
> A [bcbio](http://bcb.io/) workflow running a single chromosome subset of the [Genome in a Bottle NA12878 sample](http://jimb.stanford.edu/giab) from [Illumina's Platinum Genomes](https://www.illumina.com/platinumgenomes.html). It runs alignment, variant calling with multiple methods ([GATK4 HaplotypeCaller](http://gatkforums.broadinstitute.org/gatk/categories/gatk-4-alpha), [FreeBayes](https://github.com/ekg/freebayes), [Platypus](https://github.com/andyrimmer/Platypus),[samtools](https://github.com/samtools/samtools)) and quality control, validating outputs against reference standards. It uses 8 cores and 4Gb/memory per core, using 50Gb of disk space (35Gb for inputs, 15Gb for analyses). On an AWS m4.2xlarge instance with 8 cores and 32Gb of memory, it runs in 4 hours.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-08-29**: Replace dots with underscores in variable names, providing compatibility with Rabix Bunny and Seven Bridges.
+ **2017-08-25**: Improve CWL to avoid unused inputs, better specify secondary files, and provide compatibility with other workflow systems. Thanks to DNAnexus and SevenBridges for compatibility work.
+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Vipin T. Sreedharan"" # your name here
institution: ""ETH Zürich, NEXUS Personalized Health Technologies"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

```YAML
date_accessed: ""2017-09-28"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""Rabix"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""rabix 1.0.0"" # indicate executor version used
docker_version: ""1.12.6, build c4618fb"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""32Gb"" # indicate available RAM in environment
env_disk: ""140Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

At our institute, on a compute machine called `wfexec` with Red Hat Enterprise Linux Server release 7.4 (Maipo), installed Docker. Created a group named ""docker"" since it was preferred to use Docker as a non-root user on this machine. The instance has a non-root user called `wfrunner`. Next added the non-root user `wfrunner` to the ""docker"" group. Then started the docker engine and all the below commands were executed using root user privileges [sudo]:
```shell
yum install docker
groupadd docker 
usermod -aG docker wfrunner  
systemctl start docker 
# required for Rabix
yum install java-1.8.0-openjdk-devel.x86_64 
```

As a non-root user `wfrunner` on `wfexec` machine, installed Anaconda and Rabix to the home path:
```shell
su - wfrunner
wget https://repo.continuum.io/archive/Anaconda2-4.4.0-Linux-x86_64.sh
bash Anaconda2-4.4.0-Linux-x86_64.sh 
conda install virtualenv
virtualenv -p python2 /home/wfrunner/venv
source /home/wfrunner/venv/bin/activate
pip install cwltools
deactivate
conda install -c bioconda synapseclient
wget https://github.com/rabix/bunny/releases/download/v1.0.0/rabix-1.0.0.tar.gz -O rabix-1.0.0.tar.gz
tar -xzf rabix-1.0.0.tar.gz
export PATH=$PATH:/home/wfrunner/rabix-cli-1.0.0/
```

Created a utilities directory for storing the `synapse-get` and `synapse-submit` CWL tools. In the same folder, created Synapse credential file `.synapse_config` and put there Synapse ID and password. 
```shell
mkdir -p /home/wfrunner/synapse_utils
cd /home/wfrunner/synapse_utils
wget -O dockstore-tool-synapse-get.cwl https://raw.githubusercontent.com/GA4GH-DREAM/dockstore-tool-synapse-get/master/Dockstore.cwl 
wget -O dockstore-tool-synapse-submit.cwl https://raw.githubusercontent.com/GA4GH-DREAM/dockstore-tool-synapse-submit/master/Dockstore.cwl
touch .synapse_config
vim .synapse_config
[WRITE] Synapse username & password
```

#### 2. Provision all workflow files

Created a working directory for the current workflow. 
```shell
mkdir -p /home/wfrunner/bcbio_NA12878-chr20
cd /home/wfrunner/bcbio_NA12878-chr20
```
Used `synapseclient ` with targetId `syn9725771` to download workflow input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
synapse get -r syn9725771
[PASTE] username & password
```
Wait until downloading is finished.

#### 3. Run main workflow

Used `rabix` to run the workflow, as defined in `NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20.cwl` and parameterized by `NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20-samples.json`:
```shell
cd /home/wfrunner/bcbio_NA12878-chr20
rabix --tmpdir-prefix ~/tmp/ --tmp-outdir-prefix ~/tmp/ NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20.cwl NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20-samples.json 
```
Wait for the run to finish. 

#### 4. Run workflow checker tool 

Before running the checker tool, modified the parameter in `bcbio_NA12878-chr20_checker.json`:
```shell
cd /home/wfrunner/bcbio_NA12878-chr20
find -iname grading-summary-NA12878-chr20.csv
vim bcbio_NA12878-chr20_checker.json
```
Paste the correct value as:
```JSON
{
    ""baseline"": {
        ""class"": ""File"",
        ""path"": ""grading-summary-NA12878-chr20-baseline.csv""
    },
    ""comparison"": {
        ""class"": ""File"",
        ""path"": ""./NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20-2017-09-28-150818.687/root/summarize_vc/validate/grading-summary-NA12878-chr20.csv""
    }
}
```
Run checker tool to validate workflow results before submission as follows:
```shell
cd /home/wfrunner/bcbio_NA12878-chr20
rabix --tmpdir-prefix ~/tmp/ --tmp-outdir-prefix ~/tmp/ bcbio_NA12878-chr20_checker.cwl bcbio_NA12878-chr20_checker.json
```
Check results:
```shell
cd /home/wfrunner/bcbio_NA12878-chr20
cat  bcbio_NA12878-chr20_checker-2017-09-29-121607.160/root/results.json | grep -i overall 
[OUTPUT]          ""Overall"": true, 
```

#### 5. Submit workflow outputs

Modified the parameters in  `bcbio_NA12878-chr20_submit.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": ""/home/wfrunner/synapse_utils/.synapse_config""
    },
    ""team_name"": """",
    ""eval_id"": ""9605240"",
    ""file"": [
        {
            ""class"": ""File"",
            ""path"": ""./NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20-2017-09-28-150818.687/root/summarize_vc/validate/grading-summary-NA12878-chr20.csv""
        }
    ],
    ""parent_id"": ""syn10929786""
}
```

Finally, submitted outputs using the submission tool `dockstore-tool-synapse-submit.cwl`:
```shell
cd /home/wfrunner/bcbio_NA12878-chr20
rabix --tmpdir-prefix ~/tmp/ --tmp-outdir-prefix ~/tmp/ ~/synapse_utils/dockstore-tool-synapse-submit.cwl bcbio_NA12878-chr20_submit.json
```
---",9638363
bcbio_NA12878-chr20,9639346_report.md,"## bcbio NA12878 chr20 variant calling and validation

### Workflow description

```YAML
contributor: ""Brad Chapman""
workflow_handle: ""bcbio_NA12878-chr20""
input_handle: ""NA12878 chr20""
```
The following description is provided by the workflow author:
> A [bcbio](http://bcb.io/) workflow running a single chromosome subset of the [Genome in a Bottle NA12878 sample](http://jimb.stanford.edu/giab) from [Illumina's Platinum Genomes](https://www.illumina.com/platinumgenomes.html). It runs alignment, variant calling with multiple methods ([GATK4 HaplotypeCaller](http://gatkforums.broadinstitute.org/gatk/categories/gatk-4-alpha), [FreeBayes](https://github.com/ekg/freebayes), [Platypus](https://github.com/andyrimmer/Platypus),[samtools](https://github.com/samtools/samtools)) and quality control, validating outputs against reference standards. It uses 8 cores and 4Gb/memory per core, using 50Gb of disk space (35Gb for inputs, 15Gb for analyses). On an AWS m4.2xlarge instance with 8 cores and 32Gb of memory, it runs in 4 hours.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-08-29**: Replace dots with underscores in variable names, providing compatibility with Rabix Bunny and Seven Bridges.
+ **2017-08-25**: Improve CWL to avoid unused inputs, better specify secondary files, and provide compatibility with other workflow systems. Thanks to DNAnexus and SevenBridges for compatibility work.
+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Abraham Chavez"" # your name here
institution: ""UCSC Genomics Institute"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-29T16:36:57+00:00"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170413194156"" # indicate executor version used
docker_version: ""17.06.2-ce"" # from `docker --version`
environment: ""Google CC"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""4"" # indicate number of cores in environment
env_memory: ""16Gb"" # indicate available RAM in environment
env_disk: ""200Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

If you have not set up your environment and install dependencies like **cwltool**, **dockstore**, **java** and so on
I recommend you follow [**this**](https://www.synapse.org/#!Synapse:syn10220609) instructions.

>**NOTE:** When configuring `docker` to run as root. You might encounter problems setting the credentials as directed in digital ocean, try replacing `su - ${USER}` with `sudo su -` and running `usermod -aG docker ${USER}` and `su - ${USER}` inside root terminal.

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir bcbio
cd bcbio
cp ~/.synapseConfig .
```
###### Download & Run
I created a script that provision the required data and runs the workflow as directed in one of the available scripts available on the github repo, provided by the author.
In a script called `bcbio_runner.sh` insert the following.
```shell
#!/bin/bash
synapse get -r syn9725771
synapse -c .synapseConfig get syn9770802   # dockstore-tool-synapse-get.cwl
synapse -c .synapseConfig get syn9732885   # dockstore-tool-synapse-submit.cwl
#synapse get -r syn9725771
PNAME=NA12878-platinum-chr20
WORKDIR=`pwd`/cwltool_work
CWL_TMPDIR=$WORKDIR/tmpcwl
mkdir -p $CWL_TMPDIR
export TMPDIR=$CWL_TMPDIR
cwltool --tmpdir-prefix $CWL_TMPDIR --tmp-outdir-prefix $CWL_TMPDIR $PNAME-workflow/main-$PNAME.cwl $PNAME-workflow/main-$PNAME-samples.json
```
Ensure the script is in the path
```shell
chmod u+x bcbio_runner.sh
```
Run the script w/ workflow as follows.
```shell
./bcbio_runner.sh
```
>**NOTE** Workflow takes about 8-10 hours to run. With provided specs.

>**Author Notes**. The [NA12878-chr20 directory on GitHub](https://github.com/bcbio/bcbio_validation_workflows/tree/master/NA12878-chr20) contains starter shell scripts to run this with different CWL-enabled tools: [cwltool](https://github.com/common-workflow-language/cwltool), [Toil](https://github.com/BD2KGenomics/toil) or [rabix bunny](https://github.com/rabix/bunny). It can either use a local bcbio installation or [bcbio Docker containers](https://github.com/bcbio/bcbio_docker). If you're using cwltool, we recommend using the version that ships with bcbio-vm (`cwltool==1.0.20170413194156`) and using a similar command line to [the example wrapper script](https://github.com/bcbio/bcbio_validation_workflows/blob/master/NA12878-chr20/run_cwltool.sh) that correctly sets temporary directories. The `--cachedir` argument for cwltool specifically appears to have an issue with this workflow so should be avoided.
---",9639346
bcbio_NA12878-chr20,9646113_report.md,"## bcbio NA12878 chr20 variant calling and validation

### Workflow description

```YAML
contributor: ""Brad Chapman""
workflow_handle: ""bcbio_NA12878-chr20""
input_handle: ""NA12878 chr20""
```
The following description is provided by the workflow author:
> A [bcbio](http://bcb.io/) workflow running a single chromosome subset of the [Genome in a Bottle NA12878 sample](http://jimb.stanford.edu/giab) from [Illumina's Platinum Genomes](https://www.illumina.com/platinumgenomes.html). It runs alignment, variant calling with multiple methods ([GATK4 HaplotypeCaller](http://gatkforums.broadinstitute.org/gatk/categories/gatk-4-alpha), [FreeBayes](https://github.com/ekg/freebayes), [Platypus](https://github.com/andyrimmer/Platypus),[samtools](https://github.com/samtools/samtools)) and quality control, validating outputs against reference standards. It uses 8 cores and 4Gb/memory per core, using 50Gb of disk space (35Gb for inputs, 15Gb for analyses). On an AWS m4.2xlarge instance with 8 cores and 32Gb of memory, it runs in 4 hours.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-08-29**: Replace dots with underscores in variable names, providing compatibility with Rabix Bunny and Seven Bridges.
+ **2017-08-25**: Improve CWL to avoid unused inputs, better specify secondary files, and provide compatibility with other workflow systems. Thanks to DNAnexus and SevenBridges for compatibility work.
+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Joe Slagel"" # your name here
institution: ""Institute for Systems Biology"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""11/1/2017"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""cwl"" # CWL or WDL
runner_version: ""1.0.20170217172322"" # indicate executor version used
docker_version: ""Docker version 17.09.0-ce, build afdb6d4"" # from `docker --version`
environment: ""Google Compute"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""30 GB"" # indicate available RAM in environment
env_disk: ""100 GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-19""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""EC2"" 
env_cpus_ex: ""32""
env_memory_ex: ""244Gb""
env_disk_ex: ""elastic""
```

### Steps

1. Using Google Cloud console launched a Compute VM, type n1-standard-8 (8 vCPUs, 30 GB memory)

2. Installed pip:

        sudo apt-get install python-pip python-dev build-essential

3. Installed cwltool and synapse tool

        sudo pip install cwltool==1.0.20170217172322
        sudo pip install html5lib
        sudo pip install synapseclient
        cwltool --version          # reported error about version mismatch with ruamel.yaml
        sudo pip install ruamel.yaml==0.14.1

4. Installed docker

        sudo apt-get install apt-transport-https ca-certificates curl software-properties-common
        curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
        sudo apt-get update
        sudo apt-get install docker-ce

5. Created a .synapseConfig file with my username, credentials.

6. Retrieved the synapse files:

        synapse -c .synapseConfig get syn10204916  # biowardrobe_chipseq_se_get.json
        synapse -c .synapseConfig get syn9770802   # dockstore-tool-synapse-get.cwl
        synapse -c .synapseConfig get syn9732885   # dockstore-tool-synapse-submit.cwl

7. Retrieved workflow CWL and data:

        sudo cwltool --debug --non-strict dockstore-tool-synapse-get.cwl biowardrobe_chipseq_se_get.json

8. Ran the workflow:

        sudo cwltool --debug --non-strict biowardrobe_chipseq_se.cwl biowardrobe_chipseq_se.json > run.log 2>&1 &

9. Checked the results:

        sudo cwltool --debug --non-strict biowardrobe_chipseq_se_checker.cwl biowardrobe_chipseq_se_checker.json
---",9646113
bcbio_NA12878-chr20,9646941_report.md,"## bcbio NA12878 chr20 variant calling and validation

### Workflow description

```YAML
contributor: ""Brad Chapman""
workflow_handle: ""bcbio_NA12878-chr20""
input_handle: ""NA12878 chr20""
```
The following description is provided by the workflow author:
> A [bcbio](http://bcb.io/) workflow running a single chromosome subset of the [Genome in a Bottle NA12878 sample](http://jimb.stanford.edu/giab) from [Illumina's Platinum Genomes](https://www.illumina.com/platinumgenomes.html). It runs alignment, variant calling with multiple methods ([GATK4 HaplotypeCaller](http://gatkforums.broadinstitute.org/gatk/categories/gatk-4-alpha), [FreeBayes](https://github.com/ekg/freebayes), [Platypus](https://github.com/andyrimmer/Platypus),[samtools](https://github.com/samtools/samtools)) and quality control, validating outputs against reference standards. It uses 8 cores and 4Gb/memory per core, using 50Gb of disk space (35Gb for inputs, 15Gb for analyses). On an AWS m4.2xlarge instance with 8 cores and 32Gb of memory, it runs in 4 hours.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-08-29**: Replace dots with underscores in variable names, providing compatibility with Rabix Bunny and Seven Bridges.
+ **2017-08-25**: Improve CWL to avoid unused inputs, better specify secondary files, and provide compatibility with other workflow systems. Thanks to DNAnexus and SevenBridges for compatibility work.
+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Todd Pihl"" # your name here
institution: ""ISB-CGC"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-10-27"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170217172322"" # indicate executor version used
docker_version: ""17.06.2-ce, build cec0b72"" # from `docker --version`
environment: ""Google Compute"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""35M"" # indicate available RAM in environment
env_disk: ""250G"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-19""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""EC2"" 
env_cpus_ex: ""32""
env_memory_ex: ""244Gb""
env_disk_ex: ""elastic""
```

### Steps

1. [Install bcbio-vm](https://github.com/chapmanb/bcbio-nextgen-vm#installation) which has wrapper scripts and ready to run distributions of several CWL enabled tools (cwltool, toil, bunny) and infrastructure (synapse):

        wget https://repo.continuum.io/miniconda/Miniconda2-latest-Linux-x86_64.sh
        bash Miniconda2-latest-Linux-x86_64.sh -b -p ~/install/bcbio-vm/anaconda
        ~/install/bcbio-vm/anaconda/bin/conda install --yes -c conda-forge -c bioconda bcbio-nextgen-vm
        export PATH=~/install/bcbio-vm/anaconda/bin:$PATH

2. If you've not already retrieved the CWL and data with synapse-get, you can use the [Synapse python client](https://github.com/Sage-Bionetworks/synapsePythonClient#installation):

        synapse get -r syn9725771


3. The [NA12878-chr20 directory on GitHub](https://github.com/bcbio/bcbio_validation_workflows/tree/master/NA12878-chr20) contains starter shell scripts to run this with different CWL-enabled tools: [cwltool](https://github.com/common-workflow-language/cwltool), [Toil](https://github.com/BD2KGenomics/toil) or [rabix bunny](https://github.com/rabix/bunny). It can either use a local bcbio installation or [bcbio Docker containers](https://github.com/bcbio/bcbio_docker). If you're using cwltool, we recommend using the version that ships with bcbio-vm (`cwltool==1.0.20170413194156`) and using a similar command line to [the example wrapper script](https://github.com/bcbio/bcbio_validation_workflows/blob/master/NA12878-chr20/run_cwltool.sh) that correctly sets temporary directories. The `--cachedir` argument for cwltool specifically appears to have an issue with this workflow so should be avoided.
---",9646941
bcbio_NA12878-chr20,9650685_report.md,"## bcbio NA12878 chr20 variant calling and validation

### Workflow description

```YAML
contributor: ""Brad Chapman""
workflow_handle: ""bcbio_NA12878-chr20""
input_handle: ""NA12878 chr20""
```
The following description is provided by the workflow author:
> A [bcbio](http://bcb.io/) workflow running a single chromosome subset of the [Genome in a Bottle NA12878 sample](http://jimb.stanford.edu/giab) from [Illumina's Platinum Genomes](https://www.illumina.com/platinumgenomes.html). It runs alignment, variant calling with multiple methods ([GATK4 HaplotypeCaller](http://gatkforums.broadinstitute.org/gatk/categories/gatk-4-alpha), [FreeBayes](https://github.com/ekg/freebayes), [Platypus](https://github.com/andyrimmer/Platypus),[samtools](https://github.com/samtools/samtools)) and quality control, validating outputs against reference standards. It uses 8 cores and 4Gb/memory per core, using 50Gb of disk space (35Gb for inputs, 15Gb for analyses). On an AWS m4.2xlarge instance with 8 cores and 32Gb of memory, it runs in 4 hours.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-08-29**: Replace dots with underscores in variable names, providing compatibility with Rabix Bunny and Seven Bridges.
+ **2017-08-25**: Improve CWL to avoid unused inputs, better specify secondary files, and provide compatibility with other workflow systems. Thanks to DNAnexus and SevenBridges for compatibility work.
+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Michael Krause"" # your name here
institution: ""UCSC Genomics Institute"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

```YAML
date_accessed: ""2017-11-02"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""Toil/cwltoil"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170822192924"" # indicate executor version used
docker_version: "" 17.09.0-ce, build afdb6d4"" # from `docker --version`
environment: ""EC2"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""4"" # indicate number of cores in environment
env_memory: ""30.5G"" # indicate available RAM in environment
env_disk: ""200G"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

####1. Select an EC2 instance
Select an Amazon AMI Ubuntu 16.04 LTS (ami-6e1a0117) and create an r4.xlarge instance on EC2. Run: 

```bash
sudo apt-get update
sudo apt-get install virtualenv
```
(Note: this instance only has 4 cores, and not 8 as the workflow author recommends.)

####2. Install Java, Docker, and Dockstore
Install Oracle's JDK, docker and dockstore, as described [here] (https://www.synapse.org/#!Synapse:syn10220609). Specifically, make sure that `docker run hello-world` runs without `sudo`, and that `dockstore` shows the help. We need `pip`, `virtualenv`, and several other Python packages which I will go into now because it has been covered in that link as well.

####3. Install Toil
Create a dedicated folder and a virtual environment and in it create a copy of the file containing Synapse credentials. Next download and install the development version of Toil. All future steps are performed in the virtual environment `venv` from here on:

```bash
cp ~/.synapseConfig .
virtualenv venv
source venv/bin/activate
git clone https://github.com/BD2KGenomics/toil.git
cd toil
make prepare
make develop
cd ..
```

####4. Install CWL packages
Now we use `pip` to install `cwltool`, `synapseclient`, and several helper packages/dependencies into that environment:

```bash
pip install cwl-runner schema-salad==2.6.20170630075932 avro==1.8.1 galaxy-lib==17.9.3 cwltool==1.0.20170822192924 ruamel.yaml==0.14.12 --no-cache-dir
pip install synapseclient --no-cache-dir
pip install html5lib cwltest
```

####5. Provision CWL files and their object files (JSON files) from Synapse
Execution of the last command takes a little more than 1 h. 
```bash
synapse get -r syn9689286
synapse get -r syn9689284
cwltoil dockstore-tool-synapse-get.cwl bcbio_NA12878-chr20_get.cwl.json
```

####6. Run the workflow using Toil
Before I executed the main workflow I used an editor (nano) to set the value for the number of cores to 4 (it was set to 8 by the workflow author, but my EC2 instance only has 4 cores).

```bash
cat NA12878-platinum-chr20-workflow/steps/process_alignment.cwl | less | grep coresMin
  coresMin: 4
```
Then I used Toil to perform alignment, variant calling and quality control. Both the CWL file and the object JSON file are located in `NA12878-platinum-chr20-workflow`. 
```bash
cwltoil NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20.cwl NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20-samples.json
```

####8. Verify return output of workflow
Move (or copy) the CSV file that contains the results of the workflow into the current directory, and execute the CWL checker tool to compare it against the results in the database.
```bash
mv NA12878-platinum-chr20-workflow/grading-summary-NA12878-chr20.csv grading-summary-NA12878-chr20.csv
cwltoil bcbio_NA12878-chr20_checker.cwl bcbio_NA12878-chr20_checker.cwl.json
```

####7. Submit the workflow results.
I've added the parent ID of my workflow to the JSON file `bcbio_NA12878-chr20_submit.json` (and forgot to fill in my team affiliation, which is ""UCSC GA4GH-DREAM Challenge Team""):
```bash
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": """",
    ""eval_id"": ""9605240"",
    ""file"": [
        {
            ""class"": ""File"",
            ""path"": ""grading-summary-NA12878-chr20.csv""
        }
    ],
    ""parent_id"": ""11382088""
}
```

and ran the following code to submit the results.

```bash
cwltoil dockstore-tool-synapse-submit.cwl bcbio_NA12878-chr20_submit.json
```",9650685
bcbio_NA12878-chr20,9653358_report.md,"## bcbio NA12878 chr20 variant calling and validation

### Workflow description

```YAML
contributor: ""Brad Chapman""
workflow_handle: ""bcbio_NA12878-chr20""
input_handle: ""NA12878 chr20""
```
The following description is provided by the workflow author:
> A [bcbio](http://bcb.io/) workflow running a single chromosome subset of the [Genome in a Bottle NA12878 sample](http://jimb.stanford.edu/giab) from [Illumina's Platinum Genomes](https://www.illumina.com/platinumgenomes.html). It runs alignment, variant calling with multiple methods ([GATK4 HaplotypeCaller](http://gatkforums.broadinstitute.org/gatk/categories/gatk-4-alpha), [FreeBayes](https://github.com/ekg/freebayes), [Platypus](https://github.com/andyrimmer/Platypus),[samtools](https://github.com/samtools/samtools)) and quality control, validating outputs against reference standards. It uses 8 cores and 4Gb/memory per core, using 50Gb of disk space (35Gb for inputs, 15Gb for analyses). On an AWS m4.2xlarge instance with 8 cores and 32Gb of memory, it runs in 4 hours.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-11-07**: Improve coverage calculations with separate steps. Parallelize variant calling allowing use of multicore callers.
+ **2017-08-29**: Replace dots with underscores in variable names, providing compatibility with Rabix Bunny and Seven Bridges.
+ **2017-08-25**: Improve CWL to avoid unused inputs, better specify secondary files, and provide compatibility with other workflow systems. Thanks to DNAnexus and SevenBridges for compatibility work.
+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Karl Sebby"" # your name here
institution: ""xD Bio"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-11-15"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""cwl"" # CWL or WDL
runner_version: ""cwltool==1.0.20171107133715"" # indicate executor version used
docker_version: ""17.09.0-ce, build afdb6d4"" # from `docker --version`
environment: ""Google Compute"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""54Gb"" # indicate available RAM in environment
env_disk: ""80Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-19""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""EC2"" 
env_cpus_ex: ""32""
env_memory_ex: ""244Gb""
env_disk_ex: ""elastic""
```

### Steps
**Ran everything as root to make docker happy and not have to keep changing permissions.**

```shell
sudo bash
```
#### 1. Set up environment
 [Install bcbio-vm](https://github.com/chapmanb/bcbio-nextgen-vm#installation) which has wrapper scripts and ready to run distributions of several CWL enabled tools (cwltool, toil, bunny) and infrastructure (synapse):

        wget https://repo.continuum.io/miniconda/Miniconda2-latest-Linux-x86_64.sh
        bash Miniconda2-latest-Linux-x86_64.sh -b -p ~/install/bcbio-vm/anaconda
        ~/install/bcbio-vm/anaconda/bin/conda install --yes -c conda-forge -c bioconda bcbio-nextgen-vm
        export PATH=~/install/bcbio-vm/anaconda/bin:$PATH
ssh  to google compute engine instance from local machine (linux mint with cinnamon desktop running in virtual box on Macbook pro.)
```shell
screen
ssh `external_ip`
```

On google instance, install docker, pip3, cwltool (with pip3).
Set up directory structure from ~:
```shell
mkdir -p projects/dreamChallenge/bcbio_NA12878-chr20
cd projects/dreamChallenge
```
Create .synapseConfig file and paste in text from synapse website. Change username and password.
```shell 
vi .synapseConfig
```

#### 2. Download required files
Steps completed in the projects/dreamChallenge directory unless specified otherwise.

Use curl to get the dockstore-tool-synapse-get.cwl and dockstore-tool-synapse-submit.cwl:
```shell
curl https://raw.githubusercontent.com/GA4GH-DREAM/dockstore-tool-synapse-get/master/Dockstore.cwl > dockstore-tool-synapse-get.cwl
curl https://raw.githubusercontent.com/GA4GH-DREAM/dockstore-tool-synapse-submit/master/Dockstore.cwl > dockstore-tool-synapse-submit.cwl
```
Downloaded the `bcbio_NA12878-chr20_get.cwl.json` file to my local machine from synapse website. Opened the file in TextEdit and copied contents. In google compute shell create the `bcbio_NA12878-chr20_get.cwl.json` file and paste the contents and save:
```shell
vi bcbio_NA12878-chr20_get.cwl.json
```

Get the files:
```shell
cd bcbio_NA12878-chr20
cwltool ../dockstore-tool-synapse-get.cwl ../bcbio_NA12878-chr20_get.cwl.json
```
#### 3. Run main workflow
Use the [specified example script](https://github.com/bcbio/bcbio_validation_workflows/blob/master/NA12878-chr20/run_cwltool.sh) as a guide to execute the workflow.
```shell
mkdir -p /cwltool_work/tmpcwl
cwltool --tmpdir-prefix /cwltool_work/tmpcwl --tmp-outdir-prefix /cwltool_work/tmpcwl NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20.cwl NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20-samples.json

```
#### 4. Run workflow checker tool
For checker to run successfully, I had to move `NA12878-platinum-chr20-workflow/grading-summary-NA12878-chr20.csv` into its parent directory:
```shell
mv grading-summary-NA12878-chr20.csv ..
```
To verify the workflow results before submission, use `cwltool` to run the checker as follows:
```shell
cwltool bcbio_NA12878-chr20_checker.cwl bcbio_NA12878-chr20_checker.json
cat results.json
```
#### 5. Submit workflow outputs

Modify the parameters in `bcbio_NA12878-chr20_submit.json` appropriately: `parent_id` and config_file path (to parent directory):
```
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": ""../.synapseConfig""
    },
    ""team_name"": """",
    ""eval_id"": ""9605240"",
    ""file"": [
        {
            ""class"": ""File"",
            ""path"": ""grading-summary-NA12878-chr20.csv""
        }
    ],
    ""parent_id"": ""syn123456""
}

```

Finally, submit the outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool ../dockstore-tool-synapse-submit.cwl bcbio_NA12878-chr20_submit.json
```

---",9653358
bcbio_NA12878-chr20,9654881_report.md,"## bcbio NA12878 chr20 variant calling and validation

### Workflow description

```YAML
contributor: ""Brad Chapman""
workflow_handle: ""bcbio_NA12878-chr20""
input_handle: ""NA12878 chr20""
```
The following description is provided by the workflow author:
> A [bcbio](http://bcb.io/) workflow running a single chromosome subset of the [Genome in a Bottle NA12878 sample](http://jimb.stanford.edu/giab) from [Illumina's Platinum Genomes](https://www.illumina.com/platinumgenomes.html). It runs alignment, variant calling with multiple methods ([GATK4 HaplotypeCaller](http://gatkforums.broadinstitute.org/gatk/categories/gatk-4-alpha), [FreeBayes](https://github.com/ekg/freebayes), [Platypus](https://github.com/andyrimmer/Platypus),[samtools](https://github.com/samtools/samtools)) and quality control, validating outputs against reference standards. It uses 8 cores and 4Gb/memory per core, using 50Gb of disk space (35Gb for inputs, 15Gb for analyses). On an AWS m4.2xlarge instance with 8 cores and 32Gb of memory, it runs in 4 hours.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-11-07**: Improve coverage calculations with separate steps. Parallelize variant calling allowing use of multicore callers.
+ **2017-08-29**: Replace dots with underscores in variable names, providing compatibility with Rabix Bunny and Seven Bridges.
+ **2017-08-25**: Improve CWL to avoid unused inputs, better specify secondary files, and provide compatibility with other workflow systems. Thanks to DNAnexus and SevenBridges for compatibility work.
+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Azza E Ahmed"" # your name here
institution: ""University of Khartoum"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-11-21"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170217172322"" # indicate executor version used
docker_version: ""17.03.1-ce, build c6d412e"" # from `docker --version`
environment: ""EGI FedCloud"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""32GB"" # indicate available RAM in environment
env_disk: ""100GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-19""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""EC2"" 
env_cpus_ex: ""32""
env_memory_ex: ""244Gb""
env_disk_ex: ""elastic""
```

### Steps

0. I launched a VM instance from EGI FedCloud resources (EGI Docker (Ubuntu 14.04) from CESNET MetaCloud (IaaS Cloud)) with extra large memory (32GB ram, 100GB disk, 8 cores). Overall, the challenge required 60GB of storage space, and the 50GB was not enough.

1.  Next, I created the challenge directory:
```
 mkdir /mnt/storage01/bcbio_NA12878-chr20
```

1. bcbio, environment set up, and data download instructions  were all wrapped up in a script and made to run, as collectively they take a good hour or 2 to be set up:
```
$ cat prep_env.sh 
#/bin/bash
cd ~
wget https://repo.continuum.io/miniconda/Miniconda2-latest-Linux-x86_64.sh
bash Miniconda2-latest-Linux-x86_64.sh -b -p ~/install/bcbio-vm/anaconda
~/install/bcbio-vm/anaconda/bin/conda install --yes -c conda-forge -c bioconda bcbio-nextgen-vm
export PATH=~/install/bcbio-vm/anaconda/bin:$PATH

sudo usermod -a -G docker $USER
pip install schema-salad==2.2.20170222151604 cwltool==1.0.20170217172322 --no-cache-dir
synapse login -u <my_synapse_user_name> -p <my_password> --rememberMe
synapse get -r syn9725771

cd /mnt/storage01/bcbio_NA12878-chr20
git clone  https://github.com/bcbio/bcbio_validation_workflows.git

$nohup ./prep_env.sh &> log.prep_env.sh &
```

2. Run the workflow using the wrapper script downloaded from the bcbio_validation_worflows github repo:
```
$mv bcbio_validation_workflows/NA12878-chr20/run_cwltool.sh .
$chmod +x run_cwltool.sh
$nohup ./run_cwltool.sh &> log.run_cwltool.sh &
```
3. Once finished running, check the result with the checker:
```
$cwltool  bcbio_NA12878-chr20_checker.cwl bcbio_NA12878-chr20_checker.json
$vi log.txt # shows that all features counts are within allowed difference range
$vi  results.json # shows that ""Overall"":true, so all is good and ready to submit
```

4. Now,  submit the final result. Here, since I manually downloaded the data, I needed to explicitly download the submission script, create a `.synapseConfig` of my credentials, and also update the submission json file by adding the name of my team, and the parent synapse folder that will host the submission file:
```
curl https://raw.githubusercontent.com/GA4GH-DREAM/dockstore-tool-synapse-submit/master/Dockstore.cwl > dockstore-tool-synapse-submit.cwl
vi .synapseConfig
vi bcbio_NA12878-chr20_submit.json 
cwltool  --debug --non-strict dockstore-tool-synapse-submit.cwl bcbio_NA12878-chr20_submit.json 
```

---",9654881
bcbio_NA12878-chr20,9655741_report.md,"## bcbio NA12878 chr20 variant calling and validation

### Workflow description

```YAML
contributor: ""Brad Chapman""
workflow_handle: ""bcbio_NA12878-chr20""
input_handle: ""NA12878 chr20""
```
The following description is provided by the workflow author:
> A [bcbio](http://bcb.io/) workflow running a single chromosome subset of the [Genome in a Bottle NA12878 sample](http://jimb.stanford.edu/giab) from [Illumina's Platinum Genomes](https://www.illumina.com/platinumgenomes.html). It runs alignment, variant calling with multiple methods ([GATK4 HaplotypeCaller](http://gatkforums.broadinstitute.org/gatk/categories/gatk-4-alpha), [FreeBayes](https://github.com/ekg/freebayes), [Platypus](https://github.com/andyrimmer/Platypus),[samtools](https://github.com/samtools/samtools)) and quality control, validating outputs against reference standards. It uses 8 cores and 4Gb/memory per core, using 50Gb of disk space (35Gb for inputs, 15Gb for analyses). On an AWS m4.2xlarge instance with 8 cores and 32Gb of memory, it runs in 4 hours.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-11-07**: Improve coverage calculations with separate steps. Parallelize variant calling allowing use of multicore callers.
+ **2017-08-29**: Replace dots with underscores in variable names, providing compatibility with Rabix Bunny and Seven Bridges.
+ **2017-08-25**: Improve CWL to avoid unused inputs, better specify secondary files, and provide compatibility with other workflow systems. Thanks to DNAnexus and SevenBridges for compatibility work.
+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Joe Slagel"" # your name here
institution: ""ISB"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-11-30"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""ISB-CGC dsub/cwltool/cwl_runner.sh"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""cwltool-1.0.20171107133715"" # indicate executor version used
docker_version: ""17.11.0"" # from `docker --version`
environment: ""Google Compute"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""30"" # indicate available RAM in environment
env_disk: ""200"" # indicate available disk space, or note ""elastic"" for EFS et al.
```
### Steps

I was curious as to how much of the challenge I could do using only dsub and cwl_runner.sh.  On a personal Google Cloud VM with gcloud, gsutil, dsub and cwl_runner.sh installed I:

#### 1. Set up environment

```shell
gsutil cp ~/.synapseConfig gs://isb-ga4gh-dream/bcbio_NA12878-chr20/data/.synapseConfig
dsub \
   --name dream-setup-bcbio_NA12878-chr20 \
   --project cgc-05-0026 \
   --zones 'us-*' \
   --image quay.io/ga4gh-dream/dockstore-tool-synapse-get \
   --input  'CFG=gs://isb-ga4gh-dream/bcbio_NA12878-chr20/data/.synapseConfig' \
   --output-recursive 'OUT=gs://isb-ga4gh-dream/bcbio_NA12878-chr20/data/' \
   --logging 'gs://isb-ga4gh-dream/bcbio_NA12878-chr20/log' \
   --wait \
   --command 'cd ${OUT}; \
              synapse -c ${CFG} get syn9770802; \
              synapse -c ${CFG} get syn9732885; \
              synapse -c ${CFG} get -r syn9725771; \
             '
```

#### 2. Download required files

Nothing to do.

#### 3. Run main workflow
 
```shell
./cwl_runner.sh \
   -m n1-standard-8 \
   -r gs://isb-ga4gh-dream/bcbio_NA12878-chr20/data/ \
   -w gs://isb-ga4gh-dream/bcbio_NA12878-chr20/data/NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20.cwl \
   -s gs://isb-ga4gh-dream/bcbio_NA12878-chr20/data/NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20-samples.json \
   -o gs://isb-ga4gh-dream/bcbio_NA12878-chr20/data
```

#### 4. Run workflow checker tool

```shell
./cwl_runner.sh \
   -m n1-standard-8 \
   -r gs://isb-ga4gh-dream/bcbio_NA12878-chr20/data/ \
   -w gs://isb-ga4gh-dream/bcbio_NA12878-chr20/data/bcbio_NA12878-chr20_checker.cwl \
   -s gs://isb-ga4gh-dream/bcbio_NA12878-chr20/data/bcbio_NA12878-chr20_checker.json \
   -o gs://isb-ga4gh-dream/bcbio_NA12878-chr20/data
```

#### 5. Submit workflow outputs

```shell
gsutil cat gs://isb-ga4gh-dream/bcbio_NA12878-chr20/data/bcbio_NA12878-chr20_submit.json \
   | jq '.team_name=""ISB-CGC"" | .parent_id=""syn11413153""' \
   | gsutil cp - gs://isb-ga4gh-dream/bcbio_NA12878-chr20/data/bcbio_NA12878-chr20_submit.json
./cwl_runner.sh \
   -m n1-standard-2 \
   -r gs://isb-ga4gh-dream/bcbio_NA12878-chr20/data/ \
   -w gs://isb-ga4gh-dream/bcbio_NA12878-chr20/data/dockstore-tool-synapse-submit.cwl \
   -s gs://isb-ga4gh-dream/bcbio_NA12878-chr20/data/bcbio_NA12878-chr20_submit.json \
   -o gs://isb-ga4gh-dream/bcbio_NA12878-chr20/data
```

---",9655741
bcbio_NA12878-chr20,9657797_report.md,"## bcbio NA12878 chr20 variant calling and validation

### Workflow description

```YAML
contributor: ""Brad Chapman""
workflow_handle: ""bcbio_NA12878-chr20""
input_handle: ""NA12878 chr20""
```
The following description is provided by the workflow author:
> A [bcbio](http://bcb.io/) workflow running a single chromosome subset of the [Genome in a Bottle NA12878 sample](http://jimb.stanford.edu/giab) from [Illumina's Platinum Genomes](https://www.illumina.com/platinumgenomes.html). It runs alignment, variant calling with multiple methods ([GATK4 HaplotypeCaller](http://gatkforums.broadinstitute.org/gatk/categories/gatk-4-alpha), [FreeBayes](https://github.com/ekg/freebayes), [Platypus](https://github.com/andyrimmer/Platypus),[samtools](https://github.com/samtools/samtools)) and quality control, validating outputs against reference standards. It uses 8 cores and 4Gb/memory per core, using 50Gb of disk space (35Gb for inputs, 15Gb for analyses). On an AWS m4.2xlarge instance with 8 cores and 32Gb of memory, it runs in 4 hours.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-11-07**: Improve coverage calculations with separate steps. Parallelize variant calling allowing use of multicore callers.
+ **2017-08-29**: Replace dots with underscores in variable names, providing compatibility with Rabix Bunny and Seven Bridges.
+ **2017-08-25**: Improve CWL to avoid unused inputs, better specify secondary files, and provide compatibility with other workflow systems. Thanks to DNAnexus and SevenBridges for compatibility work.
+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Nihar Sheth"" # your name here
institution: ""DNAnexus Inc."" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

```YAML
date_accessed: ""2017-12-18"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""DNAnexus-CWL"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""alpha"" # indicate executor version used
docker_version: ""dx-docker"" # from `docker --version`
environment: ""DNAnexus"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""autoscale"" # indicate number of cores in environment
env_memory: ""autoscale"" # indicate available RAM in environment
env_disk: ""autoscale"" # indicate available disk space, or note ""elastic"" for EFS et al.
```


### Steps

#### 1. Set up environment

On a Linux desktop with dx-toolkit and Docker installed, log into a DNAnexus project.
Also, set environment variables for your project and authentication token.
```
dx env
```
will give you your project ID.  We will assume it's accessible via `$PROJECT`.

You can generate a token via these instructions: https://wiki.dnanexus.com/Command-Line-Client/Login-and-Logout#Authentication-Tokens

Clone the dx-cwl repository:

```
https://github.com/dnanexus/dx-cwl.git
```

This was a commit hash used around the time of submission if you'd like to check it out: 2687fe8c671c113e8a780a790a85a18396aea23e

Ensure all pre-requisites are installed using the install-prerequisites.sh script or building a Docker image from the Dockerfile in the repository.

#### 2. Download required files
. If you've not already retrieved the CWL and data with synapse-get, you can use the [Synapse python client](https://github.com/Sage-Bionetworks/synapsePythonClient#installation):

```

        synapse get -r syn9725771
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `bcbio_NA12878-chr20_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl bcbio_NA12878-chr20_get.cwl.json
```

#### 4. Run main workflow

Upload downloaded files to the DNAnexus project

```
dx upload -r .
```

Compile the workflow to DNAnexus

```
dx-cwl/dx-cwl compile-workflow MAIN-NA12878-PLATINUM-CHR20.CWL --project $PROJECT --token $TOKEN
```

Run the workflow on the platform

```
dx-cwl/dx-cwl run-workflow dx-cwl-run/MAIN-NA12878-PLATINUM-CHR20.CWL/MAIN-NA12878-PLATINUM-CHR20  MAIN-NA12878-PLATINUM-CHR20-SAMPLES.JSON
```
Note that the file in the second argument is referring to the one you uploaded to the platform.

#### 5. Run workflow checker tool

Using the UI, or `dx describe` on the analysis ID from above, download relevant outputs using:

`dx download [filename or ID]`


#### 6. Submit workflow outputs


Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl BCBIO_NA12878-CHR20_SUBMIT.JSON
```
",9657797
bcbio_NA12878-chr20,9657910_report.md,"## bcbio NA12878 chr20 variant calling and validation

### Workflow description

```YAML
contributor: ""Brad Chapman""
workflow_handle: ""bcbio_NA12878-chr20""
input_handle: ""NA12878 chr20""
```
The following description is provided by the workflow author:
> A [bcbio](http://bcb.io/) workflow running a single chromosome subset of the [Genome in a Bottle NA12878 sample](http://jimb.stanford.edu/giab) from [Illumina's Platinum Genomes](https://www.illumina.com/platinumgenomes.html). It runs alignment, variant calling with multiple methods ([GATK4 HaplotypeCaller](http://gatkforums.broadinstitute.org/gatk/categories/gatk-4-alpha), [FreeBayes](https://github.com/ekg/freebayes), [Platypus](https://github.com/andyrimmer/Platypus),[samtools](https://github.com/samtools/samtools)) and quality control, validating outputs against reference standards. It uses 8 cores and 4Gb/memory per core, using 50Gb of disk space (35Gb for inputs, 15Gb for analyses). On an AWS m4.2xlarge instance with 8 cores and 32Gb of memory, it runs in 4 hours.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-11-07**: Improve coverage calculations with separate steps. Parallelize variant calling allowing use of multicore callers.
+ **2017-08-29**: Replace dots with underscores in variable names, providing compatibility with Rabix Bunny and Seven Bridges.
+ **2017-08-25**: Improve CWL to avoid unused inputs, better specify secondary files, and provide compatibility with other workflow systems. Thanks to DNAnexus and SevenBridges for compatibility work.
+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Junjun Zhang"" # your name here
institution: ""Ontario Institute for Cancer Research"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-11-15"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""JTracker"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
cwltool_version: ""1.0.2017110733715""
runner_version: ""0.2.0a5"" # indicate executor version used
docker_version: ""1.12.6"" # from `docker --version`
environment: ""OpenStack VM"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""96GB"" # indicate available RAM in environment
env_disk: ""2TB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-08-31""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""1.12.6""
environment_ex: ""local"" 
env_cpus_ex: ""8""
env_memory_ex: ""96GB""
env_disk_ex: ""2TB""
```

### Write a JTracker Workflow
The JTracker workflow is written to automatically execute necessary steps to complete a Dream Challenge workflow. The JTracker workflow is named as `dream-challenge-wf-runner`, the source code is checked in Github at: https://github.com/jthub/demo-workflows/tree/master/dream-challenge-wf-runner/workflow.

Once tested out successfully, make a release of the source code. In this case, it is release version 0.0.7: https://github.com/jthub/demo-workflows/releases/tag/dream-challenge-wf-runner.0.0.7

### Register the JTracker Workflow in JTHub
#### Install JTracker command line tool

Follow the instructions here: https://github.com/icgc-dcc/jtracker

Once install successfully, you should be able to see the version number.
```
jt --version
```

#### Signup a JTHub account
Assume we choose `ga4gh_dream` as account name:
```
jt user signup -u ga4gh_dream
```
Login as `ga4gh_dream`
```
jt user login -u ga4gh_dream
```

#### Register the JTracker Dream Challenge Runner Workflow
Register a workflow is basically provide information to access the JTracker workflow source code in GitHub.
```
jt wf register --git-server https://github.com --git-account jthub --git-repo demo-workflows \
                       --git-path dream-challenge-wf-runner --git-tag dream-challenge-wf-runner.0.0.7 \
                       --wf-name dream-challenge-wf-runner --wf-version 0.0.7
```
To list all registered workflows in your account, do this:
```
jt wf ls
```

### Create a Job Queue
Once we have the workflow registered, you will be able to create a job queue for it.
```
jt queue add --wf-name dream-challenge-wf-runner --wf-version 0.0.7
```
Upon success, you will get a unique job queue ID. In my case, my queue ID is: `758b7668-0057-4ef6-a5b0-6f48acf38583`

To list all job queues you created, do this:
```
jt queue ls
```

### Add workflow job to the above queue
If we want to run `bcbio_NA12878-chr20`, fill out the appropriate parameters in the job JSON as below:
```
jt job add -q 758b7668-0057-4ef6-a5b0-6f48acf38583 -j '
{
    ""workflow_name"": ""bcbio_NA12878-chr20"",
    ""workflow_type"": ""CWL"",
    ""data_syn_id"": ""syn9725771"",
    ""wf_file_name"": ""NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20.cwl"",
    ""job_file_name"": ""NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20-samples.json"",
    ""checker_wf_file_name"": ""bcbio_NA12878-chr20_checker.cwl"",
    ""checker_job_file_name"": ""bcbio_NA12878-chr20_checker.json"",
    ""submit_job_file_name"": ""submit.json"",
    ""team_name"": ""PCAWG-Tech"",
    ""syn_parent_id"": ""syn11639122"",
    ""eval_id"": ""9605240""
}
'
```
To list all jobs in the queue:
```
jt job ls -q 758b7668-0057-4ef6-a5b0-6f48acf38583
```
Note that the above steps can be done on any computer, it could be a normal workstation or a laptop.


### Run the above queued Sanger workflow job

To execute the workflow job you will need to set up necessary environment and tools, follow these steps:

#### Setting up environment
1. Install Docker

2. Install `cwltool` (version 1.0.20170217172322) and  `synapseclient`
```
pip install cwltool==1.0.20170217172322
pip install synapseclient
```

3. Create Synapse credentials file `.synapseConfig`
Put there Synapse ID and password
```
[authentication]
username: user@usermail.org
password: <user-password>
```
Put this file a particular place, for example under home directory, eg, `/home/ubuntu/.synapseConfig`, then export the follow environment variable:
```
export SYNCONF=/home/ubuntu/.synapseConfig
```
4. Install JTracker command line
This is the same step as the previous section. Follow installation instruction here: https://github.com/icgc-dcc/jtracker

#### Start JTracker Executor
Start the executor to run jobs in the queue as:
```
jt user login ga4gh_dream
SYNCONF=/home/ubuntu/.synapseConfig jt exec run -q 758b7668-0057-4ef6-a5b0-6f48acf38583
```
If everything goes well, in about 5 hours, the job should finish and you will see `pcawg-sanger-variant-caller` result uploaded to specified location on Synapse.


---",9657910
bcbio_NA12878-chr20,9657917_report.md,"### Workflow description

```YAML
contributor: ""Brad Chapman""
workflow_handle: ""bcbio_NA12878-chr20""
input_handle: ""NA12878 chr20""
```

### Participant information
```YAML
name: ""Ben Ernest""
institution: ""Digicon Corporation""
```

### Submission overview
```YAML
date_accessed: ""2017-12-05"" 
platform: ""cwltool"" 
workflow_type: ""CWL"" 
runner_version: ""1.0.20170217172322"" 
docker_version: ""17.09.0-ce"" 
environment: ""cluster"" 
env_cpus: ""12"" 
env_memory: ""62Gb"" 
env_disk: ""5Tb"" 
```

### Steps

#### 1. Set up environment, following instructions at https://dockstore.org/quick-start.  These only need to be done once for all workflows that use `cwltool`.
##### Instructions are for Linux CentOS

Download and install dockstore.  
```shell
mkdir -p ~/bin
curl -L -o ~/bin/dockstore https://github.com/ga4gh/dockstore/releases/download/1.3.0/dockstore
chmod +x ~/bin/dockstore
echo 'export PATH=~/bin:$PATH' >> ~/.bashrc
source ~/.bashrc
```

Create configuration file
```shell
mkdir -p ~/.dockstore
printf ""token: dummy-token\nserver-url: https://dockstore.org:8443\n"" > ~/.dockstore/config
```

Install `pip`
```shell
curl -L -o ~/get-pip.py https://bootstrap.pypa.io/get-pip.py
sudo python get-pip.py
```

Install `cwltool` (**note: version 1.0.20170217172322**)
```shell
sudo pip install setuptools==36.5.0
sudo pip install cwl-runner cwltool==1.0.20170217172322 schema-salad==2.6.20170806163416 avro==1.8.1 ruamel.yaml==0.14.12 requests==2.18.4
```

Install Docker
```shell
sudo yum install -y yum-utils device-mapper-persistent-data lvm2
sudo yum-config-manager --add-repo ""https://download.docker.com/linux/centos/docker-ce.repo""
sudo yum-config-manager --enable extras
sudo yum -y install docker-ce
sudo usermod -aG docker $USER
exec newgrp docker
```

Create aliases to start and stop Docker
```shell
echo 'alias start_docker=""sudo systemctl start docker""' >> ~/.bashrc
echo `alias stop_docker=""sudo systemctl stop docker""' >> ~/.bashrc
source ~/.bashrc
```
Install `synapseclient`
```
sudo pip install synapseclient
```

Create synapse credentials file with the content below, using your own Synapse credentials (no quotes or extra characters).  It can be named anything, but I'm using `.synapseConfig`.
```
[authentication]
username: email
password: password
```

Create a working directory and copy synapse credentials file into that folder.
```shell
mkdir -p bcbio_chr20_run
cd bcbio_chr20_run
cp ~/.synapseConfig .
```

#### 2. Download required files
Download tools to fetch workflow input data.
```shell
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
synapse get syn9819444 # bcbio_NA12878-chr20_get.cwl.json
```

#### 3. Provision all workflow files
Start docker, using alias created previously.
```shell
start_docker
```

Use `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `bcbio_NA12878-chr20_get.cwl.json` to download files, data, and tools required for running the workflow and submitting results.
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl bcbio_NA12878-chr20_get.cwl.json
```

#### 4. Run main workflow
Use `cwltool` to run the workflow, as defined in `NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20.cwl` and parameterized by `NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20-samples.json`:
```shell
nohup cwltool --non-strict NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20.cwl NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20-samples.json
```

#### 5. Run workflow checker tool
To verify workflow results before submission, use `cwltool` to run the checker as follows:
```shell
cwltool --non-strict bcbio_NA12878-chr20_checker.cwl bcbio_NA12878-chr20_checker.json
```

#### 6. Submit workflow outputs
Modify `team_name` and `parent_id` in `bcbio_NA12878-chr20_submit.json` as shown below, assuming Synapse credentials file is named `.synapseConfig` and located in `~/bcbio_chr20_run.
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""BioGenLink"",
    ""eval_id"": ""9605240"",
    ""file"": [
        {
            ""class"": ""File"",
            ""path"": ""grading-summary-NA12878-chr20.csv""
        }
    ],
    ""parent_id"": ""syn11565409""
}

```

Submit outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl bcbio_NA12878-chr20_submit.json
```

Stop Docker if desired.
```shell
stop_docker
```",9657917
bcbio_NA12878-chr20,9657918_report.md,"### Workflow description

```YAML
contributor: ""Brad Chapman""
workflow_handle: ""bcbio_NA12878-chr20""
input_handle: ""NA12878 chr20""
```

### Participant information
```YAML
name: ""Ben Ernest""
institution: ""Digicon Corporation""
```

### Submission overview
```YAML
date_accessed: ""2017-12-12"" 
platform: ""Dockstore"" 
workflow_type: ""CWL"" 
runner_version: ""1.0.20170217172322"" 
docker_version: ""17.09.0-ce"" 
environment: ""BioGenLink"" 
env_cpus: ""1"" 
env_memory: ""8Gb"" 
env_disk: ""5Tb"" 
```

### Steps
#####This workflow was run using the [BioGenLink](http://digicon.com/biogenlink.html) platform from [Digicon](http://digicon.com/).  Click [here](http://digicon.com/biogenlink.html) or [email us](mailto:biogenlink@digiconasp.com) for more information. 

#### **Setup**

##### Create synapse credentials file.  
This only needs to be done once, and the credentials file can be used for each workflow.
1. Log into BioGenLink.  [Click here](http://digicon.com/biogenlink.html) or [email us](mailto:biogenlink@digiconasp.com) for more information. 
${image?fileName=login%5Fscreen%5Fempty%2E2017%2D12%2D19%2Epng&align=None&scale=75&responsive=true}

2. In the **files** tab, right-click on any directory in the file system, select `Create File`, give the file a name (e.g., ""synapse_config.txt""), and click `Preview` to edit the file.  
${image?fileName=create%5Ffile%5Fpreview%2E2017%2D12%2D19%2Epng&align=None&scale=75&responsive=true}

Enter the following information in the file and save it by clicking **Save** (the disk button just above the text area).
```
[authentication]
username: email
password: password
[cache]
location: biodtfs/path/to/cache
```
**Note:** the cache directory is used by synapseClient for temporary files, and we must specify it in BioGenLink to avoid permissions errors. It can be be any directory the user chooses, even a non-existing one as long as the parent directory is valid.  It is suggested to create a working directory for each workflow and keep this file in a parent directory outside of the working directories.  

#### **Provision workflow files**

1. Create a working directory.  
    - Right-click on any directory in the file system, select `Create Folder`, and enter a name for the working directory (e.g., `bcbio_workflow`).

2. Run the `Synapse get` tool.
    - In the **tools** tab, find and select the `Synapse get` tool.  It can be found by keyword search or browsing to `Synapse/All/Synapse get`.  Double-clicking (shown below) the tool will open it in the workspace for editing and browsing documentation and will display the menu for providing inputs and running the tool.
${image?fileName=synapse%5Fget%5Fopen%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
    - In the `Synapse IDs` field, enter the Synapse IDs for files to be downloaded.  In this case, the synapse IDs include the following, which correspond to `bcbio_NA12878-chr20_get.cwl.json`, `dockstore-tool-synapse-submit.cwl`, and `dockstore-tool-synapse-get.cwl`:
```shell
syn9819444 
syn9770802   
syn9732885   
```   
${image?fileName=synapse%5Fget%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
    - Drag and drop the synapse credentials file (e.g., `synapse_config.txt`) from the file system into the field called `Synapse config file`.
    - Drag and drop the working directory into the field called `Output directory`.
    - Run the tool by clicking `Quick Launch`.

#### **Run the workflow**
- Run the `Dockstore launch` tool.
    1. In the **Tools** tab, find and select the `Dockstore launch` tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore launch`.  
${image?fileName=dockstore%5Flaunch%2E2018%2D01%2D04%2Epng&align=None&scale=75&responsive=true}
    2. Drag and drop the `NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20.cwl` and `NA12878-platinum-chr20-workflow/main-NA12878-platinum-chr20-samples.json` files from the working directory into the fields labeled `CWL file` and `JSON file`, respectively.  Drag and drop the parent directory (e.g., `bcbio_workflow`) into the field labeled `Parent directory`.   
    3. Click `Quick Launch`.

#### **Validate the results**
- Run the `Dockstore checker` tool.
1. In the **tools** tab, find and select the `Dockstore checker` tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore checker`.  
${image?fileName=dockstore%5Fchecker%2E2017%2D12%2D25%2Epng&align=None&scale=75&responsive=true}
  2. Drag and drop the `bcbio_NA12878-chr20_checker.cwl` and `bcbio_NA12878-chr20_checker.json` files from the working directory into the fields labeled `Checker CWL file` and `Checker JSON file`, respectively.  
  3. Click `Quick Launch`.
  4. Verify that the workflow ran successfully by opening the `results.json` file and confirming that the `Overall` field is equal to `true`.
${image?fileName=results%5Fjson%2E2017%2D12%2D25%2Epng&align=None&scale=75&responsive=true}

#### **Submit the results to Synapse**
- Run the `Dockstore submit` tool.
  1. In the **Tools** tab, find and select the `Dockstore submit` tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore submit`.  
${image?fileName=dockstore%5Fsubmit%2E2017%2D12%2D26%2Epng&align=None&scale=75&responsive=true}
  2. Drag and drop the `bcbio_NA12878-chr20_submit.json` file into the field labeled `Submit JSON file`.  
  3. Enter a team name and the Synapse parent ID into the corresponding fields.  
  4. Drag and drop the synapse credentials file (e.g., `synapse_config.txt`) into the field labeled `Synapse config file`.
  5. Click `Quick Launch`.
---",9657918
biowardrobe_chipseq_se,9615868_report.md,"## BioWardrobe ChIP-Seq

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Michael Kotliar""
workflow_handle: ""biowardrobe_chipseq_se""
input_handle: ""SRR1198790""
```

The following description is provided by the workflow author:
> This workflow from BioWardrobe runs basic analysis of single read ChIP-Seq data. Workflow starts with BowTie alignment to a reference genome resulting in an unsorted SAM file. The SAM file is then sorted and indexed to obtain with samtools a BAM file and a BAI index. Depending on workflow’s input parameters the indexed and sorted BAM file can be processed to remove duplicate reads. If the duplicate removal is performed, sorting and indexing are repeated. Next MACS2 is used to call peaks and to estimate fragment size. If the fragment size is less than 80, then the peak calling is repeated with forced fixed fragment size (150). Fragment size can also be specified as an input parameter.  In the last few steps the coverage by estimated fragments is calculated from the BAM file and is output in bigWig format. The pipeline also reports statistics such as read quality, peak number, base frequency and other troubleshooting information using tools such as fastx, bamtools. Logs are saved in the working directory.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Denis Yuen"" # your name here
institution: ""OICR"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""dockstore"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.2.5"" # indicate executor version used
docker_version: ""17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""64GB"" # indicate available RAM in environment
env_disk: ""400GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

On a personal desktop, I installed Docker, pip, cwltool, and the Dockstore command-line helper using a procedure similar to https://github.com/denis-yuen/2017-cloud-workflows-misc/blob/master/install-and-run-with-dockstore.md

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir biowardrobe_files
cd biowardrobe_files
cp ~/.synapseConfig .
```

#### 2. Download required files

I downloaded hello_world_get.json from the website. I then got the synapse-submit and synapse-get commands from Dockstore. 
```shell
dockstore tool cwl --entry quay.io/ga4gh-dream/dockstore-tool-synapse-submit > dockstore-tool-synapse-submit.cwl
dockstore tool cwl --entry quay.io/ga4gh-dream/dockstore-tool-synapse-get > dockstore-tool-synapse-get.cwl
```

#### 3. Modify path for download 

I changed biowardrobe_chipseq_se_get.cwl.json to 
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""synapse_id"": ""syn9772359"",
    ""recursive"": true,
    ""output"": {
        ""class"": ""Directory"",
        ""path"": ""/home/dyuen/ga4gh-dream2/biowardrobe_files/""
    }
}
```

#### 4. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `hello_world_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
dockstore tool launch --local-entry dockstore-tool-synapse-get.cwl --json biowardrobe_chipseq_se_get.cwl.json 
```

#### 5. Run main workflow

I used the `dockstore cli` to run the workflow, as defined in `hello_world.cwl` and parameterized by `hello_world.cwl.json`:
```shell
dockstore workflow launch --local-entry biowardrobe_chipseq_se.cwl --json biowardrobe_chipseq_se.json
```

#### 6. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows (file provisioning issues disallow use of Dockstore CLI, for this version):
```shell
cwltool --debug --non-strict biowardrobe_chipseq_se_checker.cwl biowardrobe_chipseq_se_checker.json
```

#### 7. Submit workflow outputs

I modified the parameters in `biowardrobe_chipseq_se_submit.cwl.json` as follows:
```JSON
{
  ""config_file"": {
    ""class"": ""File"",
    ""path"": "".synapseConfig""
  },
  ""team_name"": ""Dockstore team"",
  ""eval_id"": ""9604287"",
  ""file"": [
    {""class"": ""File"", ""path"": ""SRR1198790.fastq.fastxstat""},
    {""class"": ""File"", ""path"": ""SRR1198790.sam.log""},
    {""class"": ""File"", ""path"": ""SRR1198790.sam.stat""},
    {""class"": ""File"", ""path"": ""SRR1198790.sorted.bam""},
    {""class"": ""File"", ""path"": ""SRR1198790.sorted.bam.bai""},
    {""class"": ""File"", ""path"": ""SRR1198790.sorted.sorted.bigwig""},
    {""class"": ""File"", ""path"": ""SRR1198790.sorted_peaks.xls""}
  ],
  ""parent_id"": ""syn9961864""
}
```

Finally, I submitted outputs using `dockstore cli` and `dockstore-tool-synapse-submit.cwl`:
```shell
dockstore tool launch --local-entry dockstore-tool-synapse-submit.cwl --json biowardrobe_chipseq_se_submit.cwl.json
```

---",9615868
biowardrobe_chipseq_se,9621027_report.md,"## BioWardrobe ChIP-Seq

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Michael Kotliar""
workflow_handle: ""biowardrobe_chipseq_se""
input_handle: ""SRR1198790""
```

The following description is provided by the workflow author:
> This workflow from BioWardrobe runs basic analysis of single read ChIP-Seq data. Workflow starts with BowTie alignment to a reference genome resulting in an unsorted SAM file. The SAM file is then sorted and indexed to obtain with samtools a BAM file and a BAI index. Depending on workflow’s input parameters the indexed and sorted BAM file can be processed to remove duplicate reads. If the duplicate removal is performed, sorting and indexing are repeated. Next MACS2 is used to call peaks and to estimate fragment size. If the fragment size is less than 80, then the peak calling is repeated with forced fixed fragment size (150). Fragment size can also be specified as an input parameter.  In the last few steps the coverage by estimated fragments is calculated from the BAM file and is output in bigWig format. The pipeline also reports statistics such as read quality, peak number, base frequency and other troubleshooting information using tools such as fastx, bamtools. Logs are saved in the working directory.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Jeltje van Baren""
institution: ""UCSC""
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""cwltool""
workflow_type: ""CWL""
runner_version: ""1.0.20170704143016""
docker_version: ""1.12.1, build 23cf638""
environment: ""UCSC podcloud VM Ubuntu 16:04""
env_cpus: ""31""
env_memory: ""252 G""
env_disk: ""1 Tb""
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""500Gb""
```

### Steps

1. Used link on [3.3 - Access Data and Tools](https://www.synapse.org/#!Synapse:syn8507134/wiki/416015) to download [biowardrobe_chipseq_se_get.cwl.json](https://www.synapse.org/Portal/filehandleassociation?associatedObjectId=9909809&associatedObjectType=FileEntity&fileHandleId=15588003&xsrfToken=5D9B3FA24C29121558A6DF4048E46A16)

2. From the same page, downloaded [dockstore-tool-synapse-get.cwl](https://www.synapse.org/Portal/filehandleassociation?associatedObjectId=9770802&associatedObjectType=FileEntity&fileHandleId=15691607&xsrfToken=F397E2A807CC92157AEC380011771547) and [dockstore-tool-synapse-submit.cwl](https://www.synapse.org/Portal/filehandleassociation?associatedObjectId=9732885&associatedObjectType=FileEntity&fileHandleId=16683837&xsrfToken=F397E2A807CC92157AEC380011771547):

      dockstore-tool-synapse-get.cwl pulls quay.io/ga4gh-dream/dockstore-tool-synapse-get:1.6.2.dev--2
      dockstore-tool-synapse-submit.cwl pulls  quay.io/ga4gh-dream/dockstore-tool-synapse-submit:1.7.1--1

3. Retrieved data:

    source ~/venv/cwl/bin/activate
    export TMPDIR=/mnt/tempdir
    tmpstuff=""--tmpdir-prefix=/mnt/tempdir --tmp-outdir-prefix=/mnt/tempdir""
    ln -s ~/.synapse.key .synapseConfig
    cwltool $tmpstuff --non-strict dockstore-tool-synapse-get.cwl biowardrobe_chipseq_se_get.cwl.json

4. Ran workflow:

    cwltool $tmpstuff --non-strict biowardrobe_chipseq_se.cwl  biowardrobe_chipseq_se.json

5. Created a synapse project for this workflow [biowardrobe_chipseq_se_GA4GH_cwl: syn10160387](https://www.synapse.org/#!Synapse:syn10160387), updated biowardrobe_chipseq_se_submit.cwl.json with this information and submitted the output:

    cwltool $tmpstuff --non-strict dockstore-tool-synapse-submit.cwl biowardrobe_chipseq_se_submit.cwl.json

Contents of biowardrobe_chipseq_se_submit.cwl.json:
```
{
  ""config_file"": {
    ""class"": ""File"",
    ""path"": "".synapseConfig""
  },
  ""team_name"": """",
  ""eval_id"": ""9604287"",
  ""file"": [
    {""class"": ""File"", ""path"": ""SRR1198790.fastq.fastxstat""},
    {""class"": ""File"", ""path"": ""SRR1198790.sam.log""},
    {""class"": ""File"", ""path"": ""SRR1198790.sam.stat""},
    {""class"": ""File"", ""path"": ""SRR1198790.sorted.bam""},
    {""class"": ""File"", ""path"": ""SRR1198790.sorted.bam.bai""},
    {""class"": ""File"", ""path"": ""SRR1198790.sorted.sorted.bigwig""},
    {""class"": ""File"", ""path"": ""SRR1198790.sorted_peaks.xls""}
  ],
  ""parent_id"": ""syn10160387""
}
```
",9621027
biowardrobe_chipseq_se,9622397_report.md,"## BioWardrobe ChIP-Seq

### Workflow description

```YAML
contributor: ""Michael Kotliar""
workflow_handle: ""biowardrobe_chipseq_se""
input_handle: ""SRR1198790""
```

The following description is provided by the workflow author:
> This workflow from BioWardrobe runs basic analysis of single read ChIP-Seq data. Workflow starts with BowTie alignment to a reference genome resulting in an unsorted SAM file. The SAM file is then sorted and indexed to obtain with samtools a BAM file and a BAI index. Depending on workflow’s input parameters the indexed and sorted BAM file can be processed to remove duplicate reads. If the duplicate removal is performed, sorting and indexing are repeated. Next MACS2 is used to call peaks and to estimate fragment size. If the fragment size is less than 80, then the peak calling is repeated with forced fixed fragment size (150). Fragment size can also be specified as an input parameter.  In the last few steps the coverage by estimated fragments is calculated from the BAM file and is output in bigWig format. The pipeline also reports statistics such as read quality, peak number, base frequency and other troubleshooting information using tools such as fastx, bamtools. Logs are saved in the working directory.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

### Participant information

```YAML
name: ""Lon Blauvelt""
institution: ""UCSC""
```

### Submission overview

```YAML
platform: ""cwltool""
workflow_type: ""CWL""
runner_version: ""1.0.20170217172322""
docker_version: ""17.06.0-ce, build 02c1d87""
environment: ""EC2""
env_cpus: ""8""
env_memory: ""32 Gb""
env_disk: ""50 Gb""
```
> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""EC2"" 
env_cpus_ex: ""32""
env_memory_ex: ""244Gb""
env_disk_ex: ""elastic""
```

### Steps

#### 1. Set up environment

*I launched an EC2 instance of type `t2.2xlarge` with one node, mounted a 50 Gb EFS volume.*

I used the following to update the instance:

```shell
sudo apt-get update
sudo apt-get -y upgrade
sudo apt-get -y dist-upgrade
```

Install docker:

```shell
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
sudo add-apt-repository ""deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable""
sudo apt-get update
apt-cache policy docker-ce
sudo apt-get install -y docker-ce
sudo usermod -aG docker ${USER}
sudo su - ${USER}
```

Install pip, a virtualenv, and the requisite pip installs (cwltool, schema-salad, avro, synapse, and html5lib):

```shell
sudo apt install -y python-pip
sudo pip install --upgrade pip
sudo pip install virtualenv
virtualenv --python /usr/bin/python2 cwl
source /home/ubuntu/cwl/bin/activate
pip install cwl-runner cwltool==1.0.20170217172322 schema-salad==2.6.20170630075932 avro==1.8.1  ruamel.yaml==0.14.12 --no-cache-dir
pip install synapseclient --no-cache-dir
pip install html5lib
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:

```shell
mkdir syn
cd syn
nano syn-login.synapseConfig
[PASTE] username & password
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **biowardrobe_chipseq_se** workflow, and then modify the get file:
```shell
synapse get -r syn9689286
[PASTE] username & password
synapse get -r syn9689284
[PASTE] username & password

nano biowardrobe_chipseq_se_get.cwl.json
[PASTE] /home/ubuntu/syn/syn-login.synapseConfig
```

#### 4. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `biowardrobe_chipseq_se_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.

```shell
cwltool --tmpdir-prefix tmp/ --cachedir cache/ --non-strict dockstore-tool-synapse-get.cwl biowardrobe_chipseq_se_get.cwl.json
```

#### 5. Run main workflow

I again used `cwltool` to run the workflow, as defined in `biowardrobe_chipseq_se.cwl` and parameterized by `biowardrobe_chipseq_se.cwl.json`:
```
cwltool --cachedir cache/ --tmpdir-prefix tmp/ --non-strict biowardrobe_chipseq_se.cwl biowardrobe_chipseq_se.cwl.json
```

#### 6. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool --non-strict biowardrobe_chipseq_se_checker.cwl biowardrobe_chipseq_se_checker.cwl.json
```

#### 7. Submit workflow outputs

I modified the parameters in `biowardrobe_chipseq_se_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": ""/home/ubuntu/syn/syn-login.synapseConfig""
    },
    ""team_name"": ""UCSC GA4GH-DREAM Challenge Team"",
    ""eval_id"": ""9604596"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""123e4567-e89b-12d3-a456-426655440000.db""
        }
    ],
    ""parent_id"": ""syn10182019""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool dockstore-tool-synapse-submit.cwl biowardrobe_chipseq_se_submit.cwl.json
```",9622397
biowardrobe_chipseq_se,9622485_report.md,"## BioWardrobe ChIP-Seq

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Michael Kotliar""
workflow_handle: ""biowardrobe_chipseq_se""
input_handle: ""SRR1198790""
```

The following description is provided by the workflow author:
> This workflow from BioWardrobe runs basic analysis of single read ChIP-Seq data. Workflow starts with BowTie alignment to a reference genome resulting in an unsorted SAM file. The SAM file is then sorted and indexed to obtain with samtools a BAM file and a BAI index. Depending on workflow’s input parameters the indexed and sorted BAM file can be processed to remove duplicate reads. If the duplicate removal is performed, sorting and indexing are repeated. Next MACS2 is used to call peaks and to estimate fragment size. If the fragment size is less than 80, then the peak calling is repeated with forced fixed fragment size (150). Fragment size can also be specified as an input parameter.  In the last few steps the coverage by estimated fragments is calculated from the BAM file and is output in bigWig format. The pipeline also reports statistics such as read quality, peak number, base frequency and other troubleshooting information using tools such as fastx, bamtools. Logs are saved in the working directory.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Michael Kotliar""
institution: ""CCHMC, Barski Lab""
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""cwltool""
workflow_type: ""CWL""
runner_version: ""1.0.20170217172322""
docker_version: ""17.06.0-ce""
environment: ""local""
env_cpus: ""4""
env_memory: ""16GB""
env_disk: ""500GB""
```

### Steps

### Setting up environment
Install `cwltool` (version 1.0.20170217172322), `html5lib` and  `synapseclient`
```
pip install cwltool==1.0.20170217172322
pip install html5lib
pip install synapseclient
```
Create empty folder for workflow running
```
mkdir biowardrobe_chipseq_se
cd biowardrobe_chipseq_se
```
Create Synapse credentials file `.synapseConfig`, put there Synapse ID and password
```
[authentication]
username: user@usermail.org
password: <user-password>
```
### Downloading required files
Download tools to fetch workflow input data
```
synapse -c .synapseConfig get syn10204916  # biowardrobe_chipseq_se_get.json
synapse -c .synapseConfig get syn9770802   # dockstore-tool-synapse-get.cwl
synapse -c .synapseConfig get syn9732885   # dockstore-tool-synapse-submit.cwl
```
Download workflow input data
```
cwltool --debug --non-strict dockstore-tool-synapse-get.cwl biowardrobe_chipseq_se_get.json
```
Wait until downloading is finished

### Running workflow
Update `threads ` field to 4 in `biowardrobe_chipseq_se.json` file
Run the workflow
```
cwltool --debug --non-strict biowardrobe_chipseq_se.cwl biowardrobe_chipseq_se.json
```
### Validating results
Run checker tool
```
cwltool --debug --non-strict biowardrobe_chipseq_se_checker.cwl biowardrobe_chipseq_se_checker.json
```
Check results
```
cat results.json
``` 
```json
{
    ""steps"": {
        ""macs2_callpeak_forced"": ""true"", 
        ""macs2_callpeak"": ""true"", 
        ""samtools_sort_index_after_rmdup"": ""true"", 
        ""bam_to_bigwig"": ""true"", 
        ""macs_island_count"": ""true"", 
        ""samtools_sort_index"": ""true"", 
        ""bowtie_aligner"": ""true"", 
        ""samtools_rmdup"": ""true"", 
        ""fastx_quality_stats"": ""true"", 
        ""bamtools_stats"": ""true""
    }, 
    ""overall"": ""true""
}
```
### Submitting results
Update `biowardrobe_chipseq_se_submit.cwl.json` with correct
`team_name` - the name of your team in plain text format (e.g., ""GA4GH-Sage Contenders"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
Run the tool
```
cwltool --debug --non-strict dockstore-tool-synapse-submit.cwl biowardrobe_chipseq_se_submit.json
```
***Running time:*** 15 min  
***Disk usage:*** 4.0G",9622485
biowardrobe_chipseq_se,9622519_report.md,"## BioWardrobe ChIP-Seq

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Michael Kotliar""
workflow_handle: ""biowardrobe_chipseq_se""
input_handle: ""SRR1198790""
```

The following description is provided by the workflow author:
> This workflow from BioWardrobe runs basic analysis of single read ChIP-Seq data. Workflow starts with BowTie alignment to a reference genome resulting in an unsorted SAM file. The SAM file is then sorted and indexed to obtain with samtools a BAM file and a BAI index. Depending on workflow’s input parameters the indexed and sorted BAM file can be processed to remove duplicate reads. If the duplicate removal is performed, sorting and indexing are repeated. Next MACS2 is used to call peaks and to estimate fragment size. If the fragment size is less than 80, then the peak calling is repeated with forced fixed fragment size (150). Fragment size can also be specified as an input parameter.  In the last few steps the coverage by estimated fragments is calculated from the BAM file and is output in bigWig format. The pipeline also reports statistics such as read quality, peak number, base frequency and other troubleshooting information using tools such as fastx, bamtools. Logs are saved in the working directory.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Abraham Chavez"" # your name here
institution: ""UCSC"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170217172322"" # indicate executor version used
docker_version: ""17.06.0-ce-rc4"" # from `docker --version`
environment: ""EC2"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""32"" # indicate number of cores in environment
env_memory: ""240"" # indicate available RAM in environment
env_disk: ""200"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""500Gb""
```

### Steps

_____________________

### Setting up environment

If you have not set up your environment and install dependencies like **cwltool**, **dockstore**, **java** and so on
I recommend you follow [**this**](https://www.synapse.org/#!Synapse:syn10220609) instructions.

Create empty folder for workflow running
```
mkdir biowardrobe_chipseq_se_cwltool
cd biowardrobe_chipseq_se_cwltool
cp ../.synapseConfig .
```
Information about `.synapseConfig` can be found [**here**](https://www.synapse.org/#!Synapse:syn8507133/wiki/451408)

### Downloading required files
Download tools to fetch workflow input data
```
synapse -c .synapseConfig get syn10204916  # biowardrobe_chipseq_se_get.json
synapse -c .synapseConfig get syn9770802   # dockstore-tool-synapse-get.cwl
synapse -c .synapseConfig get syn9732885   # dockstore-tool-synapse-submit.cwl
```
Download workflow input data
```
cwltool --debug --non-strict dockstore-tool-synapse-get.cwl biowardrobe_chipseq_se_get.json
```
Wait until downloading is finished

### Running workflow
Update `threads ` field to 4 in `biowardrobe_chipseq_se.json` file
Run the workflow
```
cwltool --debug --non-strict biowardrobe_chipseq_se.cwl biowardrobe_chipseq_se.json
```
### Validating results
Run checker tool
```
cwltool --debug --non-strict biowardrobe_chipseq_se_checker.cwl biowardrobe_chipseq_se_checker.json
```
Check results
```
cat results.json
``` 
```json
{
    ""steps"": {
        ""macs2_callpeak_forced"": ""true"", 
        ""macs2_callpeak"": ""true"", 
        ""samtools_sort_index_after_rmdup"": ""true"", 
        ""bam_to_bigwig"": ""true"", 
        ""macs_island_count"": ""true"", 
        ""samtools_sort_index"": ""true"", 
        ""bowtie_aligner"": ""true"", 
        ""samtools_rmdup"": ""true"", 
        ""fastx_quality_stats"": ""true"", 
        ""bamtools_stats"": ""true""
    }, 
    ""overall"": ""true""
}
```
### Submitting results
Update `biowardrobe_chipseq_se_submit.cwl.json` with correct
`team_name` - the name of your team in plain text format (e.g., ""GA4GH-Sage Contenders"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
Run the tool
```
cwltool --debug --non-strict dockstore-tool-synapse-submit.cwl biowardrobe_chipseq_se_submit.json
```
***Running time:*** 15 min  
***Disk usage:*** 4.0G",9622519
biowardrobe_chipseq_se,9622676_report.md,"## BioWardrobe ChIP-Seq


### Workflow description

```YAML
contributor: ""Michael Kotliar""
workflow_handle: ""biowardrobe_chipseq_se""
input_handle: ""SRR1198790""
```

The following description is provided by the workflow author:
> This workflow from BioWardrobe runs basic analysis of single read ChIP-Seq data. Workflow starts with BowTie alignment to a reference genome resulting in an unsorted SAM file. The SAM file is then sorted and indexed to obtain with samtools a BAM file and a BAI index. Depending on workflow’s input parameters the indexed and sorted BAM file can be processed to remove duplicate reads. If the duplicate removal is performed, sorting and indexing are repeated. Next MACS2 is used to call peaks and to estimate fragment size. If the fragment size is less than 80, then the peak calling is repeated with forced fixed fragment size (150). Fragment size can also be specified as an input parameter.  In the last few steps the coverage by estimated fragments is calculated from the BAM file and is output in bigWig format. The pipeline also reports statistics such as read quality, peak number, base frequency and other troubleshooting information using tools such as fastx, bamtools. Logs are saved in the working directory.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Bogdan Gavrilovic"" # your name here
institution: ""Seven Bridges Genomics"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""rabix"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.0"" # indicate executor version used
docker_version: ""17.06.0-ce"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""4"" # indicate number of cores in environment
env_memory: ""16GB"" # indicate available RAM in environment
env_disk: ""200GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

#####1. [Install rabix](https://github.com/rabix/bunny#installing) on your machine and set environment variable $BUNNY. You need docker and java installed to run rabix:
```shell
wget https://github.com/rabix/bunny/releases/download/v1.0.0/rabix-1.0.0.tar.gz -O rabix-1.0.0.tar.gz && tar -xvf rabix-1.0.0.tar.gz
export BUNNY=$PWD/rabix-cli-1.0.0/rabix
```
#####2. If you've not already retrieved the CWL and data with synapse-get, you can use the [Synapse python client](https://github.com/Sage-Bionetworks/synapsePythonClient#installation):
```shell
pip install synapseclient
synapse get -r syn9772359 # biowardrobe workflow, tools and input files
synapse get syn9732885   # dockstore-tool-synapse-submit.cwl
```
#####3. Make CWL modifications
Minor CWL modifications need to be made to make the workflow runnable using rabix. The reason for this is that some tool definitions are not in line with the CWL specification, or better said CWL specification does not provide a definite description on how the execution should behave in certain cases. The modified tools are:
- In bamtools-stats.cwl 
- In samtools-sort-index.cwl

Grab the modified tools:
```shell
synapse get -r syn10245582
```
Replace the original files in `tools/` folder with the downloaded modified versions.
>NOTE: The modified version of the tools will also work with cwl-tool
#####4. Run the workflow using rabix executor on your machine by typing in the terminal: $BUNNY <app> <inputs>
For example:
```shell
$BUNNY ./biowardrobe_chipseq_se.cwl ./biowardrobe_chipseq_se.json
```
### Validating results
Modify `biowardrobe_chipseq_se_checker.json` to include the path to the requested output file and run checker tool
```shell
$BUNNY biowardrobe_chipseq_se_checker.cwl biowardrobe_chipseq_se_checker.json
```
Check results
```shell
cat ./path/to/results.json
``` 
```json
{
    ""steps"": {
        ""macs2_callpeak_forced"": ""true"", 
        ""macs2_callpeak"": ""true"", 
        ""samtools_sort_index_after_rmdup"": ""true"", 
        ""bam_to_bigwig"": ""true"", 
        ""macs_island_count"": ""true"", 
        ""samtools_sort_index"": ""true"", 
        ""bowtie_aligner"": ""true"", 
        ""samtools_rmdup"": ""true"", 
        ""fastx_quality_stats"": ""true"", 
        ""bamtools_stats"": ""true""
    }, 
    ""overall"": ""true""
}
```
### Submitting results
- Copy the synapseConfig file to the current working directory.
- Update `biowardrobe_chipseq_se_submit.cwl.json` with correct
`team_name` - the name of your team in plain text format (e.g., ""GA4GH-Sage Contenders"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
`file` - paths to output files
Run the tool
```shell
$BUNNY dockstore-tool-synapse-submit.cwl biowardrobe_chipseq_se_submit.json
```",9622676
biowardrobe_chipseq_se,9622777_report.md,"## BioWardrobe ChIP-Seq

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Michael Kotliar""
workflow_handle: ""biowardrobe_chipseq_se""
input_handle: ""SRR1198790""
```

The following description is provided by the workflow author:
> This workflow from BioWardrobe runs basic analysis of single read ChIP-Seq data. Workflow starts with BowTie alignment to a reference genome resulting in an unsorted SAM file. The SAM file is then sorted and indexed to obtain with samtools a BAM file and a BAI index. Depending on workflow’s input parameters the indexed and sorted BAM file can be processed to remove duplicate reads. If the duplicate removal is performed, sorting and indexing are repeated. Next MACS2 is used to call peaks and to estimate fragment size. If the fragment size is less than 80, then the peak calling is repeated with forced fixed fragment size (150). Fragment size can also be specified as an input parameter.  In the last few steps the coverage by estimated fragments is calculated from the BAM file and is output in bigWig format. The pipeline also reports statistics such as read quality, peak number, base frequency and other troubleshooting information using tools such as fastx, bamtools. Logs are saved in the working directory.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Michael Kotliar""
institution: ""CCHMC, Barski Lab""
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""cwltool""
workflow_type: ""CWL""
runner_version: ""1.0.20170217172322""
docker_version: ""17.06.0-ce""
environment: ""local""
env_cpus: ""4"" 
env_memory: ""16GB""
env_disk: ""500GB""
```

### Steps

### Setting up environment
Install `cwltool` (version 1.0.20170217172322), `html5lib` and  `synapseclient`
```
pip install cwltool==1.0.20170217172322
pip install html5lib
pip install synapseclient
```
Create empty folder for workflow running
```
mkdir biowardrobe_chipseq_se
cd biowardrobe_chipseq_se
```
Create Synapse credentials file `.synapseConfig`, put there Synapse ID and password
```
[authentication]
username: user@usermail.org
password: <user-password>
```
### Downloading required files
Download tools to fetch workflow input data
```
synapse -c .synapseConfig get syn10204916  # biowardrobe_chipseq_se_get.json
synapse -c .synapseConfig get syn9770802   # dockstore-tool-synapse-get.cwl
synapse -c .synapseConfig get syn9732885   # dockstore-tool-synapse-submit.cwl
```
Download workflow input data
```
cwltool --debug --non-strict dockstore-tool-synapse-get.cwl biowardrobe_chipseq_se_get.json
```
Wait until downloading is finished

### Running workflow
Update `threads ` field to 4 in `biowardrobe_chipseq_se.json` file
Run the workflow
```
cwltool --debug --non-strict biowardrobe_chipseq_se.cwl biowardrobe_chipseq_se.json
```
### Validating results
Run checker tool
```
cwltool --debug --non-strict biowardrobe_chipseq_se_checker.cwl biowardrobe_chipseq_se_checker.json
```
Check results
```
cat results.json
``` 
```json
{
    ""steps"": {
        ""macs2_callpeak_forced"": ""true"", 
        ""macs2_callpeak"": ""true"", 
        ""samtools_sort_index_after_rmdup"": ""true"", 
        ""bam_to_bigwig"": ""true"", 
        ""macs_island_count"": ""true"", 
        ""samtools_sort_index"": ""true"", 
        ""bowtie_aligner"": ""true"", 
        ""samtools_rmdup"": ""true"", 
        ""fastx_quality_stats"": ""true"", 
        ""bamtools_stats"": ""true""
    }, 
    ""overall"": ""true""
}
```
### Submitting results
Update `biowardrobe_chipseq_se_submit.cwl.json` with correct
`team_name` - the name of your team in plain text format (e.g., ""GA4GH-Sage Contenders"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
Run the tool
```
cwltool --debug --non-strict dockstore-tool-synapse-submit.cwl biowardrobe_chipseq_se_submit.json
```
***Running time:*** 15 min  
***Disk usage:*** 4.0G",9622777
biowardrobe_chipseq_se,9623380_report.md,"## BioWardrobe ChIP-Seq

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Michael Kotliar""
workflow_handle: ""biowardrobe_chipseq_se""
input_handle: ""SRR1198790""
```

The following description is provided by the workflow author:
> This workflow from BioWardrobe runs basic analysis of single read ChIP-Seq data. Workflow starts with BowTie alignment to a reference genome resulting in an unsorted SAM file. The SAM file is then sorted and indexed to obtain with samtools a BAM file and a BAI index. Depending on workflow’s input parameters the indexed and sorted BAM file can be processed to remove duplicate reads. If the duplicate removal is performed, sorting and indexing are repeated. Next MACS2 is used to call peaks and to estimate fragment size. If the fragment size is less than 80, then the peak calling is repeated with forced fixed fragment size (150). Fragment size can also be specified as an input parameter.  In the last few steps the coverage by estimated fragments is calculated from the BAM file and is output in bigWig format. The pipeline also reports statistics such as read quality, peak number, base frequency and other troubleshooting information using tools such as fastx, bamtools. Logs are saved in the working directory.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Michael Kotliar""
institution: ""CCHMC, Barski Lab""
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""CWL-Airflow""
workflow_type: ""CWL""
runner_version: ""0.0.1""
docker_version: ""1.12.6""
environment: ""local""
env_cpus: ""64""
env_memory: ""251Gb""
env_disk: ""230Gb""
```

### Steps

### Setting up environment
Install CWL-Airflow
```
  cd /home/michael_kotliar/workspaces/airflow/
  git clone https://github.com/Barski-lab/cwl-airflow.git
  cd cwl-airflow
  git checkout v0.0.1
  pip install -e .
```
Run mysql-server:5.7 docker container
```
  cd /home/michael_kotliar/temp/cwl_airflow
  mkdir database
  docker pull mysql/mysql-server:5.7
  docker run -v /home/michael_kotliar/temp/cwl_airflow/database:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=airflow -e MYSQL_DATABASE=airflow -e MYSQL_USER=airflow -e MYSQL_PASSWORD=airflow -p 6603:3306 -d mysql/mysql-server:5.7
```
Update Airflow configuration file `/home/michael_kotliar/airflow/airflow.cfg`
```
  executor = LocalExecutor
  sql_alchemy_conn = mysql://airflow:airflow@127.0.0.1:6603/airflow
```
Install synapse client
```
  pip install synapseclient
```
Create empty folder for workflow running
```
  cd /home/michael_kotliar/temp/cwl_airflow/
  mkdir biowardrobe_chipseq_se
```
Create Synapse credentials file `/home/michael_kotliar/temp/cwl_airflow/biowardrobe_chipseq_se/.synapseConfig`, put there Synapse ID and password
```
[authentication]
username: user@usermail.org
password: <user-password>
```
### Downloading required files
Download tools to fetch workflow input data
```
cd /home/michael_kotliar/temp/cwl_airflow/biowardrobe_chipseq_se
synapse -c .synapseConfig get syn10204916  # biowardrobe_chipseq_se_get.json
synapse -c .synapseConfig get syn9770802   # dockstore-tool-synapse-get.cwl
synapse -c .synapseConfig get syn9732885   # dockstore-tool-synapse-submit.cwl
```
Download workflow input data
```
cd /home/michael_kotliar/temp/cwl_airflow/biowardrobe_chipseq_se
cwltool --debug --non-strict dockstore-tool-synapse-get.cwl biowardrobe_chipseq_se_get.json
```
Wait until downloading is finished

### Running workflow
CWL-Airflow is built on the base of cwltool 1.0.20170828135420, so to be able to run workflow
correctly, the following changes in `home/michael_kotliar/temp/cwl_airflow/biowardrobe_chipseq_se/tools/samtools-sort-index.cwl` should be applied 
```
   outputs:
           if (inputs.sort_input.secondaryFiles && inputs.trigger == false){
             return inputs.sort_input.secondaryFiles;
           } else {
-            return self.location + ext();
+            return self.basename+ext();
           }
         }
```
Run the workflow
```
cwl-airflow-runner --debug biowardrobe_chipseq_se.cwl biowardrobe_chipseq_se.json
```
### Validating results
Run checker tool
```
cd /home/michael_kotliar/temp/cwl_airflow/biowardrobe_chipseq_se
cwltool --debug --non-strict biowardrobe_chipseq_se_checker.cwl biowardrobe_chipseq_se_checker.json
```
Check results
```
cat results.json
``` 
```json
{
    ""steps"": {
        ""macs2_callpeak_forced"": ""true"", 
        ""macs2_callpeak"": ""true"", 
        ""samtools_sort_index_after_rmdup"": ""true"", 
        ""bam_to_bigwig"": ""true"", 
        ""macs_island_count"": ""true"", 
        ""samtools_sort_index"": ""true"", 
        ""bowtie_aligner"": ""true"", 
        ""samtools_rmdup"": ""true"", 
        ""fastx_quality_stats"": ""true"", 
        ""bamtools_stats"": ""true""
    }, 
    ""overall"": ""true""
}
```
### Submitting results
Update `biowardrobe_chipseq_se_submit.cwl.json` with correct
`team_name` - the name of your team in plain text format (e.g., ""GA4GH-Sage Contenders"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
Run the tool
```
cwltool --debug --non-strict dockstore-tool-synapse-submit.cwl biowardrobe_chipseq_se_submit.json
```
***Running time:*** 10 min  
***Disk usage:*** 4.0G",9623380
biowardrobe_chipseq_se,9623592_report.md,"## BioWardrobe ChIP-Seq

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Michael Kotliar""
workflow_handle: ""biowardrobe_chipseq_se""
input_handle: ""SRR1198790""
```

The following description is provided by the workflow author:
> This workflow from BioWardrobe runs basic analysis of single read ChIP-Seq data. Workflow starts with BowTie alignment to a reference genome resulting in an unsorted SAM file. The SAM file is then sorted and indexed to obtain with samtools a BAM file and a BAI index. Depending on workflow’s input parameters the indexed and sorted BAM file can be processed to remove duplicate reads. If the duplicate removal is performed, sorting and indexing are repeated. Next MACS2 is used to call peaks and to estimate fragment size. If the fragment size is less than 80, then the peak calling is repeated with forced fixed fragment size (150). Fragment size can also be specified as an input parameter.  In the last few steps the coverage by estimated fragments is calculated from the BAM file and is output in bigWig format. The pipeline also reports statistics such as read quality, peak number, base frequency and other troubleshooting information using tools such as fastx, bamtools. Logs are saved in the working directory.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Abraham Chavez"" # your name here
institution: ""UCSC"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""dockstore cli"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.2.5"" # indicate executor version used
docker_version: ""17.06.0-ce-rc4"" # from `docker --version`
environment: ""EC2"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""32"" # indicate number of cores in environment
env_memory: ""240Gb"" # indicate available RAM in environment
env_disk: ""200Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""500Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

_____________________
Launched an EC2 instance of type `r4.8xlarge` with one node, mounted an EFS volume, and installed dependencies.
#####
If you have not set up your environment and install dependencies like **cwltool**, **dockstore**, **java** and so on
I recommend you follow [**this**](https://www.synapse.org/#!Synapse:syn10220609) instructions.

##### Create empty folder for workflow running
```
mkdir biowardrobe_chipseq_se
cd biowardrobe_chipseq_se
```
Create Synapse credentials file `.synapseConfig`, put there Synapse ID and password
```
[authentication]
username: user@usermail.org
password: <user-password>
```
Information about `.synapseConfig` can be found [**here**](https://www.synapse.org/#!Synapse:syn8507133/wiki/451408)

### Downloading required files
Download tools to fetch workflow input data
```
synapse -c .synapseConfig get syn10204916  # biowardrobe_chipseq_se_get.json
synapse -c .synapseConfig get syn9732885   # dockstore-tool-synapse-submit.cwl
```
Download workflow input data
```
synapse get -r syn9772359
```
Wait until downloading is finished

### Running workflow
Run the workflow
```
dockstore workflow launch --local-entry biowardrobe_chipseq_se.cwl --json biowardrobe_chipseq_se.json
```
### Validating results
Run checker tool
```
cwltool --debug --non-strict biowardrobe_chipseq_se_checker.cwl biowardrobe_chipseq_se_checker.json
```
Check results
```
cat results.json
``` 
```json
{
    ""steps"": {
        ""macs2_callpeak_forced"": ""true"", 
        ""macs2_callpeak"": ""true"", 
        ""samtools_sort_index_after_rmdup"": ""true"", 
        ""bam_to_bigwig"": ""true"", 
        ""macs_island_count"": ""true"", 
        ""samtools_sort_index"": ""true"", 
        ""bowtie_aligner"": ""true"", 
        ""samtools_rmdup"": ""true"", 
        ""fastx_quality_stats"": ""true"", 
        ""bamtools_stats"": ""true""
    }, 
    ""overall"": ""true""
}
```
### Submitting results
Update `biowardrobe_chipseq_se_submit.cwl.json` with correct
`team_name` - the name of your team in plain text format (e.g., ""GA4GH-Sage Contenders"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
Run the tool
```
cwltool --debug --non-strict dockstore-tool-synapse-submit.cwl biowardrobe_chipseq_se_submit.json
```",9623592
biowardrobe_chipseq_se,9631844_report.md,"## BioWardrobe ChIP-Seq

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Michael Kotliar""
workflow_handle: ""biowardrobe_chipseq_se""
input_handle: ""SRR1198790""
```

The following description is provided by the workflow author:
> This workflow from BioWardrobe runs basic analysis of single read ChIP-Seq data. Workflow starts with BowTie alignment to a reference genome resulting in an unsorted SAM file. The SAM file is then sorted and indexed to obtain with samtools a BAM file and a BAI index. Depending on workflow’s input parameters the indexed and sorted BAM file can be processed to remove duplicate reads. If the duplicate removal is performed, sorting and indexing are repeated. Next MACS2 is used to call peaks and to estimate fragment size. If the fragment size is less than 80, then the peak calling is repeated with forced fixed fragment size (150). Fragment size can also be specified as an input parameter.  In the last few steps the coverage by estimated fragments is calculated from the BAM file and is output in bigWig format. The pipeline also reports statistics such as read quality, peak number, base frequency and other troubleshooting information using tools such as fastx, bamtools. Logs are saved in the working directory.

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Benjamin Story"" # your name here
institution: ""EMBL"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""08/31/2017"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""cwltool 1.0.20170413194156"" # indicate executor version used
docker_version: ""1.7.1, build 786b29d"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""12"" # indicate number of cores in environment
env_memory: ""72GB"" # indicate available RAM in environment
env_disk: ""1TB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

_____________________
### Setting up environment
Skipped installing software like cwltool due to it already being present in the environment. Created empty folder for running workflow.
```
mkdir biowardrobe_chipseq_se
cd biowardrobe_chipseq_se
```
Create Synapse credentials file `.synapseConfig`, put there Synapse ID and password
```
cp ~/.synapseConfig ./
```
### Downloading required files
Download tools to fetch workflow input data
```
synapse -c .synapseConfig get syn10204916  # biowardrobe_chipseq_se_get.json
synapse -c .synapseConfig get syn9770802   # dockstore-tool-synapse-get.cwl
synapse -c .synapseConfig get syn9732885   # dockstore-tool-synapse-submit.cwl
```
Download workflow input data
```
cwltool --tmpdir-prefix tmp/ --cachedir cache/ --non-strict dockstore-tool-synapse-get.cwl biowardrobe_chipseq_se_get.json
```
Wait until downloading is finished

### Running workflow
Run the workflow
```
cwltool --tmpdir-prefix tmp/ --cachedir cache/ --non-strict biowardrobe_chipseq_se.cwl biowardrobe_chipseq_se.json
```
### Validating results
Run checker tool
```
cwltool --tmpdir-prefix tmp/ --cachedir cache/ --non-strict biowardrobe_chipseq_se_checker.cwl biowardrobe_chipseq_se_checker.json
```
Check results
```
cat results.json
``` 
```json
{
    ""steps"": {
        ""macs2_callpeak_forced"": ""true"", 
        ""macs2_callpeak"": ""true"", 
        ""samtools_sort_index_after_rmdup"": ""true"", 
        ""bam_to_bigwig"": ""true"", 
        ""macs_island_count"": ""true"", 
        ""samtools_sort_index"": ""true"", 
        ""bowtie_aligner"": ""true"", 
        ""samtools_rmdup"": ""true"", 
        ""fastx_quality_stats"": ""true"", 
        ""bamtools_stats"": ""true""
    }, 
    ""overall"": ""true""
}
```
### Submitting results
Update `biowardrobe_chipseq_se_submit.cwl.json` with correct information
```json
{
  ""config_file"": {
    ""class"": ""File"",
    ""path"": "".synapseConfig""
  },
  ""team_name"": ""EMBL GA4GH-DREAM Challenge Team"",
  ""eval_id"": ""9604287"",
  ""file"": [
    {""class"": ""File"", ""path"": ""SRR1198790.fastq.fastxstat""},
    {""class"": ""File"", ""path"": ""SRR1198790.sam.log""},
    {""class"": ""File"", ""path"": ""SRR1198790.sam.stat""},
    {""class"": ""File"", ""path"": ""SRR1198790.sorted.bam""},
    {""class"": ""File"", ""path"": ""SRR1198790.sorted.bam.bai""},
    {""class"": ""File"", ""path"": ""SRR1198790.sorted.sorted.bigwig""},
    {""class"": ""File"", ""path"": ""SRR1198790.sorted_peaks.xls""}
  ],
  ""parent_id"": ""syn10525261""
}
```
Run the submission tool
```
cwltool --non-strict dockstore-tool-synapse-submit.cwl biowardrobe_chipseq_se_submit.json
```",9631844
biowardrobe_chipseq_se,9633634_report.md,"## BioWardrobe ChIP-Seq

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Michael Kotliar""
workflow_handle: ""biowardrobe_chipseq_se""
input_handle: ""SRR1198790""
```

The following description is provided by the workflow author:
> This workflow from BioWardrobe runs basic analysis of single read ChIP-Seq data. Workflow starts with BowTie alignment to a reference genome resulting in an unsorted SAM file. The SAM file is then sorted and indexed to obtain with samtools a BAM file and a BAI index. Depending on workflow’s input parameters the indexed and sorted BAM file can be processed to remove duplicate reads. If the duplicate removal is performed, sorting and indexing are repeated. Next MACS2 is used to call peaks and to estimate fragment size. If the fragment size is less than 80, then the peak calling is repeated with forced fixed fragment size (150). Fragment size can also be specified as an input parameter.  In the last few steps the coverage by estimated fragments is calculated from the BAM file and is output in bigWig format. The pipeline also reports statistics such as read quality, peak number, base frequency and other troubleshooting information using tools such as fastx, bamtools. Logs are saved in the working directory.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

```YAML
name: ""Byunggil Yoo""
institution: ""Children's Mercy Kansas City""
```

### Submission overview

```YAML
date_accessed: ""2017-09-05"" 
platform: ""cwltool""
workflow_type: ""CWL""
runner_version: ""1.0.20170817131858""
docker_version: ""17.06.0-ce, build 02c1d87""
environment: ""local""
env_cpus: ""48""
env_memory: ""512GB""
env_disk: ""368TB""
```

### Steps

#### 1. Set up environment

On a node (CentOS 7.2.1511) of a local cluster with Docker (17.06.0-ce) and Anaconda installed, I created and configured a virtual environment using the following YAML file:

```
channels:
  - bioconda
  - conda-forge
  - anaconda
  - r
dependencies:
  - cwltool=1.0.20170817131858
  - synapseclient
```

I created a working directory for the current workflow and created a copy of my Synapse credentials (~/.synapseConfig) in that folder:

```shell
mkdir biowardrobe_chipseq_se
cd biowardrobe_chipseq_se
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **BioWardrobe ChIP-Seq** workflow:
```shell
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
synapse get syn9909809 # biowardrobe_chipseq_se_get.cwl.json
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `biowardrobe_chipseq_se_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --outdir biowardrobe_chipseq_se --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ \
        --non-strict dockstore-tool-synapse-get.cwl biowardrobe_chipseq_se_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `biowardrobe_chipseq_se.cwl` and parameterized by `biowardrobe_chipseq_se.json`:
```shell
cwltool --basedir biowardrobe_chipseq_se/ --outdir biowardrobe_chipseq_se/ \
    --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
    biowardrobe_chipseq_se/biowardrobe_chipseq_se.cwl biowardrobe_chipseq_se/biowardrobe_chipseq_se.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool --basedir biowardrobe_chipseq_se/ --outdir biowardrobe_chipseq_se/ \
        --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
        biowardrobe_chipseq_se/biowardrobe_chipseq_se_checker.cwl biowardrobe_chipseq_se/biowardrobe_chipseq_se_checker.cwl.json
```

#### 6. Submit workflow outputs

I modified the parameters in `biowardrobe_chipseq_se_submit.cwl.json` as follows:
```JSON
{
  ""config_file"": {
    ""class"": ""File"",
    ""path"": "".synapseConfig""
  },
  ""team_name"": ""Childrens Mercy GA4GH-DREAM Challenge Team"",
  ""eval_id"": ""9604287"",
  ""file"": [
    {""class"": ""File"", ""path"": ""SRR1198790.fastq.fastxstat""},
    {""class"": ""File"", ""path"": ""SRR1198790.sam.log""},
    {""class"": ""File"", ""path"": ""SRR1198790.sam.stat""},
    {""class"": ""File"", ""path"": ""SRR1198790.sorted.bam""},
    {""class"": ""File"", ""path"": ""SRR1198790.sorted.bam.bai""},
    {""class"": ""File"", ""path"": ""SRR1198790.sorted.sorted.bigwig""},
    {""class"": ""File"", ""path"": ""SRR1198790.sorted_peaks.xls""}
  ],
  ""parent_id"": ""syn10290419""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --basedir biowardrobe_chipseq_se/ --outdir biowardrobe_chipseq_se/ \
        --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
        dockstore-tool-synapse-submit.cwl biowardrobe_chipseq_se/biowardrobe_chipseq_se_submit.json
```
",9633634
biowardrobe_chipseq_se,9635419_report.md,"## BioWardrobe ChIP-Seq

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Michael Kotliar""
workflow_handle: ""biowardrobe_chipseq_se""
input_handle: ""SRR1198790""
```

The following description is provided by the workflow author:
> This workflow from BioWardrobe runs basic analysis of single read ChIP-Seq data. Workflow starts with BowTie alignment to a reference genome resulting in an unsorted SAM file. The SAM file is then sorted and indexed to obtain with samtools a BAM file and a BAI index. Depending on workflow’s input parameters the indexed and sorted BAM file can be processed to remove duplicate reads. If the duplicate removal is performed, sorting and indexing are repeated. Next MACS2 is used to call peaks and to estimate fragment size. If the fragment size is less than 80, then the peak calling is repeated with forced fixed fragment size (150). Fragment size can also be specified as an input parameter.  In the last few steps the coverage by estimated fragments is calculated from the BAM file and is output in bigWig format. The pipeline also reports statistics such as read quality, peak number, base frequency and other troubleshooting information using tools such as fastx, bamtools. Logs are saved in the working directory.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Jeff Johnston"" # your name here
institution: ""Children's Mercy"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

```YAML
date_accessed: ""2017-09-15"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170817131858"" # indicate executor version used
docker_version: ""17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""48"" # indicate number of cores in environment
env_memory: ""512GB"" # indicate available RAM in environment
env_disk: ""368TB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

#### 1. Setup

This workflow was run on CentOS Linux release 7.2.1511. Docker and Conda 4.3.25 were installed. A conda environment was built using the following conda YAML file:

```yaml
channels:
  - bioconda
  - conda-forge
  - anaconda
  - r
dependencies:
  - cwltool=1.0.20170817131858
  - synapseclient
```

The Synapse client was configured by editing `~/.synapseConfig`.

##### 2. Download

The following commands were run within the conda environment:

```shell
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
synapse get syn9909809 # biowardrobe_chipseq_se_get.cwl.json
cwltool --outdir biowardrobe_chipseq_se --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ \
        --non-strict dockstore-tool-synapse-get.cwl biowardrobe_chipseq_se_get.cwl.json
cp ~/.synapseConfig biowardrobe_chipseq_se
```

##### 3. Run

Next, the workflow was executed in the conda environment.

```shell
cwltool --basedir biowardrobe_chipseq_se/ --outdir biowardrobe_chipseq_se/ \
    --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
    biowardrobe_chipseq_se/biowardrobe_chipseq_se.cwl biowardrobe_chipseq_se/biowardrobe_chipseq_se.json
```

##### 4. Validate

After running, the workflow results were validated:

```shell
cwltool --basedir biowardrobe_chipseq_se/ --outdir biowardrobe_chipseq_se/ \
        --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
        biowardrobe_chipseq_se/biowardrobe_chipseq_se_checker.cwl biowardrobe_chipseq_se/biowardrobe_chipseq_se_checker.cwl.json
```

##### 5. Submit

`biowardrobe_chipseq_se_submit.cwl.json` was modified for submission:

```yaml
{
  ""config_file"": {
    ""class"": ""File"",
    ""path"": "".synapseConfig""
  },
  ""team_name"": ""Childrens Mercy GA4GH-DREAM Challenge Team"",
  ""eval_id"": ""9604287"",
  ""file"": [
    {""class"": ""File"", ""path"": ""SRR1198790.fastq.fastxstat""},
    {""class"": ""File"", ""path"": ""SRR1198790.sam.log""},
    {""class"": ""File"", ""path"": ""SRR1198790.sam.stat""},
    {""class"": ""File"", ""path"": ""SRR1198790.sorted.bam""},
    {""class"": ""File"", ""path"": ""SRR1198790.sorted.bam.bai""},
    {""class"": ""File"", ""path"": ""SRR1198790.sorted.sorted.bigwig""},
    {""class"": ""File"", ""path"": ""SRR1198790.sorted_peaks.xls""}
  ],
  ""parent_id"": ""syn10290419""
}
```

Finally, results were submitted:

```shell
cwltool --basedir biowardrobe_chipseq_se/ --outdir biowardrobe_chipseq_se/ \
        --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
        dockstore-tool-synapse-submit.cwl biowardrobe_chipseq_se/biowardrobe_chipseq_se_submit.json
```

---
",9635419
biowardrobe_chipseq_se,9635969_report.md,"## BioWardrobe ChIP-Seq

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Michael Kotliar""
workflow_handle: ""biowardrobe_chipseq_se""
input_handle: ""SRR1198790""
```

The following description is provided by the workflow author:
> This workflow from BioWardrobe runs basic analysis of single read ChIP-Seq data. Workflow starts with BowTie alignment to a reference genome resulting in an unsorted SAM file. The SAM file is then sorted and indexed to obtain with samtools a BAM file and a BAI index. Depending on workflow’s input parameters the indexed and sorted BAM file can be processed to remove duplicate reads. If the duplicate removal is performed, sorting and indexing are repeated. Next MACS2 is used to call peaks and to estimate fragment size. If the fragment size is less than 80, then the peak calling is repeated with forced fixed fragment size (150). Fragment size can also be specified as an input parameter.  In the last few steps the coverage by estimated fragments is calculated from the BAM file and is output in bigWig format. The pipeline also reports statistics such as read quality, peak number, base frequency and other troubleshooting information using tools such as fastx, bamtools. Logs are saved in the working directory.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Jeff Johnston"" # your name here
institution: ""Children's Mercy"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

```YAML
date_accessed: ""2017-09-15"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170817131858"" # indicate executor version used
docker_version: ""17.06.2-ce, build cec0b72"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""1"" # indicate number of cores in environment
env_memory: ""8GB"" # indicate available RAM in environment
env_disk: ""133GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

#### 1. Setup

This workflow was run on a MacBook Pro running macOS 10.12.6. Docker and Miniconda2 were installed. Docker was configured to use 1 core and 8GB of RAM. A conda environment was built using the following conda YAML file:

```yaml
channels:
  - bioconda
  - conda-forge
  - anaconda
  - r
dependencies:
  - cwltool=1.0.20170817131858
  - synapseclient
```

The Synapse client was configured by editing `~/.synapseConfig`.

##### 2. Download

The following commands were run within the conda environment:

```shell
conda
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
synapse get syn9909809 # biowardrobe_chipseq_se_get.cwl.json
cwltool --outdir biowardrobe_chipseq_se --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ \
        --non-strict dockstore-tool-synapse-get.cwl biowardrobe_chipseq_se_get.cwl.json
cp ~/.synapseConfig biowardrobe_chipseq_se
```

##### 3. Run

Next, the workflow was executed in the conda environment.

```shell
cwltool --basedir biowardrobe_chipseq_se/ --outdir biowardrobe_chipseq_se/ \
    --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
    biowardrobe_chipseq_se/biowardrobe_chipseq_se.cwl biowardrobe_chipseq_se/biowardrobe_chipseq_se.json
```

##### 4. Validate

After running, the workflow results were validated:

```shell
cwltool --basedir biowardrobe_chipseq_se/ --outdir biowardrobe_chipseq_se/ \
        --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
        biowardrobe_chipseq_se/biowardrobe_chipseq_se_checker.cwl biowardrobe_chipseq_se/biowardrobe_chipseq_se_checker.cwl.json
```

##### 5. Submit

`biowardrobe_chipseq_se_submit.cwl.json` was modified for submission:

```yaml
{
  ""config_file"": {
    ""class"": ""File"",
    ""path"": "".synapseConfig""
  },
  ""team_name"": ""Childrens Mercy GA4GH-DREAM Challenge Team"",
  ""eval_id"": ""9604287"",
  ""file"": [
    {""class"": ""File"", ""path"": ""SRR1198790.fastq.fastxstat""},
    {""class"": ""File"", ""path"": ""SRR1198790.sam.log""},
    {""class"": ""File"", ""path"": ""SRR1198790.sam.stat""},
    {""class"": ""File"", ""path"": ""SRR1198790.sorted.bam""},
    {""class"": ""File"", ""path"": ""SRR1198790.sorted.bam.bai""},
    {""class"": ""File"", ""path"": ""SRR1198790.sorted.sorted.bigwig""},
    {""class"": ""File"", ""path"": ""SRR1198790.sorted_peaks.xls""}
  ],
  ""parent_id"": ""syn10290419""
}
```

Finally, results were submitted:

```shell
cwltool --basedir biowardrobe_chipseq_se/ --outdir biowardrobe_chipseq_se/ \
        --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
        dockstore-tool-synapse-submit.cwl biowardrobe_chipseq_se/biowardrobe_chipseq_se_submit.json
```

---
",9635969
biowardrobe_chipseq_se,9636372_report.md,"## BioWardrobe ChIP-Seq

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Michael Kotliar""
workflow_handle: ""biowardrobe_chipseq_se""
input_handle: ""SRR1198790""
```

The following description is provided by the workflow author:
> This workflow from BioWardrobe runs basic analysis of single read ChIP-Seq data. Workflow starts with BowTie alignment to a reference genome resulting in an unsorted SAM file. The SAM file is then sorted and indexed to obtain with samtools a BAM file and a BAI index. Depending on workflow’s input parameters the indexed and sorted BAM file can be processed to remove duplicate reads. If the duplicate removal is performed, sorting and indexing are repeated. Next MACS2 is used to call peaks and to estimate fragment size. If the fragment size is less than 80, then the peak calling is repeated with forced fixed fragment size (150). Fragment size can also be specified as an input parameter.  In the last few steps the coverage by estimated fragments is calculated from the BAM file and is output in bigWig format. The pipeline also reports statistics such as read quality, peak number, base frequency and other troubleshooting information using tools such as fastx, bamtools. Logs are saved in the working directory.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Gary Luu"" # your name here
institution: ""Dockstore - OICR"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-20"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""dockstore 1.2.10"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.2.10"" # indicate executor version used
docker_version: ""17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""4"" # indicate number of cores in environment
env_memory: ""32 GB"" # indicate available RAM in environment
env_disk: ""470 GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-17""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""500Gb""
```
### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

On a personal desktop, I installed Docker, pip, cwltool, and the Dockstore command-line helper using a procedure similar to https://github.com/denis-yuen/2017-cloud-workflows-misc/blob/master/install-and-run-with-dockstore.md .  
However, I used my own modified dockstore CLI (which will be 1.2.7)

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir biowardrobe
cd biowardrobe
cp ~/.synapseConfig .
```
#### 2. Download required files

I downloaded biowardrobe_chipseq_se_get.cwl.json from the website. 


#### 3. Provision all workflow files

I used the synapse-get tool from Dockstore.
```shell
dockstore tool launch --entry quay.io/ga4gh-dream/dockstore-tool-synapse-get --json biowardrobe_chipseq_se_get.cwl.json
```

#### 4. Run main workflow

Install html5lib
```shell
pip install html5lib
```

I used dockstore to launch the recently downloaded biowardrobe_chipseq_se.cwl.

```shell
dockstore workflow launch --local-entry biowardrobe_chipseq_se.cwl --json biowardrobe_chipseq_se.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `dockstore` to run the checker as follows:
```shell
dockstore tool launch --local-entry biowardrobe_chipseq_se_checker.cwl --json biowardrobe_chipseq_se_checker.json
cat results.json | grep overall
```

#### 6. Submit workflow outputs

I modified the parameters in `biowardrobe_chipseq_se_submit.json` as follows:

""parent_id"": ""syn9877725""
""team_name"": ""Dockstore Team""

Finally, I submitted outputs using dockstore-tool-synapse-submit`:
```shell
dockstore tool launch --entry quay.io/ga4gh-dream/dockstore-tool-synapse-submit --json biowardrobe_chipseq_se_submit.json
```

---",9636372
biowardrobe_chipseq_se,9636721_report.md,"## BioWardrobe ChIP-Seq

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Michael Kotliar""
workflow_handle: ""biowardrobe_chipseq_se""
input_handle: ""SRR1198790""
```

The following description is provided by the workflow author:
> This workflow from BioWardrobe runs basic analysis of single read ChIP-Seq data. Workflow starts with BowTie alignment to a reference genome resulting in an unsorted SAM file. The SAM file is then sorted and indexed to obtain with samtools a BAM file and a BAI index. Depending on workflow’s input parameters the indexed and sorted BAM file can be processed to remove duplicate reads. If the duplicate removal is performed, sorting and indexing are repeated. Next MACS2 is used to call peaks and to estimate fragment size. If the fragment size is less than 80, then the peak calling is repeated with forced fixed fragment size (150). Fragment size can also be specified as an input parameter.  In the last few steps the coverage by estimated fragments is calculated from the BAM file and is output in bigWig format. The pipeline also reports statistics such as read quality, peak number, base frequency and other troubleshooting information using tools such as fastx, bamtools. Logs are saved in the working directory.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Jonathon Saunders"" # your name here
institution: ""Children's Mercy Hospital"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-07-19"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170817131858"" # indicate executor version used
docker_version: ""Docker version 17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""4"" # indicate number of cores in environment
env_memory: ""16"" # indicate available RAM in environment
env_disk: ""500gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-17""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""500Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

_____________________
#### Example
### Setting up environment
Install `cwltool` (version 1.0.20170217172322), `html5lib` and  `synapseclient`
```
pip install cwltool==1.0.20170217172322
pip install html5lib
pip install synapseclient
```
Create empty folder for workflow running
```
mkdir biowardrobe_chipseq_se
cd biowardrobe_chipseq_se
```
Create Synapse credentials file `.synapseConfig`, put there Synapse ID and password
```
[authentication]
username: user@usermail.org
password: <user-password>
```
### Downloading required files
Download tools to fetch workflow input data
```
synapse -c .synapseConfig get syn10204916  # biowardrobe_chipseq_se_get.json
synapse -c .synapseConfig get syn9770802   # dockstore-tool-synapse-get.cwl
synapse -c .synapseConfig get syn9732885   # dockstore-tool-synapse-submit.cwl
```
Download workflow input data
```
cwltool --debug --non-strict dockstore-tool-synapse-get.cwl biowardrobe_chipseq_se_get.json
```
Wait until downloading is finished

### Running workflow
Update `threads ` field to 4 in `biowardrobe_chipseq_se.json` file
Run the workflow
```
cwltool --debug --non-strict biowardrobe_chipseq_se.cwl biowardrobe_chipseq_se.json
```
### Validating results
Run checker tool
```
cwltool --debug --non-strict biowardrobe_chipseq_se_checker.cwl biowardrobe_chipseq_se_checker.json
```
Check results
```
cat results.json
``` 
```json
{
    ""steps"": {
        ""macs2_callpeak_forced"": ""true"", 
        ""macs2_callpeak"": ""true"", 
        ""samtools_sort_index_after_rmdup"": ""true"", 
        ""bam_to_bigwig"": ""true"", 
        ""macs_island_count"": ""true"", 
        ""samtools_sort_index"": ""true"", 
        ""bowtie_aligner"": ""true"", 
        ""samtools_rmdup"": ""true"", 
        ""fastx_quality_stats"": ""true"", 
        ""bamtools_stats"": ""true""
    }, 
    ""overall"": ""true""
}
```
### Submitting results
Update `biowardrobe_chipseq_se_submit.cwl.json` with correct
`team_name` - the name of your team in plain text format (e.g., ""GA4GH-Sage Contenders"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
Run the tool
```
cwltool --debug --non-strict dockstore-tool-synapse-submit.cwl biowardrobe_chipseq_se_submit.json
```
***Running time:*** 15 min  
***Disk usage:*** 4.0G",9636721
biowardrobe_chipseq_se,9637097_report.md,"## BioWardrobe ChIP-Seq

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Michael Kotliar""
workflow_handle: ""biowardrobe_chipseq_se""
input_handle: ""SRR1198790""
```

The following description is provided by the workflow author:
> This workflow from BioWardrobe runs basic analysis of single read ChIP-Seq data. Workflow starts with BowTie alignment to a reference genome resulting in an unsorted SAM file. The SAM file is then sorted and indexed to obtain with samtools a BAM file and a BAI index. Depending on workflow’s input parameters the indexed and sorted BAM file can be processed to remove duplicate reads. If the duplicate removal is performed, sorting and indexing are repeated. Next MACS2 is used to call peaks and to estimate fragment size. If the fragment size is less than 80, then the peak calling is repeated with forced fixed fragment size (150). Fragment size can also be specified as an input parameter.  In the last few steps the coverage by estimated fragments is calculated from the BAM file and is output in bigWig format. The pipeline also reports statistics such as read quality, peak number, base frequency and other troubleshooting information using tools such as fastx, bamtools. Logs are saved in the working directory.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Vipin T. Sreedharan"" # your name here
institution: ""ETH Zürich, NEXUS Personalized Health Technologies"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-22"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""cwltool 1.0.20170828135420"" # indicate executor version used
docker_version: ""1.12.6, build c4618fb"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""32Gb"" # indicate available RAM in environment
env_disk: ""140Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

_____________________
### 1. Setting up environment

At our institute, on a compute machine called `wfexec` with Red Hat Enterprise Linux Server release 7.4 (Maipo), installed Docker. Created a group named ""docker"" since it was preferred to use Docker as a non-root user on this machine. The instance has a non-root user called `wfrunner`. Next added the non-root user `wfrunner` to the ""docker"" group. Then started the docker engine and all the below commands were executed using root user privileges [sudo]:
```shell
yum install docker
groupadd docker 
usermod -aG docker wfrunner  
systemctl start docker 
```
&nbsp;

As a non-root user `wfrunner` on `wfexec` machine, installed Anaconda and cwltool to the home path:
```shell
su - wfrunner
wget https://repo.continuum.io/archive/Anaconda2-4.4.0-Linux-x86_64.sh
bash Anaconda2-4.4.0-Linux-x86_64.sh 
conda install virtualenv
virtualenv -p python2 /home/wfrunner/venv
source /home/wfrunner/venv/bin/activate
pip install cwltools
pip install html5lib
deactivate
```
&nbsp;

Created a utilities directory for storing the `synapse-get` and `synapse-submit` CWL tools. In the same folder, created Synapse credential file `.synapse_config` and put there Synapse ID and password. 
```shell
mkdir -p /home/wfrunner/synapse_utils
cd /home/wfrunner/synapse_utils
wget -O dockstore-tool-synapse-get.cwl https://raw.githubusercontent.com/GA4GH-DREAM/dockstore-tool-synapse-get/master/Dockstore.cwl 
wget -O dockstore-tool-synapse-submit.cwl https://raw.githubusercontent.com/GA4GH-DREAM/dockstore-tool-synapse-submit/master/Dockstore.cwl
touch .synapse_config
vim .synapse_config
[WRITE] Synapse username & password
```

### 2. Downloading required files

Downloaded data config file biowardrobe_chipseq_se_get.cwl.json from the website `https://www.synapse.org/#!Synapse:syn8507133/wiki/451410` for the **biowardrobe_chipseq_se** workflow. Created a directory for the storing the workflow associated data downloading JSON parameter file: 
```shell
mkdir -p /home/wfrunner/data_config_files
mv ~/biowardrobe_chipseq_se_get.cwl.json ~/data_config_files
cd /home/wfrunner/data_config_files
vim biowardrobe_chipseq_se_get.cwl.json
[PASTE] /home/wfrunner/synapse_utils/.synapse_config
```

#### 3. Provision all workflow files

Created a working directory for the current workflow. 
```shell
mkdir -p /home/wfrunner/biowardrobe_chipseq_se
cd /home/wfrunner/biowardrobe_chipseq_se
```
&nbsp;

Used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `biowardrobe_chipseq_se_get.cwl.json` to download workflow input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --tmpdir-prefix /home/wfrunner/tmp/ --tmp-outdir-prefix /home/wfrunner/tmp/ --debug --non-strict ~/synapse_utils/dockstore-tool-synapse-get.cwl ~/config_files/biowardrobe_chipseq_se_get.cwl.json
```
Wait until downloading is finished

###  4. Run main workflow

Before running the workflow change here `biowardrobe_chipseq_se/tools/samtools-sort-index.cwl` with:
```
[OUTPUT]:
       if (inputs.sort_input.secondaryFiles && inputs.trigger == false){
         return inputs.sort_input.secondaryFiles;
       } else {
-         return self.location + ext();
+         return self.basename+ext();
       }
     }
```
to work with `cwltool` version `1.0.20170828135420`. Thanks to Michael for pointing this! the discussions are here:`https://www.synapse.org/#!Synapse:syn8507133/discussion/threadId=2222`
&nbsp;

Run the workflow
```shell
cd /home/wfrunner/biowardrobe_chipseq_se
cwltool --tmpdir-prefix ~/tmp/ --cachedir ~/tmp/cache --debug --non-strict biowardrobe_chipseq_se.cwl biowardrobe_chipseq_se.json
```

### 5. Run workflow checker tool 

Run checker tool to validate workflow results before submission:
```shell
cd /home/wfrunner/biowardrobe_chipseq_se
cwltool --tmpdir-prefix /home/wfrunner/tmp/ --cachedir /home/wfrunner/tmp/cache --debug --non-strict biowardrobe_chipseq_se_checker.cwl biowardrobe_chipseq_se_checker.json
```
&nbsp;

Check results
```shell
cd /home/wfrunner/biowardrobe_chipseq_se
cat results.json | grep -i overall
[OUTPUT] ""overall"": true,
``` 

### 6. Submit workflow outputs

Modified the parameters in `biowardrobe_chipseq_se_submit.cwl.json` as follows:
```
{
  ""config_file"": {
    ""class"": ""File"",
    ""path"": ""/home/wfrunner/synapse_utils/.synapse_config""
  },
  ""team_name"": """",
  ""eval_id"": ""9604287"",
  ""file"": [
    {""class"": ""File"", ""path"": ""SRR1198790.fastq.fastxstat""},
    {""class"": ""File"", ""path"": ""SRR1198790.sam.log""},
    {""class"": ""File"", ""path"": ""SRR1198790.sam.stat""},
    {""class"": ""File"", ""path"": ""SRR1198790.sorted.bam""},
    {""class"": ""File"", ""path"": ""SRR1198790.sorted.bam.bai""},
    {""class"": ""File"", ""path"": ""SRR1198790.sorted.sorted.bigwig""},
    {""class"": ""File"", ""path"": ""SRR1198790.sorted_peaks.xls""}
  ],
  ""parent_id"": ""syn10843373""
}
```
&nbsp;

Finally, submitted outputs using the submission tool `dockstore-tool-synapse-submit.cwl`:
```shell
cd /home/wfrunner/biowardrobe_chipseq_se
cwltool --tmpdir-prefix /home/wfrunner/tmp/ --cachedir /home/wfrunner/tmp/cache --debug --non-strict ~/synapse_utils/dockstore-tool-synapse-submit.cwl biowardrobe_chipseq_se_submit.json
```
",9637097
biowardrobe_chipseq_se,9637741_report.md,"## BioWardrobe ChIP-Seq

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Michael Kotliar""
workflow_handle: ""biowardrobe_chipseq_se""
input_handle: ""SRR1198790""
```

The following description is provided by the workflow author:
> This workflow from BioWardrobe runs basic analysis of single read ChIP-Seq data. Workflow starts with BowTie alignment to a reference genome resulting in an unsorted SAM file. The SAM file is then sorted and indexed to obtain with samtools a BAM file and a BAI index. Depending on workflow’s input parameters the indexed and sorted BAM file can be processed to remove duplicate reads. If the duplicate removal is performed, sorting and indexing are repeated. Next MACS2 is used to call peaks and to estimate fragment size. If the fragment size is less than 80, then the peak calling is repeated with forced fixed fragment size (150). Fragment size can also be specified as an input parameter.  In the last few steps the coverage by estimated fragments is calculated from the BAM file and is output in bigWig format. The pipeline also reports statistics such as read quality, peak number, base frequency and other troubleshooting information using tools such as fastx, bamtools. Logs are saved in the working directory.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Abraham Chavez"" # your name here
institution: ""UCSC"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170217172322"" # indicate executor version used
docker_version: ""17.06.0-ce-rc4"" # from `docker --version`
environment: ""Google CC"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""4"" # indicate number of cores in environment
env_memory: ""16GB"" # indicate available RAM in environment
env_disk: ""200GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

_____________________

### Setting up environment

If you have not set up your environment and install dependencies like **cwltool**, **dockstore**, **java** and so on
I recommend you follow [**this**](https://www.synapse.org/#!Synapse:syn10220609) instructions.

>**NOTE:** When configuring `docker` to run as root. You might encounter problems setting the credentials as directed in digital ocean, try replacing `su - ${USER}` with `sudo su -` and running `usermod -aG docker ${USER}` and `su - ${USER}` inside root terminal.

Create empty folder for workflow running
```
mkdir biowardrobe_chipseq_se_cwltool
cd biowardrobe_chipseq_se_cwltool
cp ../.synapseConfig .
```
Information about `.synapseConfig` can be found [**here**](https://www.synapse.org/#!Synapse:syn8507133/wiki/451408)

### Downloading required files
Download tools to fetch workflow input data
```
synapse -c .synapseConfig get syn10204916  # biowardrobe_chipseq_se_get.json
synapse -c .synapseConfig get syn9770802   # dockstore-tool-synapse-get.cwl
synapse -c .synapseConfig get syn9732885   # dockstore-tool-synapse-submit.cwl
```
Download workflow input data
```
cwltool --debug --non-strict dockstore-tool-synapse-get.cwl biowardrobe_chipseq_se_get.json
```
Wait until downloading is finished

### Running workflow
Update `threads ` field to 4 in `biowardrobe_chipseq_se.json` file
Run the workflow
```
cwltool --debug --non-strict biowardrobe_chipseq_se.cwl biowardrobe_chipseq_se.json
```
### Validating results
Run checker tool
```
cwltool --debug --non-strict biowardrobe_chipseq_se_checker.cwl biowardrobe_chipseq_se_checker.json
```
Check results
```
cat results.json
``` 
```json
{
    ""steps"": {
        ""macs2_callpeak_forced"": ""true"", 
        ""macs2_callpeak"": ""true"", 
        ""samtools_sort_index_after_rmdup"": ""true"", 
        ""bam_to_bigwig"": ""true"", 
        ""macs_island_count"": ""true"", 
        ""samtools_sort_index"": ""true"", 
        ""bowtie_aligner"": ""true"", 
        ""samtools_rmdup"": ""true"", 
        ""fastx_quality_stats"": ""true"", 
        ""bamtools_stats"": ""true""
    }, 
    ""overall"": ""true""
}
```
### Submitting results
Update `biowardrobe_chipseq_se_submit.cwl.json` with correct
`team_name` - the name of your team in plain text format (e.g., ""GA4GH-Sage Contenders"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
Run the tool
```
cwltool --debug --non-strict dockstore-tool-synapse-submit.cwl biowardrobe_chipseq_se_submit.json
```
***Running time:*** 15 min  
***Disk usage:*** 4.0G",9637741
biowardrobe_chipseq_se,9645270_report.md,"## BioWardrobe ChIP-Seq

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Michael Kotliar""
workflow_handle: ""biowardrobe_chipseq_se""
input_handle: ""SRR1198790""
```

The following description is provided by the workflow author:
> This workflow from BioWardrobe runs basic analysis of single read ChIP-Seq data. Workflow starts with BowTie alignment to a reference genome resulting in an unsorted SAM file. The SAM file is then sorted and indexed to obtain with samtools a BAM file and a BAI index. Depending on workflow’s input parameters the indexed and sorted BAM file can be processed to remove duplicate reads. If the duplicate removal is performed, sorting and indexing are repeated. Next MACS2 is used to call peaks and to estimate fragment size. If the fragment size is less than 80, then the peak calling is repeated with forced fixed fragment size (150). Fragment size can also be specified as an input parameter.  In the last few steps the coverage by estimated fragments is calculated from the BAM file and is output in bigWig format. The pipeline also reports statistics such as read quality, peak number, base frequency and other troubleshooting information using tools such as fastx, bamtools. Logs are saved in the working directory.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Michael Krause"" # your name here
institution: ""UCSC Genomics Institute"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

```YAML
date_accessed: ""2017-10-13"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170217172322"" # indicate executor version used
docker_version: ""17.09.0-ce"" # from `docker --version`
environment: ""EC2"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""4"" # indicate number of cores in environment
env_memory: ""30.5GB"" # indicate available RAM in environment
env_disk: ""500GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

_____________________
####Setting up environment
Install `cwltool` (version 1.0.20170217172322), `html5lib` and  `synapseclient`
```
pip install cwltool==1.0.20170217172322
pip install html5lib
pip install synapseclient
```
Create empty folder for workflow running
```
mkdir biowardrobe_chipseq_se
cd biowardrobe_chipseq_se
```
Create Synapse credentials file `.synapseConfig`, put there Synapse ID and password
```
[authentication]
username: user@usermail.org
password: <user-password>
```
####Downloading required files
Download tools to fetch workflow input data
```
synapse -c .synapseConfig get syn10204916  # biowardrobe_chipseq_se_get.json
synapse -c .synapseConfig get syn9770802   # dockstore-tool-synapse-get.cwl
synapse -c .synapseConfig get syn9732885   # dockstore-tool-synapse-submit.cwl
```
Download workflow input data
```
cwltool --debug --non-strict dockstore-tool-synapse-get.cwl biowardrobe_chipseq_se_get.json
```
Wait until downloading is finished

####Running workflow
Update `threads ` field to 4 in `biowardrobe_chipseq_se.json` file
Run the workflow
```
cwltool --debug --non-strict biowardrobe_chipseq_se.cwl biowardrobe_chipseq_se.json
```
####Validating results
Run checker tool
```
cwltool --debug --non-strict biowardrobe_chipseq_se_checker.cwl biowardrobe_chipseq_se_checker.json
```
Check results
```
cat results.json
``` 
```json
{
    ""steps"": {
        ""macs2_callpeak_forced"": ""true"", 
        ""macs2_callpeak"": ""true"", 
        ""samtools_sort_index_after_rmdup"": ""true"", 
        ""bam_to_bigwig"": ""true"", 
        ""macs_island_count"": ""true"", 
        ""samtools_sort_index"": ""true"", 
        ""bowtie_aligner"": ""true"", 
        ""samtools_rmdup"": ""true"", 
        ""fastx_quality_stats"": ""true"", 
        ""bamtools_stats"": ""true""
    }, 
    ""overall"": ""true""
}
```
####Submitting results
I modified `biowardrobe_chipseq_se_submit.json` like so:

```shell
{
  ""config_file"": {
    ""class"": ""File"",
    ""path"": "".synapseConfig""
  },
  ""team_name"": ""UCSC GA4GH-DREAM Challenge Team"",
  ""eval_id"": ""9604287"",
  ""file"": [
    {""class"": ""File"", ""path"": ""SRR1198790.fastq.fastxstat""},
    {""class"": ""File"", ""path"": ""SRR1198790.sam.log""},
    {""class"": ""File"", ""path"": ""SRR1198790.sam.stat""},
    {""class"": ""File"", ""path"": ""SRR1198790.sorted.bam""},
    {""class"": ""File"", ""path"": ""SRR1198790.sorted.bam.bai""},
    {""class"": ""File"", ""path"": ""SRR1198790.sorted.sorted.bigwig""},
    {""class"": ""File"", ""path"": ""SRR1198790.sorted_peaks.xls""}
  ],
  ""parent_id"": ""syn11220520""
}
```

Run the tool
```
cwltool --debug --non-strict dockstore-tool-synapse-submit.cwl biowardrobe_chipseq_se_submit.json
```
***Running time:*** 11 min  
***Disk usage:*** 4.0G",9645270
biowardrobe_chipseq_se,9646098_report.md,"## BioWardrobe ChIP-Seq

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Michael Kotliar""
workflow_handle: ""biowardrobe_chipseq_se""
input_handle: ""SRR1198790""
```

The following description is provided by the workflow author:
> This workflow from BioWardrobe runs basic analysis of single read ChIP-Seq data. Workflow starts with BowTie alignment to a reference genome resulting in an unsorted SAM file. The SAM file is then sorted and indexed to obtain with samtools a BAM file and a BAI index. Depending on workflow’s input parameters the indexed and sorted BAM file can be processed to remove duplicate reads. If the duplicate removal is performed, sorting and indexing are repeated. Next MACS2 is used to call peaks and to estimate fragment size. If the fragment size is less than 80, then the peak calling is repeated with forced fixed fragment size (150). Fragment size can also be specified as an input parameter.  In the last few steps the coverage by estimated fragments is calculated from the BAM file and is output in bigWig format. The pipeline also reports statistics such as read quality, peak number, base frequency and other troubleshooting information using tools such as fastx, bamtools. Logs are saved in the working directory.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Todd Pihl"" # your name here
institution: ""ISB-CGC/CSRA Inc"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-28"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""cwl"" # CWL or WDL
runner_version: ""1.0.20170217172322"" # indicate executor version used
docker_version: ""17.06.2-ce, build cec0b72"" # from `docker --version`
environment: ""Google Compute"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""35M"" # indicate available RAM in environment
env_disk: ""250G"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-17""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""500Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

_____________________
#### Example
### Setting up environment
Install `cwltool` (version 1.0.20170217172322), `html5lib` and  `synapseclient`
```
pip install cwltool==1.0.20170217172322
pip install html5lib
pip install synapseclient
```
Create empty folder for workflow running
```
mkdir biowardrobe_chipseq_se
cd biowardrobe_chipseq_se
```
Create Synapse credentials file `.synapseConfig`, put there Synapse ID and password
```
[authentication]
username: user@usermail.org
password: <user-password>
```
### Downloading required files
Download tools to fetch workflow input data
```
synapse -c .synapseConfig get syn10204916  # biowardrobe_chipseq_se_get.json
synapse -c .synapseConfig get syn9770802   # dockstore-tool-synapse-get.cwl
synapse -c .synapseConfig get syn9732885   # dockstore-tool-synapse-submit.cwl
```
Download workflow input data
```
cwltool --debug --non-strict dockstore-tool-synapse-get.cwl biowardrobe_chipseq_se_get.json
```
Wait until downloading is finished

### Running workflow
Update `threads ` field to 4 in `biowardrobe_chipseq_se.json` file
Run the workflow
```
cwltool --debug --non-strict biowardrobe_chipseq_se.cwl biowardrobe_chipseq_se.json
```
### Validating results
Run checker tool
```
cwltool --debug --non-strict biowardrobe_chipseq_se_checker.cwl biowardrobe_chipseq_se_checker.json
```
Check results
```
cat results.json
``` 
```json
{
    ""steps"": {
        ""macs2_callpeak_forced"": ""true"", 
        ""macs2_callpeak"": ""true"", 
        ""samtools_sort_index_after_rmdup"": ""true"", 
        ""bam_to_bigwig"": ""true"", 
        ""macs_island_count"": ""true"", 
        ""samtools_sort_index"": ""true"", 
        ""bowtie_aligner"": ""true"", 
        ""samtools_rmdup"": ""true"", 
        ""fastx_quality_stats"": ""true"", 
        ""bamtools_stats"": ""true""
    }, 
    ""overall"": ""true""
}
```
### Submitting results
Update `biowardrobe_chipseq_se_submit.cwl.json` with correct
`team_name` - the name of your team in plain text format (e.g., ""GA4GH-Sage Contenders"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
Run the tool
```
cwltool --debug --non-strict dockstore-tool-synapse-submit.cwl biowardrobe_chipseq_se_submit.json
```
***Running time:*** 15 min  
***Disk usage:*** 4.0G",9646098
biowardrobe_chipseq_se,9646120_report.md,"## BioWardrobe ChIP-Seq

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Michael Kotliar""
workflow_handle: ""biowardrobe_chipseq_se""
input_handle: ""SRR1198790""
```

The following description is provided by the workflow author:
> This workflow from BioWardrobe runs basic analysis of single read ChIP-Seq data. Workflow starts with BowTie alignment to a reference genome resulting in an unsorted SAM file. The SAM file is then sorted and indexed to obtain with samtools a BAM file and a BAI index. Depending on workflow’s input parameters the indexed and sorted BAM file can be processed to remove duplicate reads. If the duplicate removal is performed, sorting and indexing are repeated. Next MACS2 is used to call peaks and to estimate fragment size. If the fragment size is less than 80, then the peak calling is repeated with forced fixed fragment size (150). Fragment size can also be specified as an input parameter.  In the last few steps the coverage by estimated fragments is calculated from the BAM file and is output in bigWig format. The pipeline also reports statistics such as read quality, peak number, base frequency and other troubleshooting information using tools such as fastx, bamtools. Logs are saved in the working directory.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Madelyn Reyes""
institution: ""ISB-CGC/CSRA"" 
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""10/02/2017"" 
platform: ""cwltool"" 
workflow_type: ""CWL"" 
runner_version: ""1.0.20170217172322""
docker_version: ""17.09.0-ce, build afdb6d4"" 
environment: ""Google Compute"" 
env_cpus: ""8""
env_memory: ""35GB""
env_disk: ""250 GB"" 
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-17""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""500Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

_____________________
#### Example
### Setting up environment
Install `cwltool` (version 1.0.20170217172322), `html5lib` and  `synapseclient`
```
pip install cwltool==1.0.20170217172322
pip install html5lib
pip install synapseclient
```
Create empty folder for workflow running
```
mkdir biowardrobe_chipseq_se
cd biowardrobe_chipseq_se
```
Create Synapse credentials file `.synapseConfig`, put there Synapse ID and password
```
[authentication]
username: user@usermail.org
password: <user-password>
```
### Downloading required files
Download tools to fetch workflow input data
```
synapse -c .synapseConfig get syn10204916  # biowardrobe_chipseq_se_get.json
synapse -c .synapseConfig get syn9770802   # dockstore-tool-synapse-get.cwl
synapse -c .synapseConfig get syn9732885   # dockstore-tool-synapse-submit.cwl
```
Download workflow input data
```
cwltool --debug --non-strict dockstore-tool-synapse-get.cwl biowardrobe_chipseq_se_get.json
```
Wait until downloading is finished

### Running workflow
Update `threads ` field to 4 in `biowardrobe_chipseq_se.json` file
Run the workflow
```
cwltool --debug --non-strict biowardrobe_chipseq_se.cwl biowardrobe_chipseq_se.json
```
### Validating results
Run checker tool
```
cwltool --debug --non-strict biowardrobe_chipseq_se_checker.cwl biowardrobe_chipseq_se_checker.json
```
Check results
```
cat results.json
``` 
```json
{
    ""steps"": {
        ""macs2_callpeak_forced"": ""true"", 
        ""macs2_callpeak"": ""true"", 
        ""samtools_sort_index_after_rmdup"": ""true"", 
        ""bam_to_bigwig"": ""true"", 
        ""macs_island_count"": ""true"", 
        ""samtools_sort_index"": ""true"", 
        ""bowtie_aligner"": ""true"", 
        ""samtools_rmdup"": ""true"", 
        ""fastx_quality_stats"": ""true"", 
        ""bamtools_stats"": ""true""
    }, 
    ""overall"": ""true""
}
```
### Submitting results
Update `biowardrobe_chipseq_se_submit.cwl.json` with correct
`team_name` - the name of your team in plain text format (e.g., ""GA4GH-Sage Contenders"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
Run the tool
```
cwltool --debug --non-strict dockstore-tool-synapse-submit.cwl biowardrobe_chipseq_se_submit.json
```
***Running time:*** 15 min  
***Disk usage:*** 4.0G",9646120
biowardrobe_chipseq_se,9650283_report.md,"## BioWardrobe ChIP-Seq

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Michael Kotliar""
workflow_handle: ""biowardrobe_chipseq_se""
input_handle: ""SRR1198790""
```

The following description is provided by the workflow author:
> This workflow from BioWardrobe runs basic analysis of single read ChIP-Seq data. Workflow starts with BowTie alignment to a reference genome resulting in an unsorted SAM file. The SAM file is then sorted and indexed to obtain with samtools a BAM file and a BAI index. Depending on workflow’s input parameters the indexed and sorted BAM file can be processed to remove duplicate reads. If the duplicate removal is performed, sorting and indexing are repeated. Next MACS2 is used to call peaks and to estimate fragment size. If the fragment size is less than 80, then the peak calling is repeated with forced fixed fragment size (150). Fragment size can also be specified as an input parameter.  In the last few steps the coverage by estimated fragments is calculated from the BAM file and is output in bigWig format. The pipeline also reports statistics such as read quality, peak number, base frequency and other troubleshooting information using tools such as fastx, bamtools. Logs are saved in the working directory.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Joe Slagel"" # your name here
institution: ""Institute for Systems Biology"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""11/1/2017"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWK"" # CWL or WDL
runner_version: ""1.0.20170217172322"" # indicate executor version used
docker_version: ""17.09.0-ce, build afdb6d4"" # from `docker --version`
environment: ""Google Compute"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""30 GB"" # indicate available RAM in environment
env_disk: ""150 GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-17""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""500Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

_____________________
#### Example
### Setting up environment

1. Install pip:

```shell
sudo apt-get install pip
sudo apt-get install python-pip python-dev build-essential
sudo pip install --upgrade pip
```
2. Install cwltool and synapse client:

```shell
sudo pip install cwltool==1.0.20170217172322
sudo pip install html5lib
sudo pip install synapseclient
cwltool --version
```
3. Fix issue with incompatible version of ruamel.yaml

```shell
sudo pip install ruamel.yaml==0.14.1
```

4. Install docker

```shell
sudo apt-get install     apt-transport-https     ca-certificates     curl     software-properties-common
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
sudo apt-get update
sudo apt-get install docker-ce
```

5. Create Synapse credentials file `.synapseConfig`, put there Synapse ID and password

6.  Download tools to fetch workflow input data
```shell
synapse -c .synapseConfig get syn10204916  # biowardrobe_chipseq_se_get.json
synapse -c .synapseConfig get syn9770802   # dockstore-tool-synapse-get.cwl
synapse -c .synapseConfig get syn9732885   # dockstore-tool-synapse-submit.cwl
```

7. Download workflow input data
```
sudo cwltool --debug --non-strict dockstore-tool-synapse-get.cwl biowardrobe_chipseq_se_get.json
```

8.  Run workflow
Update `threads ` field to 4 in `biowardrobe_chipseq_se.json` file
Run the workflow
```
cwltool --debug --non-strict biowardrobe_chipseq_se.cwl biowardrobe_chipseq_se.json > run.log 2>&1 &
```

9.  Validating results
Run checker tool
```
cwltool --debug --non-strict biowardrobe_chipseq_se_checker.cwl biowardrobe_chipseq_se_checker.json
```
Check results
```
cat results.json
``` 
```json
{
    ""steps"": {
        ""macs2_callpeak_forced"": ""true"", 
        ""macs2_callpeak"": ""true"", 
        ""samtools_sort_index_after_rmdup"": ""true"", 
        ""bam_to_bigwig"": ""true"", 
        ""macs_island_count"": ""true"", 
        ""samtools_sort_index"": ""true"", 
        ""bowtie_aligner"": ""true"", 
        ""samtools_rmdup"": ""true"", 
        ""fastx_quality_stats"": ""true"", 
        ""bamtools_stats"": ""true""
    }, 
    ""overall"": ""true""
}
```
10.  Submit results",9650283
biowardrobe_chipseq_se,9653795_report.md,"## BioWardrobe ChIP-Seq

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Michael Kotliar""
workflow_handle: ""biowardrobe_chipseq_se""
input_handle: ""SRR1198790""
```

The following description is provided by the workflow author:
> This workflow from BioWardrobe runs basic analysis of single read ChIP-Seq data. Workflow starts with BowTie alignment to a reference genome resulting in an unsorted SAM file. The SAM file is then sorted and indexed to obtain with samtools a BAM file and a BAI index. Depending on workflow’s input parameters the indexed and sorted BAM file can be processed to remove duplicate reads. If the duplicate removal is performed, sorting and indexing are repeated. Next MACS2 is used to call peaks and to estimate fragment size. If the fragment size is less than 80, then the peak calling is repeated with forced fixed fragment size (150). Fragment size can also be specified as an input parameter.  In the last few steps the coverage by estimated fragments is calculated from the BAM file and is output in bigWig format. The pipeline also reports statistics such as read quality, peak number, base frequency and other troubleshooting information using tools such as fastx, bamtools. Logs are saved in the working directory.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Karl Sebby"" # your name here
institution: ""xD Bio"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-11-17"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""cwl"" # CWL or WDL
runner_version: ""cwltool==1.0.20171107133715"" # indicate executor version used
docker_version: ""17.09.0-ce, build afdb6d4"" # from `docker --version`
environment: ""Google Compute"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""54Gb"" # indicate available RAM in environment
env_disk: ""45Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-17""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""500Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

**Ran everything as root to make docker happy and not have to keep changing permissions.**

```shell
sudo bash
```

#### 1. Set up the environment

ssh  to google compute engine instance from local machine (linux mint with cinnamon desktop running in virtual box on Macbook pro.)
```shell
screen
ssh `external_ip`
```

On a google instance, install docker, pip3, cwltool (with pip3).
Set up directory structure from ~:
```shell
mkdir -p projects/dreamChallenge/biowardrobe_chipseq_se
cd projects/dreamChallenge
```
Create .synapseConfig file and paste in text from synapse website. Change username and password.
```shell 
vi .synapseConfig
```
Install  `html5lib` 
```
pip install html5lib
```

#### 2. Download required files

Steps started in the projects/dreamChallenge directory.

Use curl to get the dockstore-tool-synapse-get.cwl and dockstore-tool-synapse-submit.cwl:
```shell
curl https://raw.githubusercontent.com/GA4GH-DREAM/dockstore-tool-synapse-get/master/Dockstore.cwl > dockstore-tool-synapse-get.cwl
curl https://raw.githubusercontent.com/GA4GH-DREAM/dockstore-tool-synapse-submit/master/Dockstore.cwl > dockstore-tool-synapse-submit.cwl
```
Downloaded the `biowardrobe_chipseq_se_get.cwl.json` file to my local machine from synapse website. Opened the file in TextEdit and copied contents. In google compute shell create the `biowardrobe_chipseq_se_get.cwl.json ` file and paste the contents and save:
```shell
vi biowardrobe_chipseq_se_get.cwl.json
```

Get the files:
```shell
cd biowardrobe_chipseq_se/
cwltool ../dockstore-tool-synapse-get.cwl ../biowardrobe_chipseq_se_get.cwl.json
```
#### 4. Run the main workflow

NOTE: The first time I tried to run this workflow the checker produced a `results.json` file with several `False` values. Looked in the discussion and found a solution--either change the version of cwltool or change the `biowardrobe_chipseq_se/tools/samtools-sort-index.cwl` file. I updated the file. 
```shell
vi tools/samtools-sort-index.cwl
```
Updated one line in the outputs field, as specified by @michael_kotliar in the discussion.
```shell
 outputs:
           if (inputs.sort_input.secondaryFiles && inputs.trigger == false){
             return inputs.sort_input.secondaryFiles;
           } else {
-            return self.location + ext();
+            return self.basename+ext();
           }
         }
```
After that change, the workflow was fine. Ran the workflow
```
time cwltool  biowardrobe_chipseq_se.cwl biowardrobe_chipseq_se.json
```
Took 11m55s the second time.  Thought it took much longer the first time. Downloading already done.

#### 5. Run workflow checker tool
Run checker tool
```
cwltool  biowardrobe_chipseq_se_checker.cwl biowardrobe_chipseq_se_checker.json
```
Check results
```
cat results.json
``` 
```json
{
    ""steps"": {
        ""macs2_callpeak_forced"": ""true"", 
        ""macs2_callpeak"": ""true"", 
        ""samtools_sort_index_after_rmdup"": ""true"", 
        ""bam_to_bigwig"": ""true"", 
        ""macs_island_count"": ""true"", 
        ""samtools_sort_index"": ""true"", 
        ""bowtie_aligner"": ""true"", 
        ""samtools_rmdup"": ""true"", 
        ""fastx_quality_stats"": ""true"", 
        ""bamtools_stats"": ""true""
    }, 
    ""overall"": ""true""
}
```
### Submitting results
Update `biowardrobe_chipseq_se_submit.cwl.json`  `config_file` and `parent_id` fields.
```shell
vi biowardrobe_chipseq_se_submit.cwl.json
```
```shell
{
  ""config_file"": {
    ""class"": ""File"",
    ""path"": ""../.synapseConfig""
  },
  ""team_name"": """",
  ""eval_id"": ""9604287"",
  ""file"": [
    {""class"": ""File"", ""path"": ""SRR1198790.fastq.fastxstat""},
    {""class"": ""File"", ""path"": ""SRR1198790.sam.log""},
    {""class"": ""File"", ""path"": ""SRR1198790.sam.stat""},
    {""class"": ""File"", ""path"": ""SRR1198790.sorted.bam""},
    {""class"": ""File"", ""path"": ""SRR1198790.sorted.bam.bai""},
    {""class"": ""File"", ""path"": ""SRR1198790.sorted.sorted.bigwig""},
    {""class"": ""File"", ""path"": ""SRR1198790.sorted_peaks.xls""}
  ],
  ""parent_id"": ""syn12345678""
}
```

```
cwltool  ../dockstore-tool-synapse-submit.cwl biowardrobe_chipseq_se_submit.json
```
",9653795
biowardrobe_chipseq_se,9653912_report.md,"## BioWardrobe ChIP-Seq

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Michael Kotliar""
workflow_handle: ""biowardrobe_chipseq_se""
input_handle: ""SRR1198790""
```

The following description is provided by the workflow author:
> This workflow from BioWardrobe runs basic analysis of single read ChIP-Seq data. Workflow starts with BowTie alignment to a reference genome resulting in an unsorted SAM file. The SAM file is then sorted and indexed to obtain with samtools a BAM file and a BAI index. Depending on workflow’s input parameters the indexed and sorted BAM file can be processed to remove duplicate reads. If the duplicate removal is performed, sorting and indexing are repeated. Next MACS2 is used to call peaks and to estimate fragment size. If the fragment size is less than 80, then the peak calling is repeated with forced fixed fragment size (150). Fragment size can also be specified as an input parameter.  In the last few steps the coverage by estimated fragments is calculated from the BAM file and is output in bigWig format. The pipeline also reports statistics such as read quality, peak number, base frequency and other troubleshooting information using tools such as fastx, bamtools. Logs are saved in the working directory.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Azza E Ahmed"" # your name here
institution: ""University of Khartoum"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-11-18"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170928192020"" # indicate executor version used
docker_version: ""17.03.1-ce, build c6d412e"" # from `docker --version`
environment: ""EGI FedCloud"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""32GB"" # indicate available RAM in environment
env_disk: ""50GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-17""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""500Gb""
```

### Steps

I launched a VM instance from EGI FedCloud resources (EGI Docker (Ubuntu 16.04) from CESNET MetaCloud (IaaS Cloud)) with large memory (32GB ram, 50GB disk, 8 cores), as per challenge 

_____________________

### Setting up environment

 This is a new instance with docker already installed, so some extra steps were needed:

Install `cwltool` (version 1.0.20170217172322), `html5lib` and  `synapseclient`
```
sudo usermod -a -G docker $USER
pip install schema-salad==2.2.20170222151604 cwltool==1.0.20170217172322 --no-cache-dir
pip install html5lib
pip install synapseclient
```
Create empty folder for workflow running
```
mkdir biowardrobe_chipseq_se
cd biowardrobe_chipseq_se
```
Create Synapse credentials file `.synapseConfig`, put there Synapse ID and password
```
[authentication]
username: user@usermail.org
password: <user-password>
```
### Downloading required files
Download tools to fetch workflow input data
```
synapse -c .synapseConfig get syn10204916  # biowardrobe_chipseq_se_get.json
synapse -c .synapseConfig get syn9770802   # dockstore-tool-synapse-get.cwl
synapse -c .synapseConfig get syn9732885   # dockstore-tool-synapse-submit.cwl
```
Download workflow input data
```
cwltool --debug --non-strict dockstore-tool-synapse-get.cwl biowardrobe_chipseq_se_get.json
```
Wait until downloading is finished

### Running workflow
Update `threads ` field to 4 in `biowardrobe_chipseq_se.json` file
Run the workflow
```
cwltool --debug --non-strict biowardrobe_chipseq_se.cwl biowardrobe_chipseq_se.json
```
### Validating results
Run checker tool
```
cwltool --debug --non-strict biowardrobe_chipseq_se_checker.cwl biowardrobe_chipseq_se_checker.json
```
Check results
```
cat results.json
``` 
```json
{
    ""steps"": {
        ""macs2_callpeak_forced"": ""true"", 
        ""macs2_callpeak"": ""true"", 
        ""samtools_sort_index_after_rmdup"": ""true"", 
        ""bam_to_bigwig"": ""true"", 
        ""macs_island_count"": ""true"", 
        ""samtools_sort_index"": ""true"", 
        ""bowtie_aligner"": ""true"", 
        ""samtools_rmdup"": ""true"", 
        ""fastx_quality_stats"": ""true"", 
        ""bamtools_stats"": ""true""
    }, 
    ""overall"": ""true""
}
```
### Submitting results
Update `biowardrobe_chipseq_se_submit.cwl.json` with correct
`team_name` - the name of your team in plain text format: """"CBSB_pipelines""
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse ""syn11460416""
Run the tool
```
cwltool --debug --non-strict dockstore-tool-synapse-submit.cwl biowardrobe_chipseq_se_submit.json
```

***Disk usage:*** 4.0G",9653912
biowardrobe_chipseq_se,9655240_report.md,"## BioWardrobe ChIP-Seq

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Michael Kotliar""
workflow_handle: ""biowardrobe_chipseq_se""
input_handle: ""SRR1198790""
```

The following description is provided by the workflow author:
> This workflow from BioWardrobe runs basic analysis of single read ChIP-Seq data. Workflow starts with BowTie alignment to a reference genome resulting in an unsorted SAM file. The SAM file is then sorted and indexed to obtain with samtools a BAM file and a BAI index. Depending on workflow’s input parameters the indexed and sorted BAM file can be processed to remove duplicate reads. If the duplicate removal is performed, sorting and indexing are repeated. Next MACS2 is used to call peaks and to estimate fragment size. If the fragment size is less than 80, then the peak calling is repeated with forced fixed fragment size (150). Fragment size can also be specified as an input parameter.  In the last few steps the coverage by estimated fragments is calculated from the BAM file and is output in bigWig format. The pipeline also reports statistics such as read quality, peak number, base frequency and other troubleshooting information using tools such as fastx, bamtools. Logs are saved in the working directory.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Azza E Ahmed"" # your name here
institution: ""University of Khartoum"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-11-29"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""Rabix"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.0"" # indicate executor version used
docker_version: ""17.03.1-ce, build c6d412e"" # from `docker --version`
environment: ""EGI FedCloud"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""32Gb"" # indicate available RAM in environment
env_disk: ""50GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```


> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-17""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""500Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

_____________________

### Setting up environment
I launched an EGI FedCloud instance of type `EGI Docker (Ubuntu 16.04)` as provided by `CESNET MetaCloud (IaaS Cloud)` with one node, mounted a 50GB volume, and Docker pre-installed.

I created and configured a virtual environment as follows:
```
# Adding my user to the docker group
sudo usermod -a -G docker $USER

# Installing java:
sudo apt-get update
sudo apt-get install default-jre
sudo apt-get install default-jdk

# Installing Rabix:
wget https://github.com/rabix/bunny/releases/download/v1.0.0/rabix-1.0.0.tar.gz
tar -xvzf rabix-1.0.0.tar.gz
export PATH=$PATH://home/azza/software/rabix-cli-1.0.0

# Installing synapse
sudo pip install synapseclient
```
Create empty folder for workflow, in my mounted storage:
```
mkdir /mnt/storage01/ biowardrobe_chipseq_se
cd biowardrobe_chipseq_se
```
Create Synapse credentials file `.synapseConfig`, put there Synapse ID and password
```
[authentication]
username: user@usermail.org
password: <user-password>
```
### Downloading required files
Download tools to fetch workflow input data
```
synapse -c .synapseConfig get syn10204916  # biowardrobe_chipseq_se_get.json
synapse -c .synapseConfig get syn9770802   # dockstore-tool-synapse-get.cwl
synapse -c .synapseConfig get syn9732885   # dockstore-tool-synapse-submit.cwl
```
Download workflow input data
```
rabix dockstore-tool-synapse-get.cwl biowardrobe_chipseq_se_get.json
```
Wait until downloading is finished

### Running workflow
Before running the workflow, I change my path, as `RABIX` creates a new folder upon executing any script that is named after the script's named + a date-time stamp. Among the downloaded tools, 2 need to be modified to be compatible with Rabix's implementation of cwl standard. Instead, I use the uploaded files from @bogdang before running the pipeline:

```
cd dockstore-tool-synapse-get-2017-11-28-135921.236/root//synapse_files/
cd tools
synapse -c  ../../../../.synapseConfig  get -r syn10245582
cd ..

rabix ./biowardrobe_chipseq_se.cwl ./biowardrobe_chipseq_se.json
```
### Validating results
I didn't validate my files after running the pipeline, as I wasn't sure how to change the path in the `biowardrobe_chipseq_se_checker.json` file. So, here I'm relying on Synapse's pre-checking of my results only.


### Submitting results
The key results from running the workflow are in:
```
/mnt/storage01/biowardrobe_chipseq_se/dockstore-tool-synapse-get-2017-11-28-135921.236/root/synapse_files/biowardrobe_chipseq_se-2017-11-28-150401.934/root/
```
I update `biowardrobe_chipseq_se_submit.cwl.json` with correct path to each expected output, and also the `team_name` and `parent_id` before running the submission command.

```
$ vi  biowardrobe_chipseq_se_submit.cwl.json
# Edit the path to point to these files:
## /mnt/storage01/biowardrobe_chipseq_se/dockstore-tool-synapse-get-2017-11-28-135921.236/root/synapse_files/biowardrobe_chipseq_se-2017-11-28-150401.934/root/fastx_quality_stats/SRR1198790.fastq.fastxstat
## /mnt/storage01/biowardrobe_chipseq_se/dockstore-tool-synapse-get-2017-11-28-135921.236/root/synapse_files/biowardrobe_chipseq_se-2017-11-28-150401.934/root/bowtie_aligner/SRR1198790.sam.log
## /mnt/storage01/biowardrobe_chipseq_se/dockstore-tool-synapse-get-2017-11-28-135921.236/root/synapse_files/biowardrobe_chipseq_se-2017-11-28-150401.934/root/get_stat/SRR1198790.sam.stat
## /mnt/storage01/biowardrobe_chipseq_se/dockstore-tool-synapse-get-2017-11-28-135921.236/root/synapse_files/biowardrobe_chipseq_se-2017-11-28-150401.934/root/samtools_sort_index_after_rmdup/SRR1198790.sorted.bam
## /mnt/storage01/biowardrobe_chipseq_se/dockstore-tool-synapse-get-2017-11-28-135921.236/root/synapse_files/biowardrobe_chipseq_se-2017-11-28-150401.934/root/samtools_sort_index/SRR1198790.sorted.bam.bai
## /mnt/storage01/biowardrobe_chipseq_se/dockstore-tool-synapse-get-2017-11-28-135921.236/root/synapse_files/biowardrobe_chipseq_se-2017-11-28-150401.934/root/bam_to_bigwig/bigwig/SRR1198790.sorted.sorted.bigwig
## /mnt/storage01/biowardrobe_chipseq_se/dockstore-tool-synapse-get-2017-11-28-135921.236/root/synapse_files/biowardrobe_chipseq_se-2017-11-28-150401.934/root/macs2_callpeak_forced/SRR1198790.sorted_peaks.xls

$ cp ../../../dockstore-tool-synapse-submit.cwl .
$ rabix ./dockstore-tool-synapse-submit.cwl ./biowardrobe_chipseq_se_submit.json
```
",9655240
biowardrobe_chipseq_se,9656006_report.md,"### Workflow description

```YAML
contributor: ""Michael Kotliar""
workflow_handle: ""biowardrobe_chipseq_se""
input_handle: ""SRR1198790""
```

### Participant information
```YAML
name: ""Ben Ernest""
institution: ""Digicon Corporation""
```

### Submission overview
```YAML
date_accessed: ""2017-12-06"" 
platform: ""cwltool"" 
workflow_type: ""CWL"" 
runner_version: ""1.0.20170217172322"" 
docker_version: ""17.09.0-ce"" 
environment: ""cluster"" 
env_cpus: ""12"" 
env_memory: ""62Gb"" 
env_disk: ""5Tb"" 
```

### Steps

#### 1. Set up environment, following instructions at https://dockstore.org/quick-start
##### Instructions are for Linux CentOS

Download and install dockstore.  
```shell
mkdir -p ~/bin
curl -L -o ~/bin/dockstore https://github.com/ga4gh/dockstore/releases/download/1.3.0/dockstore
chmod +x ~/bin/dockstore
echo 'export PATH=~/bin:$PATH' >> ~/.bashrc
source ~/.bashrc
```

Create configuration file
```shell
mkdir -p ~/.dockstore
printf ""token: dummy-token\nserver-url: https://dockstore.org:8443\n"" > ~/.dockstore/config
```

Install `pip`
```shell
curl -L -o ~/get-pip.py https://bootstrap.pypa.io/get-pip.py
sudo python get-pip.py
```

Install `cwltool` (**note: version 1.0.20170217172322**)
```shell
sudo pip install setuptools==36.5.0
sudo pip install cwl-runner cwltool==1.0.20170217172322 schema-salad==2.6.20170806163416 avro==1.8.1 ruamel.yaml==0.14.12 requests==2.18.4
```

Install Docker
```shell
sudo yum install -y yum-utils device-mapper-persistent-data lvm2
sudo yum-config-manager --add-repo ""https://download.docker.com/linux/centos/docker-ce.repo""
sudo yum-config-manager --enable extras
sudo yum -y install docker-ce
sudo usermod -aG docker $USER
exec newgrp docker
```

Create aliases to start and stop Docker
```shell
echo 'alias start_docker=""sudo systemctl start docker""' >> ~/.bashrc
echo `alias stop_docker=""sudo systemctl stop docker""' >> ~/.bashrc
source ~/.bashrc
```
Install `synapseclient`
```
sudo pip install synapseclient
```

Create synapse credentials file with the content below, using your own Synapse credentials (no quotes or extra characters).  It can be named anything, but I'm using `.synapseConfig`.
```
[authentication]
username: user@usermail.org
password: password
```

Create a working directory and copy synapse credentials file into that folder.
```shell
mkdir -p biowardrobe_chipseq_se_run
cd biowardrobe_chipseq_se_run
cp ~/.synapseConfig .
```

#### 2. Download required files
Download tools to fetch workflow input data.
```shell
synapse get syn10204916 # biowardrobe_chipseq_se_get.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files
Start docker, using alias created previously.
```shell
start_docker
```

Use `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `biowardrobe_chipseq_se_get.json` to download files, data, and tools required for running the workflow and submitting results.
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl biowardrobe_chipseq_se_get.json
```

#### 4. Run main workflow
Use `cwltool` to run the workflow, as defined in `biowardrobe_chipseq_se.cwl` and parameterized by `biowardrobe_chipseq_se.json`:
```shell
cwltool --non-strict biowardrobe_chipseq_se.cwl biowardrobe_chipseq_se.json
```

#### 5. Run workflow checker tool
To verify workflow results before submission, use `cwltool` to run the checker as follows:
```shell
cwltool --non-strict biowardrobe_chipseq_se_checker.cwl biowardrobe_chipseq_se_checker.json
```

#### 6. Submit workflow outputs
Modify `team_name` and `parent_id` in `biowardrobe_chipseq_se_submit.json` as shown below, assuming Synapse credentials file is named `.synapseConfig` and located in `~/biowardrobe_chipseq_se_run`.
```JSON
{
  ""config_file"": {
    ""class"": ""File"",
    ""path"": "".synapseConfig""
  },
  ""team_name"": ""BioGenLink"",
  ""eval_id"": ""9604287"",
  ""file"": [
    {""class"": ""File"", ""path"": ""SRR1198790.fastq.fastxstat""},
    {""class"": ""File"", ""path"": ""SRR1198790.sam.log""},
    {""class"": ""File"", ""path"": ""SRR1198790.sam.stat""},
    {""class"": ""File"", ""path"": ""SRR1198790.sorted.bam""},
    {""class"": ""File"", ""path"": ""SRR1198790.sorted.bam.bai""},
    {""class"": ""File"", ""path"": ""SRR1198790.sorted.sorted.bigwig""},
    {""class"": ""File"", ""path"": ""SRR1198790.sorted_peaks.xls""}
  ],
  ""parent_id"": ""syn11565349""
}
```

Submit outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl biowardrobe_chipseq_se_submit.json
```

Stop Docker if desired.
```shell
stop_docker
```
",9656006
biowardrobe_chipseq_se,9656042_report.md,"## BioWardrobe ChIP-Seq

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Michael Kotliar""
workflow_handle: ""biowardrobe_chipseq_se""
input_handle: ""SRR1198790""
```

The following description is provided by the workflow author:
> This workflow from BioWardrobe runs basic analysis of single read ChIP-Seq data. Workflow starts with BowTie alignment to a reference genome resulting in an unsorted SAM file. The SAM file is then sorted and indexed to obtain with samtools a BAM file and a BAI index. Depending on workflow’s input parameters the indexed and sorted BAM file can be processed to remove duplicate reads. If the duplicate removal is performed, sorting and indexing are repeated. Next MACS2 is used to call peaks and to estimate fragment size. If the fragment size is less than 80, then the peak calling is repeated with forced fixed fragment size (150). Fragment size can also be specified as an input parameter.  In the last few steps the coverage by estimated fragments is calculated from the BAM file and is output in bigWig format. The pipeline also reports statistics such as read quality, peak number, base frequency and other troubleshooting information using tools such as fastx, bamtools. Logs are saved in the working directory.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Joe Slagel"" # your name here
institution: ""ISB"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-12-06"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""ISB-CGC dsub/cwltool/cwl_runner.sh"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""cwltool-1.0.20171107133715"" # indicate executor version used
docker_version: ""17.11.0"" # from `docker --version`
environment: ""Google Compute"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""60"" # indicate available RAM in environment
env_disk: ""200"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

I was curious as to how much of the challenge I could do using only dsub and cwl_runner.sh.  On a personal Google Cloud VM with gcloud, gsutil, dsub and cwl_runner.sh installed I :

#### 1. Set up environment

```shell
gsutil cp ~/.synapseConfig gs://isb-ga4gh-dream/biowardrobe_chipseq_se/data/.synapseConfig
dsub \
   --name dream-setup-biowardrobe_chipseq_se \
   --project cgc-05-0026 \
   --zones 'us-*' \
   --image quay.io/ga4gh-dream/dockstore-tool-synapse-get \
   --input  'CFG=gs://isb-ga4gh-dream/biowardrobe_chipseq_se/data/.synapseConfig' \
   --output-recursive 'OUT=gs://isb-ga4gh-dream/biowardrobe_chipseq_se/data/' \
   --logging 'gs://isb-ga4gh-dream/biowardrobe_chipseq_se/log' \
   --wait \
   --command 'cd ${OUT}; \
              synapse -c ${CFG} get syn9770802; \
              synapse -c ${CFG} get syn9732885; \
              synapse -c ${CFG} get syn10204916; \
             '
```

#### 2. Download required files

```shell
./cwl_runner.sh \
   -m n1-standard-2 \
   -i gs://isb-ga4gh-dream/biowardrobe_chipseq_se/data/.synapseConfig \
   -w gs://isb-ga4gh-dream/biowardrobe_chipseq_se/data/dockstore-tool-synapse-get.cwl \
   -s gs://isb-ga4gh-dream/biowardrobe_chipseq_se/data/biowardrobe_chipseq_se_get.json \
   -o gs://isb-ga4gh-dream/biowardrobe_chipseq_se/data
```

#### 3. Run main workflow

NOTE: The first time I tried to run this workflow the checker produced a results.json file with several False values. Looked in the discussion and found a solution--either change the version of cwltool or change the biowardrobe_chipseq_se/tools/samtools-sort-index.cwl file. I updated the file.

```shell
# https://www.synapse.org/#!Synapse:syn11455992
gsutil cat gs://isb-ga4gh-dream/biowardrobe_chipseq_se/data/tools/samtools-sort-index.cwl \
   | sed 's/self.location + ext/self.basename + ext/' \
   | gsutil cp - gs://isb-ga4gh-dream/biowardrobe_chipseq_se/data/tools/samtools-sort-index.cwl
./cwl_runner.sh \
   -m n1-standard-8 \
   -r gs://isb-ga4gh-dream/biowardrobe_chipseq_se/data/ \
   -w gs://isb-ga4gh-dream/biowardrobe_chipseq_se/data/biowardrobe_chipseq_se.cwl \
   -s gs://isb-ga4gh-dream/biowardrobe_chipseq_se/data/biowardrobe_chipseq_se.json \
   -o gs://isb-ga4gh-dream/biowardrobe_chipseq_se/data
```

#### 4. Run workflow checker tool

```shell
./cwl_runner.sh \
   -m n1-standard-2 \
   -r gs://isb-ga4gh-dream/biowardrobe_chipseq_se/data/ \
   -w gs://isb-ga4gh-dream/biowardrobe_chipseq_se/data/biowardrobe_chipseq_se_checker.cwl \
   -s gs://isb-ga4gh-dream/biowardrobe_chipseq_se/data/biowardrobe_chipseq_se_checker.json \
   -o gs://isb-ga4gh-dream/biowardrobe_chipseq_se/data
```

#### 5. Submit workflow outputs

```shell
gsutil cat gs://isb-ga4gh-dream/biowardrobe_chipseq_se/data/biowardrobe_chipseq_se_submit.json \
   | jq '.team_name=""ISB-CGC"" | .parent_id=""syn11583688""' \
   | gsutil cp - gs://isb-ga4gh-dream/biowardrobe_chipseq_se/data/biowardrobe_chipseq_se_submit.json
./cwl_runner.sh \
   -m n1-standard-2 \
   -r gs://isb-ga4gh-dream/biowardrobe_chipseq_se/data/ \
   -w gs://isb-ga4gh-dream/biowardrobe_chipseq_se/data/dockstore-tool-synapse-submit.cwl \
   -s gs://isb-ga4gh-dream/biowardrobe_chipseq_se/data/biowardrobe_chipseq_se_submit.json \
   -o gs://isb-ga4gh-dream/biowardrobe_chipseq_se/data
```
",9656042
biowardrobe_chipseq_se,9657471_report.md,"## BioWardrobe ChIP-Seq

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Michael Kotliar""
workflow_handle: ""biowardrobe_chipseq_se""
input_handle: ""SRR1198790""
```

The following description is provided by the workflow author:
> This workflow from BioWardrobe runs basic analysis of single read ChIP-Seq data. Workflow starts with BowTie alignment to a reference genome resulting in an unsorted SAM file. The SAM file is then sorted and indexed to obtain with samtools a BAM file and a BAI index. Depending on workflow’s input parameters the indexed and sorted BAM file can be processed to remove duplicate reads. If the duplicate removal is performed, sorting and indexing are repeated. Next MACS2 is used to call peaks and to estimate fragment size. If the fragment size is less than 80, then the peak calling is repeated with forced fixed fragment size (150). Fragment size can also be specified as an input parameter.  In the last few steps the coverage by estimated fragments is calculated from the BAM file and is output in bigWig format. The pipeline also reports statistics such as read quality, peak number, base frequency and other troubleshooting information using tools such as fastx, bamtools. Logs are saved in the working directory.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Abhishek Niroula"" # your name here
institution: ""LU"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-12-20"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170828135420"" # indicate executor version used
docker_version: ""17.06.1-ce, build 874a737"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""32Gb"" # indicate available RAM in environment
env_disk: ""2TB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-17""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""500Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

_____________________
#### Example
### Setting up environment
Install `cwltool` (version 1.0.20170217172322), `html5lib` and  `synapseclient`
```
pip install cwltool
pip install html5lib
pip install synapseclient
```
Create empty folder for workflow running
```
mkdir biowardrobe_chipseq_se
cd biowardrobe_chipseq_se
```
Create Synapse credentials file `.synapseConfig`, put there Synapse ID and password
```
[authentication]
username: user@usermail.org
password: <user-password>
```
### Downloading required files
Download tools to fetch workflow input data
```
synapse -c .synapseConfig get syn10204916  # biowardrobe_chipseq_se_get.json
synapse -c .synapseConfig get syn9770802   # dockstore-tool-synapse-get.cwl
synapse -c .synapseConfig get syn9732885   # dockstore-tool-synapse-submit.cwl
```
Download workflow input data
```
cwltool --debug --non-strict dockstore-tool-synapse-get.cwl biowardrobe_chipseq_se_get.json
```
Wait until downloading is finished

### Running workflow
I updated `threads ` field to 4 in `biowardrobe_chipseq_se.json` file. With the cwltool (version 1.0.20170828135420), the validation was not successful. So, I followed the second suggestion in [this discussion](https://www.synapse.org/#!Synapse:syn8507133/discussion/threadId=2222&replyId=12826). I updated the 'biowardrobe_chipseq_se/tools/samtools-sort-index.cwl' file as below.

```
   outputs:
           if (inputs.sort_input.secondaryFiles && inputs.trigger == false){
             return inputs.sort_input.secondaryFiles;
           } else {
-            return self.location + ext();
+            return self.basename+ext();
           }
         }

```


. Then, I ran the workflow
```
cwltool --debug --non-strict biowardrobe_chipseq_se.cwl biowardrobe_chipseq_se.json
```
### Validating results
Run checker tool
```
cwltool --debug --non-strict biowardrobe_chipseq_se_checker.cwl biowardrobe_chipseq_se_checker.json
```
Check results
```
cat results.json
``` 
```json
{
    ""steps"": {
        ""macs2_callpeak_forced"": ""true"", 
        ""macs2_callpeak"": ""true"", 
        ""samtools_sort_index_after_rmdup"": ""true"", 
        ""bam_to_bigwig"": ""true"", 
        ""macs_island_count"": ""true"", 
        ""samtools_sort_index"": ""true"", 
        ""bowtie_aligner"": ""true"", 
        ""samtools_rmdup"": ""true"", 
        ""fastx_quality_stats"": ""true"", 
        ""bamtools_stats"": ""true""
    }, 
    ""overall"": ""true""
}
```
### Submitting results
Update `biowardrobe_chipseq_se_submit.cwl.json` with correct
`team_name` - the name of your team in plain text format (e.g., ""GA4GH-Sage Contenders"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
Run the tool
```
cwltool --debug --non-strict dockstore-tool-synapse-submit.cwl biowardrobe_chipseq_se_submit.json
```
***Running time:*** 15 min  
***Disk usage:*** 4.0G",9657471
biowardrobe_chipseq_se,9657816_report.md,"### Workflow description

```YAML
contributor: ""Michael Kotliar""
workflow_handle: ""biowardrobe_chipseq_se""
input_handle: ""SRR1198790""
```

### Participant information
```YAML
name: ""Ben Ernest""
institution: ""Digicon Corporation""
```

### Submission overview
```YAML
date_accessed: ""2017-12-12"" 
platform: ""Dockstore"" 
workflow_type: ""CWL"" 
runner_version: ""1.0.20170217172322"" 
docker_version: ""17.09.0-ce"" 
environment: ""BioGenLink"" 
env_cpus: ""1"" 
env_memory: ""8Gb"" 
env_disk: ""5Tb"" 
```

### Steps
#####This workflow was run using the [BioGenLink](http://digicon.com/biogenlink.html) platform from [Digicon](http://digicon.com/).  Click [here](http://digicon.com/biogenlink.html) or [email us](mailto:biogenlink@digiconasp.com) for more information. 

#### **Setup**

##### Create synapse credentials file.  
This only needs to be done once, and the credentials file can be used for each workflow.
1. Log into BioGenLink.  [Click here](http://digicon.com/biogenlink.html) or [email us](mailto:biogenlink@digiconasp.com) for more information. 
${image?fileName=login%5Fscreen%5Fempty%2E2017%2D12%2D19%2Epng&align=None&scale=75&responsive=true}

2. In the **files** tab, right-click on any directory in the file system, select `Create File`, give the file a name (e.g., ""synapse_config.txt""), and click `Preview` to edit the file.  
${image?fileName=create%5Ffile%5Fpreview%2E2017%2D12%2D19%2Epng&align=None&scale=75&responsive=true}

Enter the following information in the file and save it by clicking **Save** (the disk button just above the text area).
```
[authentication]
username: email
password: password
[cache]
location: biodtfs/path/to/cache
```
**Note:** the cache directory is used by synapseClient for temporary files, and we must specify it in BioGenLink to avoid permissions errors. It can be be any directory the user chooses, even a non-existing one as long as the parent directory is valid.  It is suggested to create a working directory for each workflow and keep this file in a parent directory outside of the working directories.  

#### **Provision workflow files**

1. Create a working directory.  
    - Right-click on any directory in the file system, select `Create Folder`, and enter a name for the working directory (e.g., `biowardrobe_workflow`).

2. Run the `Synapse get` tool.
    - In the **tools** tab, find and select the `Synapse get` tool.  It can be found by keyword search or browsing to `Synapse/All/Synapse get`.  Double-clicking (shown below) the tool will open it in the workspace for editing and browsing documentation and will display the menu for providing inputs and running the tool.
${image?fileName=synapse%5Fget%5Fopen%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
    - In the `Synapse IDs` field, enter the Synapse IDs for files to be downloaded.  In this case, the synapse IDs include the following, which correspond to `biowardrobe_chipseq_se_get.json`, `dockstore-tool-synapse-submit.cwl`, and `dockstore-tool-synapse-get.cwl`:
```shell
syn10204916  
syn9770802   
syn9732885   
```   
${image?fileName=synapse%5Fget%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
    - Drag and drop the synapse credentials file (e.g., `synapse_config.txt`) from the file system into the field called `Synapse config file`.
    - Drag and drop the working directory into the field called `Output directory`.
    - Run the tool by clicking `Quick Launch`.

#### **Run the workflow**
- Run the `Dockstore launch` tool.
    1. In the **Tools** tab, find and select the `Dockstore launch` tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore launch`.  
${image?fileName=dockstore%5Flaunch%2E2018%2D01%2D04%2Epng&align=None&scale=75&responsive=true}
    2. Drag and drop the `biowardrobe_chipseq_se.cwl` and `biowardrobe_chipseq_se.json` files from the working directory into the fields labeled `CWL file` and `JSON file`, respectively.  `Parent directory` can be left blank, since the directory containing the two input files will be used as the parent directory by default.   
    3. Click `Quick Launch`.

#### **Validate the results**
- Run the `Dockstore checker` tool.
1. In the **tools** tab, find and select the `Dockstore checker` tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore checker`.  
${image?fileName=dockstore%5Fchecker%2E2017%2D12%2D25%2Epng&align=None&scale=75&responsive=true}
  2. Drag and drop the `biowardrobe_chipseq_se_checker.cwl` and `biowardrobe_chipseq_se_checker.json` files from the working directory into the fields labeled `Checker CWL file` and `Checker JSON file`, respectively.  
  3. Click `Quick Launch`.
  4. Verify that the workflow ran successfully by opening the `results.json` file and confirming that the `Overall` field is equal to `true`.
${image?fileName=results%5Fjson%2E2017%2D12%2D25%2Epng&align=None&scale=75&responsive=true}

#### **Submit the results to Synapse**
- Run the `Dockstore submit` tool.
  1. In the **Tools** tab, find and select the `Dockstore submit` tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore submit`.  
${image?fileName=dockstore%5Fsubmit%2E2017%2D12%2D26%2Epng&align=None&scale=75&responsive=true}
  2. Drag and drop the `biowardrobe_chipseq_se_submit.json` file into the field labeled `Submit JSON file`.  
  3. Enter a team name and the Synapse parent ID into the corresponding fields.  
  4. Drag and drop the synapse credentials file (e.g., `synapse_config.txt`) into the field labeled `Synapse config file`.
  5. Click `Quick Launch`.",9657816
biowardrobe_chipseq_se,9657901_report.md,"## BioWardrobe ChIP-Seq

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Michael Kotliar""
workflow_handle: ""biowardrobe_chipseq_se""
input_handle: ""SRR1198790""
```

The following description is provided by the workflow author:
> This workflow from BioWardrobe runs basic analysis of single read ChIP-Seq data. Workflow starts with BowTie alignment to a reference genome resulting in an unsorted SAM file. The SAM file is then sorted and indexed to obtain with samtools a BAM file and a BAI index. Depending on workflow’s input parameters the indexed and sorted BAM file can be processed to remove duplicate reads. If the duplicate removal is performed, sorting and indexing are repeated. Next MACS2 is used to call peaks and to estimate fragment size. If the fragment size is less than 80, then the peak calling is repeated with forced fixed fragment size (150). Fragment size can also be specified as an input parameter.  In the last few steps the coverage by estimated fragments is calculated from the BAM file and is output in bigWig format. The pipeline also reports statistics such as read quality, peak number, base frequency and other troubleshooting information using tools such as fastx, bamtools. Logs are saved in the working directory.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Junjun Zhang"" # your name here
institution: ""Ontario Institute for Cancer Research"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-11-15"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""JTracker"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
cwltool_version: ""1.0.2017110733715""
runner_version: ""0.2.0a5"" # indicate executor version used
docker_version: ""1.12.6"" # from `docker --version`
environment: ""OpenStack VM"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""96GB"" # indicate available RAM in environment
env_disk: ""2TB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-08-31""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""1.12.6""
environment_ex: ""local"" 
env_cpus_ex: ""8""
env_memory_ex: ""96GB""
env_disk_ex: ""2TB""
```

### Write a JTracker Workflow
The JTracker workflow is written to automatically execute necessary steps to complete a Dream Challenge workflow. The JTracker workflow is named as `dream-challenge-wf-runner`, the source code is checked in Github at: https://github.com/jthub/demo-workflows/tree/master/dream-challenge-wf-runner/workflow.

Once tested out successfully, make a release of the source code. In this case, it is release version 0.0.7: https://github.com/jthub/demo-workflows/releases/tag/dream-challenge-wf-runner.0.0.7

### Register the JTracker Workflow in JTHub
#### Install JTracker command line tool

Follow the instructions here: https://github.com/icgc-dcc/jtracker

Once install successfully, you should be able to see the version number.
```
jt --version
```

#### Signup a JTHub account
Assume we choose `ga4gh_dream` as account name:
```
jt user signup -u ga4gh_dream
```
Login as `ga4gh_dream`
```
jt user login -u ga4gh_dream
```

#### Register the JTracker Dream Challenge Runner Workflow
Register a workflow is basically provide information to access the JTracker workflow source code in GitHub.
```
jt wf register --git-server https://github.com --git-account jthub --git-repo demo-workflows \
                       --git-path dream-challenge-wf-runner --git-tag dream-challenge-wf-runner.0.0.7 \
                       --wf-name dream-challenge-wf-runner --wf-version 0.0.7
```
To list all registered workflows in your account, do this:
```
jt wf ls
```

### Create a Job Queue
Once we have the workflow registered, you will be able to create a job queue for it.
```
jt queue add --wf-name dream-challenge-wf-runner --wf-version 0.0.7
```
Upon success, you will get a unique job queue ID. In my case, my queue ID is: `758b7668-0057-4ef6-a5b0-6f48acf38583`

To list all job queues you created, do this:
```
jt queue ls
```

### Add workflow job to the above queue
If we want to run `biowardrobe_chipseq_se`, fill out the appropriate parameters in the job JSON as below:
```
jt job add -q 758b7668-0057-4ef6-a5b0-6f48acf38583 -j '
{
    ""workflow_name"": ""biowardrobe_chipseq_se"",
    ""workflow_type"": ""CWL"",
    ""data_syn_id"": ""syn9772359"",
    ""wf_file_name"": ""biowardrobe_chipseq_se.cwl"",
    ""job_file_name"": ""biowardrobe_chipseq_se.json"",
    ""checker_wf_file_name"": ""biowardrobe_chipseq_se_checker.cwl"",
    ""checker_job_file_name"": ""biowardrobe_chipseq_se_checker.json"",
    ""submit_job_file_name"": ""submit.json"",
    ""team_name"": ""PCAWG-Tech"",
    ""syn_parent_id"": ""syn11638849"",
    ""eval_id"": ""9604287""
}
'
```
To list all jobs in the queue:
```
jt job ls -q 758b7668-0057-4ef6-a5b0-6f48acf38583
```
Note that the above steps can be done on any computer, it could be a normal workstation or a laptop.


### Run the above queued Sanger workflow job

To execute the workflow job you will need to set up necessary environment and tools, follow these steps:

#### Setting up environment
1. Install Docker

2. Install `cwltool` (version 1.0.20170217172322) and  `synapseclient`
```
pip install cwltool==1.0.20170217172322
pip install html5lib
pip install synapseclient
```

3. Create Synapse credentials file `.synapseConfig`
Put there Synapse ID and password
```
[authentication]
username: user@usermail.org
password: <user-password>
```
Put this file a particular place, for example under home directory, eg, `/home/ubuntu/.synapseConfig`, then export the follow environment variable:
```
export SYNCONF=/home/ubuntu/.synapseConfig
```
4. Install JTracker command line
This is the same step as the previous section. Follow installation instruction here: https://github.com/icgc-dcc/jtracker

#### Start JTracker Executor
Start the executor to run jobs in the queue as:
```
jt user login ga4gh_dream
SYNCONF=/home/ubuntu/.synapseConfig jt exec run -q 758b7668-0057-4ef6-a5b0-6f48acf38583
```
If everything goes well, in about 5 hours, the job should finish and you will see `pcawg-sanger-variant-caller` result uploaded to specified location on Synapse.

",9657901
biowardrobe_chipseq_se,9657903_report.md,"## BioWardrobe ChIP-Seq

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Michael Kotliar""
workflow_handle: ""biowardrobe_chipseq_se""
input_handle: ""SRR1198790""
```

The following description is provided by the workflow author:
> This workflow from BioWardrobe runs basic analysis of single read ChIP-Seq data. Workflow starts with BowTie alignment to a reference genome resulting in an unsorted SAM file. The SAM file is then sorted and indexed to obtain with samtools a BAM file and a BAI index. Depending on workflow’s input parameters the indexed and sorted BAM file can be processed to remove duplicate reads. If the duplicate removal is performed, sorting and indexing are repeated. Next MACS2 is used to call peaks and to estimate fragment size. If the fragment size is less than 80, then the peak calling is repeated with forced fixed fragment size (150). Fragment size can also be specified as an input parameter.  In the last few steps the coverage by estimated fragments is calculated from the BAM file and is output in bigWig format. The pipeline also reports statistics such as read quality, peak number, base frequency and other troubleshooting information using tools such as fastx, bamtools. Logs are saved in the working directory.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Junjun Zhang"" # your name here
institution: ""Ontario Institute for Cancer Research"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-11-15"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""JTracker"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
cwltool_version: ""1.0.2017110733715""
runner_version: ""0.2.0a5"" # indicate executor version used
docker_version: ""1.12.6"" # from `docker --version`
environment: ""OpenStack VM"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""96GB"" # indicate available RAM in environment
env_disk: ""2TB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-08-31""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""1.12.6""
environment_ex: ""local"" 
env_cpus_ex: ""8""
env_memory_ex: ""96GB""
env_disk_ex: ""2TB""
```

### Write a JTracker Workflow
The JTracker workflow is written to automatically execute necessary steps to complete a Dream Challenge workflow. The JTracker workflow is named as `dream-challenge-wf-runner`, the source code is checked in Github at: https://github.com/jthub/demo-workflows/tree/master/dream-challenge-wf-runner/workflow.

Once tested out successfully, make a release of the source code. In this case, it is release version 0.0.7: https://github.com/jthub/demo-workflows/releases/tag/dream-challenge-wf-runner.0.0.7

### Register the JTracker Workflow in JTHub
#### Install JTracker command line tool

Follow the instructions here: https://github.com/icgc-dcc/jtracker

Once install successfully, you should be able to see the version number.
```
jt --version
```

#### Signup a JTHub account
Assume we choose `ga4gh_dream` as account name:
```
jt user signup -u ga4gh_dream
```
Login as `ga4gh_dream`
```
jt user login -u ga4gh_dream
```

#### Register the JTracker Dream Challenge Runner Workflow
Register a workflow is basically provide information to access the JTracker workflow source code in GitHub.
```
jt wf register --git-server https://github.com --git-account jthub --git-repo demo-workflows \
                       --git-path dream-challenge-wf-runner --git-tag dream-challenge-wf-runner.0.0.7 \
                       --wf-name dream-challenge-wf-runner --wf-version 0.0.7
```
To list all registered workflows in your account, do this:
```
jt wf ls
```

### Create a Job Queue
Once we have the workflow registered, you will be able to create a job queue for it.
```
jt queue add --wf-name dream-challenge-wf-runner --wf-version 0.0.7
```
Upon success, you will get a unique job queue ID. In my case, my queue ID is: `758b7668-0057-4ef6-a5b0-6f48acf38583`

To list all job queues you created, do this:
```
jt queue ls
```

### Add workflow job to the above queue
If we want to run `biowardrobe_chipseq_se`, fill out the appropriate parameters in the job JSON as below:
```
jt job add -q 758b7668-0057-4ef6-a5b0-6f48acf38583 -j '
{
    ""workflow_name"": ""biowardrobe_chipseq_se"",
    ""workflow_type"": ""CWL"",
    ""data_syn_id"": ""syn9772359"",
    ""wf_file_name"": ""biowardrobe_chipseq_se.cwl"",
    ""job_file_name"": ""biowardrobe_chipseq_se.json"",
    ""checker_wf_file_name"": ""biowardrobe_chipseq_se_checker.cwl"",
    ""checker_job_file_name"": ""biowardrobe_chipseq_se_checker.json"",
    ""submit_job_file_name"": ""submit.json"",
    ""team_name"": ""PCAWG-Tech"",
    ""syn_parent_id"": ""syn11638849"",
    ""eval_id"": ""9604287""
}
'
```
To list all jobs in the queue:
```
jt job ls -q 758b7668-0057-4ef6-a5b0-6f48acf38583
```
Note that the above steps can be done on any computer, it could be a normal workstation or a laptop.


### Run the above queued Sanger workflow job

To execute the workflow job you will need to set up necessary environment and tools, follow these steps:

#### Setting up environment
1. Install Docker

2. Install `cwltool` (version 1.0.20170217172322) and  `synapseclient`
```
pip install cwltool==1.0.20170217172322
pip install html5lib
pip install synapseclient
```

3. Create Synapse credentials file `.synapseConfig`
Put there Synapse ID and password
```
[authentication]
username: user@usermail.org
password: <user-password>
```
Put this file a particular place, for example under home directory, eg, `/home/ubuntu/.synapseConfig`, then export the follow environment variable:
```
export SYNCONF=/home/ubuntu/.synapseConfig
```
4. Install JTracker command line
This is the same step as the previous section. Follow installation instruction here: https://github.com/icgc-dcc/jtracker

#### Start JTracker Executor
Start the executor to run jobs in the queue as:
```
jt user login ga4gh_dream
SYNCONF=/home/ubuntu/.synapseConfig jt exec run -q 758b7668-0057-4ef6-a5b0-6f48acf38583
```
If everything goes well, in about 5 hours, the job should finish and you will see `pcawg-sanger-variant-caller` result uploaded to specified location on Synapse.
",9657903
biowardrobe_chipseq_se,9657904_report.md,"### Workflow description

```YAML
contributor: ""Michael Kotliar""
workflow_handle: ""biowardrobe_chipseq_se""
input_handle: ""SRR1198790""
```

### Participant information
```YAML
name: ""Ben Ernest""
institution: ""Digicon Corporation""
```

### Submission overview
```YAML
date_accessed: ""2017-12-12"" 
platform: ""BioGenLink"" 
workflow_type: ""CWL"" 
runner_version: ""1.0.20170217172322"" 
docker_version: ""17.09.0-ce"" 
environment: ""BioGenLink"" 
env_cpus: ""1"" 
env_memory: ""8Gb"" 
env_disk: ""5Tb"" 
```

### Steps
#####This workflow was run using the [BioGenLink](http://digicon.com/biogenlink.html) platform from [Digicon](http://digicon.com/).  Click [here](http://digicon.com/biogenlink.html) or [email us](mailto:biogenlink@digiconasp.com) for more information. 

#### **Setup**

##### Create synapse credentials file.  
This only needs to be done once, and the credentials file can be used for each workflow.
1. Log into BioGenLink.  [Click here](http://digicon.com/biogenlink.html) or [email us](mailto:biogenlink@digiconasp.com) for more information.
${image?fileName=login%5Fscreen%5Fempty%2E2017%2D12%2D19%2Epng&align=None&scale=75&responsive=true}

2. In the **files** tab, right-click on any directory in the file system, select `Create File`, give the file a name (e.g., ""synapse_config.txt""), and click `Preview` to edit the file.  
${image?fileName=create%5Ffile%5Fpreview%2E2017%2D12%2D19%2Epng&align=None&scale=75&responsive=true}

Enter the following information in the file and save it by clicking **Save** (the disk button just above the text area).
```
[authentication]
username: email
password: password
[cache]
location: biodtfs/path/to/cache
```
**Note:** the cache directory is used by `synapseClient` for temporary files, and we must specify it in BioGenLink to avoid permissions errors. It can be any directory the user chooses, even a non-existing one as long as the parent directory is valid.  It is suggested to create a working directory for each workflow and keep this file in a parent directory outside of the working directories.  

#### **Provision workflow files**

1. Create a working directory.  
    - Right-click on any directory in the file system, select `Create Folder`, and enter a name for the working directory (e.g., `biowardrobe_workflow`).

2. Run the `Synapse get` tool.
    - In the **tools** tab, find and select the `Synapse get` tool.  It can be found by keyword search or browsing to `Synapse/All/Synapse get`.  Double-clicking (shown below) the tool will open it in the workspace for editing and browsing documentation and will display the menu for providing inputs and running the tool.
${image?fileName=synapse%5Fget%5Fopen%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
    - In the `Synapse IDs` field, enter the Synapse IDs for files to be downloaded.  In this case, the synapse IDs include the following, which correspond to `biowardrobe_chipseq_se_get.json`, `dockstore-tool-synapse-submit.cwl`, and `dockstore-tool-synapse-get.cwl`:
```shell
syn10204916
syn9732885
syn9770802
```
${image?fileName=synapse%5Fget%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
    - Drag and drop the synapse credentials file (e.g., `synapse_config.txt`) from the file system into the field called `Synapse config file`.
    - Drag and drop the working directory into the field called `Output directory`.
    - Run the tool by clicking `Quick Launch`.

#### **Import the workflow**
- If the workflow has not been imported yet, go to the **files** tab and find the `CWL` file corresponding to the workflow you want to build (e.g., `biowardrobe_chipseq_se.cwl`).  Right-click on the file, and select `Import CWL File`.  This will automatically build a workflow which can be edited and run within the BioGenLink platform. 
${image?fileName=import%5Fcwl%5Ffile%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
The `biowardrobe_chipseq_se` workflow is automatically created and placed in the **workflows** tab, under `CWL/Autogenerated`. 

#### **Run the workflow**
1. In the **workflows** tab, find and select the `biowardrobe_chipseq_se` workflow.  The previous step automatically places it in the `CWL/Autogenerated` folder.  Double-clicking (shown below) opens the workflow in the workspace for editing and will display the menu for providing inputs and running the workflow.
${image?fileName=hello%5Fworld%5Fworkflow%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
If the run parameters aren't visible, right-click the orange ""play button"" at top right of the workspace to open them.
${image?fileName=hello%5Fworld%5Fworkflow%5Frun%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
The default inputs should already be set, but if they aren't then drag and drop the appropriate files from the working directory into the input fields.
2. Drag and drop a directory from the file system into the `Output Directory` field.
3. Run the workflow by clicking the `RUN WITH SKIPPING` button.


#### **Validate the results**
- Run the `Dockstore checker` tool.
1. In the **tools** tab, find and select the `Dockstore checker` tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore checker`.  
${image?fileName=dockstore%5Fchecker%2E2017%2D12%2D25%2Epng&align=None&scale=75&responsive=true}
2. Drag and drop the `biowardrobe_chipseq_se_checker.cwl` and `biowardrobe_chipseq_se_checker.cwl.json` files from the working directory into the fields labeled `Checker CWL file` and `Checker JSON file`, respectively.  
3. Click `Quick Launch`.
4. Verify that the workflow ran successfully by opening the `results.json` file and confirming that the `Overall` field is equal to `true`.
${image?fileName=results%5Fjson%2E2017%2D12%2D25%2Epng&align=None&scale=75&responsive=true}

#### **Submit the results to Synapse**
- Run the `Dockstore submit` tool.
1. In the **tools** tab, find and select the `Dockstore submit` tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore submit`.  
${image?fileName=dockstore%5Fsubmit%2E2017%2D12%2D26%2Epng&align=None&scale=75&responsive=true}
2. Drag and drop the `biowardrobe_chipseq_se_submit.cwl.json` file into the field labeled `Submit JSON file`.  
3. Enter a team name and the Synapse parent ID into the corresponding fields.  
4. Drag and drop the synapse credentials file (e.g., `synapse_config.txt`) into the field labeled `Synapse config file`.
5. Click `Quick Launch`.",9657904
broad-gatk-validate-bam,9657595_report.md,"## Broad GATK ValidateBam Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted files to be viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Beri Shifaw, Broad Institute Data Sciences Platform""
workflow_handle: ""broad-gatk-validate-bam""
input_handle: ""NA12878""
```

The following description is provided by the workflow author:
> This is workflow is published by the Broad Institute's Data Sciences Platform, obtained from https://github.com/gatk-workflows. This WDL performs format validation on SAM/BAM files in a list.
> 
> **Requirements/expectations:**
> - List of SAM or BAM files to validate
> - Explicit request of either SUMMARY or VERBOSE mode in `inputs.json`
> 
> **Outputs:**
>  - Set of `.txt` files containing the validation reports, one per input file
> 
> **Cromwell version support:** 
> - Successfully tested on v24 and v29
> - Does not work on versions < v23 due to output syntax


####Suggested resources:  

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""100Gb""
```

Users should have the following installed on system
Docker: https://docs.docker.com/engine/installation/
Anaconda: https://www.anaconda.com/download/ 

#### Workflow history

+ **2017-10-10**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""James Eddy"" # your name here
institution: ""Sage Bionetworks"" # your institution here
```

### Submission overview:

Provide high level summary information for workflow execution in the fields below.

> **Note:** Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-12-20"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cromwell"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""WDL"" # CWL or WDL
runner_version: ""29"" # indicate executor version used
docker_version: ""17.09.1-ce, build 19e2cf6"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""4"" # indicate number of cores in environment
env_memory: ""16Gb"" # indicate available RAM in environment
env_disk: ""300Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.  Here we indicate the CPU's and memory made available _to Docker_ since that represents the maximum resources available to the workflow stages.

```YAML
date_accessed_ex: ""2017-10-5""
platform_ex: ""cromwell"" 
workflow_type_ex: ""WDL"" 
runner_version_ex: ""29""
docker_version_ex: ""17.09.0-ce, build afdb6d4""
environment_ex: ""macOS 10.12.6"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""1Tb""
```

### Steps

#### 1. Set up environment

On a personal laptop (Macbook Pro) with Docker and Anaconda installed, I created and configured a virtual environment as follows*:

```shell
conda create -n ValidateBam python=2.7
source activate ValidateBam
pip install schema-salad==2.2.20170222151604 cwltool==1.0.20170217172322
pip install synapseclient
```

*Note: I used Python 2.7 for the environment to avoid conflicts with another instance of `cwltool` that was installed in my global Anaconda environment.

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir ValidateBam
cd ValidateBam
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the `synapse get` command to download the synapse-get and synapse-submit CWL tools as well as the JSON parameters to download data for the **broad-gatk-validate-bam** workflow:
```shell
synapse get syn11178775 # ValidateBam_get.cwl.json 
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `ValidateBam_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl ValidateBam_get.cwl.json
```

#### 4. Run main workflow

```shell
java -jar cromwell-29.jar run validate-bam.wdl --inputs validate-bam.inputs.json --options generic.google-papi.options.json
```

#### 5. Run workflow checker tool for each output

The output directory for my workflow run was located in `./cromwell-executions/ValidateBamWF/874862a0-8612-46ae-b2a0-2195436eb64a` relative to my `ValidateBam` working directory, where ""874862a0-8612-46ae-b2a0-2195436eb64a"" was the unique ID for the run. The output text files for each BAM file were separated in different shards: 
+ `./cromwell-executions/ValidateBamsWf/874862a0-8612-46ae-b2a0-2195436eb64a/call-ValidateBAM/shard-0`
+ `./cromwell-executions/ValidateBamsWf/874862a0-8612-46ae-b2a0-2195436eb64a/call-ValidateBAM/shard-1`

Each output file was stored in the `execution` directory of each shard. 

&nbsp;
Prior to running the `ValidateBam_checker.wdl` tool, I updated the parameters in `ValidateBam_checker.wdl.json` as follows:
```JSON
{
  ""md5sumChecker.input_files"": [
    ""./cromwell-executions/ValidateBamsWf/874862a0-8612-46ae-b2a0-2195436eb64a/call-ValidateBAM/shard-0/execution/H06HDADXX130110.1.ATCACGAT.20k_reads.validation_SUMMARY.txt"", 
    ""./cromwell-executions/ValidateBamsWf/874862a0-8612-46ae-b2a0-2195436eb64a/call-ValidateBAM/shard-1/execution/H06HDADXX130110.2.ATCACGAT.20k_reads.validation_SUMMARY.txt""
  ],

  ""md5sumChecker.docker_image"": ""broadinstitute/genomes-in-the-cloud:2.3.0-1501082129"",
  ""md5sumChecker.Checkmd5sum.docker_image"": ""broadinstitute/genomes-in-the-cloud:2.3.0-1501082129"",

  ""md5sumChecker.mem_size"": ""3 GB"",
  ""md5sumChecker.Checkmd5sum.mem_size"": ""2 GB"",

  ""md5sumChecker.preemptible_tries"": 3,
  ""md5sumChecker.Checkmd5sum.preemptible_tries"": 3,

  ""md5sumChecker.disk_size"": 5,
  ""md5sumChecker.Checkmd5sum.disk_size"": 5
}
```

&nbsp;
To verify workflow results before submission I used the WDL checker tool to validate output files as follows:
```shell
java -jar cromwell-29.jar run ValidateBam_checker.wdl --inputs ValidateBam_checker.wdl.json
```

&nbsp;
The `results.json` and `log.txt` outputs were be stored in execution directory stated in the stdout: `./romwell-executions/md5sumChecker/84cd2bd4-f2a3-4695-8977-32416750038e/call-Checkmd5sum/execution/`.

&nbsp;
Output for `cat results.json` read :
```shell
{ 
""overall"": true,
  ""steps"": {
    ""r1_md5sum"": true, 
    ""r2_md5sum"": true
  }
```

#### 6. Submit workflow outputs
I modified the parameters in `ValidateBam_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""SageWorkflowRunners"",
    ""eval_id"": ""9607590"",
    ""file"": [
        {
            ""class"": ""File"",
            ""path"": ""./cromwell-executions/ValidateBamsWf/874862a0-8612-46ae-b2a0-2195436eb64a/call-ValidateBAM/shard-0/execution/H06HDADXX130110.1.ATCACGAT.20k_reads.validation_SUMMARY.txt""
        },
        {
            ""class"": ""File"",
            ""path"": ""./cromwell-executions/ValidateBamsWf/874862a0-8612-46ae-b2a0-2195436eb64a/call-ValidateBAM/shard-1/execution/H06HDADXX130110.2.ATCACGAT.20k_reads.validation_SUMMARY.txt""
        }

    ],
    ""parent_id"": ""syn11627167""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl ValidateBam_submit.cwl.json
```",9657595
broad-gatk-validate-bam,9657957_report.md,"### Workflow description

```YAML
contributor: ""Beri Shifaw, Broad Institute Data Sciences Platform""
workflow_handle: ""broad-gatk-validate-bam""
input_handle: ""NA12878""
```

```YAML
name: ""Ben Ernest"" 
institution: ""Digicon Corporation"" 
```

### Submission overview:

```YAML
date_accessed: ""2017-12-05"" 
platform: ""cromwell"" 
workflow_type: ""WDL"" 
runner_version: ""29"" 
docker_version: ""17.09.0-ce"" 
environment: ""cluster"" 
env_cpus: ""12"" 
env_memory: ""62Gb"" 
env_disk: ""5Tb"" 
```

### Steps

#### 1. Set up environment, following instructions at https://dockstore.org/quick-start.  These only need to be done once for all workflows that use `cwltool`.
##### Instructions are for Linux CentOS

Download and install dockstore.  
```shell
mkdir -p ~/bin
curl -L -o ~/bin/dockstore https://github.com/ga4gh/dockstore/releases/download/1.3.0/dockstore
chmod +x ~/bin/dockstore
echo 'export PATH=~/bin:$PATH' >> ~/.bashrc
source ~/.bashrc
```

Create configuration file
```shell
mkdir -p ~/.dockstore
printf ""token: dummy-token\nserver-url: https://dockstore.org:8443\n"" > ~/.dockstore/config
```

Install `pip`
```shell
curl -L -o ~/get-pip.py https://bootstrap.pypa.io/get-pip.py
sudo python get-pip.py
```

Install `cwltool` (**note: version 1.0.20170217172322**)
```shell
sudo pip install setuptools==36.5.0
sudo pip install cwl-runner cwltool==1.0.20170217172322 schema-salad==2.6.20170806163416 avro==1.8.1 ruamel.yaml==0.14.12 requests==2.18.4
```

Install Docker
```shell
sudo yum install -y yum-utils device-mapper-persistent-data lvm2
sudo yum-config-manager --add-repo ""https://download.docker.com/linux/centos/docker-ce.repo""
sudo yum-config-manager --enable extras
sudo yum -y install docker-ce
sudo usermod -aG docker $USER
exec newgrp docker
```

Create aliases to start and stop Docker
```shell
echo 'alias start_docker=""sudo systemctl start docker""' >> ~/.bashrc
echo `alias stop_docker=""sudo systemctl stop docker""' >> ~/.bashrc
source ~/.bashrc
```
Install `synapseclient`
```
sudo pip install synapseclient
```

Create synapse credentials file with the content below, using your own Synapse credentials (no quotes or extra characters).  It can be named anything, but I'm using `.synapseConfig`.
```
[authentication]
username: email
password: password
```

Create a working directory and copy synapse credentials file into that folder.
```shell
mkdir -p broad_gatk
cd broad_gatk
cp ~/.synapseConfig .
```

#### 2. Download required files
Download tools to fetch workflow input data.
```shell
synapse get syn11178775 # ValidateBam_get.cwl.json 
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files
Start docker, using alias created previously.
```shell
start_docker
```

Use `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `ValidateBam_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl ValidateBam_get.cwl.json
```

#### 4. Run main workflow

```shell
java -jar cromwell-29.jar run validate-bam.wdl --inputs validate-bam.inputs.json --options generic.google-papi.options.json
```

#### 5. Run workflow checker tool for outputs

The output directory for a given run will be located in `./cromwell-executions/ValidateBamWF/<unique run ID>`. The output files for each bam will be separated in different shards: `./cromwell-executions/ValidateBamsWf/<unique run ID>/call-ValidateBAM/shard-<#>` . The output will be stored in the `execution` directory of each shard. 

To make it easier to update paths in the `_checker` and `_submit` parameter JSON files below, copy the two output files into your working directory:
```shell
cp ./cromwell-executions/ValidateBamsWf/**<unique run ID>**/call-ValidateBAM/shard-0/execution/H06HDADXX130110.1.ATCACGAT.20k_reads.validation_SUMMARY.txt .
cp ./cromwell-executions/ValidateBamsWf/**<unique run ID>**/call-ValidateBAM/shard-1/execution/H06HDADXX130110.1.ATCACGAT.20k_reads.validation_SUMMARY.txt .
```

To verify workflow results before submission use wdl tool to run the checker for each output file as follows:
```shell
java -jar cromwell-29.jar run ValidateBam_checker.wdl --inputs ValidateBam_checker.wdl.json
```

The `results.json` and `log.txt` outputs will be stored in execution directory stated in the stdout: `./romwell-executions/md5sumChecker/<unique run ID>/call-Checkmd5sum/execution/`

Output for `cat results.json` should read :
```shell
{ 
""overall"": true,
  ""steps"": {
    ""r1_md5sum"": true, 
    ""r2_md5sum"": true
  }
```

#### 6. Submit workflow outputs

Modify the `team_name` and `parent_id` fields in `ValidateBam_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""BioGenLink"",
    ""eval_id"": ""9607590"",
    ""file"": [
        {
            ""class"": ""File"",
            ""path"": ""H06HDADXX130110.1.ATCACGAT.20k_reads.validation_SUMMARY.txt""
        },
        {
            ""class"": ""File"",
            ""path"": ""H06HDADXX130110.2.ATCACGAT.20k_reads.validation_SUMMARY.txt""
        }

    ],
    ""parent_id"": ""syn11643432""
}

```

Finally, submit outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl ValidateBam_submit.cwl.json
```

Stop Docker if desired.
```shell
stop_docker
```",9657957
broad-gatk-validate-bam,9657958_report.md,"### Workflow description

```YAML
contributor: ""Beri Shifaw, Broad Institute Data Sciences Platform""
workflow_handle: ""broad-gatk-validate-bam""
input_handle: ""NA12878""
```

### Participant information

```YAML
name: ""Ben Ernest"" 
institution: ""Digicon Corporation"" 
```

### Submission overview
```YAML
date_accessed: ""2017-12-12"" 
platform: ""cromwell"" 
workflow_type: ""CWL"" 
runner_version: ""1.0.20170217172322"" 
docker_version: ""17.09.0-ce"" 
environment: ""BioGenLink"" 
env_cpus: ""1"" 
env_memory: ""8Gb"" 
env_disk: ""5Tb"" 
```

### Steps

#### 1. Set up environment

On a personal laptop with Docker and Anaconda installed, create and configure a virtual environment as follows:

```shell
conda create -n ValidateBam
source activate ValidateBam
pip install --upgrade pip
pip install schema-salad==2.2.20170222151604 cwltool==1.0.20170217172322
pip install synapseclient
```

Create a working directory for the current workflow and create a copy of my Synapse credentials in that folder:
```shell
mkdir ValidateBam
cd ValidateBam
cp ~/.synapseConfig .
```

#### 2. Download required files

Use the `synapse get` command to download the synapse-get and synapse-submit CWL tools as well as the JSON parameters to download data for the **broad-gatk-validate-bam** workflow:
```shell
synapse get syn11178775 # ValidateBam_get.cwl.json 
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

Use `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `ValidateBam_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl ValidateBam_get.cwl.json
```

#### 4. Run main workflow

```shell
java -jar cromwell-29.jar run validate-bam.wdl --inputs validate-bam.inputs.json --options generic.google-papi.options.json
```

#### 5. Run workflow checker tool for outputs

The output directory for a given run will be located in `./cromwell-executions/ValidateBamWF/<unique run ID>`. The output files for each bam will be separated in different shards: `./cromwell-executions/ValidateBamsWf/<unique run ID>/call-ValidateBAM/shard-<#>` . The output will be stored in the `execution` directory of each shard. 

&nbsp;
Optionally, to make it easier to update paths in the `_checker` and `_submit` parameter JSON files below, you can copy the two output files into your working directory:
```shell
cp ./cromwell-executions/ValidateBamsWf/**<unique run ID>**/call-ValidateBAM/shard-0/execution/H06HDADXX130110.1.ATCACGAT.20k_reads.validation_SUMMARY.txt .
cp ./cromwell-executions/ValidateBamsWf/**<unique run ID>**/call-ValidateBAM/shard-1/execution/H06HDADXX130110.1.ATCACGAT.20k_reads.validation_SUMMARY.txt .
```

&nbsp;
To verify workflow results before submission use wdl tool to run the checker for each output file as follows:
```shell
java -jar cromwell-29.jar run ValidateBam_checker.wdl --inputs ValidateBam_checker.wdl.json
```

&nbsp;
The `results.json` and `log.txt` outputs will be stored in execution directory stated in the stdout: `./romwell-executions/md5sumChecker/<unique run ID>/call-Checkmd5sum/execution/`

&nbsp;
Output for `cat results.json` should read :
```shell
{ 
""overall"": true,
  ""steps"": {
    ""r1_md5sum"": true, 
    ""r2_md5sum"": true
  }
```

#### 6. Submit workflow outputs

I modified the parameters in `ValidateBam_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": """",
    ""eval_id"": ""9607590"",
    ""file"": [
        {
            ""class"": ""File"",
            ""path"": ""./cromwell-executions/ValidateBamsWf/<unique ID>/call-ValidateBAM/shard-0/execution/H06HDADXX130110.1.ATCACGAT.20k_reads.validation_SUMMARY.txt""
        },
        {
            ""class"": ""File"",
            ""path"": ""./cromwell-executions/ValidateBamsWf/<unique ID>/call-ValidateBAM/shard-1/execution/H06HDADXX130110.2.ATCACGAT.20k_reads.validation_SUMMARY.txt""
        } 
    ],
    ""parent_id"": ""syn11463816""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl ValidateBam_submit.cwl.json
```",9657958
encode_mapping_workflow,9624378_report.md,"## ENCODE ChIP-seq Mapping Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted files to be viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""J. Seth Strattan, ENCODE Data Coordinating Center""
workflow_handle: ""encode_mapping_workflow""
input_handle: ""A549_CEBP""
```

The following description is provided by the workflow author:
> This workflow is a containerized version of the mapping component from the ENCODE Uniform Analysis Pipeline for ChIP-seq experiments.  The analysis is specified by the ENCODE Data Analysis Center (Zhiping Weng, University of Massachusetts) and ENCODE Analysis Working Group (Anshul Kundaje, Stanford University) and implemented and run by the ENCODE Data Coordinating Center (J. Michael Cherry, Stanford University).
> &nbsp;
> The workflow takes raw reads in the form of a fastq file and a genome reference and generates quality-control (QC) metrics and a filtered bam file suitable for peak calling and signal track generation.  The QC metrics include read depth, library complexity estimates, and scores from cross-correlation analysis.  The workflow is written in both Common Workflow Language (CWL) `encode_mapping_workflow.cwl` and Workflow Description Language (WDL) `encode_mapping_workflow.wdl`.
> &nbsp;
> For this Challenge, known-good inputs are in the `input_data` folder.  The file `input_data/ENCFF000VOL.fastq.gz` are reads from one replicate of an ENCODE ChIP-seq experiment done on the human A549 cell line and targeting the CEBP transcription factor.  The standard GRCh38 reference used by ENCODE is included in `input_data/reference/ENCFF643CGH_ENCODE_GRCh38_bwa.tar.gz`.  Complete metadata and analysis results from this experiment are accessioned at the ENCODE Portal [under accession number ENCSR000DYI here](https://www.encodeproject.org/experiments/ENCSR000DYI/).  Paths to the input files are specified in the CWL parameter file `encode_mapping_workflow.cwl.json` and the WDL parameter file `encode_mapping_workflow.wdl.json`.  Submissions to the challenge will be scored against known-good outputs of the workflow run on these inputs.  Run time should be less than two hours.  Workflow stages will automatically scale into multiple CPU cores if they are made available to Docker.  The workflow has been tested with 4 GB per core.  Disk requirements are highly-dependent on particular workflow runners and their handling of intermediate files.  In addition to cached Docker layers, CWL runs typically use approximately 3 GB of disk space.  WDL runs with cromwell consume considerably more disk space.
> &nbsp;
> To accelerate deployment and testing the workflow is also packaged with smaller test inputs.  The reads in `input_data/ENCFF000VOL_chr21.fq.gz` are chromosome 21 extracts from the same A549/CEBP experiment as above and the companion reference `input_data/reference/GRCh38_chr21_bwa.tar.gz` is a small chromosome 21-only reference.  Paths to these inputs are in the CWL parameter file `input_data/encode_mapping_workflow.cwl_test.json` and the WDL parameter file `input_data/encode_mapping_workflow.wdl_test.json`.  Using these inputs the workflow takes less than a minute to run, not counting Docker downloads if image layers are not yet cached locally.  Do not submit results from these small test files for the Challenge.  They are only for your use in rapid deployment and testing on new platforms.
> &nbsp;
> Code for this workflow can be found in [the pipeline-container GitHub repo](https://github.com/ENCODE-DCC/pipeline-container).  The full ENCODE ChIP-seq analysis pipeline code is in [the chip-seq-pipeline GitHub repo](https://github.com/ENCODE-DCC/chip-seq-pipeline).  ENCODE Uniform Processing Pipelines are runnable on [DNAnexus](https://www.dnanexus.com/) in the featured DNAnexus project called ""ENCODE Uniform Processing Pipelines"".  More information on using ENCODE pipelines is [here](https://www.encodeproject.org/tutorials/ashg-2016-uniform-processing-pipelines/).  All the data and software products from ENCODE are distributed through the [ENCODE Portal](https://www.encodeproject.org/).

### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""30Gb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""James Eddy"" # your name here
institution: ""Sage Bionetworks"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> **Note:** Participants should update these fields to reflect the approach they used.

```YAML
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170217172322"" # indicate executor version used
docker_version: ""17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""EC2"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""61Gb"" # indicate available RAM in environment
env_disk: ""elastic"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.  Here we indicate the CPU's and memory made available _to Docker_ since that represents the maximum resources available to the workflow stages.

```YAML
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce, build 02c1d87""
environment_ex: ""macOS 10.12.6"" 
env_cpus_ex: ""7""
env_memory_ex: ""12Gb""
env_disk_ex: ""1Tb""
```

### Steps

##### EC2/EFS
I launched a single-node EC2 instance of type `r4.2xlarge` in `us-east-1f` (spot request) with the canonical Ubuntu 16.04 AMI (`ami-80861296`). I connected to the instance via SSH (user `ubuntu`) and installed the required nfs client for Amazon EFS:
```shell
sudo apt-get install nfs-common
```

I then mounted my EFS volume at `/efs`.
```shell
sudo mkdir /efs
sudo mount -t nfs4 -o nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2 fs-2067e169.efs.us-east-1.amazonaws.com:/ /efs
```

##### Docker
I installed Docker on the instance using the following commands:
```shell
sudo apt-get update &&
    sudo apt-get install -y \
        apt-transport-https \
        ca-certificates \
        curl \
        software-properties-common &&
    curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - &&
    sudo add-apt-repository \
        ""deb [arch=amd64] https://download.docker.com/linux/ubuntu \
        $(lsb_release -cs) \
        stable"" &&
    sudo apt-get update &&
    sudo apt-get install -y docker-ce
```

Next, I modified the Docker's default storage location to use a partition with more space available, creating the file `/etc/docker/daemon.json` with the following:
```shell
{
  ""debug"": true,
  ""graph"": ""/dev/docker-data""
}
```

Finally, I added `ubuntu` to the `docker` Linux group, exited the instance, and signed back in.

##### Anaconda/cwltool
I installed Anaconda (`miniconda`) for Python 2.7 under my EFS root directory (**note:** I think this makes `conda` operations a bit slower than usual...).
```shell
wget https://repo.continuum.io/miniconda/Miniconda2-latest-Linux-x86_64.sh -O miniconda.sh
bash miniconda.sh -b -p /efs/miniconda
export PATH=""/efs/miniconda/bin:$PATH""
```

I created and configured a virtual environment with `synapseclient` and `cwltool` as follows:
```shell
conda create -n syncwl
source activate syncwl
pip install synapseclient --no-cache-dir
pip install schema-salad==2.2.20170222151604 cwltool==1.0.20170217172322 --no-cache-dir
```

##### Workspace/config
I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir /efs/encode_mapping
cd /efs/encode_mapping
cp ~/.synapseConfig .
```

Within the working directory, I created a `tmp` folder to be used with `cwltool` in subsequent steps:
```shell
mkdir tmp
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir encode_mapping_workflow
cd encode_mapping_workflow
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-submit` CWL tool and the files for the encode_chip_mapping_workflow:
```shell
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn10261070 # encode_mapping_workflow_get.cwl.json
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `encode_mapping_workflow_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict dockstore-tool-synapse-get.cwl encode_mapping_workflow_get.cwl.json
```

#### 4. Run the main workflow

I used `cwltool` to run `encode_mapping_workflow.cwl` with parameters in `encode_mapping_workflow.cwl.json`.
```shell
cwltool --non-strict encode_mapping_workflow.cwl encode_mapping_workflow.cwl.json
```
Upon completion, this created a date-stamped folder of outputs.  The folder name was `7-27-2017T21H18M55S/`

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the validator on my output folder.  I first edited the file `validator.json` with the path to the outputs I want to check:
> **Note:** the `path` value here should be the relative or absolute path to the output directory your workflow run generated that contains the files `filter_qc.json`, `mapping.json`, `post_mapping.json`, and `xcor.json`.  Where these outputs are stored will depend on the workflow runner you use.  This example uses `cwltool` which saves outputs to a date-stamped folder.  Do not include a trailing slash in the folder name.
```JSON
{
  ""output_folder"": {
    ""path"": ""7-27-2017T21H18M55S"",
    ""class"": ""Directory""
  }
}
```
I then ran the validator with:
```shell
cwltool validator.cwl validator.json
cat results.json | grep overall
```
The JSON output in `results.json` indicates what outputs were checked against known-good outputs to verify that the run was successful:
```JSON
{
    ""overall"": true,
    ""steps"": {
        ""filtering_step"": {
            ""NRF"": true,
            ""PBC1"": true,
            ""PBC2"": true,
            ""duplicate_fraction"": true,
            ""n_filtered_mapped_reads"": true
        },
        ""mapping_step"": {
            ""crop_length"": true,
            ""paired_end"": true
        },
        ""post_mapping_step"": {
            ""n_mapped_reads"": true
        },
        ""xcor_step"": {
            ""NSC"": true,
            ""RSC"": true,
            ""est_frag_len"": true
        }
    }
}
```

#### 6. Submit workflow outputs

I modified the parameters in `encode_mapping_workflow_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""SageWorkflowRunners"",
    ""eval_id"": ""9605639"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""7-27-2017T21H18M55S/mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""7-27-2017T21H18M55S/post_mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""7-27-2017T21H18M55S/filter_qc.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""7-27-2017T21H18M55S/xcor.json""
        }
    ],
    ""parent_id"": ""syn9851737""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl encode_mapping_workflow_submit.cwl.json
```

---",9624378
encode_mapping_workflow,9625621_report.md,"## ENCODE ChIP-seq Mapping Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted files to be viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""J. Seth Strattan, ENCODE Data Coordinating Center""
workflow_handle: ""encode_mapping_workflow""
input_handle: ""A549_CEBP""
```

The following description is provided by the workflow author:
> This workflow is a containerized version of the mapping component from the ENCODE Uniform Analysis Pipeline for ChIP-seq experiments.  The analysis is specified by the ENCODE Data Analysis Center (Zhiping Weng, University of Massachusetts) and ENCODE Analysis Working Group (Anshul Kundaje, Stanford University) and implemented and run by the ENCODE Data Coordinating Center (J. Michael Cherry, Stanford University).
> &nbsp;
> The workflow takes raw reads in the form of a fastq file and a genome reference and generates quality-control (QC) metrics and a filtered bam file suitable for peak calling and signal track generation.  The QC metrics include read depth, library complexity estimates, and scores from cross-correlation analysis.  The workflow is written in both Common Workflow Language (CWL) `encode_mapping_workflow.cwl` and Workflow Description Language (WDL) `encode_mapping_workflow.wdl`.
> &nbsp;
> For this Challenge, known-good inputs are in the `input_data` folder.  The file `input_data/ENCFF000VOL.fastq.gz` are reads from one replicate of an ENCODE ChIP-seq experiment done on the human A549 cell line and targeting the CEBP transcription factor.  The standard GRCh38 reference used by ENCODE is included in `input_data/reference/ENCFF643CGH_ENCODE_GRCh38_bwa.tar.gz`.  Complete metadata and analysis results from this experiment are accessioned at the ENCODE Portal [under accession number ENCSR000DYI here](https://www.encodeproject.org/experiments/ENCSR000DYI/).  Paths to the input files are specified in the CWL parameter file `encode_mapping_workflow.cwl.json` and the WDL parameter file `encode_mapping_workflow.wdl.json`.  Submissions to the challenge will be scored against known-good outputs of the workflow run on these inputs.  Run time should be less than two hours.  Workflow stages will automatically scale into multiple CPU cores if they are made available to Docker.  The workflow has been tested with 4 GB per core.  Disk requirements are highly-dependent on particular workflow runners and their handling of intermediate files.  In addition to cached Docker layers, CWL runs typically use approximately 3 GB of disk space.  WDL runs with cromwell consume considerably more disk space.
> &nbsp;
> To accelerate deployment and testing the workflow is also packaged with smaller test inputs.  The reads in `input_data/ENCFF000VOL_chr21.fq.gz` are chromosome 21 extracts from the same A549/CEBP experiment as above and the companion reference `input_data/reference/GRCh38_chr21_bwa.tar.gz` is a small chromosome 21-only reference.  Paths to these inputs are in the CWL parameter file `input_data/encode_mapping_workflow.cwl_test.json` and the WDL parameter file `input_data/encode_mapping_workflow.wdl_test.json`.  Using these inputs the workflow takes less than a minute to run, not counting Docker downloads if image layers are not yet cached locally.  Do not submit results from these small test files for the Challenge.  They are only for your use in rapid deployment and testing on new platforms.
> &nbsp;
> Code for this workflow can be found in [the pipeline-container GitHub repo](https://github.com/ENCODE-DCC/pipeline-container).  The full ENCODE ChIP-seq analysis pipeline code is in [the chip-seq-pipeline GitHub repo](https://github.com/ENCODE-DCC/chip-seq-pipeline).  ENCODE Uniform Processing Pipelines are runnable on [DNAnexus](https://www.dnanexus.com/) in the featured DNAnexus project called ""ENCODE Uniform Processing Pipelines"".  More information on using ENCODE pipelines is [here](https://www.encodeproject.org/tutorials/ashg-2016-uniform-processing-pipelines/).  All the data and software products from ENCODE are distributed through the [ENCODE Portal](https://www.encodeproject.org/).

### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""30Gb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Idan Gabdank"" # your name here
institution: ""ENCODE DCC"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> **Note:** Participants should update these fields to reflect the approach they used.

```YAML
platform: ""cwltool"" 
workflow_type: ""CWL""
runner_version: ""1.0.20170217172322""
docker_version: ""Docker version 1.6.2, build 7c8fca2""
environment: ""EC2 (Ubuntu 15.10)""
env_cpus: ""36""
env_memory: ""58Gb"" # indicate available RAM in environment
env_disk: ""1Tb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```



### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.
&nbsp;
> **Note:** Steps we followed to run the CWL version of the workflow on Mac OSX are included as an example here.
#### 1. Set up the environment

On AWS EC2 instance running Ubuntu 15.10 with Docker version 17.06.0-ce, build 02c1d87 installed we added these components:
```shell
pip install --upgrade pip
pip install schema-salad==2.2.20170222151604 cwltool==1.0.20170217172322
pip install synapseclient
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir encode_mapping
cd encode_mapping
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-submit` CWL tool and the files for the encode_chip_mapping_workflow:
```shell
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get -r syn10163025 # recursively downloads encode_chip_mapping_workflow files
```

#### 4. Run the main workflow

I used `cwltool` to run `encode_mapping_workflow.cwl` with parameters in `encode_mapping_workflow.cwl.json`.
```shell
cwltool --non-strict encode_mapping_workflow.cwl encode_mapping_workflow.cwl.json
```
Upon completion, this created a date-stamped folder of outputs.  The folder name was `7-26-2017T2H43M10S/`

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the validator on my output folder.  I first edited the file `validator.json` with the path to the outputs I want to check:
> **Note:** the `path` value here should be the relative or absolute path to the output directory your workflow run generated that contains the files `filter_qc.json`, `mapping.json`, `post_mapping.json`, and `xcor.json`.  Where these outputs are stored will depend on the workflow runner you use.  This example uses `cwltool` which saves outputs to a date-stamped folder.  Do not include a trailing slash in the folder name.
```JSON
{
  ""output_folder"": {
    ""path"": ""8-8-2017T0H00M56S"",
    ""class"": ""Directory""
  }
}
```
I then ran the validator with:
```shell
cwltool validator.cwl validator.json
cat results.json | grep overall
```
The JSON output in `results.json` indicates what outputs were checked against known-good outputs to verify that the run was successful:
```JSON
{
    ""overall"": true,
    ""steps"": {
        ""filtering_step"": {
            ""NRF"": true,
            ""PBC1"": true,
            ""PBC2"": true,
            ""duplicate_fraction"": true,
            ""n_filtered_mapped_reads"": true
        },
        ""mapping_step"": {
            ""crop_length"": true,
            ""paired_end"": true
        },
        ""post_mapping_step"": {
            ""n_mapped_reads"": true
        },
        ""xcor_step"": {
            ""NSC"": true,
            ""RSC"": true,
            ""est_frag_len"": true
        }
    }
}
```

#### 6. Submit workflow outputs

I modified the parameters in `encode_mapping_workflow_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""ENCODE DCC"",
    ""eval_id"": ""9605639"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""8-8-2017T0H00M56S/mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""8-8-2017T0H00M56S/post_mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""8-8-2017T0H00M56S/filter_qc.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""8-8-2017T0H00M56S/xcor.json""
        }
    ],
    ""parent_id"": ""syn10163025""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl encode_mapping_workflow_submit.cwl.json
```
> **Thanks for running the ENCODE ChIP-seq mapping workflow!**  We look forward to learning about how you ran it in your environment.

---",9625621
encode_mapping_workflow,9625622_report.md,"## ENCODE ChIP-seq Mapping Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted files to be viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""J. Seth Strattan, ENCODE Data Coordinating Center""
workflow_handle: ""encode_mapping_workflow""
input_handle: ""A549_CEBP""
```

The following description is provided by the workflow author:
> This workflow is a containerized version of the mapping component from the ENCODE Uniform Analysis Pipeline for ChIP-seq experiments.  The analysis is specified by the ENCODE Data Analysis Center (Zhiping Weng, University of Massachusetts) and ENCODE Analysis Working Group (Anshul Kundaje, Stanford University) and implemented and run by the ENCODE Data Coordinating Center (J. Michael Cherry, Stanford University).
> &nbsp;
> The workflow takes raw reads in the form of a fastq file and a genome reference and generates quality-control (QC) metrics and a filtered bam file suitable for peak calling and signal track generation.  The QC metrics include read depth, library complexity estimates, and scores from cross-correlation analysis.  The workflow is written in both Common Workflow Language (CWL) `encode_mapping_workflow.cwl` and Workflow Description Language (WDL) `encode_mapping_workflow.wdl`.
> &nbsp;
> For this Challenge, known-good inputs are in the `input_data` folder.  The file `input_data/ENCFF000VOL.fastq.gz` are reads from one replicate of an ENCODE ChIP-seq experiment done on the human A549 cell line and targeting the CEBP transcription factor.  The standard GRCh38 reference used by ENCODE is included in `input_data/reference/ENCFF643CGH_ENCODE_GRCh38_bwa.tar.gz`.  Complete metadata and analysis results from this experiment are accessioned at the ENCODE Portal [under accession number ENCSR000DYI here](https://www.encodeproject.org/experiments/ENCSR000DYI/).  Paths to the input files are specified in the CWL parameter file `encode_mapping_workflow.cwl.json` and the WDL parameter file `encode_mapping_workflow.wdl.json`.  Submissions to the challenge will be scored against known-good outputs of the workflow run on these inputs.  Run time should be less than two hours.  Workflow stages will automatically scale into multiple CPU cores if they are made available to Docker.  The workflow has been tested with 4 GB per core.  Disk requirements are highly-dependent on particular workflow runners and their handling of intermediate files.  In addition to cached Docker layers, CWL runs typically use approximately 3 GB of disk space.  WDL runs with cromwell consume considerably more disk space.
> &nbsp;
> To accelerate deployment and testing the workflow is also packaged with smaller test inputs.  The reads in `input_data/ENCFF000VOL_chr21.fq.gz` are chromosome 21 extracts from the same A549/CEBP experiment as above and the companion reference `input_data/reference/GRCh38_chr21_bwa.tar.gz` is a small chromosome 21-only reference.  Paths to these inputs are in the CWL parameter file `input_data/encode_mapping_workflow.cwl_test.json` and the WDL parameter file `input_data/encode_mapping_workflow.wdl_test.json`.  Using these inputs the workflow takes less than a minute to run, not counting Docker downloads if image layers are not yet cached locally.  Do not submit results from these small test files for the Challenge.  They are only for your use in rapid deployment and testing on new platforms.
> &nbsp;
> Code for this workflow can be found in [the pipeline-container GitHub repo](https://github.com/ENCODE-DCC/pipeline-container).  The full ENCODE ChIP-seq analysis pipeline code is in [the chip-seq-pipeline GitHub repo](https://github.com/ENCODE-DCC/chip-seq-pipeline).  ENCODE Uniform Processing Pipelines are runnable on [DNAnexus](https://www.dnanexus.com/) in the featured DNAnexus project called ""ENCODE Uniform Processing Pipelines"".  More information on using ENCODE pipelines is [here](https://www.encodeproject.org/tutorials/ashg-2016-uniform-processing-pipelines/).  All the data and software products from ENCODE are distributed through the [ENCODE Portal](https://www.encodeproject.org/).

### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""30Gb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Idan Gabdank""
institution: ""ENCODE DCC""
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> **Note:** Participants should update these fields to reflect the approach they used.

```YAML
platform: ""cromwell"" 
workflow_type: ""WDL""
runner_version: ""cromwell: 28-5fd2237-SNAP""
docker_version: ""Docker version 1.6.2, build 7c8fca2""
environment: ""EC2 (Ubuntu 15.10)""
env_cpus: ""36""
env_memory: ""58Gb"" # indicate available RAM in environment
env_disk: ""1Tb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.
&nbsp;
> **Note:** Steps we followed to run the CWL version of the workflow on Mac OSX are included as an example here.
#### 1. Set up the environment

On AWS EC2 instance running Ubuntu 15.10 with Docker version 17.06.0-ce, build 02c1d87 installed we added these components:
```shell
pip install --upgrade pip
pip install schema-salad==2.2.20170222151604 cwltool==1.0.20170217172322
pip install synapseclient
wget https://github.com/broadinstitute/cromwell/releases/download/28.2/cromwell-28_2.jar
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir encode_mapping
cd encode_mapping
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-submit` CWL tool and the files for the encode_chip_mapping_workflow:
```shell
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get -r syn10163025 # recursively downloads encode_chip_mapping_workflow files
```

#### 4. Run the main workflow

I used `cromwell` to run `encode_mapping_workflow.wdl` with parameters in `encode_mapping_workflow.wdl.json`.
```shell
java -jar cromwell-28_2.jar run encode_mapping_workflow.wdl encode_mapping_workflow.wdl.json
```
Upon completion, this created two folders: `cromwell-executions` and `cromwell-workflow-logs`.  The output folder could be found in a sub-folder of  cromwell-executions folder, specifically at `cromwell-executions/encode_mapping_workflow/05696ec3-e401-46d4-82a6-5eedf4a92b29/call-gather_the_outputs`

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the validator on my output folder.  I first edited the file `validator.json` with the path to the outputs I want to check:
> **Note:** the `path` value here should be the relative or absolute path to the output directory your workflow run generated that contains the files `filter_qc.json`, `mapping.json`, `post_mapping.json`, and `xcor.json`.  Where these outputs are stored will depend on the workflow runner you use.  This example uses `cwltool` which saves outputs to a date-stamped folder.  Do not include a trailing slash in the folder name.
```JSON
{
  ""output_folder"": {
    ""path"": ""cromwell-executions/encode_mapping_workflow/05696ec3-e401-46d4-82a6-5eedf4a92b29/call-gather_the_outputs"",
    ""class"": ""Directory""
  }
}
```
I then ran the validator with:
```shell
cwltool validator.cwl validator.json
cat results.json | grep overall
```
The JSON output in `results.json` indicates what outputs were checked against known-good outputs to verify that the run was successful:
```JSON
{
    ""overall"": true,
    ""steps"": {
        ""filtering_step"": {
            ""NRF"": true,
            ""PBC1"": true,
            ""PBC2"": true,
            ""duplicate_fraction"": true,
            ""n_filtered_mapped_reads"": true
        },
        ""mapping_step"": {
            ""crop_length"": true,
            ""paired_end"": true
        },
        ""post_mapping_step"": {
            ""n_mapped_reads"": true
        },
        ""xcor_step"": {
            ""NSC"": true,
            ""RSC"": true,
            ""est_frag_len"": true
        }
    }
}
```

#### 6. Submit workflow outputs

I modified the parameters in `encode_mapping_workflow_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""ENCODE DCC"",
    ""eval_id"": ""9605639"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""cromwell-executions/encode_mapping_workflow/05696ec3-e401-46d4-82a6-5eedf4a92b29/call-gather_the_outputs/mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""cromwell-executions/encode_mapping_workflow/05696ec3-e401-46d4-82a6-5eedf4a92b29/call-gather_the_outputs/post_mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""cromwell-executions/encode_mapping_workflow/05696ec3-e401-46d4-82a6-5eedf4a92b29/call-gather_the_outputs/filter_qc.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""cromwell-executions/encode_mapping_workflow/05696ec3-e401-46d4-82a6-5eedf4a92b29/call-gather_the_outputs/xcor.json""
        }
    ],
    ""parent_id"": ""syn10163025""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl encode_mapping_workflow_submit.cwl.json
```
> **Thanks for running the ENCODE ChIP-seq mapping workflow!**  We look forward to learning about how you ran it in your environment.

---",9625622
encode_mapping_workflow,9626580_report.md,"## ENCODE ChIP-seq Mapping Workflow

### Workflow description

```YAML
contributor: ""J. Seth Strattan, ENCODE Data Coordinating Center""
workflow_handle: ""encode_mapping_workflow""
input_handle: ""A549_CEBP""
```

The following description is provided by the workflow author:
> This workflow is a containerized version of the mapping component from the ENCODE Uniform Analysis Pipeline for ChIP-seq experiments.  The analysis is specified by the ENCODE Data Analysis Center (Zhiping Weng, University of Massachusetts) and ENCODE Analysis Working Group (Anshul Kundaje, Stanford University) and implemented and run by the ENCODE Data Coordinating Center (J. Michael Cherry, Stanford University).
> &nbsp;
> The workflow takes raw reads in the form of a fastq file and a genome reference and generates quality-control (QC) metrics and a filtered bam file suitable for peak calling and signal track generation.  The QC metrics include read depth, library complexity estimates, and scores from cross-correlation analysis.  The workflow is written in both Common Workflow Language (CWL) `encode_mapping_workflow.cwl` and Workflow Description Language (WDL) `encode_mapping_workflow.wdl`.
> &nbsp;
> For this Challenge, known-good inputs are in the `input_data` folder.  The file `input_data/ENCFF000VOL.fastq.gz` are reads from one replicate of an ENCODE ChIP-seq experiment done on the human A549 cell line and targeting the CEBP transcription factor.  The standard GRCh38 reference used by ENCODE is included in `input_data/reference/ENCFF643CGH_ENCODE_GRCh38_bwa.tar.gz`.  Complete metadata and analysis results from this experiment are accessioned at the ENCODE Portal [under accession number ENCSR000DYI here](https://www.encodeproject.org/experiments/ENCSR000DYI/).  Paths to the input files are specified in the CWL parameter file `encode_mapping_workflow.cwl.json` and the WDL parameter file `encode_mapping_workflow.wdl.json`.  Submissions to the challenge will be scored against known-good outputs of the workflow run on these inputs.  Run time should be less than two hours.  Workflow stages will automatically scale into multiple CPU cores if they are made available to Docker.  The workflow has been tested with 4 GB per core.  Disk requirements are highly-dependent on particular workflow runners and their handling of intermediate files.  In addition to cached Docker layers, CWL runs typically use approximately 3 GB of disk space.  WDL runs with cromwell consume considerably more disk space.
> &nbsp;
> To accelerate deployment and testing the workflow is also packaged with smaller test inputs.  The reads in `input_data/ENCFF000VOL_chr21.fq.gz` are chromosome 21 extracts from the same A549/CEBP experiment as above and the companion reference `input_data/reference/GRCh38_chr21_bwa.tar.gz` is a small chromosome 21-only reference.  Paths to these inputs are in the CWL parameter file `input_data/encode_mapping_workflow.cwl_test.json` and the WDL parameter file `input_data/encode_mapping_workflow.wdl_test.json`.  Using these inputs the workflow takes less than a minute to run, not counting Docker downloads if image layers are not yet cached locally.  Do not submit results from these small test files for the Challenge.  They are only for your use in rapid deployment and testing on new platforms.
> &nbsp;
> Code for this workflow can be found in [the pipeline-container GitHub repo](https://github.com/ENCODE-DCC/pipeline-container).  The full ENCODE ChIP-seq analysis pipeline code is in [the chip-seq-pipeline GitHub repo](https://github.com/ENCODE-DCC/chip-seq-pipeline).  ENCODE Uniform Processing Pipelines are runnable on [DNAnexus](https://www.dnanexus.com/) in the featured DNAnexus project called ""ENCODE Uniform Processing Pipelines"".  More information on using ENCODE pipelines is [here](https://www.encodeproject.org/tutorials/ashg-2016-uniform-processing-pipelines/).  All the data and software products from ENCODE are distributed through the [ENCODE Portal](https://www.encodeproject.org/).

### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""30Gb""
```

### Participant informations

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Bogdan Gavrilovic"" # your name here
institution: ""Seven Bridges Genomics"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> **Note:** Participants should update these fields to reflect the approach they used.

```YAML
platform: ""rabix"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.0"" # indicate executor version used
docker_version: ""1.12.6"" # from `docker --version`
environment: ""EC2"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""32"" # indicate number of cores in environment
env_memory: ""60Gb"" # indicate available RAM in environment
env_disk: ""700Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

#####1. [Install rabix](https://github.com/rabix/bunny#installing) on your machine and set environment variable $BUNNY. You need docker and java installed to run rabix:
```shell
wget https://github.com/rabix/bunny/releases/download/v1.0.0/rabix-1.0.0.tar.gz -O rabix-1.0.0.tar.gz && tar -xvf rabix-1.0.0.tar.gz
export BUNNY=$PWD/rabix-cli-1.0.0/rabix
```
#####2. If you've not already retrieved the CWL and data with synapse-get, you can use the [Synapse python client](https://github.com/Sage-Bionetworks/synapsePythonClient#installation):
```shell
pip install synapseclient
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get -r syn10163025 # recursively downloads encode_chip_mapping_workflow files
```
#####3. Run the workflow using rabix executor on your machine by typing in the terminal: $BUNNY <app> <inputs>
For example:
```shell
$BUNNY ./encode_mapping_workflow.cwl encode_mapping_workflow.cwl.json
```

##### 4.Upon completion, create a folder named `outputs` and copy all output files there.

### Validating results

To verify workflow results before submission, edit the file `validator.json` with the path to the `outputs` folder

```JSON
{
  ""output_folder"": {
    ""path"": ""outputs"",
    ""class"": ""Directory""
  }
}
```
I then ran the validator with:
```shell
$BUNNY validator.cwl validator.json
```
Check results
```shell
cat ./path/to/results.json
``` 
The JSON output in `results.json` indicates what outputs were checked against known-good outputs to verify that the run was successful:
```JSON
{
    ""overall"": true,
    ""steps"": {
        ""filtering_step"": {
            ""NRF"": true,
            ""PBC1"": true,
            ""PBC2"": true,
            ""duplicate_fraction"": true,
            ""n_filtered_mapped_reads"": true
        },
        ""mapping_step"": {
            ""crop_length"": true,
            ""paired_end"": true
        },
        ""post_mapping_step"": {
            ""n_mapped_reads"": true
        },
        ""xcor_step"": {
            ""NSC"": true,
            ""RSC"": true,
            ""est_frag_len"": true
        }
    }
}
```

### Submitting results

- Copy the `synapseConfig` file to the current working directory.
- Update `encode_mapping_workflow_submit.cwl.json` to reflect your 
`team_name` - the name of your team in plain text format (e.g., ""GA4GH-Sage Contenders"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
`file'` - paths to output files
For example:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""ENCODE DCC"",
    ""eval_id"": ""9605639"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""outputs/mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""outputs/post_mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""outputs/filter_qc.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""outputs/xcor.json""
        }
    ],
    ""parent_id"": ""syn10163025""
}
```

Run the tool
```shell
$BUNNY dockstore-tool-synapse-submit.cwl encode_mapping_workflow_submit.cwl.json
```
> **Thanks for running the ENCODE ChIP-seq mapping workflow!**  We look forward to learning about how you ran it in your environment.

---",9626580
encode_mapping_workflow,9627504_report.md,"## ENCODE ChIP-seq Mapping Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted files to be viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""J. Seth Strattan, ENCODE Data Coordinating Center""
workflow_handle: ""encode_mapping_workflow""
input_handle: ""A549_CEBP""
```

The following description is provided by the workflow author:
> This workflow is a containerized version of the mapping component from the ENCODE Uniform Analysis Pipeline for ChIP-seq experiments.  The analysis is specified by the ENCODE Data Analysis Center (Zhiping Weng, University of Massachusetts) and ENCODE Analysis Working Group (Anshul Kundaje, Stanford University) and implemented and run by the ENCODE Data Coordinating Center (J. Michael Cherry, Stanford University).
> &nbsp;
> The workflow takes raw reads in the form of a fastq file and a genome reference and generates quality-control (QC) metrics and a filtered bam file suitable for peak calling and signal track generation.  The QC metrics include read depth, library complexity estimates, and scores from cross-correlation analysis.  The workflow is written in both Common Workflow Language (CWL) `encode_mapping_workflow.cwl` and Workflow Description Language (WDL) `encode_mapping_workflow.wdl`.
> &nbsp;
> For this Challenge, known-good inputs are in the `input_data` folder.  The file `input_data/ENCFF000VOL.fastq.gz` are reads from one replicate of an ENCODE ChIP-seq experiment done on the human A549 cell line and targeting the CEBP transcription factor.  The standard GRCh38 reference used by ENCODE is included in `input_data/reference/ENCFF643CGH_ENCODE_GRCh38_bwa.tar.gz`.  Complete metadata and analysis results from this experiment are accessioned at the ENCODE Portal [under accession number ENCSR000DYI here](https://www.encodeproject.org/experiments/ENCSR000DYI/).  Paths to the input files are specified in the CWL parameter file `encode_mapping_workflow.cwl.json` and the WDL parameter file `encode_mapping_workflow.wdl.json`.  Submissions to the challenge will be scored against known-good outputs of the workflow run on these inputs.  Run time should be less than two hours.  Workflow stages will automatically scale into multiple CPU cores if they are made available to Docker.  The workflow has been tested with 4 GB per core.  Disk requirements are highly-dependent on particular workflow runners and their handling of intermediate files.  In addition to cached Docker layers, CWL runs typically use approximately 3 GB of disk space.  WDL runs with cromwell consume considerably more disk space.
> &nbsp;
> To accelerate deployment and testing the workflow is also packaged with smaller test inputs.  The reads in `input_data/ENCFF000VOL_chr21.fq.gz` are chromosome 21 extracts from the same A549/CEBP experiment as above and the companion reference `input_data/reference/GRCh38_chr21_bwa.tar.gz` is a small chromosome 21-only reference.  Paths to these inputs are in the CWL parameter file `input_data/encode_mapping_workflow.cwl_test.json` and the WDL parameter file `input_data/encode_mapping_workflow.wdl_test.json`.  Using these inputs the workflow takes less than a minute to run, not counting Docker downloads if image layers are not yet cached locally.  Do not submit results from these small test files for the Challenge.  They are only for your use in rapid deployment and testing on new platforms.
> &nbsp;
> Code for this workflow can be found in [the pipeline-container GitHub repo](https://github.com/ENCODE-DCC/pipeline-container).  The full ENCODE ChIP-seq analysis pipeline code is in [the chip-seq-pipeline GitHub repo](https://github.com/ENCODE-DCC/chip-seq-pipeline).  ENCODE Uniform Processing Pipelines are runnable on [DNAnexus](https://www.dnanexus.com/) in the featured DNAnexus project called ""ENCODE Uniform Processing Pipelines"".  More information on using ENCODE pipelines is [here](https://www.encodeproject.org/tutorials/ashg-2016-uniform-processing-pipelines/).  All the data and software products from ENCODE are distributed through the [ENCODE Portal](https://www.encodeproject.org/).

### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""30Gb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Denis Yuen"" # your name here
institution: ""OICR"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> **Note:** Participants should update these fields to reflect the approach they used.

```YAML
platform: ""dockstore"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.2.5"" # indicate executor version used
docker_version: ""17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""64GB"" # indicate available RAM in environment
env_disk: ""400GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

#### 1. Set up the environment

On a personal desktop, I installed Docker, pip, cwltool, and the Dockstore command-line helper using a procedure similar to https://github.com/denis-yuen/2017-cloud-workflows-misc/blob/master/install-and-run-with-dockstore.md

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir encode
cd encode
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the website to download encode_mapping_workflow_get.cwl.json:
```shell
dockstore tool cwl --entry quay.io/ga4gh-dream/dockstore-tool-synapse-submit > dockstore-tool-synapse-submit.cwl
dockstore tool cwl --entry quay.io/ga4gh-dream/dockstore-tool-synapse-get > dockstore-tool-synapse-get.cwl
```

#### 3. Modify path for download and then download the required files

I changed md5sum_get.cwl.json to 
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""synapse_id"": ""syn10163025"",
    ""recursive"": true,
    ""output"": {
        ""class"": ""Directory"",
        ""path"": ""/home/ubuntu/encode""
    }
}
```
```shell
dockstore tool launch --local-entry dockstore-tool-synapse-get.cwl --json encode_mapping_workflow_get.cwl.json
```

#### 4. Run the main workflow

I used `dockstore cli` to run `encode_mapping_workflow.cwl` with parameters in `encode_mapping_workflow.cwl.json`.
```shell
dockstore workflow launch --local-entry encode_mapping_workflow.cwl --json encode_mapping_workflow.cwl.json
```
Upon completion, this dumped the created files in the current directory. 
I needed to move the resulting files to an output directory

```shell
mkdir output
cp filter_qc.json output
cp mapping.json output
cp post_mapping.json output
cp xcor.json output
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `dockstore cli` to run the validator on my output folder.  I first edited the file `validator.json` with the path to the outputs I wanted to check:

```JSON
{
  ""output_folder"": {
    ""path"": ""/home/ubuntu/encode/output"",
    ""class"": ""Directory""
  }
}
```
I then ran the validator with:
```shell
dockstore tool launch --local-entry validator.cwl --json validator.json
cat results.json
```
The JSON output in `results.json` indicates what outputs were checked against known-good outputs to verify that the run was successful:
```JSON
{
    ""overall"": true,
    ""steps"": {
        ""filtering_step"": {
            ""NRF"": true,
            ""PBC1"": true,
            ""PBC2"": true,
            ""duplicate_fraction"": true,
            ""n_filtered_mapped_reads"": true
        },
        ""mapping_step"": {
            ""crop_length"": true,
            ""paired_end"": true
        },
        ""post_mapping_step"": {
            ""n_mapped_reads"": true
        },
        ""xcor_step"": {
            ""NSC"": true,
            ""RSC"": true,
            ""est_frag_len"": true
        }
    }
}
```

#### 6. Submit workflow outputs

I modified the parameters in `encode_mapping_workflow_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""Dockstore Team"",
    ""eval_id"": ""9605639"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""output/mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""output/post_mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""output/filter_qc.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""output/xcor.json""
        }
    ],
    ""parent_id"": ""syn9961864""
}
```

Finally, I submitted outputs using `dockstore cli` and `dockstore-tool-synapse-submit.cwl`:
```shell
dockstore tool launch --local-entry  dockstore-tool-synapse-submit.cwl --json encode_mapping_workflow_submit.cwl.json
```
---",9627504
encode_mapping_workflow,9627684_report.md,"## ENCODE ChIP-seq Mapping Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted files to be viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""J. Seth Strattan, ENCODE Data Coordinating Center""
workflow_handle: ""encode_mapping_workflow""
input_handle: ""A549_CEBP""
```

The following description is provided by the workflow author:
> This workflow is a containerized version of the mapping component from the ENCODE Uniform Analysis Pipeline for ChIP-seq experiments.  The analysis is specified by the ENCODE Data Analysis Center (Zhiping Weng, University of Massachusetts) and ENCODE Analysis Working Group (Anshul Kundaje, Stanford University) and implemented and run by the ENCODE Data Coordinating Center (J. Michael Cherry, Stanford University).
> &nbsp;
> The workflow takes raw reads in the form of a fastq file and a genome reference and generates quality-control (QC) metrics and a filtered bam file suitable for peak calling and signal track generation.  The QC metrics include read depth, library complexity estimates, and scores from cross-correlation analysis.  The workflow is written in both Common Workflow Language (CWL) `encode_mapping_workflow.cwl` and Workflow Description Language (WDL) `encode_mapping_workflow.wdl`.
> &nbsp;
> For this Challenge, known-good inputs are in the `input_data` folder.  The file `input_data/ENCFF000VOL.fastq.gz` are reads from one replicate of an ENCODE ChIP-seq experiment done on the human A549 cell line and targeting the CEBP transcription factor.  The standard GRCh38 reference used by ENCODE is included in `input_data/reference/ENCFF643CGH_ENCODE_GRCh38_bwa.tar.gz`.  Complete metadata and analysis results from this experiment are accessioned at the ENCODE Portal [under accession number ENCSR000DYI here](https://www.encodeproject.org/experiments/ENCSR000DYI/).  Paths to the input files are specified in the CWL parameter file `encode_mapping_workflow.cwl.json` and the WDL parameter file `encode_mapping_workflow.wdl.json`.  Submissions to the challenge will be scored against known-good outputs of the workflow run on these inputs.  Run time should be less than two hours.  Workflow stages will automatically scale into multiple CPU cores if they are made available to Docker.  The workflow has been tested with 4 GB per core.  Disk requirements are highly-dependent on particular workflow runners and their handling of intermediate files.  In addition to cached Docker layers, CWL runs typically use approximately 3 GB of disk space.  WDL runs with cromwell consume considerably more disk space.
> &nbsp;
> To accelerate deployment and testing the workflow is also packaged with smaller test inputs.  The reads in `input_data/ENCFF000VOL_chr21.fq.gz` are chromosome 21 extracts from the same A549/CEBP experiment as above and the companion reference `input_data/reference/GRCh38_chr21_bwa.tar.gz` is a small chromosome 21-only reference.  Paths to these inputs are in the CWL parameter file `input_data/encode_mapping_workflow.cwl_test.json` and the WDL parameter file `input_data/encode_mapping_workflow.wdl_test.json`.  Using these inputs the workflow takes less than a minute to run, not counting Docker downloads if image layers are not yet cached locally.  Do not submit results from these small test files for the Challenge.  They are only for your use in rapid deployment and testing on new platforms.
> &nbsp;
> Code for this workflow can be found in [the pipeline-container GitHub repo](https://github.com/ENCODE-DCC/pipeline-container).  The full ENCODE ChIP-seq analysis pipeline code is in [the chip-seq-pipeline GitHub repo](https://github.com/ENCODE-DCC/chip-seq-pipeline).  ENCODE Uniform Processing Pipelines are runnable on [DNAnexus](https://www.dnanexus.com/) in the featured DNAnexus project called ""ENCODE Uniform Processing Pipelines"".  More information on using ENCODE pipelines is [here](https://www.encodeproject.org/tutorials/ashg-2016-uniform-processing-pipelines/).  All the data and software products from ENCODE are distributed through the [ENCODE Portal](https://www.encodeproject.org/).

### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""30Gb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Lon Blauvelt"" # your name here
institution: ""UCSC"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> **Note:** Participants should update these fields to reflect the approach they used.

```YAML
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170217172322"" # indicate executor version used
docker_version: ""17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""EC2"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""32Gb"" # indicate available RAM in environment
env_disk: ""elastic"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.  Here we indicate the CPU's and memory made available _to Docker_ since that represents the maximum resources available to the workflow stages.

```YAML
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce, build 02c1d87""
environment_ex: ""macOS 10.12.6"" 
env_cpus_ex: ""7""
env_memory_ex: ""12Gb""
env_disk_ex: ""1Tb""
```

### Steps

#### 1. Set up environment

*I launched an EC2 instance of type `t2.2xlarge` with one node, mounted a 50 Gb EFS volume.*

I used the following to update the instance:

```shell
sudo apt-get update
sudo apt-get -y upgrade
sudo apt-get -y dist-upgrade
```

Install docker:

```shell
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
sudo add-apt-repository ""deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable""
sudo apt-get update
apt-cache policy docker-ce
sudo apt-get install -y docker-ce
sudo usermod -aG docker ${USER}
sudo su - ${USER}
```

Install pip, a virtualenv, and the requisite pip installs (cwltool, schema-salad, avro, synapse, and html5lib):

```shell
sudo apt install -y python-pip
sudo pip install --upgrade pip
sudo pip install virtualenv
virtualenv --python /usr/bin/python2 cwl
source /home/ubuntu/cwl/bin/activate
pip install cwl-runner cwltool==1.0.20170217172322 schema-salad==2.6.20170630075932 avro==1.8.1  ruamel.yaml==0.14.12 --no-cache-dir
pip install synapseclient --no-cache-dir
pip install html5lib
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:

```shell
mkdir syn
cd syn
nano syn-login.synapseConfig
[PASTE] username & password
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-submit` CWL tool and the files for the encode_chip_mapping_workflow, and edit the get file to contain the synapse credentials path:
```shell
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn10261070 # encode_mapping_workflow_get.cwl.json
```

```shell
nano encode_mapping_workflow_get.cwl.json
[PASTE] /home/ubuntu/syn/syn-login.synapseConfig
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `encode_mapping_workflow_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict dockstore-tool-synapse-get.cwl encode_mapping_workflow_get.cwl.json
```

#### 4. Run the main workflow

I used `cwltool` to run `encode_mapping_workflow.cwl` with parameters in `encode_mapping_workflow.cwl.json`.
```shell
cwltool --non-strict encode_mapping_workflow.cwl encode_mapping_workflow.cwl.json
```
Upon completion, this created a date-stamped folder of outputs.  The folder name was `8-16-2017T5H10M02S/`

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the validator on my output folder.  I first edited the file `validator.json` with the path to the outputs I want to check:
> **Note:** the `path` value here should be the relative or absolute path to the output directory your workflow run generated that contains the files `filter_qc.json`, `mapping.json`, `post_mapping.json`, and `xcor.json`.  Where these outputs are stored will depend on the workflow runner you use.  This example uses `cwltool` which saves outputs to a date-stamped folder.  Do not include a trailing slash in the folder name.
```JSON
{
  ""output_folder"": {
    ""path"": ""8-16-2017T5H10M02S"",
    ""class"": ""Directory""
  }
}
```
I then ran the validator with:
```shell
cwltool validator.cwl validator.json
```

#### 6. Submit workflow outputs

I modified the parameters in `encode_mapping_workflow_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": ""/home/ubuntu/syn/syn-login.synapseConfig""
    },
    ""team_name"": ""UCSC GA4GH-DREAM Challenge Team"",
    ""eval_id"": ""9605639"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""8-16-2017T5H10M02S/mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""8-16-2017T5H10M02S/post_mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""8-16-2017T5H10M02S/filter_qc.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""8-16-2017T5H10M02S/xcor.json""
        }
    ],
    ""parent_id"": ""syn10329800""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl encode_mapping_workflow_submit.cwl.json
```

---",9627684
encode_mapping_workflow,9627720_report.md,"## ENCODE ChIP-seq Mapping Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted files to be viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""J. Seth Strattan, ENCODE Data Coordinating Center""
workflow_handle: ""encode_mapping_workflow""
input_handle: ""A549_CEBP""
```

The following description is provided by the workflow author:
> This workflow is a containerized version of the mapping component from the ENCODE Uniform Analysis Pipeline for ChIP-seq experiments.  The analysis is specified by the ENCODE Data Analysis Center (Zhiping Weng, University of Massachusetts) and ENCODE Analysis Working Group (Anshul Kundaje, Stanford University) and implemented and run by the ENCODE Data Coordinating Center (J. Michael Cherry, Stanford University).
> &nbsp;
> The workflow takes raw reads in the form of a fastq file and a genome reference and generates quality-control (QC) metrics and a filtered bam file suitable for peak calling and signal track generation.  The QC metrics include read depth, library complexity estimates, and scores from cross-correlation analysis.  The workflow is written in both Common Workflow Language (CWL) `encode_mapping_workflow.cwl` and Workflow Description Language (WDL) `encode_mapping_workflow.wdl`.
> &nbsp;
> For this Challenge, known-good inputs are in the `input_data` folder.  The file `input_data/ENCFF000VOL.fastq.gz` are reads from one replicate of an ENCODE ChIP-seq experiment done on the human A549 cell line and targeting the CEBP transcription factor.  The standard GRCh38 reference used by ENCODE is included in `input_data/reference/ENCFF643CGH_ENCODE_GRCh38_bwa.tar.gz`.  Complete metadata and analysis results from this experiment are accessioned at the ENCODE Portal [under accession number ENCSR000DYI here](https://www.encodeproject.org/experiments/ENCSR000DYI/).  Paths to the input files are specified in the CWL parameter file `encode_mapping_workflow.cwl.json` and the WDL parameter file `encode_mapping_workflow.wdl.json`.  Submissions to the challenge will be scored against known-good outputs of the workflow run on these inputs.  Run time should be less than two hours.  Workflow stages will automatically scale into multiple CPU cores if they are made available to Docker.  The workflow has been tested with 4 GB per core.  Disk requirements are highly-dependent on particular workflow runners and their handling of intermediate files.  In addition to cached Docker layers, CWL runs typically use approximately 3 GB of disk space.  WDL runs with cromwell consume considerably more disk space.
> &nbsp;
> To accelerate deployment and testing the workflow is also packaged with smaller test inputs.  The reads in `input_data/ENCFF000VOL_chr21.fq.gz` are chromosome 21 extracts from the same A549/CEBP experiment as above and the companion reference `input_data/reference/GRCh38_chr21_bwa.tar.gz` is a small chromosome 21-only reference.  Paths to these inputs are in the CWL parameter file `input_data/encode_mapping_workflow.cwl_test.json` and the WDL parameter file `input_data/encode_mapping_workflow.wdl_test.json`.  Using these inputs the workflow takes less than a minute to run, not counting Docker downloads if image layers are not yet cached locally.  Do not submit results from these small test files for the Challenge.  They are only for your use in rapid deployment and testing on new platforms.
> &nbsp;
> Code for this workflow can be found in [the pipeline-container GitHub repo](https://github.com/ENCODE-DCC/pipeline-container).  The full ENCODE ChIP-seq analysis pipeline code is in [the chip-seq-pipeline GitHub repo](https://github.com/ENCODE-DCC/chip-seq-pipeline).  ENCODE Uniform Processing Pipelines are runnable on [DNAnexus](https://www.dnanexus.com/) in the featured DNAnexus project called ""ENCODE Uniform Processing Pipelines"".  More information on using ENCODE pipelines is [here](https://www.encodeproject.org/tutorials/ashg-2016-uniform-processing-pipelines/).  All the data and software products from ENCODE are distributed through the [ENCODE Portal](https://www.encodeproject.org/).

### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""30Gb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Lon Blauvelt""
institution: ""UCSC""
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> **Note:** Participants should update these fields to reflect the approach they used.

```YAML
platform: ""cromwell"" 
workflow_type: ""WDL""
runner_version: ""cromwell: 28-5fd2237-SNAP""
docker_version: ""17.06.0-ce, build 02c1d87""
environment: ""EC2 (Ubuntu 16.04)""
env_cpus: ""8""
env_memory: ""32Gb"" # indicate available RAM in environment
env_disk: ""100Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

#### 1. Set up environment

*I launched an EC2 instance of type `t2.2xlarge` with one node, and mounted a 100 Gb EFS volume.*

I used the following to update the instance:

```shell
sudo apt-get update
sudo apt-get -y upgrade
sudo apt-get -y dist-upgrade
```

Install docker:

```shell
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
sudo add-apt-repository ""deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable""
sudo apt-get update
apt-cache policy docker-ce
sudo apt-get install -y docker-ce
sudo usermod -aG docker ${USER}
sudo su - ${USER}
```

Install java, pip, a virtualenv, and the requisite pip installs (cwltool, schema-salad, avro, synapse, and html5lib):

```shell
sudo apt-get install default-jre
sudo apt install -y python-pip
sudo pip install --upgrade pip
sudo pip install virtualenv
virtualenv --python /usr/bin/python2 cwl
source /home/ubuntu/cwl/bin/activate
pip install cwl-runner cwltool==1.0.20170217172322 schema-salad==2.6.20170630075932 avro==1.8.1  ruamel.yaml==0.14.12 --no-cache-dir
pip install synapseclient --no-cache-dir
pip install html5lib
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:

```shell
mkdir syn
cd syn
nano syn-login.synapseConfig
[PASTE] username & password
```

#### 2. Download required files

I used the `synapse get` and `wget` commands to download the `synapse-submit` CWL tool, `cromwell`, and the files for the encode_chip_mapping_workflow:
```shell
synapse get -r syn9689286
synapse get -r syn10163025
wget https://github.com/broadinstitute/cromwell/releases/download/28.2/cromwell-28_2.jar
```

#### 3. Run the main workflow

I used `cromwell` to run `encode_mapping_workflow.wdl` with parameters in `encode_mapping_workflow.wdl.json`.
```shell
java -jar cromwell-28_2.jar run encode_mapping_workflow.wdl encode_mapping_workflow.wdl.json
```
Upon completion, this created two folders: `cromwell-executions` and `cromwell-workflow-logs`.  The output folder could be found in a sub-folder of cromwell-executions folder, in this case at: `/home/ubuntu/cromwell-executions/encode_mapping_workflow/5ab1e0f4-3d7b-4338-a6eb-d5f21b9ec217/call-gather_the_outputs/execution/`

#### 4. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the validator on my output folder.  I first edited the file `validator.json` with the path to the outputs I want to check.
> **Note:** the `path` value here should be the relative or absolute path to the output directory your workflow run generated that contains the files `filter_qc.json`, `mapping.json`, `post_mapping.json`, and `xcor.json`.
```JSON
{
  ""output_folder"": {
    ""path"": ""/home/ubuntu/cromwell-executions/encode_mapping_workflow/5ab1e0f4-3d7b-4338-a6eb-d5f21b9ec217/call-gather_the_outputs/execution/"",
    ""class"": ""Directory""
  }
}
```
I then ran the validator with:
```shell
cwltool validator.cwl validator.json
```

#### 5. Submit workflow outputs

I modified the parameters in `encode_mapping_workflow_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": ""/home/ubuntu/syn/syn-login.synapseConfig""
    },
    ""team_name"": ""UCSC GA4GH-DREAM Challenge Team"",
    ""eval_id"": ""9605639"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""/home/ubuntu/cromwell-executions/encode_mapping_workflow/5ab1e0f4-3d7b-4338-a6eb-d5f21b9ec217/call-gather_the_outputs/execution/mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""/home/ubuntu/cromwell-executions/encode_mapping_workflow/5ab1e0f4-3d7b-4338-a6eb-d5f21b9ec217/call-gather_the_outputs/execution/post_mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""/home/ubuntu/cromwell-executions/encode_mapping_workflow/5ab1e0f4-3d7b-4338-a6eb-d5f21b9ec217/call-gather_the_outputs/execution/filter_qc.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""/home/ubuntu/cromwell-executions/encode_mapping_workflow/5ab1e0f4-3d7b-4338-a6eb-d5f21b9ec217/call-gather_the_outputs/execution/xcor.json""
        }
    ],
    ""parent_id"": ""syn10338261""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl` after modifying the json file to include my synapse credentials path:
```shell
nano encode_mapping_workflow_submit.cwl.json
[PASTE] /home/ubuntu/syn/syn-login.synapseConfig
cwltool --non-strict dockstore-tool-synapse-submit.cwl encode_mapping_workflow_submit.cwl.json
```
---",9627720
encode_mapping_workflow,9631597_report.md,"## ENCODE ChIP-seq Mapping Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted files to be viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""J. Seth Strattan, ENCODE Data Coordinating Center""
workflow_handle: ""encode_mapping_workflow""
input_handle: ""A549_CEBP""
```

The following description is provided by the workflow author:
> This workflow is a containerized version of the mapping component from the ENCODE Uniform Analysis Pipeline for ChIP-seq experiments.  The analysis is specified by the ENCODE Data Analysis Center (Zhiping Weng, University of Massachusetts) and ENCODE Analysis Working Group (Anshul Kundaje, Stanford University) and implemented and run by the ENCODE Data Coordinating Center (J. Michael Cherry, Stanford University).
> &nbsp;
> The workflow takes raw reads in the form of a fastq file and a genome reference and generates quality-control (QC) metrics and a filtered bam file suitable for peak calling and signal track generation.  The QC metrics include read depth, library complexity estimates, and scores from cross-correlation analysis.  The workflow is written in both Common Workflow Language (CWL) `encode_mapping_workflow.cwl` and Workflow Description Language (WDL) `encode_mapping_workflow.wdl`.
> &nbsp;
> For this Challenge, known-good inputs are in the `input_data` folder.  The file `input_data/ENCFF000VOL.fastq.gz` are reads from one replicate of an ENCODE ChIP-seq experiment done on the human A549 cell line and targeting the CEBP transcription factor.  The standard GRCh38 reference used by ENCODE is included in `input_data/reference/ENCFF643CGH_ENCODE_GRCh38_bwa.tar.gz`.  Complete metadata and analysis results from this experiment are accessioned at the ENCODE Portal [under accession number ENCSR000DYI here](https://www.encodeproject.org/experiments/ENCSR000DYI/).  Paths to the input files are specified in the CWL parameter file `encode_mapping_workflow.cwl.json` and the WDL parameter file `encode_mapping_workflow.wdl.json`.  Submissions to the challenge will be scored against known-good outputs of the workflow run on these inputs.  Run time should be less than two hours.  Workflow stages will automatically scale into multiple CPU cores if they are made available to Docker.  The workflow has been tested with 4 GB per core.  Disk requirements are highly-dependent on particular workflow runners and their handling of intermediate files.  In addition to cached Docker layers, CWL runs typically use approximately 3 GB of disk space.  WDL runs with cromwell consume considerably more disk space.
> &nbsp;
> To accelerate deployment and testing the workflow is also packaged with smaller test inputs.  The reads in `input_data/ENCFF000VOL_chr21.fq.gz` are chromosome 21 extracts from the same A549/CEBP experiment as above and the companion reference `input_data/reference/GRCh38_chr21_bwa.tar.gz` is a small chromosome 21-only reference.  Paths to these inputs are in the CWL parameter file `input_data/encode_mapping_workflow.cwl_test.json` and the WDL parameter file `input_data/encode_mapping_workflow.wdl_test.json`.  Using these inputs the workflow takes less than a minute to run, not counting Docker downloads if image layers are not yet cached locally.  Do not submit results from these small test files for the Challenge.  They are only for your use in rapid deployment and testing on new platforms.
> &nbsp;
> Code for this workflow can be found in [the pipeline-container GitHub repo](https://github.com/ENCODE-DCC/pipeline-container).  The full ENCODE ChIP-seq analysis pipeline code is in [the chip-seq-pipeline GitHub repo](https://github.com/ENCODE-DCC/chip-seq-pipeline).  ENCODE Uniform Processing Pipelines are runnable on [DNAnexus](https://www.dnanexus.com/) in the featured DNAnexus project called ""ENCODE Uniform Processing Pipelines"".  More information on using ENCODE pipelines is [here](https://www.encodeproject.org/tutorials/ashg-2016-uniform-processing-pipelines/).  All the data and software products from ENCODE are distributed through the [ENCODE Portal](https://www.encodeproject.org/).

#### Workflow history

+ **2017-08-10**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: “Benjamin Story“
institution: “EMBL”
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> **Note:** Participants should update these fields to reflect the approach they used.

```YAML
platform: ""cromwell""
workflow_type: ""WDL""
runner_version: ""cromwell: 28-5fd2237-SNAP""
docker_version: ""1.7.1, build 786b29d""
cwltool_version: ""1.0.20170217172322""
environment: ""centos-release-6-7.el6.centos.12.3.x86_64""
env_cpus: ""12""
env_memory: ""72Gb"" # indicate available RAM in environment
env_disk: ""800Gb"" # indicate available disk space
```

#### 1. Set up environment

Built my folder structure
```shell
mkdir encode
cd encode
cp ~/.synapseConfig ./
```

#### 2. Download required files

Downloaded relevant files for running the workflow
```shell
synapse get -r syn9689286
synapse get -r syn10163025
wget https://github.com/broadinstitute/cromwell/releases/download/28.2/cromwell-28_2.jar
```
Downloaded relevant missing files for submitting the workflow
```shell
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
```

#### 3. Run the main workflow

I used `cromwell` to run `encode_mapping_workflow.wdl` with parameters in `encode_mapping_workflow.wdl.json`.
```shell
java -jar cromwell-28_2.jar run encode_mapping_workflow.wdl encode_mapping_workflow.wdl.json
```

#### 4. Run workflow checker tool

Modified `validator.json` file to point to the correct output directory
```JSON
{
  ""output_folder"": {
    ""path"": ""/tmpdata/story/encode/cromwell-executions"",
    ""class"": ""Directory""
  }
}
```
I then ran the validator with:
```shell
cwltool validator.cwl validator.json
```

#### 5. Submit workflow outputs

**Note:** In the command below I forgot to include my team name.
I modified the parameters in `encode_mapping_workflow_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": """",
    ""eval_id"": ""9605639"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""/tmpdata/story/encode/cromwell-executions/encode_mapping_workflow/8c8a8a24-13c4-4354-885a-5a8355d50317/call-gather_the_outputs/execution/mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""/tmpdata/story/encode/cromwell-executions/encode_mapping_workflow/8c8a8a24-13c4-4354-885a-5a8355d50317/call-gather_the_outputs/execution/post_mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""/tmpdata/story/encode/cromwell-executions/encode_mapping_workflow/8c8a8a24-13c4-4354-885a-5a8355d50317/call-gather_the_outputs/execution/filter_qc.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""/tmpdata/story/encode/cromwell-executions/encode_mapping_workflow/8c8a8a24-13c4-4354-885a-5a8355d50317/call-gather_the_outputs/execution/xcor.json""
        }
    ],
    ""parent_id"": ""syn10514791""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl encode_mapping_workflow_submit.cwl.json
```
---",9631597
encode_mapping_workflow,9631755_report.md,"## ENCODE ChIP-seq Mapping Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted files to be viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""J. Seth Strattan, ENCODE Data Coordinating Center""
workflow_handle: ""encode_mapping_workflow""
input_handle: ""A549_CEBP""
```

The following description is provided by the workflow author:
> This workflow is a containerized version of the mapping component from the ENCODE Uniform Analysis Pipeline for ChIP-seq experiments.  The analysis is specified by the ENCODE Data Analysis Center (Zhiping Weng, University of Massachusetts) and ENCODE Analysis Working Group (Anshul Kundaje, Stanford University) and implemented and run by the ENCODE Data Coordinating Center (J. Michael Cherry, Stanford University).
> &nbsp;
> The workflow takes raw reads in the form of a fastq file and a genome reference and generates quality-control (QC) metrics and a filtered bam file suitable for peak calling and signal track generation.  The QC metrics include read depth, library complexity estimates, and scores from cross-correlation analysis.  The workflow is written in both Common Workflow Language (CWL) `encode_mapping_workflow.cwl` and Workflow Description Language (WDL) `encode_mapping_workflow.wdl`.
> &nbsp;
> For this Challenge, known-good inputs are in the `input_data` folder.  The file `input_data/ENCFF000VOL.fastq.gz` are reads from one replicate of an ENCODE ChIP-seq experiment done on the human A549 cell line and targeting the CEBP transcription factor.  The standard GRCh38 reference used by ENCODE is included in `input_data/reference/ENCFF643CGH_ENCODE_GRCh38_bwa.tar.gz`.  Complete metadata and analysis results from this experiment are accessioned at the ENCODE Portal [under accession number ENCSR000DYI here](https://www.encodeproject.org/experiments/ENCSR000DYI/).  Paths to the input files are specified in the CWL parameter file `encode_mapping_workflow.cwl.json` and the WDL parameter file `encode_mapping_workflow.wdl.json`.  Submissions to the challenge will be scored against known-good outputs of the workflow run on these inputs.  Run time should be less than two hours.  Workflow stages will automatically scale into multiple CPU cores if they are made available to Docker.  The workflow has been tested with 4 GB per core.  Disk requirements are highly-dependent on particular workflow runners and their handling of intermediate files.  In addition to cached Docker layers, CWL runs typically use approximately 3 GB of disk space.  WDL runs with cromwell consume considerably more disk space.
> &nbsp;
> To accelerate deployment and testing the workflow is also packaged with smaller test inputs.  The reads in `input_data/ENCFF000VOL_chr21.fq.gz` are chromosome 21 extracts from the same A549/CEBP experiment as above and the companion reference `input_data/reference/GRCh38_chr21_bwa.tar.gz` is a small chromosome 21-only reference.  Paths to these inputs are in the CWL parameter file `input_data/encode_mapping_workflow.cwl_test.json` and the WDL parameter file `input_data/encode_mapping_workflow.wdl_test.json`.  Using these inputs the workflow takes less than a minute to run, not counting Docker downloads if image layers are not yet cached locally.  Do not submit results from these small test files for the Challenge.  They are only for your use in rapid deployment and testing on new platforms.
> &nbsp;
> Code for this workflow can be found in [the pipeline-container GitHub repo](https://github.com/ENCODE-DCC/pipeline-container).  The full ENCODE ChIP-seq analysis pipeline code is in [the chip-seq-pipeline GitHub repo](https://github.com/ENCODE-DCC/chip-seq-pipeline).  ENCODE Uniform Processing Pipelines are runnable on [DNAnexus](https://www.dnanexus.com/) in the featured DNAnexus project called ""ENCODE Uniform Processing Pipelines"".  More information on using ENCODE pipelines is [here](https://www.encodeproject.org/tutorials/ashg-2016-uniform-processing-pipelines/).  All the data and software products from ENCODE are distributed through the [ENCODE Portal](https://www.encodeproject.org/).

### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""30Gb""
```

#### Workflow history

+ **2017-08-10**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Abraham Chavez"" # your name here
institution: ""UCSC GI"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> **Note:** Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-08-30T20:20:34+00:00"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""dockstore cli"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.2.5"" # indicate executor version used
docker_version: ""17.06.0-ce-rc4"" # from `docker --version`
environment: ""EC2"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""32"" # indicate number of cores in environment
env_memory: ""240Gb"" # indicate available RAM in environment
env_disk: ""200Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.  Here we indicate the CPU's and memory made available _to Docker_ since that represents the maximum resources available to the workflow stages.

```YAML
date_accessed_ex: ""2017-08-16""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce, build 02c1d87""
environment_ex: ""macOS 10.12.6"" 
env_cpus_ex: ""7""
env_memory_ex: ""12Gb""
env_disk_ex: ""1Tb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.
&nbsp;
_____________________
Launched an EC2 instance of type `r4.8xlarge` with one node, mounted an EFS volume, and installed dependencies.
#####
If you have not set up your environment and install dependencies like **cwltool**, **dockstore**, **java** and so on
I recommend you follow [**this**](https://www.synapse.org/#!Synapse:syn10220609) instructions.

##### Create empty folder for workflow running
```
mkdir encode_mapping_workflow
cd encode_mapping_workflow
```
Create Synapse credentials file `.synapseConfig`, put there Synapse ID and password
```
[authentication]
username: user@usermail.org
password: <user-password>
```
Information about `.synapseConfig` can be found [**here**](https://www.synapse.org/#!Synapse:syn8507133/wiki/451408)

#### 2. Download required files

I used the `synapse get` command to download the `synapse-submit` CWL tool and the files for the encode_chip_mapping_workflow:
```shell
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get -r syn10163025 # recursively downloads encode_chip_mapping_workflow files
```

#### 4. Run the main workflow

I used `dockstore` to run `encode mapping workflow` with parameters in `encode_mapping_workflow.cwl.json`.
```shell
dockstore workflow launch --entry ENCODE-DCC/pipeline-container/encode-mapping-cwl:v1.0 --json encode_mapping_workflow.cwl.json
```
>**Note:** Upon completion, this created a date-stamped folder of outputs.  The folder name was `0-00-2017T0H00M00S/`

#### 5. Run workflow checker tool


> **Note:** The `path` value should be configure to the path you generated being the time and date of when you, the user, ran the tool.
```JSON
{
  ""output_folder"": {
    ""path"": ""0-00-2017T0H00M00S"",
    ""class"": ""Directory""
  }
}
```
I then ran the validator with:
```shell
cwltool validator.cwl validator.json
cat results.json | grep overall
```
The JSON output in `results.json` indicates what outputs were checked against known-good outputs to verify that the run was successful:
```JSON
{
    ""overall"": true,
    ""steps"": {
        ""filtering_step"": {
            ""NRF"": true,
            ""PBC1"": true,
            ""PBC2"": true,
            ""duplicate_fraction"": true,
            ""n_filtered_mapped_reads"": true
        },
        ""mapping_step"": {
            ""crop_length"": true,
            ""paired_end"": true
        },
        ""post_mapping_step"": {
            ""n_mapped_reads"": true
        },
        ""xcor_step"": {
            ""NSC"": true,
            ""RSC"": true,
            ""est_frag_len"": true
        }
    }
}
```

#### 6. Submit workflow outputs

I modified the parameters in `encode_mapping_workflow_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""Your Team Name"",
    ""eval_id"": ""9605639"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""0-00-2017T0H00M00S/mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""0-00-2017T0H00M00S/post_mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""0-00-2017T0H00M00S/filter_qc.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""0-00-2017T0H00M00S/xcor.json""
        }
    ],
    ""parent_id"": ""syn1234567""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl encode_mapping_workflow_submit.cwl.json
```
> **Thanks for running the ENCODE ChIP-seq mapping workflow!**  We look forward to learning about how you ran it in your environment.

---",9631755
encode_mapping_workflow,9631756_report.md,"## ENCODE ChIP-seq Mapping Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted files to be viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""J. Seth Strattan, ENCODE Data Coordinating Center""
workflow_handle: ""encode_mapping_workflow""
input_handle: ""A549_CEBP""
```

The following description is provided by the workflow author:
> This workflow is a containerized version of the mapping component from the ENCODE Uniform Analysis Pipeline for ChIP-seq experiments.  The analysis is specified by the ENCODE Data Analysis Center (Zhiping Weng, University of Massachusetts) and ENCODE Analysis Working Group (Anshul Kundaje, Stanford University) and implemented and run by the ENCODE Data Coordinating Center (J. Michael Cherry, Stanford University).
> &nbsp;
> The workflow takes raw reads in the form of a fastq file and a genome reference and generates quality-control (QC) metrics and a filtered bam file suitable for peak calling and signal track generation.  The QC metrics include read depth, library complexity estimates, and scores from cross-correlation analysis.  The workflow is written in both Common Workflow Language (CWL) `encode_mapping_workflow.cwl` and Workflow Description Language (WDL) `encode_mapping_workflow.wdl`.
> &nbsp;
> For this Challenge, known-good inputs are in the `input_data` folder.  The file `input_data/ENCFF000VOL.fastq.gz` are reads from one replicate of an ENCODE ChIP-seq experiment done on the human A549 cell line and targeting the CEBP transcription factor.  The standard GRCh38 reference used by ENCODE is included in `input_data/reference/ENCFF643CGH_ENCODE_GRCh38_bwa.tar.gz`.  Complete metadata and analysis results from this experiment are accessioned at the ENCODE Portal [under accession number ENCSR000DYI here](https://www.encodeproject.org/experiments/ENCSR000DYI/).  Paths to the input files are specified in the CWL parameter file `encode_mapping_workflow.cwl.json` and the WDL parameter file `encode_mapping_workflow.wdl.json`.  Submissions to the challenge will be scored against known-good outputs of the workflow run on these inputs.  Run time should be less than two hours.  Workflow stages will automatically scale into multiple CPU cores if they are made available to Docker.  The workflow has been tested with 4 GB per core.  Disk requirements are highly-dependent on particular workflow runners and their handling of intermediate files.  In addition to cached Docker layers, CWL runs typically use approximately 3 GB of disk space.  WDL runs with cromwell consume considerably more disk space.
> &nbsp;
> To accelerate deployment and testing the workflow is also packaged with smaller test inputs.  The reads in `input_data/ENCFF000VOL_chr21.fq.gz` are chromosome 21 extracts from the same A549/CEBP experiment as above and the companion reference `input_data/reference/GRCh38_chr21_bwa.tar.gz` is a small chromosome 21-only reference.  Paths to these inputs are in the CWL parameter file `input_data/encode_mapping_workflow.cwl_test.json` and the WDL parameter file `input_data/encode_mapping_workflow.wdl_test.json`.  Using these inputs the workflow takes less than a minute to run, not counting Docker downloads if image layers are not yet cached locally.  Do not submit results from these small test files for the Challenge.  They are only for your use in rapid deployment and testing on new platforms.
> &nbsp;
> Code for this workflow can be found in [the pipeline-container GitHub repo](https://github.com/ENCODE-DCC/pipeline-container).  The full ENCODE ChIP-seq analysis pipeline code is in [the chip-seq-pipeline GitHub repo](https://github.com/ENCODE-DCC/chip-seq-pipeline).  ENCODE Uniform Processing Pipelines are runnable on [DNAnexus](https://www.dnanexus.com/) in the featured DNAnexus project called ""ENCODE Uniform Processing Pipelines"".  More information on using ENCODE pipelines is [here](https://www.encodeproject.org/tutorials/ashg-2016-uniform-processing-pipelines/).  All the data and software products from ENCODE are distributed through the [ENCODE Portal](https://www.encodeproject.org/).

### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""30Gb""
```

#### Workflow history

+ **2017-08-10**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Abraham Chavez"" # your name here
institution: ""UCSC GI"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> **Note:** Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-08-30T20:50:34+00:00"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170217172322"" # indicate executor version used
docker_version: ""17.06.0-ce-rc4"" # from `docker --version`
environment: ""EC2"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""32"" # indicate number of cores in environment
env_memory: ""240Gb"" # indicate available RAM in environment
env_disk: ""200Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.  Here we indicate the CPU's and memory made available _to Docker_ since that represents the maximum resources available to the workflow stages.

```YAML
date_accessed_ex: ""2017-08-16""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce, build 02c1d87""
environment_ex: ""macOS 10.12.6"" 
env_cpus_ex: ""7""
env_memory_ex: ""12Gb""
env_disk_ex: ""1Tb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.
&nbsp;
_____________________
Launched an EC2 instance of type `r4.8xlarge` with one node, mounted an EFS volume, and installed dependencies.
#####
If you have not set up your environment and install dependencies like **cwltool**, **dockstore**, **java** and so on
I recommend you follow [**this**](https://www.synapse.org/#!Synapse:syn10220609) instructions.

##### Create empty folder for workflow running
```
mkdir encode_mapping_workflow
cd encode_mapping_workflow
```
Create Synapse credentials file `.synapseConfig`, put there Synapse ID and password
```
[authentication]
username: user@usermail.org
password: <user-password>
```
Information about `.synapseConfig` can be found [**here**](https://www.synapse.org/#!Synapse:syn8507133/wiki/451408)

#### 2. Download required files

I used the `synapse get` command to download the `synapse-submit` CWL tool and the files for the encode_chip_mapping_workflow:
```shell
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get -r syn10163025 # recursively downloads encode_chip_mapping_workflow files
```

#### 4. Run the main workflow

I used `cwltool` to run `encode_mapping_workflow.cwl` with parameters in `encode_mapping_workflow.cwl.json`.
```shell
cwltool --non-strict encode_mapping_workflow.cwl encode_mapping_workflow.cwl.json
```
Upon completion, this created a date-stamped folder of outputs.  The folder name was `7-26-2017T2H43M10S/`

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the validator on my output folder.  I first edited the file `validator.json` with the path to the outputs I want to check:
> **Note:** the `path` value here should be the relative or absolute path to the output directory your workflow run generated that contains the files `filter_qc.json`, `mapping.json`, `post_mapping.json`, and `xcor.json`.  Where these outputs are stored will depend on the workflow runner you use.  This example uses `cwltool` which saves outputs to a date-stamped folder.  Do not include a trailing slash in the folder name.
```JSON
{
  ""output_folder"": {
    ""path"": ""7-26-2017T2H43M10S"",
    ""class"": ""Directory""
  }
}
```
I then ran the validator with:
```shell
cwltool validator.cwl validator.json
cat results.json | grep overall
```
The JSON output in `results.json` indicates what outputs were checked against known-good outputs to verify that the run was successful:
```JSON
{
    ""overall"": true,
    ""steps"": {
        ""filtering_step"": {
            ""NRF"": true,
            ""PBC1"": true,
            ""PBC2"": true,
            ""duplicate_fraction"": true,
            ""n_filtered_mapped_reads"": true
        },
        ""mapping_step"": {
            ""crop_length"": true,
            ""paired_end"": true
        },
        ""post_mapping_step"": {
            ""n_mapped_reads"": true
        },
        ""xcor_step"": {
            ""NSC"": true,
            ""RSC"": true,
            ""est_frag_len"": true
        }
    }
}
```

#### 6. Submit workflow outputs

I modified the parameters in `encode_mapping_workflow_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""Your Team Name"",
    ""eval_id"": ""9605639"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""7-26-2017T2H43M10S/mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""7-26-2017T2H43M10S/post_mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""7-26-2017T2H43M10S/filter_qc.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""7-26-2017T2H43M10S/xcor.json""
        }
    ],
    ""parent_id"": ""syn12345678""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl encode_mapping_workflow_submit.cwl.json
```
> **Thanks for running the ENCODE ChIP-seq mapping workflow!**  We look forward to learning about how you ran it in your environment.

---",9631756
encode_mapping_workflow,9633520_report.md,"## ENCODE ChIP-seq Mapping Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted files to be viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""J. Seth Strattan, ENCODE Data Coordinating Center""
workflow_handle: ""encode_mapping_workflow""
input_handle: ""A549_CEBP""
```

The following description is provided by the workflow author:
> This workflow is a containerized version of the mapping component from the ENCODE Uniform Analysis Pipeline for ChIP-seq experiments.  The analysis is specified by the ENCODE Data Analysis Center (Zhiping Weng, University of Massachusetts) and ENCODE Analysis Working Group (Anshul Kundaje, Stanford University) and implemented and run by the ENCODE Data Coordinating Center (J. Michael Cherry, Stanford University).
> &nbsp;
> The workflow takes raw reads in the form of a fastq file and a genome reference and generates quality-control (QC) metrics and a filtered bam file suitable for peak calling and signal track generation.  The QC metrics include read depth, library complexity estimates, and scores from cross-correlation analysis.  The workflow is written in both Common Workflow Language (CWL) `encode_mapping_workflow.cwl` and Workflow Description Language (WDL) `encode_mapping_workflow.wdl`.
> &nbsp;
> For this Challenge, known-good inputs are in the `input_data` folder.  The file `input_data/ENCFF000VOL.fastq.gz` are reads from one replicate of an ENCODE ChIP-seq experiment done on the human A549 cell line and targeting the CEBP transcription factor.  The standard GRCh38 reference used by ENCODE is included in `input_data/reference/ENCFF643CGH_ENCODE_GRCh38_bwa.tar.gz`.  Complete metadata and analysis results from this experiment are accessioned at the ENCODE Portal [under accession number ENCSR000DYI here](https://www.encodeproject.org/experiments/ENCSR000DYI/).  Paths to the input files are specified in the CWL parameter file `encode_mapping_workflow.cwl.json` and the WDL parameter file `encode_mapping_workflow.wdl.json`.  Submissions to the challenge will be scored against known-good outputs of the workflow run on these inputs.  Run time should be less than two hours.  Workflow stages will automatically scale into multiple CPU cores if they are made available to Docker.  The workflow has been tested with 4 GB per core.  Disk requirements are highly-dependent on particular workflow runners and their handling of intermediate files.  In addition to cached Docker layers, CWL runs typically use approximately 3 GB of disk space.  WDL runs with cromwell consume considerably more disk space.
> &nbsp;
> To accelerate deployment and testing the workflow is also packaged with smaller test inputs.  The reads in `input_data/ENCFF000VOL_chr21.fq.gz` are chromosome 21 extracts from the same A549/CEBP experiment as above and the companion reference `input_data/reference/GRCh38_chr21_bwa.tar.gz` is a small chromosome 21-only reference.  Paths to these inputs are in the CWL parameter file `input_data/encode_mapping_workflow.cwl_test.json` and the WDL parameter file `input_data/encode_mapping_workflow.wdl_test.json`.  Using these inputs the workflow takes less than a minute to run, not counting Docker downloads if image layers are not yet cached locally.  Do not submit results from these small test files for the Challenge.  They are only for your use in rapid deployment and testing on new platforms.
> &nbsp;
> Code for this workflow can be found in [the pipeline-container GitHub repo](https://github.com/ENCODE-DCC/pipeline-container).  The full ENCODE ChIP-seq analysis pipeline code is in [the chip-seq-pipeline GitHub repo](https://github.com/ENCODE-DCC/chip-seq-pipeline).  ENCODE Uniform Processing Pipelines are runnable on [DNAnexus](https://www.dnanexus.com/) in the featured DNAnexus project called ""ENCODE Uniform Processing Pipelines"".  More information on using ENCODE pipelines is [here](https://www.encodeproject.org/tutorials/ashg-2016-uniform-processing-pipelines/).  All the data and software products from ENCODE are distributed through the [ENCODE Portal](https://www.encodeproject.org/).

### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""30Gb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Lon Blauvelt"" # your name here
institution: ""UCSC"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> **Note:** Participants should update these fields to reflect the approach they used.

```YAML
platform: ""Toil"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""Toil 3.11.0a1"" # indicate executor version used
docker_version: ""Docker version 17.06.1-ce, build 874a737"" # from `docker -v`
environment: ""EC2 t2.2xlarge"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""32"" # indicate available RAM in environment
env_disk: ""2Tb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.  Here we indicate the CPU's and memory made available _to Docker_ since that represents the maximum resources available to the workflow stages.

```YAML
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce, build 02c1d87""
environment_ex: ""macOS 10.12.6"" 
env_cpus_ex: ""7""
env_memory_ex: ""12Gb""
env_disk_ex: ""1Tb""
```

### Steps

#### 1. Set up environment

*I launched an EC2 instance of type `t2.2xlarge` with one node, mounted a 200 Gb EFS volume.*

I used the following to update the instance:

```shell
sudo apt-get update
sudo apt-get -y upgrade
sudo apt-get -y dist-upgrade
```

Install docker:

```shell
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
sudo add-apt-repository ""deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable""
sudo apt-get update
apt-cache policy docker-ce
sudo apt-get install -y docker-ce
sudo usermod -aG docker ${USER}
sudo su - ${USER}
```

Install pip, a virtualenv, the dev version of toil, and the requisite pip installs (cwltool, schema-salad, avro, synapse, and html5lib):

```shell
sudo apt install -y python-pip
sudo pip install --upgrade pip
sudo pip install virtualenv
git clone https://github.com/BD2KGenomics/toil.git
cd toil
virtualenv --python /usr/bin/python2 dev
source /home/ubuntu/toil/dev/bin/activate
make prepare
make develop
pip install cwl-runner schema-salad==2.6.20170630075932 avro==1.8.1 cwltool==1.0.20170822192924 ruamel.yaml==0.14.12 --no-cache-dir
pip install synapseclient --no-cache-dir
pip install html5lib cwltest
cd ..
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:

```shell
mkdir syn
cd syn
nano syn-login.synapseConfig
[PASTE] username & password
cd ..
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-submit` CWL tool and the files for the encode_chip_mapping_workflow, and edit the get file to contain the synapse credentials path:
```shell
synapse get -r syn9689286
[PASTE] username & password
synapse get -r syn9689284
[PASTE] username & password
```

```shell
nano encode_mapping_workflow_get.cwl.json
[PASTE] /home/ubuntu/syn/syn-login.synapseConfig
```

#### 3. Provision all workflow files

I used `cwltoil` to run `dockstore-tool-synapse-get.cwl` with parameters in `encode_mapping_workflow_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltoil dockstore-tool-synapse-get.cwl encode_mapping_workflow_get.cwl.json
```

#### 4. Run the main workflow

I used `cwltoil` to run `encode_mapping_workflow.cwl` with parameters in `encode_mapping_workflow.cwl.json`.
```shell
cwltoil encode_mapping_workflow.cwl encode_mapping_workflow.cwl.json
```
Upon completion, this created a date-stamped folder of outputs.  This folder name was `9-10-2017T1H48M08S`.

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltoil` to run the validator on my output folder.  I first edited the file `validator.json` with the path to the outputs I want to check:
> **Note:** the `path` value here should be the relative or absolute path to the output directory your workflow run generated that contains the files `filter_qc.json`, `mapping.json`, `post_mapping.json`, and `xcor.json`.  Where these outputs are stored will depend on the workflow runner you use.  This example uses `cwltoil` which saves outputs to a date-stamped folder.  Do not include a trailing slash in the folder name.
```JSON
{
  ""output_folder"": {
    ""path"": ""9-10-2017T1H48M08S"",
    ""class"": ""Directory""
  }
}
```
I then ran the validator with:
```shell
cwltoil validator.cwl validator.json
```

#### 6. Submit workflow outputs

I modified the parameters in `encode_mapping_workflow_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": ""/home/ubuntu/syn/syn-login.synapseConfig""
    },
    ""team_name"": ""UCSC GA4GH-DREAM Challenge Team"",
    ""eval_id"": ""9605639"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""9-10-2017T1H48M08S/mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""9-10-2017T1H48M08S/post_mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""9-10-2017T1H48M08S/filter_qc.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""9-10-2017T1H48M08S/xcor.json""
        }
    ],
    ""parent_id"": ""syn10676057""
}
```

Finally, I submitted outputs using `cwltoil` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltoil dockstore-tool-synapse-submit.cwl encode_mapping_workflow_submit.cwl.json
```

---",9633520
encode_mapping_workflow,9633630_report.md,"## ENCODE ChIP-seq Mapping Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted files to be viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""J. Seth Strattan, ENCODE Data Coordinating Center""
workflow_handle: ""encode_mapping_workflow""
input_handle: ""A549_CEBP""
```

The following description is provided by the workflow author:
> This workflow is a containerized version of the mapping component from the ENCODE Uniform Analysis Pipeline for ChIP-seq experiments.  The analysis is specified by the ENCODE Data Analysis Center (Zhiping Weng, University of Massachusetts) and ENCODE Analysis Working Group (Anshul Kundaje, Stanford University) and implemented and run by the ENCODE Data Coordinating Center (J. Michael Cherry, Stanford University).
> &nbsp;
> The workflow takes raw reads in the form of a fastq file and a genome reference and generates quality-control (QC) metrics and a filtered bam file suitable for peak calling and signal track generation.  The QC metrics include read depth, library complexity estimates, and scores from cross-correlation analysis.  The workflow is written in both Common Workflow Language (CWL) `encode_mapping_workflow.cwl` and Workflow Description Language (WDL) `encode_mapping_workflow.wdl`.
> &nbsp;
> For this Challenge, known-good inputs are in the `input_data` folder.  The file `input_data/ENCFF000VOL.fastq.gz` are reads from one replicate of an ENCODE ChIP-seq experiment done on the human A549 cell line and targeting the CEBP transcription factor.  The standard GRCh38 reference used by ENCODE is included in `input_data/reference/ENCFF643CGH_ENCODE_GRCh38_bwa.tar.gz`.  Complete metadata and analysis results from this experiment are accessioned at the ENCODE Portal [under accession number ENCSR000DYI here](https://www.encodeproject.org/experiments/ENCSR000DYI/).  Paths to the input files are specified in the CWL parameter file `encode_mapping_workflow.cwl.json` and the WDL parameter file `encode_mapping_workflow.wdl.json`.  Submissions to the challenge will be scored against known-good outputs of the workflow run on these inputs.  Run time should be less than two hours.  Workflow stages will automatically scale into multiple CPU cores if they are made available to Docker.  The workflow has been tested with 4 GB per core.  Disk requirements are highly-dependent on particular workflow runners and their handling of intermediate files.  In addition to cached Docker layers, CWL runs typically use approximately 3 GB of disk space.  WDL runs with cromwell consume considerably more disk space.
> &nbsp;
> To accelerate deployment and testing the workflow is also packaged with smaller test inputs.  The reads in `input_data/ENCFF000VOL_chr21.fq.gz` are chromosome 21 extracts from the same A549/CEBP experiment as above and the companion reference `input_data/reference/GRCh38_chr21_bwa.tar.gz` is a small chromosome 21-only reference.  Paths to these inputs are in the CWL parameter file `input_data/encode_mapping_workflow.cwl_test.json` and the WDL parameter file `input_data/encode_mapping_workflow.wdl_test.json`.  Using these inputs the workflow takes less than a minute to run, not counting Docker downloads if image layers are not yet cached locally.  Do not submit results from these small test files for the Challenge.  They are only for your use in rapid deployment and testing on new platforms.
> &nbsp;
> Code for this workflow can be found in [the pipeline-container GitHub repo](https://github.com/ENCODE-DCC/pipeline-container).  The full ENCODE ChIP-seq analysis pipeline code is in [the chip-seq-pipeline GitHub repo](https://github.com/ENCODE-DCC/chip-seq-pipeline).  ENCODE Uniform Processing Pipelines are runnable on [DNAnexus](https://www.dnanexus.com/) in the featured DNAnexus project called ""ENCODE Uniform Processing Pipelines"".  More information on using ENCODE pipelines is [here](https://www.encodeproject.org/tutorials/ashg-2016-uniform-processing-pipelines/).  All the data and software products from ENCODE are distributed through the [ENCODE Portal](https://www.encodeproject.org/).

### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""30Gb""
```

#### Workflow history

+ **2017-08-10**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Byunggil Yoo""
institution: ""Children's Mercy Kansas City""
```

### Submission overview

```YAML
date_accessed: ""2017-09-05"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170817131858"" # indicate executor version used
docker_version: ""17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""48"" # indicate number of cores in environment
env_memory: ""512GB"" # indicate available RAM in environment
env_disk: ""368TB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

#### 1. Set up the environment

On a node (CentOS 7.2.1511) of a local cluster with Docker (17.06.0-ce) and Anaconda installed, I created and configured a virtual environment using the following YAML file:

```
channels:
  - bioconda
  - conda-forge
  - anaconda
  - r
dependencies:
  - cwltool=1.0.20170817131858
  - synapseclient
```

I created a working directory for the current workflow and created a copy of my Synapse credentials (~/.synapseConfig) in that folder:

```shell
mkdir encode_mapping_workflow
cd encode_mapping_workflow
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **encode_mapping_workflow** workflow:
```shell
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
synapse get syn10261070 # encode_mapping_workflow_get.cwl.json
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `encode_mapping_workflow_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --outdir encode_mapping_workflow --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ \
        --non-strict dockstore-tool-synapse-get.cwl encode_mapping_workflow_get.cwl.json
```

#### 4. Run the main workflow

I used `cwltool` to run `encode_mapping_workflow.cwl` with parameters in `encode_mapping_workflow.cwl.json`.
```shell
cwltool --basedir encode_mapping_workflow/ --outdir encode_mapping_workflow/ \
    --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
    encode_mapping_workflow/encode_mapping_workflow.cwl encode_mapping_workflow/encode_mapping_workflow.cwl.json
```
Upon completion, this created a date-stamped folder of outputs.  The folder name was `9-6-2017T18H48M11S`

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the validator on my output folder.  I first edited the file `validator.json` with the path to the outputs I want to check:
```JSON
{
  ""output_folder"": {
    ""path"": ""9-6-2017T18H48M11S"",
    ""class"": ""Directory""
  }
}
```
I then ran the validator with:
```shell
cwltool --basedir encode_mapping_workflow/ --outdir encode_mapping_workflow/ \
        --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
        encode_mapping_workflow/validator.cwl encode_mapping_workflow/validator.json
```

#### 6. Submit workflow outputs

I modified the parameters in `encode_mapping_workflow_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""Childrens Mercy GA4GH-DREAM Challenge Team"",
    ""eval_id"": ""9605639"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""9-6-2017T18H48M11S/mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""9-6-2017T18H48M11S/post_mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""9-6-2017T18H48M11S/filter_qc.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""9-6-2017T18H48M11S/xcor.json""
        }
    ],
    ""parent_id"": ""syn10290419""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --basedir encode_mapping_workflow/ --outdir encode_mapping_workflow/ \
        --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
        dockstore-tool-synapse-submit.cwl encode_mapping_workflow/encode_mapping_workflow_submit.cwl.json
```

---",9633630
encode_mapping_workflow,9635416_report.md,"## ENCODE ChIP-seq Mapping Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted files to be viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""J. Seth Strattan, ENCODE Data Coordinating Center""
workflow_handle: ""encode_mapping_workflow""
input_handle: ""A549_CEBP""
```

The following description is provided by the workflow author:
> This workflow is a containerized version of the mapping component from the ENCODE Uniform Analysis Pipeline for ChIP-seq experiments.  The analysis is specified by the ENCODE Data Analysis Center (Zhiping Weng, University of Massachusetts) and ENCODE Analysis Working Group (Anshul Kundaje, Stanford University) and implemented and run by the ENCODE Data Coordinating Center (J. Michael Cherry, Stanford University).
> &nbsp;
> The workflow takes raw reads in the form of a fastq file and a genome reference and generates quality-control (QC) metrics and a filtered bam file suitable for peak calling and signal track generation.  The QC metrics include read depth, library complexity estimates, and scores from cross-correlation analysis.  The workflow is written in both Common Workflow Language (CWL) `encode_mapping_workflow.cwl` and Workflow Description Language (WDL) `encode_mapping_workflow.wdl`.
> &nbsp;
> For this Challenge, known-good inputs are in the `input_data` folder.  The file `input_data/ENCFF000VOL.fastq.gz` are reads from one replicate of an ENCODE ChIP-seq experiment done on the human A549 cell line and targeting the CEBP transcription factor.  The standard GRCh38 reference used by ENCODE is included in `input_data/reference/ENCFF643CGH_ENCODE_GRCh38_bwa.tar.gz`.  Complete metadata and analysis results from this experiment are accessioned at the ENCODE Portal [under accession number ENCSR000DYI here](https://www.encodeproject.org/experiments/ENCSR000DYI/).  Paths to the input files are specified in the CWL parameter file `encode_mapping_workflow.cwl.json` and the WDL parameter file `encode_mapping_workflow.wdl.json`.  Submissions to the challenge will be scored against known-good outputs of the workflow run on these inputs.  Run time should be less than two hours.  Workflow stages will automatically scale into multiple CPU cores if they are made available to Docker.  The workflow has been tested with 4 GB per core.  Disk requirements are highly-dependent on particular workflow runners and their handling of intermediate files.  In addition to cached Docker layers, CWL runs typically use approximately 3 GB of disk space.  WDL runs with cromwell consume considerably more disk space.
> &nbsp;
> To accelerate deployment and testing the workflow is also packaged with smaller test inputs.  The reads in `input_data/ENCFF000VOL_chr21.fq.gz` are chromosome 21 extracts from the same A549/CEBP experiment as above and the companion reference `input_data/reference/GRCh38_chr21_bwa.tar.gz` is a small chromosome 21-only reference.  Paths to these inputs are in the CWL parameter file `input_data/encode_mapping_workflow.cwl_test.json` and the WDL parameter file `input_data/encode_mapping_workflow.wdl_test.json`.  Using these inputs the workflow takes less than a minute to run, not counting Docker downloads if image layers are not yet cached locally.  Do not submit results from these small test files for the Challenge.  They are only for your use in rapid deployment and testing on new platforms.
> &nbsp;
> Code for this workflow can be found in [the pipeline-container GitHub repo](https://github.com/ENCODE-DCC/pipeline-container).  The full ENCODE ChIP-seq analysis pipeline code is in [the chip-seq-pipeline GitHub repo](https://github.com/ENCODE-DCC/chip-seq-pipeline).  ENCODE Uniform Processing Pipelines are runnable on [DNAnexus](https://www.dnanexus.com/) in the featured DNAnexus project called ""ENCODE Uniform Processing Pipelines"".  More information on using ENCODE pipelines is [here](https://www.encodeproject.org/tutorials/ashg-2016-uniform-processing-pipelines/).  All the data and software products from ENCODE are distributed through the [ENCODE Portal](https://www.encodeproject.org/).

### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""30Gb""
```

#### Workflow history

+ **2017-08-10**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Jeff Johnston"" # your name here
institution: ""Children's Mercy"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

```YAML
date_accessed: ""2017-09-15"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170817131858"" # indicate executor version used
docker_version: ""17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""48"" # indicate number of cores in environment
env_memory: ""512GB"" # indicate available RAM in environment
env_disk: ""368TB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

#### 1. Setup

This workflow was run on CentOS Linux release 7.2.1511. Docker and Conda 4.3.25 were installed. A conda environment was built using the following conda YAML file:

```yaml
channels:
  - bioconda
  - conda-forge
  - anaconda
  - r
dependencies:
  - cwltool=1.0.20170817131858
  - synapseclient
```

The Synapse client was configured by editing `~/.synapseConfig`.

##### 2. Download

The following commands were run within the conda environment:

```shell
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
synapse get syn10261070 # encode_mapping_workflow_get.cwl.json
cwltool --outdir encode_mapping_workflow --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ \
        --non-strict dockstore-tool-synapse-get.cwl encode_mapping_workflow_get.cwl.json
cp ~/.synapseConfig encode_mapping_workflow
```

##### 3. Run

Next, the workflow was executed in the conda environment.

```shell
cwltool --basedir encode_mapping_workflow/ --outdir encode_mapping_workflow/ \
    --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
    encode_mapping_workflow/encode_mapping_workflow.cwl encode_mapping_workflow/encode_mapping_workflow.cwl.json
```

##### 4. Validate

After running, the workflow results were validated:

```shell
cwltool --basedir encode_mapping_workflow/ --outdir encode_mapping_workflow/ \
        --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
        encode_mapping_workflow/validator.cwl encode_mapping_workflow/validator.json
```

##### 5. Submit

`encode_mapping_workflow_submit.cwl.json` was modified for submission:

```yaml
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""Childrens Mercy GA4GH-DREAM Challenge Team"",
    ""eval_id"": ""9605639"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""9-14-2017T18H00M20S/mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""9-14-2017T18H00M20S/post_mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""9-14-2017T18H00M20S/filter_qc.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""9-14-2017T18H00M20S/xcor.json""
        }
    ],
    ""parent_id"": ""syn10290419""
}
```

Finally, results were submitted:

```shell
cwltool --basedir encode_mapping_workflow/ --outdir encode_mapping_workflow/ \
        --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
        dockstore-tool-synapse-submit.cwl encode_mapping_workflow/encode_mapping_workflow_submit.cwl.json
```

---
",9635416
encode_mapping_workflow,9636346_report.md,"## ENCODE ChIP-seq Mapping Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted files to be viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""J. Seth Strattan, ENCODE Data Coordinating Center""
workflow_handle: ""encode_mapping_workflow""
input_handle: ""A549_CEBP""
```

The following description is provided by the workflow author:
> This workflow is a containerized version of the mapping component from the ENCODE Uniform Analysis Pipeline for ChIP-seq experiments.  The analysis is specified by the ENCODE Data Analysis Center (Zhiping Weng, University of Massachusetts) and ENCODE Analysis Working Group (Anshul Kundaje, Stanford University) and implemented and run by the ENCODE Data Coordinating Center (J. Michael Cherry, Stanford University).
> &nbsp;
> The workflow takes raw reads in the form of a fastq file and a genome reference and generates quality-control (QC) metrics and a filtered bam file suitable for peak calling and signal track generation.  The QC metrics include read depth, library complexity estimates, and scores from cross-correlation analysis.  The workflow is written in both Common Workflow Language (CWL) `encode_mapping_workflow.cwl` and Workflow Description Language (WDL) `encode_mapping_workflow.wdl`.
> &nbsp;
> For this Challenge, known-good inputs are in the `input_data` folder.  The file `input_data/ENCFF000VOL.fastq.gz` are reads from one replicate of an ENCODE ChIP-seq experiment done on the human A549 cell line and targeting the CEBP transcription factor.  The standard GRCh38 reference used by ENCODE is included in `input_data/reference/ENCFF643CGH_ENCODE_GRCh38_bwa.tar.gz`.  Complete metadata and analysis results from this experiment are accessioned at the ENCODE Portal [under accession number ENCSR000DYI here](https://www.encodeproject.org/experiments/ENCSR000DYI/).  Paths to the input files are specified in the CWL parameter file `encode_mapping_workflow.cwl.json` and the WDL parameter file `encode_mapping_workflow.wdl.json`.  Submissions to the challenge will be scored against known-good outputs of the workflow run on these inputs.  Run time should be less than two hours.  Workflow stages will automatically scale into multiple CPU cores if they are made available to Docker.  The workflow has been tested with 4 GB per core.  Disk requirements are highly-dependent on particular workflow runners and their handling of intermediate files.  In addition to cached Docker layers, CWL runs typically use approximately 3 GB of disk space.  WDL runs with cromwell consume considerably more disk space.
> &nbsp;
> To accelerate deployment and testing the workflow is also packaged with smaller test inputs.  The reads in `input_data/ENCFF000VOL_chr21.fq.gz` are chromosome 21 extracts from the same A549/CEBP experiment as above and the companion reference `input_data/reference/GRCh38_chr21_bwa.tar.gz` is a small chromosome 21-only reference.  Paths to these inputs are in the CWL parameter file `input_data/encode_mapping_workflow.cwl_test.json` and the WDL parameter file `input_data/encode_mapping_workflow.wdl_test.json`.  Using these inputs the workflow takes less than a minute to run, not counting Docker downloads if image layers are not yet cached locally.  Do not submit results from these small test files for the Challenge.  They are only for your use in rapid deployment and testing on new platforms.
> &nbsp;
> Code for this workflow can be found in [the pipeline-container GitHub repo](https://github.com/ENCODE-DCC/pipeline-container).  The full ENCODE ChIP-seq analysis pipeline code is in [the chip-seq-pipeline GitHub repo](https://github.com/ENCODE-DCC/chip-seq-pipeline).  ENCODE Uniform Processing Pipelines are runnable on [DNAnexus](https://www.dnanexus.com/) in the featured DNAnexus project called ""ENCODE Uniform Processing Pipelines"".  More information on using ENCODE pipelines is [here](https://www.encodeproject.org/tutorials/ashg-2016-uniform-processing-pipelines/).  All the data and software products from ENCODE are distributed through the [ENCODE Portal](https://www.encodeproject.org/).

### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""30Gb""
```

#### Workflow history

+ **2017-08-10**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Vipin T. Sreedharan""
institution: ""ETH Zürich, NEXUS Personalized Health Technologies""
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> **Note:** Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-19"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170828135420"" # indicate executor version used
docker_version: ""1.12.6"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""32Gb"" # indicate available RAM in environment
env_disk: ""140Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.
&nbsp;

#### 1. Set up environment

At our institute, on a compute machine called `wfexec` with Red Hat Enterprise Linux Server release 7.4 (Maipo), installed Docker. Created a group named ""docker"" since it was preferred to use Docker as a non-root user on this machine. The instance has a non-root user called `wfrunner`. Next added the non-root user `wfrunner` to the ""docker"" group. Then started the docker engine and all the below commands were executed using root user privileges [sudo]:
&nbsp;
```shell
yum install docker
groupadd docker 
usermod -aG docker wfrunner  
systemctl start docker 
```

As a non-root user on `wfexec` machine, installed Anaconda and cwltool to the home path of user `wfrunner`:
&nbsp;
```shell
su - wfrunner
wget https://repo.continuum.io/archive/Anaconda2-4.4.0-Linux-x86_64.sh
bash Anaconda2-4.4.0-Linux-x86_64.sh 
conda install virtualenv
virtualenv -p python2 /home/wfrunner/venv
source /home/wfrunner/venv/bin/activate
pip install cwltools
deactivate
```

Created a utilities directory for storing the `synapse-get` and `synapse-submit` CWL tools. In the same folder, created a file with my Synapse credentials. 
&nbsp;
```shell
mkdir -p /home/wfrunner/synapse_utils
cd /home/wfrunner/synapse_utils
wget -O dockstore-tool-synapse-get.cwl https://raw.githubusercontent.com/GA4GH-DREAM/dockstore-tool-synapse-get/master/Dockstore.cwl 
wget -O dockstore-tool-synapse-submit.cwl https://raw.githubusercontent.com/GA4GH-DREAM/dockstore-tool-synapse-submit/master/Dockstore.cwl
touch .synapse_config
vim .synapse_config
[WRITE] Synapse username & password
```

#### 2. Download required files

Downloaded data config file encode_mapping_workflow_get.cwl.json from the website `https://www.synapse.org/#!Synapse:syn8507133/wiki/451410` for the **encode_mapping_workflow** workflow. Created a directory for the storing the workflow associated data downloading JSON parameter file: 
&nbsp;
```shell
mkdir -p /home/wfrunner/data_config_files
mv ~/encode_mapping_workflow_get.cwl.json ~/data_config_files
cd /home/wfrunner/data_config_files
vim encode_mapping_workflow_get.cwl.json
[PASTE] /home/wfrunner/synapse_utils/.synapse_config
```

#### 3. Provision all workflow files

Created a working directory for the current workflow. Used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `encode_mapping_workflow_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
&nbsp;
```shell
mkdir -p /home/wfrunner/encode_mapping_workflow
cd /home/wfrunner/encode_mapping_workflow
cwltool --debug --non-strict ~/synapse_utils/dockstore-tool-synapse-get.cwl ~/data_config_files/encode_mapping_workflow_get.cwl.json
```

#### 4. Run the main workflow

Again `cwltool` was used to run the workflow, as defined in `encode_mapping_workflow.cwl` and parameterized by `encode_mapping_workflow.cwl.json`:
&nbsp;
```shell
cd /home/wfrunner/encode_mapping_workflow
cwltool --tmpdir-prefix /home/wfrunner/tmp/ --cachedir /home/wfrunner/tmp/cache --debug --non-strict encode_mapping_workflow.cwl encode_mapping_workflow.cwl.json
```
Upon completion, this created a date-stamped folder of outputs.  The folder name was `9-19-2017T15H21M41S`

#### 5. Run workflow checker tool
To verify workflow results before submission, used `cwltool` to run the validator on the output folder. First edited the file `validator.json` with the path `9-19-2017T15H21M41S` to the outputs want to check:

> **Note:** the `path` value here should be the relative or absolute path to the output directory your workflow run generated that contains the files `filter_qc.json`, `mapping.json`, `post_mapping.json`, and `xcor.json`.  Where these outputs are stored will depend on the workflow runner you use.  This example uses `cwltool` which saves outputs to a date-stamped folder. 
```JSON
{
  ""output_folder"": {
    ""path"": ""9-19-2017T15H21M41S"",
    ""class"": ""Directory""
  }
}
```
Then ran the validator with:
&nbsp;
```shell
cd /home/wfrunner/encode_mapping_workflow
cwltool --tmpdir-prefix /home/wfrunner/tmp/ --cachedir /home/wfrunner/tmp/cache --debug --non-strict validator.cwl validator.json
cat results.json | grep overall
```
The JSON output in `results.json` indicates what outputs were checked against known-good outputs to verify that the run was successful:
&nbsp;
```JSON
{
    ""overall"": true,
    ""steps"": {
        ""filtering_step"": {
            ""NRF"": true,
            ""PBC1"": true,
            ""PBC2"": true,
            ""duplicate_fraction"": true,
            ""n_filtered_mapped_reads"": true
        },
        ""mapping_step"": {
            ""crop_length"": true,
            ""paired_end"": true
        },
        ""post_mapping_step"": {
            ""n_mapped_reads"": true
        },
        ""xcor_step"": {
            ""NSC"": true,
            ""RSC"": true,
            ""est_frag_len"": true
        }
    }
}
```

#### 6. Submit workflow outputs

Modified the parameters in `encode_mapping_workflow_submit.cwl.json` as follows:
&nbsp;
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": ""/home/wfrunner/synapse_utils/.synapse_config""
    },
    ""team_name"": """",
    ""eval_id"": ""9605639"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""9-19-2017T15H21M41S/mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""9-19-2017T15H21M41S/post_mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""9-19-2017T15H21M41S/filter_qc.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""9-19-2017T15H21M41S/xcor.json""
        }
    ],
    ""parent_id"": ""syn10849368""
}
```

Finally, submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
&nbsp;
```shell
cd /home/wfrunner/encode_mapping_workflow
cwltool --tmpdir-prefix /home/wfrunner/tmp/ --cachedir /home/wfrunner/tmp/cache --debug --non-strict ~/synapse_utils/dockstore-tool-synapse-submit.cwl encode_mapping_workflow_submit.cwl.json
```

---",9636346
encode_mapping_workflow,9636472_report.md,"## ENCODE ChIP-seq Mapping Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted files to be viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""J. Seth Strattan, ENCODE Data Coordinating Center""
workflow_handle: ""encode_mapping_workflow""
input_handle: ""A549_CEBP""
```

The following description is provided by the workflow author:
> This workflow is a containerized version of the mapping component from the ENCODE Uniform Analysis Pipeline for ChIP-seq experiments.  The analysis is specified by the ENCODE Data Analysis Center (Zhiping Weng, University of Massachusetts) and ENCODE Analysis Working Group (Anshul Kundaje, Stanford University) and implemented and run by the ENCODE Data Coordinating Center (J. Michael Cherry, Stanford University).
> &nbsp;
> The workflow takes raw reads in the form of a fastq file and a genome reference and generates quality-control (QC) metrics and a filtered bam file suitable for peak calling and signal track generation.  The QC metrics include read depth, library complexity estimates, and scores from cross-correlation analysis.  The workflow is written in both Common Workflow Language (CWL) `encode_mapping_workflow.cwl` and Workflow Description Language (WDL) `encode_mapping_workflow.wdl`.
> &nbsp;
> For this Challenge, known-good inputs are in the `input_data` folder.  The file `input_data/ENCFF000VOL.fastq.gz` are reads from one replicate of an ENCODE ChIP-seq experiment done on the human A549 cell line and targeting the CEBP transcription factor.  The standard GRCh38 reference used by ENCODE is included in `input_data/reference/ENCFF643CGH_ENCODE_GRCh38_bwa.tar.gz`.  Complete metadata and analysis results from this experiment are accessioned at the ENCODE Portal [under accession number ENCSR000DYI here](https://www.encodeproject.org/experiments/ENCSR000DYI/).  Paths to the input files are specified in the CWL parameter file `encode_mapping_workflow.cwl.json` and the WDL parameter file `encode_mapping_workflow.wdl.json`.  Submissions to the challenge will be scored against known-good outputs of the workflow run on these inputs.  Run time should be less than two hours.  Workflow stages will automatically scale into multiple CPU cores if they are made available to Docker.  The workflow has been tested with 4 GB per core.  Disk requirements are highly-dependent on particular workflow runners and their handling of intermediate files.  In addition to cached Docker layers, CWL runs typically use approximately 3 GB of disk space.  WDL runs with cromwell consume considerably more disk space.
> &nbsp;
> To accelerate deployment and testing the workflow is also packaged with smaller test inputs.  The reads in `input_data/ENCFF000VOL_chr21.fq.gz` are chromosome 21 extracts from the same A549/CEBP experiment as above and the companion reference `input_data/reference/GRCh38_chr21_bwa.tar.gz` is a small chromosome 21-only reference.  Paths to these inputs are in the CWL parameter file `input_data/encode_mapping_workflow.cwl_test.json` and the WDL parameter file `input_data/encode_mapping_workflow.wdl_test.json`.  Using these inputs the workflow takes less than a minute to run, not counting Docker downloads if image layers are not yet cached locally.  Do not submit results from these small test files for the Challenge.  They are only for your use in rapid deployment and testing on new platforms.
> &nbsp;
> Code for this workflow can be found in [the pipeline-container GitHub repo](https://github.com/ENCODE-DCC/pipeline-container).  The full ENCODE ChIP-seq analysis pipeline code is in [the chip-seq-pipeline GitHub repo](https://github.com/ENCODE-DCC/chip-seq-pipeline).  ENCODE Uniform Processing Pipelines are runnable on [DNAnexus](https://www.dnanexus.com/) in the featured DNAnexus project called ""ENCODE Uniform Processing Pipelines"".  More information on using ENCODE pipelines is [here](https://www.encodeproject.org/tutorials/ashg-2016-uniform-processing-pipelines/).  All the data and software products from ENCODE are distributed through the [ENCODE Portal](https://www.encodeproject.org/).

### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""30Gb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Denis Yuen"" # your name here
institution: ""OICR"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> **Note:** Participants should update these fields to reflect the approach they used.

```YAML
platform: ""dockstore 1.2.10"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.2.10"" # indicate executor version used
docker_version: ""17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""64GB"" # indicate available RAM in environment
env_disk: ""400GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

#### 1. Set up the environment

On a personal desktop, I installed Docker, pip, cwltool, and the Dockstore command-line helper using a procedure similar to https://github.com/denis-yuen/2017-cloud-workflows-misc/blob/master/install-and-run-with-dockstore.md

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir encode
cd encode
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the website to download encode_mapping_workflow_get.cwl.json:
```shell
dockstore tool cwl --entry quay.io/ga4gh-dream/dockstore-tool-synapse-submit > dockstore-tool-synapse-submit.cwl
dockstore tool cwl --entry quay.io/ga4gh-dream/dockstore-tool-synapse-get > dockstore-tool-synapse-get.cwl
```

#### 3. Download the required files

```
```shell
dockstore tool launch --local-entry dockstore-tool-synapse-get.cwl --json encode_mapping_workflow_get.cwl.json
```

#### 4. Run the main workflow

I used `dockstore cli` to run `encode_mapping_workflow.cwl` with parameters in `encode_mapping_workflow.cwl.json`.
```shell
dockstore workflow launch --local-entry encode_mapping_workflow.cwl --json encode_mapping_workflow.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `dockstore cli` to run the validator on my output folder.  I first edited the file `validator.json` with the path to the outputs I wanted to check:

```JSON
{
  ""output_folder"": {
    ""path"": ""/home/ubuntu/encode"",
    ""class"": ""Directory""
  }
}
```
I then ran the validator with:
```shell
dockstore tool launch --local-entry validator.cwl --json validator.json
cat results.json
```
The JSON output in `results.json` indicates what outputs were checked against known-good outputs to verify that the run was successful:
```JSON
{
    ""overall"": true,
    ""steps"": {
        ""filtering_step"": {
            ""NRF"": true,
            ""PBC1"": true,
            ""PBC2"": true,
            ""duplicate_fraction"": true,
            ""n_filtered_mapped_reads"": true
        },
        ""mapping_step"": {
            ""crop_length"": true,
            ""paired_end"": true
        },
        ""post_mapping_step"": {
            ""n_mapped_reads"": true
        },
        ""xcor_step"": {
            ""NSC"": true,
            ""RSC"": true,
            ""est_frag_len"": true
        }
    }
}
```

#### 6. Submit workflow outputs

I modified the parameters in `encode_mapping_workflow_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""Dockstore Team"",
    ""eval_id"": ""9605639"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""./mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""./post_mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""./filter_qc.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""./xcor.json""
        }
    ],
    ""parent_id"": ""syn9961864""
}
```

Finally, I submitted outputs using `dockstore cli` and `dockstore-tool-synapse-submit.cwl`:
```shell
dockstore tool launch --local-entry  dockstore-tool-synapse-submit.cwl --json encode_mapping_workflow_submit.cwl.json
```
---",9636472
encode_mapping_workflow,9636717_report.md,"## ENCODE ChIP-seq Mapping Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted files to be viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""J. Seth Strattan, ENCODE Data Coordinating Center""
workflow_handle: ""encode_mapping_workflow""
input_handle: ""A549_CEBP""
```

The following description is provided by the workflow author:
> This workflow is a containerized version of the mapping component from the ENCODE Uniform Analysis Pipeline for ChIP-seq experiments.  The analysis is specified by the ENCODE Data Analysis Center (Zhiping Weng, University of Massachusetts) and ENCODE Analysis Working Group (Anshul Kundaje, Stanford University) and implemented and run by the ENCODE Data Coordinating Center (J. Michael Cherry, Stanford University).
> &nbsp;
> The workflow takes raw reads in the form of a fastq file and a genome reference and generates quality-control (QC) metrics and a filtered bam file suitable for peak calling and signal track generation.  The QC metrics include read depth, library complexity estimates, and scores from cross-correlation analysis.  The workflow is written in both Common Workflow Language (CWL) `encode_mapping_workflow.cwl` and Workflow Description Language (WDL) `encode_mapping_workflow.wdl`.
> &nbsp;
> For this Challenge, known-good inputs are in the `input_data` folder.  The file `input_data/ENCFF000VOL.fastq.gz` are reads from one replicate of an ENCODE ChIP-seq experiment done on the human A549 cell line and targeting the CEBP transcription factor.  The standard GRCh38 reference used by ENCODE is included in `input_data/reference/ENCFF643CGH_ENCODE_GRCh38_bwa.tar.gz`.  Complete metadata and analysis results from this experiment are accessioned at the ENCODE Portal [under accession number ENCSR000DYI here](https://www.encodeproject.org/experiments/ENCSR000DYI/).  Paths to the input files are specified in the CWL parameter file `encode_mapping_workflow.cwl.json` and the WDL parameter file `encode_mapping_workflow.wdl.json`.  Submissions to the challenge will be scored against known-good outputs of the workflow run on these inputs.  Run time should be less than two hours.  Workflow stages will automatically scale into multiple CPU cores if they are made available to Docker.  The workflow has been tested with 4 GB per core.  Disk requirements are highly-dependent on particular workflow runners and their handling of intermediate files.  In addition to cached Docker layers, CWL runs typically use approximately 3 GB of disk space.  WDL runs with cromwell consume considerably more disk space.
> &nbsp;
> To accelerate deployment and testing the workflow is also packaged with smaller test inputs.  The reads in `input_data/ENCFF000VOL_chr21.fq.gz` are chromosome 21 extracts from the same A549/CEBP experiment as above and the companion reference `input_data/reference/GRCh38_chr21_bwa.tar.gz` is a small chromosome 21-only reference.  Paths to these inputs are in the CWL parameter file `input_data/encode_mapping_workflow.cwl_test.json` and the WDL parameter file `input_data/encode_mapping_workflow.wdl_test.json`.  Using these inputs the workflow takes less than a minute to run, not counting Docker downloads if image layers are not yet cached locally.  Do not submit results from these small test files for the Challenge.  They are only for your use in rapid deployment and testing on new platforms.
> &nbsp;
> Code for this workflow can be found in [the pipeline-container GitHub repo](https://github.com/ENCODE-DCC/pipeline-container).  The full ENCODE ChIP-seq analysis pipeline code is in [the chip-seq-pipeline GitHub repo](https://github.com/ENCODE-DCC/chip-seq-pipeline).  ENCODE Uniform Processing Pipelines are runnable on [DNAnexus](https://www.dnanexus.com/) in the featured DNAnexus project called ""ENCODE Uniform Processing Pipelines"".  More information on using ENCODE pipelines is [here](https://www.encodeproject.org/tutorials/ashg-2016-uniform-processing-pipelines/).  All the data and software products from ENCODE are distributed through the [ENCODE Portal](https://www.encodeproject.org/).

### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""30Gb""
```

#### Workflow history

+ **2017-08-10**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Jonathon Saunders"" # your name here
institution: ""Children's Mercy Hospital"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> **Note:** Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-07-19"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170817131858"" # indicate executor version used
docker_version: ""Docker version 17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""4"" # indicate number of cores in environment
env_memory: ""16"" # indicate available RAM in environment
env_disk: ""500gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.  Here we indicate the CPU's and memory made available _to Docker_ since that represents the maximum resources available to the workflow stages.

```YAML
date_accessed_ex: ""2017-08-16""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce, build 02c1d87""
environment_ex: ""macOS 10.12.6"" 
env_cpus_ex: ""7""
env_memory_ex: ""12Gb""
env_disk_ex: ""1Tb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.
&nbsp;
> **Note:** Steps we followed to run the CWL version of the workflow on Mac OSX are included as an example here.
#### 1. Set up the environment

On a MacBook Pro running macOS 10.12.6 (Sierra) with Docker version 17.06.0-ce, build 02c1d87 installed we added these components:
```shell
pip install --upgrade pip
pip install schema-salad==2.2.20170222151604 cwltool==1.0.20170217172322
pip install synapseclient
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir encode_mapping
cd encode_mapping
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-submit` CWL tool and the files for the encode_chip_mapping_workflow:
```shell
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get -r syn10163025 # recursively downloads encode_chip_mapping_workflow files
```

#### 4. Run the main workflow

I used `cwltool` to run `encode_mapping_workflow.cwl` with parameters in `encode_mapping_workflow.cwl.json`.
```shell
cwltool --non-strict encode_mapping_workflow.cwl encode_mapping_workflow.cwl.json
```
Upon completion, this created a date-stamped folder of outputs.  The folder name was `7-26-2017T2H43M10S/`

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the validator on my output folder.  I first edited the file `validator.json` with the path to the outputs I want to check:
> **Note:** the `path` value here should be the relative or absolute path to the output directory your workflow run generated that contains the files `filter_qc.json`, `mapping.json`, `post_mapping.json`, and `xcor.json`.  Where these outputs are stored will depend on the workflow runner you use.  This example uses `cwltool` which saves outputs to a date-stamped folder.  Do not include a trailing slash in the folder name.
```JSON
{
  ""output_folder"": {
    ""path"": ""7-26-2017T2H43M10S"",
    ""class"": ""Directory""
  }
}
```
I then ran the validator with:
```shell
cwltool validator.cwl validator.json
cat results.json | grep overall
```
The JSON output in `results.json` indicates what outputs were checked against known-good outputs to verify that the run was successful:
```JSON
{
    ""overall"": true,
    ""steps"": {
        ""filtering_step"": {
            ""NRF"": true,
            ""PBC1"": true,
            ""PBC2"": true,
            ""duplicate_fraction"": true,
            ""n_filtered_mapped_reads"": true
        },
        ""mapping_step"": {
            ""crop_length"": true,
            ""paired_end"": true
        },
        ""post_mapping_step"": {
            ""n_mapped_reads"": true
        },
        ""xcor_step"": {
            ""NSC"": true,
            ""RSC"": true,
            ""est_frag_len"": true
        }
    }
}
```

#### 6. Submit workflow outputs

I modified the parameters in `encode_mapping_workflow_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""ENCODE DCC"",
    ""eval_id"": ""9605639"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""7-26-2017T2H43M10S/mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""7-26-2017T2H43M10S/post_mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""7-26-2017T2H43M10S/filter_qc.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""7-26-2017T2H43M10S/xcor.json""
        }
    ],
    ""parent_id"": ""syn10163025""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl encode_mapping_workflow_submit.cwl.json
```
> **Thanks for running the ENCODE ChIP-seq mapping workflow!**  We look forward to learning about how you ran it in your environment.

---",9636717
encode_mapping_workflow,9637098_report.md,"## ENCODE ChIP-seq Mapping Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted files to be viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""J. Seth Strattan, ENCODE Data Coordinating Center""
workflow_handle: ""encode_mapping_workflow""
input_handle: ""A549_CEBP""
```

The following description is provided by the workflow author:
> This workflow is a containerized version of the mapping component from the ENCODE Uniform Analysis Pipeline for ChIP-seq experiments.  The analysis is specified by the ENCODE Data Analysis Center (Zhiping Weng, University of Massachusetts) and ENCODE Analysis Working Group (Anshul Kundaje, Stanford University) and implemented and run by the ENCODE Data Coordinating Center (J. Michael Cherry, Stanford University).
> &nbsp;
> The workflow takes raw reads in the form of a fastq file and a genome reference and generates quality-control (QC) metrics and a filtered bam file suitable for peak calling and signal track generation.  The QC metrics include read depth, library complexity estimates, and scores from cross-correlation analysis.  The workflow is written in both Common Workflow Language (CWL) `encode_mapping_workflow.cwl` and Workflow Description Language (WDL) `encode_mapping_workflow.wdl`.
> &nbsp;
> For this Challenge, known-good inputs are in the `input_data` folder.  The file `input_data/ENCFF000VOL.fastq.gz` are reads from one replicate of an ENCODE ChIP-seq experiment done on the human A549 cell line and targeting the CEBP transcription factor.  The standard GRCh38 reference used by ENCODE is included in `input_data/reference/ENCFF643CGH_ENCODE_GRCh38_bwa.tar.gz`.  Complete metadata and analysis results from this experiment are accessioned at the ENCODE Portal [under accession number ENCSR000DYI here](https://www.encodeproject.org/experiments/ENCSR000DYI/).  Paths to the input files are specified in the CWL parameter file `encode_mapping_workflow.cwl.json` and the WDL parameter file `encode_mapping_workflow.wdl.json`.  Submissions to the challenge will be scored against known-good outputs of the workflow run on these inputs.  Run time should be less than two hours.  Workflow stages will automatically scale into multiple CPU cores if they are made available to Docker.  The workflow has been tested with 4 GB per core.  Disk requirements are highly-dependent on particular workflow runners and their handling of intermediate files.  In addition to cached Docker layers, CWL runs typically use approximately 3 GB of disk space.  WDL runs with cromwell consume considerably more disk space.
> &nbsp;
> To accelerate deployment and testing the workflow is also packaged with smaller test inputs.  The reads in `input_data/ENCFF000VOL_chr21.fq.gz` are chromosome 21 extracts from the same A549/CEBP experiment as above and the companion reference `input_data/reference/GRCh38_chr21_bwa.tar.gz` is a small chromosome 21-only reference.  Paths to these inputs are in the CWL parameter file `input_data/encode_mapping_workflow.cwl_test.json` and the WDL parameter file `input_data/encode_mapping_workflow.wdl_test.json`.  Using these inputs the workflow takes less than a minute to run, not counting Docker downloads if image layers are not yet cached locally.  Do not submit results from these small test files for the Challenge.  They are only for your use in rapid deployment and testing on new platforms.
> &nbsp;
> Code for this workflow can be found in [the pipeline-container GitHub repo](https://github.com/ENCODE-DCC/pipeline-container).  The full ENCODE ChIP-seq analysis pipeline code is in [the chip-seq-pipeline GitHub repo](https://github.com/ENCODE-DCC/chip-seq-pipeline).  ENCODE Uniform Processing Pipelines are runnable on [DNAnexus](https://www.dnanexus.com/) in the featured DNAnexus project called ""ENCODE Uniform Processing Pipelines"".  More information on using ENCODE pipelines is [here](https://www.encodeproject.org/tutorials/ashg-2016-uniform-processing-pipelines/).  All the data and software products from ENCODE are distributed through the [ENCODE Portal](https://www.encodeproject.org/).

### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""30Gb""
```

#### Workflow history

+ **2017-08-10**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Azza E. Ahmed"" # your name here
institution: ""University of Khartoum, Sudan"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-22"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170217172322"" # indicate executor version used
docker_version: ""1.13.1, build 092cba3"" # from `docker --version`
environment: ""stand alone server"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""24"" # indicate number of cores in environment
env_memory: ""125G"" # indicate available RAM in environment
env_disk: ""7.5T"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-20""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```


### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.
&nbsp;

#### 1. Set up the e`nvironment

I'm running on a stand alone server, Ubuntu 16.04 with synapse client already installed. Therefore, I went ahead to run the workflow. My Synapse credentials are in its parent directory, as it will be used for all workflows.
```shell
mkdir encode_mapping
cd encode_mapping
```

#### 2. Download required files
For some reason, the `synapse-get` command took too long to show any response or indication that it is starting to actually download files. Therefore, I downloaded the entire folder contents recursively, in the more direct way:
```shell
synapse get -r syn10163025 # recursively downloads encode_chip_mapping_workflow files
```

#### 4. Run the main workflow

I used `cwltool` to run `encode_mapping_workflow.cwl` with parameters in `encode_mapping_workflow.cwl.json`.
```shell
cwltool --non-strict encode_mapping_workflow.cwl encode_mapping_workflow.cwl.json
```
Upon completion, this created a date-stamped folder of outputs.  The folder name was `9-22-2017T21H18M35S `

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the validator on my output folder.  I first edited the file `validator.json` with the path to the outputs I want to check:
> **Note:** the `path` value here should be the relative or absolute path to the output directory your workflow run generated that contains the files `filter_qc.json`, `mapping.json`, `post_mapping.json`, and `xcor.json`.  Where these outputs are stored will depend on the workflow runner you use.  This example uses `cwltool` which saves outputs to a date-stamped folder.  Do not include a trailing slash in the folder name.
```JSON
{
  ""output_folder"": {
    ""path"": ""7-26-2017T2H43M10S"",
    ""class"": ""Directory""
  }
}
```
I then ran the validator with:
```shell
cwltool validator.cwl validator.json
cat results.json | grep overall
```
The JSON output in `results.json` indicates what outputs were checked against known-good outputs to verify that the run was successful:
```JSON
{
    ""overall"": true,
    ""steps"": {
        ""filtering_step"": {
            ""NRF"": true,
            ""PBC1"": true,
            ""PBC2"": true,
            ""duplicate_fraction"": true,
            ""n_filtered_mapped_reads"": true
        },
        ""mapping_step"": {
            ""crop_length"": true,
            ""paired_end"": true
        },
        ""post_mapping_step"": {
            ""n_mapped_reads"": true
        },
        ""xcor_step"": {
            ""NSC"": true,
            ""RSC"": true,
            ""est_frag_len"": true
        }
    }
}
```

#### 6. Submit workflow outputs

I modified the parameters in `encode_mapping_workflow_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": ""../.synapseConfig""
    },
    ""team_name"": ""CBSB_pipelines"",
    ""eval_id"": ""9605639"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""9-22-2017T21H18M35S /mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""9-22-2017T21H18M35S /post_mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""9-22-2017T21H18M35S /filter_qc.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""9-22-2017T21H18M35S /xcor.json""
        }
    ],
    ""parent_id"": ""syn10891339""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl encode_mapping_workflow_submit.cwl.json
```
> **Thanks for running the ENCODE ChIP-seq mapping workflow!**  We look forward to learning about how you ran it in your environment.

---",9637098
encode_mapping_workflow,9637440_report.md,"## ENCODE ChIP-seq Mapping Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted files to be viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""J. Seth Strattan, ENCODE Data Coordinating Center""
workflow_handle: ""encode_mapping_workflow""
input_handle: ""A549_CEBP""
```

The following description is provided by the workflow author:
> This workflow is a containerized version of the mapping component from the ENCODE Uniform Analysis Pipeline for ChIP-seq experiments.  The analysis is specified by the ENCODE Data Analysis Center (Zhiping Weng, University of Massachusetts) and ENCODE Analysis Working Group (Anshul Kundaje, Stanford University) and implemented and run by the ENCODE Data Coordinating Center (J. Michael Cherry, Stanford University).
> &nbsp;
> The workflow takes raw reads in the form of a fastq file and a genome reference and generates quality-control (QC) metrics and a filtered bam file suitable for peak calling and signal track generation.  The QC metrics include read depth, library complexity estimates, and scores from cross-correlation analysis.  The workflow is written in both Common Workflow Language (CWL) `encode_mapping_workflow.cwl` and Workflow Description Language (WDL) `encode_mapping_workflow.wdl`.
> &nbsp;
> For this Challenge, known-good inputs are in the `input_data` folder.  The file `input_data/ENCFF000VOL.fastq.gz` are reads from one replicate of an ENCODE ChIP-seq experiment done on the human A549 cell line and targeting the CEBP transcription factor.  The standard GRCh38 reference used by ENCODE is included in `input_data/reference/ENCFF643CGH_ENCODE_GRCh38_bwa.tar.gz`.  Complete metadata and analysis results from this experiment are accessioned at the ENCODE Portal [under accession number ENCSR000DYI here](https://www.encodeproject.org/experiments/ENCSR000DYI/).  Paths to the input files are specified in the CWL parameter file `encode_mapping_workflow.cwl.json` and the WDL parameter file `encode_mapping_workflow.wdl.json`.  Submissions to the challenge will be scored against known-good outputs of the workflow run on these inputs.  Run time should be less than two hours.  Workflow stages will automatically scale into multiple CPU cores if they are made available to Docker.  The workflow has been tested with 4 GB per core.  Disk requirements are highly-dependent on particular workflow runners and their handling of intermediate files.  In addition to cached Docker layers, CWL runs typically use approximately 3 GB of disk space.  WDL runs with cromwell consume considerably more disk space.
> &nbsp;
> To accelerate deployment and testing the workflow is also packaged with smaller test inputs.  The reads in `input_data/ENCFF000VOL_chr21.fq.gz` are chromosome 21 extracts from the same A549/CEBP experiment as above and the companion reference `input_data/reference/GRCh38_chr21_bwa.tar.gz` is a small chromosome 21-only reference.  Paths to these inputs are in the CWL parameter file `input_data/encode_mapping_workflow.cwl_test.json` and the WDL parameter file `input_data/encode_mapping_workflow.wdl_test.json`.  Using these inputs the workflow takes less than a minute to run, not counting Docker downloads if image layers are not yet cached locally.  Do not submit results from these small test files for the Challenge.  They are only for your use in rapid deployment and testing on new platforms.
> &nbsp;
> Code for this workflow can be found in [the pipeline-container GitHub repo](https://github.com/ENCODE-DCC/pipeline-container).  The full ENCODE ChIP-seq analysis pipeline code is in [the chip-seq-pipeline GitHub repo](https://github.com/ENCODE-DCC/chip-seq-pipeline).  ENCODE Uniform Processing Pipelines are runnable on [DNAnexus](https://www.dnanexus.com/) in the featured DNAnexus project called ""ENCODE Uniform Processing Pipelines"".  More information on using ENCODE pipelines is [here](https://www.encodeproject.org/tutorials/ashg-2016-uniform-processing-pipelines/).  All the data and software products from ENCODE are distributed through the [ENCODE Portal](https://www.encodeproject.org/).

### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""30Gb""
```

#### Workflow history

+ **2017-08-10**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Vipin T. Sreedharan"" # your name here
institution: ""ETH Zürich, NEXUS Personalized Health Technologies"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

```YAML
date_accessed: ""2017-09-20"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""Toil"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""cwltoil 3.11.0"" # indicate executor version used
docker_version: ""1.12.6, build c4618fb"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""32Gb"" # indicate available RAM in environment
env_disk: ""140Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up the environment

At our institute, on a compute machine called `wfexec` with Red Hat Enterprise Linux Server release 7.4 (Maipo), installed Docker. Created a group named ""docker"" since it was preferred to use Docker as a non-root user on this machine. The instance has a non-root user called `wfrunner`. Next added the non-root user `wfrunner` to the ""docker"" group. Then started the docker engine and all the below commands were executed using root user privileges [sudo]:
```shell
yum install docker
groupadd docker 
usermod -aG docker wfrunner  
systemctl start docker 
```

As a non-root user `wfrunner` on `wfexec` machine, installed Anaconda and Toil to the home path:
```shell
su - wfrunner
wget https://repo.continuum.io/archive/Anaconda2-4.4.0-Linux-x86_64.sh
bash Anaconda2-4.4.0-Linux-x86_64.sh 
conda install virtualenv
virtualenv -p python2 /home/wfrunner/venv
source /home/wfrunner/venv/bin/activate
pip install toil
deactivate
export PATH=$PATH:/home/wfrunner/venv/bin/
```

Created a utilities directory for storing the `synapse-get` and `synapse-submit` CWL tools. In the same folder, created Synapse credential file `.synapse_config` and put there Synapse ID and password. 
```shell
mkdir -p /home/wfrunner/synapse_utils
cd /home/wfrunner/synapse_utils
wget -O dockstore-tool-synapse-get.cwl https://raw.githubusercontent.com/GA4GH-DREAM/dockstore-tool-synapse-get/master/Dockstore.cwl 
wget -O dockstore-tool-synapse-submit.cwl https://raw.githubusercontent.com/GA4GH-DREAM/dockstore-tool-synapse-submit/master/Dockstore.cwl
touch .synapse_config
vim .synapse_config
[WRITE] Synapse username & password
```

#### 2. Downloading required files

Downloaded data config file `encode_mapping_workflow_get.cwl.json` from the website `https://www.synapse.org/#!Synapse:syn8507133/wiki/451410` for the **encode_mapping_workflow** workflow. Created a directory for the storing the workflow associated data downloading JSON parameter file: 
```shell
mkdir -p /home/wfrunner/data_config_files
mv ~/encode_mapping_workflow_get.cwl.json ~/data_config_files
cd /home/wfrunner/data_config_files
vim encode_mapping_workflow_get.cwl.json
[PASTE] /home/wfrunner/synapse_utils/.synapse_config
```

#### 3. Provision all workflow files

Created a working directory for the current workflow. 
```shell
mkdir -p /home/wfrunner/encode_mapping_workflow
cd /home/wfrunner/encode_mapping_workflow
```

Used `cwltoil` to run `dockstore-tool-synapse-get.cwl` with parameters in `encode_mapping_workflow_get.cwl.json` to download workflow input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltoil --workDir ~/tmp/ ~/synapse_utils/dockstore-tool-synapse-get.cwl ~/config_files/encode_mapping_workflow_get.cwl.json
```
Wait until downloading is finished.

#### 4. Run main workflow

Before running the workflow, I have to change the amount of disk space (`outdirMin` & `tmpdirMin` variables) requested by `Toil` specified in individual CWL stages of the workflow. I have to specifically modify the default value (512000)  of the variable `outdirMin` and `tmpdirMin` to 20000 and  30000 (account for 20Gb & 30Gb) respectively in the following CWL files mapping.cwl, post_processing.cwl, filter_qc.cwl, and xcor.cwl as: 
```
  - class: ResourceRequirement
    coresMin: 1
    ramMin: 4092 #""the process requires at least 4G of RAM
-        outdirMin: 512000 #default request 5TB 
-        tmpdirMin: 512000
+        outdirMin: 20000 #changing to 20GB
+        tmpdirMin: 30000
```
Depends of the free disk space available on your machine you can adjust the value. 

Then use `cwltoil` to run the workflow, as defined in `encode_mapping_workflow.cwl` and parameterized by `encode_mapping_workflow.cwl.json`
```shell
cd /home/wfrunner/encode_mapping_workflow
cwltoil --workDir ~/tmp/ encode_mapping_workflow.cwl encode_mapping_workflow.cwl.json
```
Wait for the run to finish. Upon completion, this created a date-stamped folder of outputs.

#### 5. Run workflow checker tool

To verify the workflow results before submission, use `cwltoil` to run the checker programs. 
First edited the file `validator.json` with the path `9-23-2017T2H43M10S` to the outputs want to check:
```JSON
{
  ""output_folder"": {
    ""path"": ""9-23-2017T2H43M10S"",
    ""class"": ""Directory""
  }
}
```
> **Note:** the `path` value here should be the relative or absolute path to the output directory your workflow run generated that contains the files `filter_qc.json`, `mapping.json`, `post_mapping.json`, and `xcor.json`.  Where these outputs are stored will depend on the workflow runner you use.  This example uses `cwltoil` which saves outputs to a date-stamped folder.  Do not include a trailing slash in the folder name.

Then ran the validator tool with:
```shell
cd /home/wfrunner/encode_mapping_workflow
cwltoil --workDir ~/tmp/ validator.cwl validator.json
```
Wait for the run to finish. 

Check results:
The JSON output in `results.json` indicates what outputs were checked against known-good outputs to verify that the run was successful:
```shell
cd /home/wfrunner/encode_mapping_workflow
cat results.json | grep -i overall
[OUTPUT] “overall"": true,
``` 

#### 6. Submit workflow outputs

Modified the parameters in `encode_mapping_workflow_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": ""/home/wfrunner/synapse_utils/.synapse_config""
    },
    ""team_name"": """",
    ""eval_id"": ""9605639"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""9-23-2017T2H43M10S/mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""9-23-2017T2H43M10S/post_mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""9-23-2017T2H43M10S/filter_qc.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""9-23-2017T2H43M10S/xcor.json""
        }
    ],
    ""parent_id"": ""syn10900838""
}
```

Finally, submitted outputs using the submission tool `dockstore-tool-synapse-submit.cwl`:
```shell
cd /home/wfrunner/encode_mapping_workflow
cwltoil ~/synapse_utils/dockstore-tool-synapse-submit.cwl encode_mapping_workflow_submit.cwl.json
```

> **Thanks for running the ENCODE ChIP-seq mapping workflow!**  We look forward to learning about how you ran it in your environment.

---",9637440
encode_mapping_workflow,9637536_report.md,"## ENCODE ChIP-seq Mapping Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted files to be viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""J. Seth Strattan, ENCODE Data Coordinating Center""
workflow_handle: ""encode_mapping_workflow""
input_handle: ""A549_CEBP""
```

The following description is provided by the workflow author:
> This workflow is a containerized version of the mapping component from the ENCODE Uniform Analysis Pipeline for ChIP-seq experiments.  The analysis is specified by the ENCODE Data Analysis Center (Zhiping Weng, University of Massachusetts) and ENCODE Analysis Working Group (Anshul Kundaje, Stanford University) and implemented and run by the ENCODE Data Coordinating Center (J. Michael Cherry, Stanford University).
> &nbsp;
> The workflow takes raw reads in the form of a fastq file and a genome reference and generates quality-control (QC) metrics and a filtered bam file suitable for peak calling and signal track generation.  The QC metrics include read depth, library complexity estimates, and scores from cross-correlation analysis.  The workflow is written in both Common Workflow Language (CWL) `encode_mapping_workflow.cwl` and Workflow Description Language (WDL) `encode_mapping_workflow.wdl`.
> &nbsp;
> For this Challenge, known-good inputs are in the `input_data` folder.  The file `input_data/ENCFF000VOL.fastq.gz` are reads from one replicate of an ENCODE ChIP-seq experiment done on the human A549 cell line and targeting the CEBP transcription factor.  The standard GRCh38 reference used by ENCODE is included in `input_data/reference/ENCFF643CGH_ENCODE_GRCh38_bwa.tar.gz`.  Complete metadata and analysis results from this experiment are accessioned at the ENCODE Portal [under accession number ENCSR000DYI here](https://www.encodeproject.org/experiments/ENCSR000DYI/).  Paths to the input files are specified in the CWL parameter file `encode_mapping_workflow.cwl.json` and the WDL parameter file `encode_mapping_workflow.wdl.json`.  Submissions to the challenge will be scored against known-good outputs of the workflow run on these inputs.  Run time should be less than two hours.  Workflow stages will automatically scale into multiple CPU cores if they are made available to Docker.  The workflow has been tested with 4 GB per core.  Disk requirements are highly-dependent on particular workflow runners and their handling of intermediate files.  In addition to cached Docker layers, CWL runs typically use approximately 3 GB of disk space.  WDL runs with cromwell consume considerably more disk space.
> &nbsp;
> To accelerate deployment and testing the workflow is also packaged with smaller test inputs.  The reads in `input_data/ENCFF000VOL_chr21.fq.gz` are chromosome 21 extracts from the same A549/CEBP experiment as above and the companion reference `input_data/reference/GRCh38_chr21_bwa.tar.gz` is a small chromosome 21-only reference.  Paths to these inputs are in the CWL parameter file `input_data/encode_mapping_workflow.cwl_test.json` and the WDL parameter file `input_data/encode_mapping_workflow.wdl_test.json`.  Using these inputs the workflow takes less than a minute to run, not counting Docker downloads if image layers are not yet cached locally.  Do not submit results from these small test files for the Challenge.  They are only for your use in rapid deployment and testing on new platforms.
> &nbsp;
> Code for this workflow can be found in [the pipeline-container GitHub repo](https://github.com/ENCODE-DCC/pipeline-container).  The full ENCODE ChIP-seq analysis pipeline code is in [the chip-seq-pipeline GitHub repo](https://github.com/ENCODE-DCC/chip-seq-pipeline).  ENCODE Uniform Processing Pipelines are runnable on [DNAnexus](https://www.dnanexus.com/) in the featured DNAnexus project called ""ENCODE Uniform Processing Pipelines"".  More information on using ENCODE pipelines is [here](https://www.encodeproject.org/tutorials/ashg-2016-uniform-processing-pipelines/).  All the data and software products from ENCODE are distributed through the [ENCODE Portal](https://www.encodeproject.org/).

### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""30Gb""
```

#### Workflow history

+ **2017-08-10**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Byunggil Yoo"" # your name here
institution: ""Children's Mercy Hospital"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

```YAML
date_accessed: ""2017-09-07"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cromwell"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""WDL"" # CWL or WDL
runner_version: ""29"" # indicate executor version used
docker_version: ""17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""48"" # indicate number of cores in environment
env_memory: ""512GB"" # indicate available RAM in environment
env_disk: ""367TB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up the environment

On a local machine running CentOS Linux release 7.2.1511 with Docker and Anaconda installed, conda environment is created using the following YAML file:
```shell
channels:
  - bioconda
  - conda-forge
  - anaconda
  - r
dependencies:
  - cwltool=1.0.20170817131858
  - synapseclient
```

The Synapse client was configured by editing `~/.synapseConfig`

#### 2. Download required files

I used the `synapse get` command to download the `synapse-submit` CWL tool and the files for the encode_chip_mapping_workflow:
```shell
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn10261070 # encode_mapping_workflow_get.cwl.json
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `encode_mapping_workflow_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
Then I copied ~/.synapseConfig to the project directory for subsequent steps.
```
cwltool --outdir encode_mapping_workflow --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ \
              --non-strict dockstore-tool-synapse-get.cwl encode_mapping_workflow_get.cwl.json
cp ~/.synapseConfig encode_mapping_workflow
```

#### 4. Run the main workflow

I used `cromwell` to run `encode_mapping_workflow.wdl` with parameters in `encode_mapping_workflow.wdl.json`.
```shell
java -Duser.dir=encode_mapping_workflow -jar cromwell-29.jar run \
            encode_mapping_workflow.wdl -i encode_mapping_workflow.wdl.json \
            -m encode_mapping_workflow.wdl.run.metadata 
```
Upon completion, this created a date-stamped folder of outputs.  The folder name was `cromwell-executions/encode_mapping_workflow/9efe53d3-f0da-43cf-a030-3f774c21657b/call-gather_the_outputs/execution`

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the validator on my output folder.  I first edited the file `validator.json` with the path to the outputs I want to check and renamed as `validator.wdl.json`:

```JSON
{
  ""output_folder"": {
    ""path"": ""cromwell-executions/encode_mapping_workflow/9efe53d3-f0da-43cf-a030-3f774c21657b/call-gather_the_outputs/execution"",
    ""class"": ""Directory""
  }
}
```
I then ran the validator with:
```shell
cwltool validator.cwl validator.wdl.json
cat results.json | grep overall
```
The JSON output in `results.json` indicates what outputs were checked against known-good outputs to verify that the run was successful:
```JSON
{
    ""overall"": true,
    ""steps"": {
        ""filtering_step"": {
            ""NRF"": true,
            ""PBC1"": true,
            ""PBC2"": true,
            ""duplicate_fraction"": true,
            ""n_filtered_mapped_reads"": true
        },
        ""mapping_step"": {
            ""crop_length"": true,
            ""paired_end"": true
        },
        ""post_mapping_step"": {
            ""n_mapped_reads"": true
        },
        ""xcor_step"": {
            ""NSC"": true,
            ""RSC"": true,
            ""est_frag_len"": true
        }
    }
}
```

#### 6. Submit workflow outputs

I modified the parameters in `encode_mapping_workflow_submit.cwl.json` as follows and renamed as `encode_mapping_workflow_submit.wdl.json`:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""Childrens Mercy GA4GH-DREAM Challenge Team"",
    ""eval_id"": ""9605639"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""cromwell-executions/encode_mapping_workflow/9efe53d3-f0da-43cf-a030-3f774c21657b/call-gather_the_outputs/execution/mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""cromwell-executions/encode_mapping_workflow/9efe53d3-f0da-43cf-a030-3f774c21657b/call-gather_the_outputs/execution/post_mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""cromwell-executions/encode_mapping_workflow/9efe53d3-f0da-43cf-a030-3f774c21657b/call-gather_the_outputs/execution/filter_qc.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""cromwell-executions/encode_mapping_workflow/9efe53d3-f0da-43cf-a030-3f774c21657b/call-gather_the_outputs/execution/xcor.json""
        }
    ],
    ""parent_id"": ""syn10814328""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --basedir encode_mapping_workflow --outdir encode_mapping_workflow \
        --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ \
        --non-strict dockstore-tool-synapse-submit.cwl encode_mapping_workflow_submit.wdl.json
```

---",9637536
encode_mapping_workflow,9637953_report.md,"## ENCODE ChIP-seq Mapping Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted files to be viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""J. Seth Strattan, ENCODE Data Coordinating Center""
workflow_handle: ""encode_mapping_workflow""
input_handle: ""A549_CEBP""
```

The following description is provided by the workflow author:
> This workflow is a containerized version of the mapping component from the ENCODE Uniform Analysis Pipeline for ChIP-seq experiments.  The analysis is specified by the ENCODE Data Analysis Center (Zhiping Weng, University of Massachusetts) and ENCODE Analysis Working Group (Anshul Kundaje, Stanford University) and implemented and run by the ENCODE Data Coordinating Center (J. Michael Cherry, Stanford University).
> &nbsp;
> The workflow takes raw reads in the form of a fastq file and a genome reference and generates quality-control (QC) metrics and a filtered bam file suitable for peak calling and signal track generation.  The QC metrics include read depth, library complexity estimates, and scores from cross-correlation analysis.  The workflow is written in both Common Workflow Language (CWL) `encode_mapping_workflow.cwl` and Workflow Description Language (WDL) `encode_mapping_workflow.wdl`.
> &nbsp;
> For this Challenge, known-good inputs are in the `input_data` folder.  The file `input_data/ENCFF000VOL.fastq.gz` are reads from one replicate of an ENCODE ChIP-seq experiment done on the human A549 cell line and targeting the CEBP transcription factor.  The standard GRCh38 reference used by ENCODE is included in `input_data/reference/ENCFF643CGH_ENCODE_GRCh38_bwa.tar.gz`.  Complete metadata and analysis results from this experiment are accessioned at the ENCODE Portal [under accession number ENCSR000DYI here](https://www.encodeproject.org/experiments/ENCSR000DYI/).  Paths to the input files are specified in the CWL parameter file `encode_mapping_workflow.cwl.json` and the WDL parameter file `encode_mapping_workflow.wdl.json`.  Submissions to the challenge will be scored against known-good outputs of the workflow run on these inputs.  Run time should be less than two hours.  Workflow stages will automatically scale into multiple CPU cores if they are made available to Docker.  The workflow has been tested with 4 GB per core.  Disk requirements are highly-dependent on particular workflow runners and their handling of intermediate files.  In addition to cached Docker layers, CWL runs typically use approximately 3 GB of disk space.  WDL runs with cromwell consume considerably more disk space.
> &nbsp;
> To accelerate deployment and testing the workflow is also packaged with smaller test inputs.  The reads in `input_data/ENCFF000VOL_chr21.fq.gz` are chromosome 21 extracts from the same A549/CEBP experiment as above and the companion reference `input_data/reference/GRCh38_chr21_bwa.tar.gz` is a small chromosome 21-only reference.  Paths to these inputs are in the CWL parameter file `input_data/encode_mapping_workflow.cwl_test.json` and the WDL parameter file `input_data/encode_mapping_workflow.wdl_test.json`.  Using these inputs the workflow takes less than a minute to run, not counting Docker downloads if image layers are not yet cached locally.  Do not submit results from these small test files for the Challenge.  They are only for your use in rapid deployment and testing on new platforms.
> &nbsp;
> Code for this workflow can be found in [the pipeline-container GitHub repo](https://github.com/ENCODE-DCC/pipeline-container).  The full ENCODE ChIP-seq analysis pipeline code is in [the chip-seq-pipeline GitHub repo](https://github.com/ENCODE-DCC/chip-seq-pipeline).  ENCODE Uniform Processing Pipelines are runnable on [DNAnexus](https://www.dnanexus.com/) in the featured DNAnexus project called ""ENCODE Uniform Processing Pipelines"".  More information on using ENCODE pipelines is [here](https://www.encodeproject.org/tutorials/ashg-2016-uniform-processing-pipelines/).  All the data and software products from ENCODE are distributed through the [ENCODE Portal](https://www.encodeproject.org/).

### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""30Gb""
```

#### Workflow history

+ **2017-08-10**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Thomas B. Mooney"" # your name here
institution: ""MGI WUSTL"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> **Note:** Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-27"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170828135420"" # indicate executor version used
docker_version: ""17.06.2-ce"" # from `docker --version`
environment: ""local openstack VM"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""2"" # indicate number of cores in environment
env_memory: ""64 GB"" # indicate available RAM in environment
env_disk: ""160 GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up the environment

Spin up a new OpenStack VM with a Xenial cloud image, then install [docker](https://docs.docker.com/engine/installation/linux/docker-ce/ubuntu/) and  [pyenv](https://github.com/pyenv/pyenv-installer).
Then install the tools to obtain and run the workflows:
```shell
pyenv install 2.7.14
pyenv shell 2.7.14
pip install cwltool
pip install synapseclient
```

Create a directory to hold the results and link in the configuration for connecting to synapse:
```shell
mkdir -p ~/ga4gh/encode_mapping_workflow
cd ~/ga4gh/encode_mapping_workflow
ln -s ~/.synapseConfig .synapseConfig
```

#### 2. Download required files

Download the tool for submitting workflows and the ""encode_mapping_workflow"" workflow data:
```shell
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get -r syn10163025 # encode_mapping_workflow
```

#### 3. Run the main workflow

Run the workflow downloaded in the previous step.
```shell
cwltool --non-strict encode_mapping_workflow.cwl encode_mapping_workflow.cwl.json
```

#### 4. Run workflow checker tool

The workflow stores its outputs in a directory named with a timestamp, so the `validator.json` needs to be edited with this path:
```JSON
{
  ""output_folder"": {
    ""path"": ""9-27-2017T20H30M30S"",
    ""class"": ""Directory""
  }
}
```

Then the checker workflow is run to verify the results:
```shell
cwltool validator.cwl validator.json
```

This produces a report, `results.json`:
```JSON
{
    ""overall"": true,
    ""steps"": {
        ""filtering_step"": {
            ""NRF"": true,
            ""PBC1"": true,
            ""PBC2"": true,
            ""duplicate_fraction"": true,
            ""n_filtered_mapped_reads"": true
        },
        ""mapping_step"": {
            ""crop_length"": true,
            ""paired_end"": true
        },
        ""post_mapping_step"": {
            ""n_mapped_reads"": true
        },
        ""xcor_step"": {
            ""NSC"": true,
            ""RSC"": true,
            ""est_frag_len"": true
        }
    }
}
```

#### 5. Submit workflow outputs

The `encode_mapping_workflow_submit.cwl.json` also needs to be modified to include the correct directory path as in the previous step as well as filling in the submission information:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""MGI WUSTL"",
    ""eval_id"": ""9605639"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""9-27-2017T20H30M30S/mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""9-27-2017T20H30M30S/post_mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""9-27-2017T20H30M30S/filter_qc.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""9-27-2017T20H30M30S/xcor.json""
        }
    ],
    ""parent_id"": ""syn10913435""
}
```

Finally, run the workflow to submit the results:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl encode_mapping_workflow_submit.cwl.json
```
> **Thanks for running the ENCODE ChIP-seq mapping workflow!**  We look forward to learning about how you ran it in your environment.

---",9637953
encode_mapping_workflow,9646108_report.md,"## ENCODE ChIP-seq Mapping Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted files to be viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""J. Seth Strattan, ENCODE Data Coordinating Center""
workflow_handle: ""encode_mapping_workflow""
input_handle: ""A549_CEBP""
```

The following description is provided by the workflow author:
> This workflow is a containerized version of the mapping component from the ENCODE Uniform Analysis Pipeline for ChIP-seq experiments.  The analysis is specified by the ENCODE Data Analysis Center (Zhiping Weng, University of Massachusetts) and ENCODE Analysis Working Group (Anshul Kundaje, Stanford University) and implemented and run by the ENCODE Data Coordinating Center (J. Michael Cherry, Stanford University).
> &nbsp;
> The workflow takes raw reads in the form of a fastq file and a genome reference and generates quality-control (QC) metrics and a filtered bam file suitable for peak calling and signal track generation.  The QC metrics include read depth, library complexity estimates, and scores from cross-correlation analysis.  The workflow is written in both Common Workflow Language (CWL) `encode_mapping_workflow.cwl` and Workflow Description Language (WDL) `encode_mapping_workflow.wdl`.
> &nbsp;
> For this Challenge, known-good inputs are in the `input_data` folder.  The file `input_data/ENCFF000VOL.fastq.gz` are reads from one replicate of an ENCODE ChIP-seq experiment done on the human A549 cell line and targeting the CEBP transcription factor.  The standard GRCh38 reference used by ENCODE is included in `input_data/reference/ENCFF643CGH_ENCODE_GRCh38_bwa.tar.gz`.  Complete metadata and analysis results from this experiment are accessioned at the ENCODE Portal [under accession number ENCSR000DYI here](https://www.encodeproject.org/experiments/ENCSR000DYI/).  Paths to the input files are specified in the CWL parameter file `encode_mapping_workflow.cwl.json` and the WDL parameter file `encode_mapping_workflow.wdl.json`.  Submissions to the challenge will be scored against known-good outputs of the workflow run on these inputs.  Run time should be less than two hours.  Workflow stages will automatically scale into multiple CPU cores if they are made available to Docker.  The workflow has been tested with 4 GB per core.  Disk requirements are highly-dependent on particular workflow runners and their handling of intermediate files.  In addition to cached Docker layers, CWL runs typically use approximately 3 GB of disk space.  WDL runs with cromwell consume considerably more disk space.
> &nbsp;
> To accelerate deployment and testing the workflow is also packaged with smaller test inputs.  The reads in `input_data/ENCFF000VOL_chr21.fq.gz` are chromosome 21 extracts from the same A549/CEBP experiment as above and the companion reference `input_data/reference/GRCh38_chr21_bwa.tar.gz` is a small chromosome 21-only reference.  Paths to these inputs are in the CWL parameter file `input_data/encode_mapping_workflow.cwl_test.json` and the WDL parameter file `input_data/encode_mapping_workflow.wdl_test.json`.  Using these inputs the workflow takes less than a minute to run, not counting Docker downloads if image layers are not yet cached locally.  Do not submit results from these small test files for the Challenge.  They are only for your use in rapid deployment and testing on new platforms.
> &nbsp;
> Code for this workflow can be found in [the pipeline-container GitHub repo](https://github.com/ENCODE-DCC/pipeline-container).  The full ENCODE ChIP-seq analysis pipeline code is in [the chip-seq-pipeline GitHub repo](https://github.com/ENCODE-DCC/chip-seq-pipeline).  ENCODE Uniform Processing Pipelines are runnable on [DNAnexus](https://www.dnanexus.com/) in the featured DNAnexus project called ""ENCODE Uniform Processing Pipelines"".  More information on using ENCODE pipelines is [here](https://www.encodeproject.org/tutorials/ashg-2016-uniform-processing-pipelines/).  All the data and software products from ENCODE are distributed through the [ENCODE Portal](https://www.encodeproject.org/).

### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""30Gb""
```

#### Workflow history

+ **2017-08-10**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Todd Pihl"" # your name here
institution: ""ISB-CGC/CSRA Inc"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> **Note:** Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-10-19"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""cwl"" # CWL or WDL
runner_version: ""1.0.20170217172322"" # indicate executor version used
docker_version: ""17.06.2-ce, build cec0b72"" # from `docker --version`
environment: ""Google Compute"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""35M"" # indicate available RAM in environment
env_disk: ""250G"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.  Here we indicate the CPU's and memory made available _to Docker_ since that represents the maximum resources available to the workflow stages.

```YAML
date_accessed_ex: ""2017-08-16""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce, build 02c1d87""
environment_ex: ""macOS 10.12.6"" 
env_cpus_ex: ""7""
env_memory_ex: ""12Gb""
env_disk_ex: ""1Tb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.
&nbsp;
> **Note:** Steps we followed to run the CWL version of the workflow on Mac OSX are included as an example here.
#### 1. Set up the environment

On a MacBook Pro running macOS 10.12.6 (Sierra) with Docker version 17.06.0-ce, build 02c1d87 installed we added these components:
```shell
pip install --upgrade pip
pip install schema-salad==2.2.20170222151604 cwltool==1.0.20170217172322
pip install synapseclient
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir encode_mapping
cd encode_mapping
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-submit` CWL tool and the files for the encode_chip_mapping_workflow:
```shell
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get -r syn10163025 # recursively downloads encode_chip_mapping_workflow files
```

#### 4. Run the main workflow

I used `cwltool` to run `encode_mapping_workflow.cwl` with parameters in `encode_mapping_workflow.cwl.json`.
```shell
cwltool --non-strict encode_mapping_workflow.cwl encode_mapping_workflow.cwl.json
```
Upon completion, this created a date-stamped folder of outputs.  The folder name was `7-26-2017T2H43M10S/`

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the validator on my output folder.  I first edited the file `validator.json` with the path to the outputs I want to check:
> **Note:** the `path` value here should be the relative or absolute path to the output directory your workflow run generated that contains the files `filter_qc.json`, `mapping.json`, `post_mapping.json`, and `xcor.json`.  Where these outputs are stored will depend on the workflow runner you use.  This example uses `cwltool` which saves outputs to a date-stamped folder.  Do not include a trailing slash in the folder name.
```JSON
{
  ""output_folder"": {
    ""path"": ""7-26-2017T2H43M10S"",
    ""class"": ""Directory""
  }
}
```
I then ran the validator with:
```shell
cwltool validator.cwl validator.json
cat results.json | grep overall
```
The JSON output in `results.json` indicates what outputs were checked against known-good outputs to verify that the run was successful:
```JSON
{
    ""overall"": true,
    ""steps"": {
        ""filtering_step"": {
            ""NRF"": true,
            ""PBC1"": true,
            ""PBC2"": true,
            ""duplicate_fraction"": true,
            ""n_filtered_mapped_reads"": true
        },
        ""mapping_step"": {
            ""crop_length"": true,
            ""paired_end"": true
        },
        ""post_mapping_step"": {
            ""n_mapped_reads"": true
        },
        ""xcor_step"": {
            ""NSC"": true,
            ""RSC"": true,
            ""est_frag_len"": true
        }
    }
}
```

#### 6. Submit workflow outputs

I modified the parameters in `encode_mapping_workflow_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""ENCODE DCC"",
    ""eval_id"": ""9605639"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""7-26-2017T2H43M10S/mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""7-26-2017T2H43M10S/post_mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""7-26-2017T2H43M10S/filter_qc.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""7-26-2017T2H43M10S/xcor.json""
        }
    ],
    ""parent_id"": ""syn10163025""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl encode_mapping_workflow_submit.cwl.json
```
> **Thanks for running the ENCODE ChIP-seq mapping workflow!**  We look forward to learning about how you ran it in your environment.

---",9646108
encode_mapping_workflow,9646314_report.md,"## ENCODE ChIP-seq Mapping Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted files to be viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""J. Seth Strattan, ENCODE Data Coordinating Center""
workflow_handle: ""encode_mapping_workflow""
input_handle: ""A549_CEBP""
```

The following description is provided by the workflow author:
> This workflow is a containerized version of the mapping component from the ENCODE Uniform Analysis Pipeline for ChIP-seq experiments.  The analysis is specified by the ENCODE Data Analysis Center (Zhiping Weng, University of Massachusetts) and ENCODE Analysis Working Group (Anshul Kundaje, Stanford University) and implemented and run by the ENCODE Data Coordinating Center (J. Michael Cherry, Stanford University).
> &nbsp;
> The workflow takes raw reads in the form of a fastq file and a genome reference and generates quality-control (QC) metrics and a filtered bam file suitable for peak calling and signal track generation.  The QC metrics include read depth, library complexity estimates, and scores from cross-correlation analysis.  The workflow is written in both Common Workflow Language (CWL) `encode_mapping_workflow.cwl` and Workflow Description Language (WDL) `encode_mapping_workflow.wdl`.
> &nbsp;
> For this Challenge, known-good inputs are in the `input_data` folder.  The file `input_data/ENCFF000VOL.fastq.gz` are reads from one replicate of an ENCODE ChIP-seq experiment done on the human A549 cell line and targeting the CEBP transcription factor.  The standard GRCh38 reference used by ENCODE is included in `input_data/reference/ENCFF643CGH_ENCODE_GRCh38_bwa.tar.gz`.  Complete metadata and analysis results from this experiment are accessioned at the ENCODE Portal [under accession number ENCSR000DYI here](https://www.encodeproject.org/experiments/ENCSR000DYI/).  Paths to the input files are specified in the CWL parameter file `encode_mapping_workflow.cwl.json` and the WDL parameter file `encode_mapping_workflow.wdl.json`.  Submissions to the challenge will be scored against known-good outputs of the workflow run on these inputs.  Run time should be less than two hours.  Workflow stages will automatically scale into multiple CPU cores if they are made available to Docker.  The workflow has been tested with 4 GB per core.  Disk requirements are highly-dependent on particular workflow runners and their handling of intermediate files.  In addition to cached Docker layers, CWL runs typically use approximately 3 GB of disk space.  WDL runs with cromwell consume considerably more disk space.
> &nbsp;
> To accelerate deployment and testing the workflow is also packaged with smaller test inputs.  The reads in `input_data/ENCFF000VOL_chr21.fq.gz` are chromosome 21 extracts from the same A549/CEBP experiment as above and the companion reference `input_data/reference/GRCh38_chr21_bwa.tar.gz` is a small chromosome 21-only reference.  Paths to these inputs are in the CWL parameter file `input_data/encode_mapping_workflow.cwl_test.json` and the WDL parameter file `input_data/encode_mapping_workflow.wdl_test.json`.  Using these inputs the workflow takes less than a minute to run, not counting Docker downloads if image layers are not yet cached locally.  Do not submit results from these small test files for the Challenge.  They are only for your use in rapid deployment and testing on new platforms.
> &nbsp;
> Code for this workflow can be found in [the pipeline-container GitHub repo](https://github.com/ENCODE-DCC/pipeline-container).  The full ENCODE ChIP-seq analysis pipeline code is in [the chip-seq-pipeline GitHub repo](https://github.com/ENCODE-DCC/chip-seq-pipeline).  ENCODE Uniform Processing Pipelines are runnable on [DNAnexus](https://www.dnanexus.com/) in the featured DNAnexus project called ""ENCODE Uniform Processing Pipelines"".  More information on using ENCODE pipelines is [here](https://www.encodeproject.org/tutorials/ashg-2016-uniform-processing-pipelines/).  All the data and software products from ENCODE are distributed through the [ENCODE Portal](https://www.encodeproject.org/).

### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""30Gb""
```

#### Workflow history

+ **2017-08-10**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Bogdan Gavrilovic"" # your name here
institution: ""Seven Bridges Genomics"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> **Note:** Participants should update these fields to reflect the approach they used.

```YAML
platform: ""SevenBridges"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""latest"" # indicate executor version used
docker_version: ""1.12.6"" # from `docker --version`
environment: ""EC2"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""15Gb"" # indicate available RAM in environment
env_disk: ""1000Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

#####1. [Install rabix](https://github.com/rabix/bunny#installing) on your machine and set environment variable $BUNNY. You need docker and java installed to run rabix:
```shell
wget https://github.com/rabix/bunny/releases/download/v1.0.2/rabix-1.0.2.tar.gz -O rabix-1.0.2.tar.gz && tar -xvf rabix-1.0.2.tar.gz
export BUNNY=$PWD/rabix-cli-1.0.2/rabix
```  

#####2. If you've not already retrieved the CWL and data with synapse-get, you can use the [Synapse python client](https://github.com/Sage-Bionetworks/synapsePythonClient#installation):
```shell
pip install synapseclient
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get -r syn10163025 # recursively downloads encode_chip_mapping_workflow files
```
#### Running on the [Cancer Genomics Cloud](https://cgc.sbgenomics.com/) 

#####3. Log in to the [Cancer Genomics Cloud](https://cgc.sbgenomics.com/) and [create a project](https://docs.cancergenomicscloud.org/docs/create-a-project) 
- Academic Users can create a free account on the Cancer Genomics Cloud (CGC). New users receive \$300 in cloud computing credits that you can apply to this challenge, and your own research. Additionally, users that leave feedback on their experience receive an additional \$1000 in cloud compute credits.
- Commercial users of the Seven Bridges Platform that wish to participate in the DREAM challenge can also create an account on the CGC to participate in this academic exercise and receive free credits to run the challenge workflows. Alternatively, commercial users are free to run DREAM challenge workflows in their commercial platform accounts, but should realize that they will incur cloud compute charges to do so. 
&nbsp;
#####4. Installing the workflow on the platform can be done using:  
**a)** [Rabix Composer app for CWL tool editing](http://rabix.io/) or   
**b)** a [CWL CommandLineTool](https://github.com/bogdang989/Import-CWL-to-SevenBridges) for importing CWL workflows to the Seven Bridges platform.  

#####4a. Rabix Composer
If you’re interested in trying out Seven Bridges’ new integrated development environment for creating CWL descriptions of tools and workflows, you can use the [Rabix Composer](http://rabix.io/) to upload the workflow to the platform. 
Use Rabix Composer to add the workflow to the platform:  
- [Install Rabix Composer](http://docs.rabix.io/rabix-composer-installation)
- [Configure Composer](http://docs.rabix.io/rabix-composer-configuration) to connect to the CGC or Seven Bridges platform
- [Add the project](http://docs.rabix.io/rabix-composer-configuration) you created for the DREAM challenge to the workspace
- [Add the local directory](http://docs.rabix.io/rabix-composer-configuration) containing the workflow to the workspace
- [Open](http://docs.rabix.io/rabix-composer-basics) the workflow with Composer
- [Save the workflow to the Platform project](http://docs.rabix.io/rabix-composer-basics) you added to the workspace
- Log into the Platform and [upload the input files](https://docs.cancergenomicscloud.org/docs/upload-to-the-cgc) to the project. 
- Run the task

> You can [upload the files manually to the platform](https://docs.cancergenomicscloud.org/docs/upload-to-the-cgc) by using either CGC Uploader app, command-line uploader, Python API or some other available upload method... All of the available methods are described in [the documentation](https://docs.cancergenomicscloud.org/docs/upload-to-the-cgc) 

#####4b. CWLtoSBG import tool
Download the CWL importing tool and **place it in the same directory with the CWL workflow** that should be installed on the platform. You can download the tool from [github](https://github.com/bogdang989/Import-CWL-to-SevenBridges) manually or from command-line by typing:
```shell
git clone https://github.com/bogdang989/Import-CWL-to-SevenBridges
```
Modify the `cwl_to_sbg-inputs.yaml` to include:

- Paths to `encode_mapping_workflow.cwl and `encode_mapping_workflow.cwl.json`
- Id of your project on the platform (From project URL, in format *user-name/project-name* )
For example if project URL is https://cgc.sbgenomics.com/u/bogdang/demo-project; project_id is `bogdang/demo-project`
- Your [authentication token](http://docs.sevenbridges.com/docs/get-your-authentication-token)
- Adequate [EC2 instance type](http://www.ec2instances.info/)
&nbsp;
After modifying `cwl_to_sbg-inputs.yaml` with your information, import the workflow to the platform by running
```shell
$BUNNY cwl_to_sbg.cwl cwl_to_sbg-inputs.yaml
```
This will install the workflow and all required apps on the platform. All the files that are required for the task execution are uploaded if they are not uploaded previously. Template draft task is created. If `run_task` is set to `true` the task execution will start on the platform.
You can now open `task` page on the platform project to see task execution details.

### Validating results
[Download the output files](https://docs.cancergenomicscloud.org/docs/download-results) to your local machine.

To verify workflow results before submission, edit the file `validator.json` with the path to the `outputs` folder

```JSON
{
  ""output_folder"": {
    ""path"": ""outputs"",
    ""class"": ""Directory""
  }
}
```
I then ran the validator with:
```shell
$BUNNY validator.cwl validator.json
```
Check results
```shell
cat ./path/to/results.json
``` 
The JSON output in `results.json` indicates what outputs were checked against known-good outputs to verify that the run was successful:
```JSON
{
    ""overall"": true,
    ""steps"": {
        ""filtering_step"": {
            ""NRF"": true,
            ""PBC1"": true,
            ""PBC2"": true,
            ""duplicate_fraction"": true,
            ""n_filtered_mapped_reads"": true
        },
        ""mapping_step"": {
            ""crop_length"": true,
            ""paired_end"": true
        },
        ""post_mapping_step"": {
            ""n_mapped_reads"": true
        },
        ""xcor_step"": {
            ""NSC"": true,
            ""RSC"": true,
            ""est_frag_len"": true
        }
    }
}
```

### Submitting results

- Copy the `synapseConfig` file to the current working directory.
- Update `encode_mapping_workflow_submit.cwl.json` to reflect your 
`team_name` - the name of your team in plain text format (e.g., ""GA4GH-Sage Contenders"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
`file'` - paths to output files
For example:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""ENCODE DCC"",
    ""eval_id"": ""9605639"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""outputs/mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""outputs/post_mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""outputs/filter_qc.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""outputs/xcor.json""
        }
    ],
    ""parent_id"": ""syn10163025""
}
```

Run the tool
```shell
$BUNNY dockstore-tool-synapse-submit.cwl encode_mapping_workflow_submit.cwl.json
```

> **Thanks for running the ENCODE ChIP-seq mapping workflow!**  We look forward to learning about how you ran it in your environment.

---",9646314
encode_mapping_workflow,9646357_report.md,"## ENCODE ChIP-seq Mapping Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted files to be viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""J. Seth Strattan, ENCODE Data Coordinating Center""
workflow_handle: ""encode_mapping_workflow""
input_handle: ""A549_CEBP""
```

The following description is provided by the workflow author:
> This workflow is a containerized version of the mapping component from the ENCODE Uniform Analysis Pipeline for ChIP-seq experiments.  The analysis is specified by the ENCODE Data Analysis Center (Zhiping Weng, University of Massachusetts) and ENCODE Analysis Working Group (Anshul Kundaje, Stanford University) and implemented and run by the ENCODE Data Coordinating Center (J. Michael Cherry, Stanford University).
> &nbsp;
> The workflow takes raw reads in the form of a fastq file and a genome reference and generates quality-control (QC) metrics and a filtered bam file suitable for peak calling and signal track generation.  The QC metrics include read depth, library complexity estimates, and scores from cross-correlation analysis.  The workflow is written in both Common Workflow Language (CWL) `encode_mapping_workflow.cwl` and Workflow Description Language (WDL) `encode_mapping_workflow.wdl`.
> &nbsp;
> For this Challenge, known-good inputs are in the `input_data` folder.  The file `input_data/ENCFF000VOL.fastq.gz` are reads from one replicate of an ENCODE ChIP-seq experiment done on the human A549 cell line and targeting the CEBP transcription factor.  The standard GRCh38 reference used by ENCODE is included in `input_data/reference/ENCFF643CGH_ENCODE_GRCh38_bwa.tar.gz`.  Complete metadata and analysis results from this experiment are accessioned at the ENCODE Portal [under accession number ENCSR000DYI here](https://www.encodeproject.org/experiments/ENCSR000DYI/).  Paths to the input files are specified in the CWL parameter file `encode_mapping_workflow.cwl.json` and the WDL parameter file `encode_mapping_workflow.wdl.json`.  Submissions to the challenge will be scored against known-good outputs of the workflow run on these inputs.  Run time should be less than two hours.  Workflow stages will automatically scale into multiple CPU cores if they are made available to Docker.  The workflow has been tested with 4 GB per core.  Disk requirements are highly-dependent on particular workflow runners and their handling of intermediate files.  In addition to cached Docker layers, CWL runs typically use approximately 3 GB of disk space.  WDL runs with cromwell consume considerably more disk space.
> &nbsp;
> To accelerate deployment and testing the workflow is also packaged with smaller test inputs.  The reads in `input_data/ENCFF000VOL_chr21.fq.gz` are chromosome 21 extracts from the same A549/CEBP experiment as above and the companion reference `input_data/reference/GRCh38_chr21_bwa.tar.gz` is a small chromosome 21-only reference.  Paths to these inputs are in the CWL parameter file `input_data/encode_mapping_workflow.cwl_test.json` and the WDL parameter file `input_data/encode_mapping_workflow.wdl_test.json`.  Using these inputs the workflow takes less than a minute to run, not counting Docker downloads if image layers are not yet cached locally.  Do not submit results from these small test files for the Challenge.  They are only for your use in rapid deployment and testing on new platforms.
> &nbsp;
> Code for this workflow can be found in [the pipeline-container GitHub repo](https://github.com/ENCODE-DCC/pipeline-container).  The full ENCODE ChIP-seq analysis pipeline code is in [the chip-seq-pipeline GitHub repo](https://github.com/ENCODE-DCC/chip-seq-pipeline).  ENCODE Uniform Processing Pipelines are runnable on [DNAnexus](https://www.dnanexus.com/) in the featured DNAnexus project called ""ENCODE Uniform Processing Pipelines"".  More information on using ENCODE pipelines is [here](https://www.encodeproject.org/tutorials/ashg-2016-uniform-processing-pipelines/).  All the data and software products from ENCODE are distributed through the [ENCODE Portal](https://www.encodeproject.org/).

### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""30Gb""
```

#### Workflow history

+ **2017-08-10**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Madelyn Reyes""
institution: ""ISB-CGC/CSRA"" 
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> **Note:** Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""09/28/2017"" 
platform: ""cwltool"" 
workflow_type: ""CWL"" 
runner_version: ""1.0.20170217172322""
docker_version: ""17.09.0-ce, build afdb6d4"" 
environment: ""Google Compute"" 
env_cpus: ""8""
env_memory: ""35GB""
env_disk: ""250 GB"" 
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.  Here we indicate the CPU's and memory made available _to Docker_ since that represents the maximum resources available to the workflow stages.

```YAML
date_accessed_ex: ""2017-08-16""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce, build 02c1d87""
environment_ex: ""macOS 10.12.6"" 
env_cpus_ex: ""7""
env_memory_ex: ""12Gb""
env_disk_ex: ""1Tb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.
&nbsp;
> **Note:** Steps we followed to run the CWL version of the workflow on Mac OSX are included as an example here.
#### 1. Set up the environment

On a MacBook Pro running macOS 10.12.6 (Sierra) with Docker version 17.06.0-ce, build 02c1d87 installed we added these components:
```shell
pip install --upgrade pip
pip install schema-salad==2.2.20170222151604 cwltool==1.0.20170217172322
pip install synapseclient
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir encode_mapping
cd encode_mapping
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-submit` CWL tool and the files for the encode_chip_mapping_workflow:
```shell
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get -r syn10163025 # recursively downloads encode_chip_mapping_workflow files
```

#### 4. Run the main workflow

I used `cwltool` to run `encode_mapping_workflow.cwl` with parameters in `encode_mapping_workflow.cwl.json`.
```shell
cwltool --non-strict encode_mapping_workflow.cwl encode_mapping_workflow.cwl.json
```
Upon completion, this created a date-stamped folder of outputs.  The folder name was `7-26-2017T2H43M10S/`

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the validator on my output folder.  I first edited the file `validator.json` with the path to the outputs I want to check:
> **Note:** the `path` value here should be the relative or absolute path to the output directory your workflow run generated that contains the files `filter_qc.json`, `mapping.json`, `post_mapping.json`, and `xcor.json`.  Where these outputs are stored will depend on the workflow runner you use.  This example uses `cwltool` which saves outputs to a date-stamped folder.  Do not include a trailing slash in the folder name.
```JSON
{
  ""output_folder"": {
    ""path"": ""7-26-2017T2H43M10S"",
    ""class"": ""Directory""
  }
}
```
I then ran the validator with:
```shell
cwltool validator.cwl validator.json
cat results.json | grep overall
```
The JSON output in `results.json` indicates what outputs were checked against known-good outputs to verify that the run was successful:
```JSON
{
    ""overall"": true,
    ""steps"": {
        ""filtering_step"": {
            ""NRF"": true,
            ""PBC1"": true,
            ""PBC2"": true,
            ""duplicate_fraction"": true,
            ""n_filtered_mapped_reads"": true
        },
        ""mapping_step"": {
            ""crop_length"": true,
            ""paired_end"": true
        },
        ""post_mapping_step"": {
            ""n_mapped_reads"": true
        },
        ""xcor_step"": {
            ""NSC"": true,
            ""RSC"": true,
            ""est_frag_len"": true
        }
    }
}
```

#### 6. Submit workflow outputs

I modified the parameters in `encode_mapping_workflow_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""ENCODE DCC"",
    ""eval_id"": ""9605639"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""7-26-2017T2H43M10S/mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""7-26-2017T2H43M10S/post_mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""7-26-2017T2H43M10S/filter_qc.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""7-26-2017T2H43M10S/xcor.json""
        }
    ],
    ""parent_id"": ""syn10163025""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl encode_mapping_workflow_submit.cwl.json
```
> **Thanks for running the ENCODE ChIP-seq mapping workflow!**  We look forward to learning about how you ran it in your environment.

---",9646357
encode_mapping_workflow,9647793_report.md,"## ENCODE ChIP-seq Mapping Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted files to be viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""J. Seth Strattan, ENCODE Data Coordinating Center""
workflow_handle: ""encode_mapping_workflow""
input_handle: ""A549_CEBP""
```

The following description is provided by the workflow author:
> This workflow is a containerized version of the mapping component from the ENCODE Uniform Analysis Pipeline for ChIP-seq experiments.  The analysis is specified by the ENCODE Data Analysis Center (Zhiping Weng, University of Massachusetts) and ENCODE Analysis Working Group (Anshul Kundaje, Stanford University) and implemented and run by the ENCODE Data Coordinating Center (J. Michael Cherry, Stanford University).
> &nbsp;
> The workflow takes raw reads in the form of a fastq file and a genome reference and generates quality-control (QC) metrics and a filtered bam file suitable for peak calling and signal track generation.  The QC metrics include read depth, library complexity estimates, and scores from cross-correlation analysis.  The workflow is written in both Common Workflow Language (CWL) `encode_mapping_workflow.cwl` and Workflow Description Language (WDL) `encode_mapping_workflow.wdl`.
> &nbsp;
> For this Challenge, known-good inputs are in the `input_data` folder.  The file `input_data/ENCFF000VOL.fastq.gz` are reads from one replicate of an ENCODE ChIP-seq experiment done on the human A549 cell line and targeting the CEBP transcription factor.  The standard GRCh38 reference used by ENCODE is included in `input_data/reference/ENCFF643CGH_ENCODE_GRCh38_bwa.tar.gz`.  Complete metadata and analysis results from this experiment are accessioned at the ENCODE Portal [under accession number ENCSR000DYI here](https://www.encodeproject.org/experiments/ENCSR000DYI/).  Paths to the input files are specified in the CWL parameter file `encode_mapping_workflow.cwl.json` and the WDL parameter file `encode_mapping_workflow.wdl.json`.  Submissions to the challenge will be scored against known-good outputs of the workflow run on these inputs.  Run time should be less than two hours.  Workflow stages will automatically scale into multiple CPU cores if they are made available to Docker.  The workflow has been tested with 4 GB per core.  Disk requirements are highly-dependent on particular workflow runners and their handling of intermediate files.  In addition to cached Docker layers, CWL runs typically use approximately 3 GB of disk space.  WDL runs with cromwell consume considerably more disk space.
> &nbsp;
> To accelerate deployment and testing the workflow is also packaged with smaller test inputs.  The reads in `input_data/ENCFF000VOL_chr21.fq.gz` are chromosome 21 extracts from the same A549/CEBP experiment as above and the companion reference `input_data/reference/GRCh38_chr21_bwa.tar.gz` is a small chromosome 21-only reference.  Paths to these inputs are in the CWL parameter file `input_data/encode_mapping_workflow.cwl_test.json` and the WDL parameter file `input_data/encode_mapping_workflow.wdl_test.json`.  Using these inputs the workflow takes less than a minute to run, not counting Docker downloads if image layers are not yet cached locally.  Do not submit results from these small test files for the Challenge.  They are only for your use in rapid deployment and testing on new platforms.
> &nbsp;
> Code for this workflow can be found in [the pipeline-container GitHub repo](https://github.com/ENCODE-DCC/pipeline-container).  The full ENCODE ChIP-seq analysis pipeline code is in [the chip-seq-pipeline GitHub repo](https://github.com/ENCODE-DCC/chip-seq-pipeline).  ENCODE Uniform Processing Pipelines are runnable on [DNAnexus](https://www.dnanexus.com/) in the featured DNAnexus project called ""ENCODE Uniform Processing Pipelines"".  More information on using ENCODE pipelines is [here](https://www.encodeproject.org/tutorials/ashg-2016-uniform-processing-pipelines/).  All the data and software products from ENCODE are distributed through the [ENCODE Portal](https://www.encodeproject.org/).

### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""30Gb""
```

#### Workflow history

+ **2017-08-10**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Joe Slagel"" # your name here
institution: ""Institute for Systems Biology"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> **Note:** Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""10/25/2017"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170822192924"" # indicate executor version used
docker_version: ""Docker version 1.12.6, build 78d1802"" # from `docker --version`
environment: ""Google Compute"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""30 GB"" # indicate available RAM in environment
env_disk: ""250 GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.  Here we indicate the CPU's and memory made available _to Docker_ since that represents the maximum resources available to the workflow stages.

```YAML
date_accessed_ex: ""2017-08-16""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce, build 02c1d87""
environment_ex: ""macOS 10.12.6"" 
env_cpus_ex: ""7""
env_memory_ex: ""12Gb""
env_disk_ex: ""1Tb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.
&nbsp;
> **Note:** Steps we followed to run the CWL version of the workflow on Mac OSX are included as an example here.

Installed synclient via normal instructions, along with docker and the latest version of cwltool.  Than ran the workflow as described in its steps.

---",9647793
encode_mapping_workflow,9653348_report.md,"## ENCODE ChIP-seq Mapping Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted files to be viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""J. Seth Strattan, ENCODE Data Coordinating Center""
workflow_handle: ""encode_mapping_workflow""
input_handle: ""A549_CEBP""
```

The following description is provided by the workflow author:
> This workflow is a containerized version of the mapping component from the ENCODE Uniform Analysis Pipeline for ChIP-seq experiments.  The analysis is specified by the ENCODE Data Analysis Center (Zhiping Weng, University of Massachusetts) and ENCODE Analysis Working Group (Anshul Kundaje, Stanford University) and implemented and run by the ENCODE Data Coordinating Center (J. Michael Cherry, Stanford University).
> &nbsp;
> The workflow takes raw reads in the form of a fastq file and a genome reference and generates quality-control (QC) metrics and a filtered bam file suitable for peak calling and signal track generation.  The QC metrics include read depth, library complexity estimates, and scores from cross-correlation analysis.  The workflow is written in both Common Workflow Language (CWL) `encode_mapping_workflow.cwl` and Workflow Description Language (WDL) `encode_mapping_workflow.wdl`.
> &nbsp;
> For this Challenge, known-good inputs are in the `input_data` folder.  The file `input_data/ENCFF000VOL.fastq.gz` are reads from one replicate of an ENCODE ChIP-seq experiment done on the human A549 cell line and targeting the CEBP transcription factor.  The standard GRCh38 reference used by ENCODE is included in `input_data/reference/ENCFF643CGH_ENCODE_GRCh38_bwa.tar.gz`.  Complete metadata and analysis results from this experiment are accessioned at the ENCODE Portal [under accession number ENCSR000DYI here](https://www.encodeproject.org/experiments/ENCSR000DYI/).  Paths to the input files are specified in the CWL parameter file `encode_mapping_workflow.cwl.json` and the WDL parameter file `encode_mapping_workflow.wdl.json`.  Submissions to the challenge will be scored against known-good outputs of the workflow run on these inputs.  Run time should be less than two hours.  Workflow stages will automatically scale into multiple CPU cores if they are made available to Docker.  The workflow has been tested with 4 GB per core.  Disk requirements are highly-dependent on particular workflow runners and their handling of intermediate files.  In addition to cached Docker layers, CWL runs typically use approximately 3 GB of disk space.  WDL runs with cromwell consume considerably more disk space.
> &nbsp;
> To accelerate deployment and testing the workflow is also packaged with smaller test inputs.  The reads in `input_data/ENCFF000VOL_chr21.fq.gz` are chromosome 21 extracts from the same A549/CEBP experiment as above and the companion reference `input_data/reference/GRCh38_chr21_bwa.tar.gz` is a small chromosome 21-only reference.  Paths to these inputs are in the CWL parameter file `input_data/encode_mapping_workflow.cwl_test.json` and the WDL parameter file `input_data/encode_mapping_workflow.wdl_test.json`.  Using these inputs the workflow takes less than a minute to run, not counting Docker downloads if image layers are not yet cached locally.  Do not submit results from these small test files for the Challenge.  They are only for your use in rapid deployment and testing on new platforms.
> &nbsp;
> Code for this workflow can be found in [the pipeline-container GitHub repo](https://github.com/ENCODE-DCC/pipeline-container).  The full ENCODE ChIP-seq analysis pipeline code is in [the chip-seq-pipeline GitHub repo](https://github.com/ENCODE-DCC/chip-seq-pipeline).  ENCODE Uniform Processing Pipelines are runnable on [DNAnexus](https://www.dnanexus.com/) in the featured DNAnexus project called ""ENCODE Uniform Processing Pipelines"".  More information on using ENCODE pipelines is [here](https://www.encodeproject.org/tutorials/ashg-2016-uniform-processing-pipelines/).  All the data and software products from ENCODE are distributed through the [ENCODE Portal](https://www.encodeproject.org/).

### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""30Gb""
```

#### Workflow history

+ **2017-08-10**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Karl Sebby"" # your name here
institution: ""xD Bio"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> **Note:** Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-11-13"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""cwl"" # CWL or WDL
runner_version: ""cwltool==1.0.20171107133715"" # indicate executor version used
docker_version: ""17.09.0-ce, build afdb6d4"" # from `docker --version`
environment: ""Google Compute"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""54Gb"" # indicate available RAM in environment
env_disk: ""75Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.  Here we indicate the CPU's and memory made available _to Docker_ since that represents the maximum resources available to the workflow stages.

```YAML
date_accessed_ex: ""2017-08-16""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce, build 02c1d87""
environment_ex: ""macOS 10.12.6"" 
env_cpus_ex: ""7""
env_memory_ex: ""12Gb""
env_disk_ex: ""1Tb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.
&nbsp;
**Ran everything as root to make docker happy and not have to keep changing permissions.**

```shell
sudo bash
```
#### 1. Set up the environment

ssh  to google compute engine instance from local machine (linux mint with cinnamon desktop running in virtual box on Macbook pro.)
```shell
screen
ssh `external_ip`
```

On a google instance, install docker, pip3, cwltool (with pip3).
Set up directory structure from ~:
```shell
mkdir -p projects/dreamChallenge/encode_mapping
cd projects/dreamChallenge
```
Create .synapseConfig file and paste in text from synapse website. Change username and password.
```shell 
vi .synapseConfig
```
#### 2. Download required files

Steps completed in the projects/dreamChallenge directory unless specified otherwise.

Use curl to get the dockstore-tool-synapse-get.cwl and dockstore-tool-synapse-submit.cwl:
```shell
curl https://raw.githubusercontent.com/GA4GH-DREAM/dockstore-tool-synapse-get/master/Dockstore.cwl > dockstore-tool-synapse-get.cwl
curl https://raw.githubusercontent.com/GA4GH-DREAM/dockstore-tool-synapse-submit/master/Dockstore.cwl > dockstore-tool-synapse-submit.cwl
```
Downloaded the encode_mapping_workflow_get.cwl.json file to my local machine from synapse website. Opened the file in TextEdit and copied contents. In google compute shell create the encode_mapping_workflow_get.cwl.json file and paste the contents and save:
```shell
vi encode_mapping_workflow_get.cwl.json
```

Get the files:
```shell
cd encode_mapping
cwltool ../dockstore-tool-synapse-get.cwl ../encode_mapping_workflow_get.cwl.json
```

#### 4. Run the main workflow

I used `cwltool` to run `encode_mapping_workflow.cwl` with parameters in `encode_mapping_workflow.cwl.json`.
```shell
cwltool --non-strict encode_mapping_workflow.cwl encode_mapping_workflow.cwl.json
```
Upon completion, this created a date-stamped folder of outputs.  The folder name was `11-13-2017T23H19M03S`

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the validator on my output folder.  I first edited the file `validator.json` with the path to the outputs I want to check:
> **Note:** the `path` value here should be the relative or absolute path to the output directory your workflow run generated that contains the files `filter_qc.json`, `mapping.json`, `post_mapping.json`, and `xcor.json`.  Where these outputs are stored will depend on the workflow runner you use.  This example uses `cwltool` which saves outputs to a date-stamped folder.  Do not include a trailing slash in the folder name.
```JSON
{
  ""output_folder"": {
    ""path"": ""11-13-2017T23H19M03S"",
    ""class"": ""Directory""
  }
}
```
I then ran the validator with:
```shell
cwltool validator.cwl validator.json
cat results.json | grep overall
```
The JSON output in `results.json` indicates what outputs were checked against known-good outputs to verify that the run was successful:
```JSON
{
    ""overall"": true,
    ""steps"": {
        ""filtering_step"": {
            ""NRF"": true,
            ""PBC1"": true,
            ""PBC2"": true,
            ""duplicate_fraction"": true,
            ""n_filtered_mapped_reads"": true
        },
        ""mapping_step"": {
            ""crop_length"": true,
            ""paired_end"": true
        },
        ""post_mapping_step"": {
            ""n_mapped_reads"": true
        },
        ""xcor_step"": {
            ""NSC"": true,
            ""RSC"": true,
            ""est_frag_len"": true
        }
    }
}
```

#### 6. Submit workflow outputs

I modified the parameters in `encode_mapping_workflow_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": ""../.synapseConfig""
    },
    ""team_name"": """",
    ""eval_id"": ""9605639"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""11-13-2017T23H19M03S/mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""11-13-2017T23H19M03S/post_mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""11-13-2017T23H19M03S/filter_qc.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""11-13-2017T23H19M03S/xcor.json""
        }
    ],
    ""parent_id"": ""syn11445483""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool  ../dockstore-tool-synapse-submit.cwl encode_mapping_workflow_submit.cwl.json
```


---",9653348
encode_mapping_workflow,9655148_report.md,"## ENCODE ChIP-seq Mapping Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted files to be viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""J. Seth Strattan, ENCODE Data Coordinating Center""
workflow_handle: ""encode_mapping_workflow""
input_handle: ""A549_CEBP""
```

The following description is provided by the workflow author:
> This workflow is a containerized version of the mapping component from the ENCODE Uniform Analysis Pipeline for ChIP-seq experiments.  The analysis is specified by the ENCODE Data Analysis Center (Zhiping Weng, University of Massachusetts) and ENCODE Analysis Working Group (Anshul Kundaje, Stanford University) and implemented and run by the ENCODE Data Coordinating Center (J. Michael Cherry, Stanford University).
> &nbsp;
> The workflow takes raw reads in the form of a fastq file and a genome reference and generates quality-control (QC) metrics and a filtered bam file suitable for peak calling and signal track generation.  The QC metrics include read depth, library complexity estimates, and scores from cross-correlation analysis.  The workflow is written in both Common Workflow Language (CWL) `encode_mapping_workflow.cwl` and Workflow Description Language (WDL) `encode_mapping_workflow.wdl`.
> &nbsp;
> For this Challenge, known-good inputs are in the `input_data` folder.  The file `input_data/ENCFF000VOL.fastq.gz` are reads from one replicate of an ENCODE ChIP-seq experiment done on the human A549 cell line and targeting the CEBP transcription factor.  The standard GRCh38 reference used by ENCODE is included in `input_data/reference/ENCFF643CGH_ENCODE_GRCh38_bwa.tar.gz`.  Complete metadata and analysis results from this experiment are accessioned at the ENCODE Portal [under accession number ENCSR000DYI here](https://www.encodeproject.org/experiments/ENCSR000DYI/).  Paths to the input files are specified in the CWL parameter file `encode_mapping_workflow.cwl.json` and the WDL parameter file `encode_mapping_workflow.wdl.json`.  Submissions to the challenge will be scored against known-good outputs of the workflow run on these inputs.  Run time should be less than two hours.  Workflow stages will automatically scale into multiple CPU cores if they are made available to Docker.  The workflow has been tested with 4 GB per core.  Disk requirements are highly-dependent on particular workflow runners and their handling of intermediate files.  In addition to cached Docker layers, CWL runs typically use approximately 3 GB of disk space.  WDL runs with cromwell consume considerably more disk space.
> &nbsp;
> To accelerate deployment and testing the workflow is also packaged with smaller test inputs.  The reads in `input_data/ENCFF000VOL_chr21.fq.gz` are chromosome 21 extracts from the same A549/CEBP experiment as above and the companion reference `input_data/reference/GRCh38_chr21_bwa.tar.gz` is a small chromosome 21-only reference.  Paths to these inputs are in the CWL parameter file `input_data/encode_mapping_workflow.cwl_test.json` and the WDL parameter file `input_data/encode_mapping_workflow.wdl_test.json`.  Using these inputs the workflow takes less than a minute to run, not counting Docker downloads if image layers are not yet cached locally.  Do not submit results from these small test files for the Challenge.  They are only for your use in rapid deployment and testing on new platforms.
> &nbsp;
> Code for this workflow can be found in [the pipeline-container GitHub repo](https://github.com/ENCODE-DCC/pipeline-container).  The full ENCODE ChIP-seq analysis pipeline code is in [the chip-seq-pipeline GitHub repo](https://github.com/ENCODE-DCC/chip-seq-pipeline).  ENCODE Uniform Processing Pipelines are runnable on [DNAnexus](https://www.dnanexus.com/) in the featured DNAnexus project called ""ENCODE Uniform Processing Pipelines"".  More information on using ENCODE pipelines is [here](https://www.encodeproject.org/tutorials/ashg-2016-uniform-processing-pipelines/).  All the data and software products from ENCODE are distributed through the [ENCODE Portal](https://www.encodeproject.org/).

### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""30Gb""
```

#### Workflow history

+ **2017-08-10**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Jim Vlasblom"" # your name here
institution: ""DNAstack"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> **Note:** Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-11-23"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""DNAstack/cromwell"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""WDL"" # CWL or WDL
runner_version: ""28"" # indicate executor version used
docker_version: ""Provided by v1alpha2 of Google Genomics Pipelines"" # from `docker --version`
environment: ""Google Compute"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""2"" # indicate number of cores in environment
env_memory: ""17.1 GB"" # indicate available RAM in environment
env_disk: ""420"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.  Here we indicate the CPU's and memory made available _to Docker_ since that represents the maximum resources available to the workflow stages.

```YAML
date_accessed_ex: ""2017-08-16""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce, build 02c1d87""
environment_ex: ""macOS 10.12.6"" 
env_cpus_ex: ""7""
env_memory_ex: ""12Gb""
env_disk_ex: ""1Tb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.
&nbsp;
> **Note:** Steps we followed to run the CWL version of the workflow on Mac OSX are included as an example here.
#### 1. Set up the environment

On a local or remote compute instance (I used a Google compute engine instance) with python/pip and docker installed:
```shell
pip install --upgrade pip
pip install schema-salad==2.2.20170222151604 cwltool==1.0.20170217172322
pip install synapseclient
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir encode_mapping
cd encode_mapping
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-submit` CWL tool and the files for the encode_chip_mapping_workflow:
```shell
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get -r syn10163025 # recursively downloads encode_chip_mapping_workflow files
```

Next, I fixed the Docker images referenced by the encode_mapping_workflow.wdl by noting which images were referenced, and creating a new image from each of those images with the entrypoint cleared:
```shell
cat encode_mapping_workflow.wdl | grep docker
```
For each image of the form quay.io/encode-dcc/<image>:v1.0,  I created a corresponding subdirectory <image>, and within that directory I created a Dockerfile with the contents:
```
FROM quay.io/encode-dcc/<image>:v1.0
ENTRYPOINT []
```
I ended up with four subdirectories:
```
.:
filter  mapping  post_processing  xcor

./filter:
Dockerfile  foo.txt

./mapping:
Dockerfile

./post_processing:
Dockerfile

./xcor:
Dockerfile
```

I entered each of these directories in turn and built and tagged the modified images, and pushed them to my quay.io repository:
```shell
docker build -t quay.io/jnvlasblom/<image>:v1.0 .
docker push quay.io/jnvlasblom/<image>:v1.0
```

This change was necessary because the current version of Google pipelines doesn't work well with entrypoints.  One consequence of this is that Cromwell cannot execute the encode mapping WDL with the default docker image using on Google JES (Pipelines), although it can execute it properly locally.   See also the discussion on the [encode synapse message forum](https://www.synapse.org/#!Synapse:syn8507133/discussion/threadId=2313)

#### 4. Run the main workflow
##### DNAstack Project Configuration
- Visit https://dnastack.com
- Click 'Sign in'
- Click 'Sign up' and register a new account
- Click 'Create a new organization'.  Entered 'DNAstack DREAM Challenges'.
- Click 'Create' beside projects to create a new project.  Entered 'Phase 2'.  Under Billing, selected 'Free Trial'.

##### Create and execute workflow in DNAstack
- Click 'Workflows', then 'Create Workflow', then 'Import from Dockstore'.
- Type 'encode'.  Choose 'ENCODE-DCC/pipeline-container/encode-mapping-wdl', and select Version 'master' from the dropdown.
- Click 'import'.
- On Workflow run page, click 'Edit' tab, then change references to quay.io/encode-dcc/* to quay.io/jnvlasblom/*, and click save.
- On run tab, fill out the inputs.  The trimming_parameter was set to native, and the file inputs were set by clicking choose files beside the corresponding input, and clicking '+ choose files' to select files from your local instance.  Choose ENCFF000VOL.fastq.gz for 'fastqs', and 'ENCFF643CGH_ENCODE_GRCh38_bwa.tar.gz for 'reference'.  (Since i used a remote compute engine instance, I had to copy them to my laptop first from the encode_mapping/inputs directory)
- After selecting the input, click 'run', and then select the 'workflow job' link.
- When job is done, click 'outputs' tab and download the outputs to /path/to/encode_mapping/outputs/  (since I used a remote compute engine instance, I saved the outputs to my laptop and copied them to the remote instance)

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the validator on my output folder.  I first edited the file `validator.json` with the path to the outputs I want to check:
> **Note:** the `path` value here should be the relative or absolute path to the output directory your workflow run generated that contains the files `filter_qc.json`, `mapping.json`, `post_mapping.json`, and `xcor.json`.  Where these outputs are stored will depend on the workflow runner you use.  This example uses `cwltool` which saves outputs to a date-stamped folder.  Do not include a trailing slash in the folder name.
```JSON
{
  ""output_folder"": {
    ""path"": ""outputs"",
    ""class"": ""Directory""
  }
}
```
I then ran the validator with:
```shell
cwltool validator.cwl validator.json
cat results.json | grep overall
```
The JSON output in `results.json` indicates what outputs were checked against known-good outputs to verify that the run was successful:
```JSON
{
    ""overall"": true,
    ""steps"": {
        ""filtering_step"": {
            ""NRF"": true,
            ""PBC1"": true,
            ""PBC2"": true,
            ""duplicate_fraction"": true,
            ""n_filtered_mapped_reads"": true
        },
        ""mapping_step"": {
            ""crop_length"": true,
            ""paired_end"": true
        },
        ""post_mapping_step"": {
            ""n_mapped_reads"": true
        },
        ""xcor_step"": {
            ""NSC"": true,
            ""RSC"": true,
            ""est_frag_len"": true
        }
    }
}
```

#### 6. Submit workflow outputs

I modified the parameters in `encode_mapping_workflow_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""DNAstack"",
    ""eval_id"": ""9605639"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""outputs/mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""outputs/post_mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""outputs/filter_qc.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""outputs/xcor.json""
        }
    ],
    ""parent_id"": ""syn11503388""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl encode_mapping_workflow_submit.cwl.json
```
> **Thanks for running the ENCODE ChIP-seq mapping workflow!**  We look forward to learning about how you ran it in your environment.

---",9655148
encode_mapping_workflow,9655828_report.md,"## ENCODE ChIP-seq Mapping Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted files to be viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""J. Seth Strattan, ENCODE Data Coordinating Center""
workflow_handle: ""encode_mapping_workflow""
input_handle: ""A549_CEBP""
```

The following description is provided by the workflow author:
> This workflow is a containerized version of the mapping component from the ENCODE Uniform Analysis Pipeline for ChIP-seq experiments.  The analysis is specified by the ENCODE Data Analysis Center (Zhiping Weng, University of Massachusetts) and ENCODE Analysis Working Group (Anshul Kundaje, Stanford University) and implemented and run by the ENCODE Data Coordinating Center (J. Michael Cherry, Stanford University).
> &nbsp;
> The workflow takes raw reads in the form of a fastq file and a genome reference and generates quality-control (QC) metrics and a filtered bam file suitable for peak calling and signal track generation.  The QC metrics include read depth, library complexity estimates, and scores from cross-correlation analysis.  The workflow is written in both Common Workflow Language (CWL) `encode_mapping_workflow.cwl` and Workflow Description Language (WDL) `encode_mapping_workflow.wdl`.
> &nbsp;
> For this Challenge, known-good inputs are in the `input_data` folder.  The file `input_data/ENCFF000VOL.fastq.gz` are reads from one replicate of an ENCODE ChIP-seq experiment done on the human A549 cell line and targeting the CEBP transcription factor.  The standard GRCh38 reference used by ENCODE is included in `input_data/reference/ENCFF643CGH_ENCODE_GRCh38_bwa.tar.gz`.  Complete metadata and analysis results from this experiment are accessioned at the ENCODE Portal [under accession number ENCSR000DYI here](https://www.encodeproject.org/experiments/ENCSR000DYI/).  Paths to the input files are specified in the CWL parameter file `encode_mapping_workflow.cwl.json` and the WDL parameter file `encode_mapping_workflow.wdl.json`.  Submissions to the challenge will be scored against known-good outputs of the workflow run on these inputs.  Run time should be less than two hours.  Workflow stages will automatically scale into multiple CPU cores if they are made available to Docker.  The workflow has been tested with 4 GB per core.  Disk requirements are highly-dependent on particular workflow runners and their handling of intermediate files.  In addition to cached Docker layers, CWL runs typically use approximately 3 GB of disk space.  WDL runs with cromwell consume considerably more disk space.
> &nbsp;
> To accelerate deployment and testing the workflow is also packaged with smaller test inputs.  The reads in `input_data/ENCFF000VOL_chr21.fq.gz` are chromosome 21 extracts from the same A549/CEBP experiment as above and the companion reference `input_data/reference/GRCh38_chr21_bwa.tar.gz` is a small chromosome 21-only reference.  Paths to these inputs are in the CWL parameter file `input_data/encode_mapping_workflow.cwl_test.json` and the WDL parameter file `input_data/encode_mapping_workflow.wdl_test.json`.  Using these inputs the workflow takes less than a minute to run, not counting Docker downloads if image layers are not yet cached locally.  Do not submit results from these small test files for the Challenge.  They are only for your use in rapid deployment and testing on new platforms.
> &nbsp;
> Code for this workflow can be found in [the pipeline-container GitHub repo](https://github.com/ENCODE-DCC/pipeline-container).  The full ENCODE ChIP-seq analysis pipeline code is in [the chip-seq-pipeline GitHub repo](https://github.com/ENCODE-DCC/chip-seq-pipeline).  ENCODE Uniform Processing Pipelines are runnable on [DNAnexus](https://www.dnanexus.com/) in the featured DNAnexus project called ""ENCODE Uniform Processing Pipelines"".  More information on using ENCODE pipelines is [here](https://www.encodeproject.org/tutorials/ashg-2016-uniform-processing-pipelines/).  All the data and software products from ENCODE are distributed through the [ENCODE Portal](https://www.encodeproject.org/).

### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""30Gb""
```

#### Workflow history

+ **2017-08-10**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Joe Slagel"" # your name here
institution: ""ISB"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> **Note:** Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-11-28"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""ISB-CGC dsub/cwltool/cwl_runner.sh"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""cwltool-1.0.20171107133715"" # indicate executor version used
docker_version: ""17.11.0"" # from `docker --version`
environment: ""Google Compute"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""30"" # indicate available RAM in environment
env_disk: ""200"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

I was curious as to how much of the challenge I could do using only dsub and cwl_runner.sh.  On a personal Google Cloud VM with gcloud, gsutil, dsub and cwl_runner.sh installed I:

#### 1. Set up the environment

```shell
gsutil cp ~/.synapseConfig gs://isb-ga4gh-dream/encode_mapping_workflow/data/.synapseConfig
dsub \
   --name dream-setup-encode_mapping_workflow \
   --project cgc-05-0026 \
   --zones 'us-*' \
   --image quay.io/ga4gh-dream/dockstore-tool-synapse-get \
   --input  'CFG=gs://isb-ga4gh-dream/encode_mapping_workflow/data/.synapseConfig' \
   --output-recursive 'OUT=gs://isb-ga4gh-dream/encode_mapping_workflow/data/' \
   --logging 'gs://isb-ga4gh-dream/encode_mapping_workflow/log' \
   --wait \
   --command 'cd ${OUT}; \
              synapse -c ${CFG} get syn9770802; \
              synapse -c ${CFG} get syn9732885; \
              synapse -c ${CFG} get -r syn10163025; \
             '
```

#### 2. Provision all workflow files

Nothing to do.

#### 3. Run the main workflow

```shell
cwltool --non-strict encode_mapping_workflow.cwl encode_mapping_workflow.cwl.json
```
Upon completion, this created a date-stamped folder of outputs.  The folder name was `12-2-2017T2H28M52S`

#### 4. Run workflow checker tool

```shell
gsutil cat gs://isb-ga4gh-dream/encode_mapping_workflow/data/validator.json \
   | sed 's/7-26-2017T2H43M10S/12-2-2017T2H28M52S/' \
   | gsutil cp - gs://isb-ga4gh-dream/encode_mapping_workflow/data/validator.json
./cwl_runner.sh \
   -m n1-standard-2 \
   -r gs://isb-ga4gh-dream/encode_mapping_workflow/data/ \
   -w gs://isb-ga4gh-dream/encode_mapping_workflow/data/validator.cwl \
   -s gs://isb-ga4gh-dream/encode_mapping_workflow/data/validator.json \
   -o gs://isb-ga4gh-dream/encode_mapping_workflow/data
```

#### 5. Submit workflow outputs

```shell
gsutil cat gs://isb-ga4gh-dream/encode_mapping_workflow/data/encode_mapping_workflow_submit.cwl.json \
   | jq '.team_name=""ISB-CGC"" | .parent_id=""syn11413161""' \
   | gsutil cp - gs://isb-ga4gh-dream/encode_mapping_workflow/data/encode_mapping_workflow_submit.cwl.json
./cwl_runner.sh \
   -m n1-standard-2 \
   -r gs://isb-ga4gh-dream/encode_mapping_workflow/data/ \
   -w gs://isb-ga4gh-dream/encode_mapping_workflow/data/dockstore-tool-synapse-submit.cwl \
   -s gs://isb-ga4gh-dream/encode_mapping_workflow/data/encode_mapping_workflow_submit.cwl.json \
   -o gs://isb-ga4gh-dream/encode_mapping_workflow/data
```

---",9655828
encode_mapping_workflow,9656007_report.md,"## ENCODE ChIP-seq Mapping Workflow

Arvados container record https://cloud.curoverse.com/container_requests/qr1hi-xvhdp-6qud0jj07rdnvx6

### Workflow description

```YAML
contributor: ""J. Seth Strattan, ENCODE Data Coordinating Center""
workflow_handle: ""encode_mapping_workflow""
input_handle: ""A549_CEBP""
```

The following description is provided by the workflow author:
> This workflow is a containerized version of the mapping component from the ENCODE Uniform Analysis Pipeline for ChIP-seq experiments.  The analysis is specified by the ENCODE Data Analysis Center (Zhiping Weng, University of Massachusetts) and ENCODE Analysis Working Group (Anshul Kundaje, Stanford University) and implemented and run by the ENCODE Data Coordinating Center (J. Michael Cherry, Stanford University).
> &nbsp;
> The workflow takes raw reads in the form of a fastq file and a genome reference and generates quality-control (QC) metrics and a filtered bam file suitable for peak calling and signal track generation.  The QC metrics include read depth, library complexity estimates, and scores from cross-correlation analysis.  The workflow is written in both Common Workflow Language (CWL) `encode_mapping_workflow.cwl` and Workflow Description Language (WDL) `encode_mapping_workflow.wdl`.
> &nbsp;
> For this Challenge, known-good inputs are in the `input_data` folder.  The file `input_data/ENCFF000VOL.fastq.gz` are reads from one replicate of an ENCODE ChIP-seq experiment done on the human A549 cell line and targeting the CEBP transcription factor.  The standard GRCh38 reference used by ENCODE is included in `input_data/reference/ENCFF643CGH_ENCODE_GRCh38_bwa.tar.gz`.  Complete metadata and analysis results from this experiment are accessioned at the ENCODE Portal [under accession number ENCSR000DYI here](https://www.encodeproject.org/experiments/ENCSR000DYI/).  Paths to the input files are specified in the CWL parameter file `encode_mapping_workflow.cwl.json` and the WDL parameter file `encode_mapping_workflow.wdl.json`.  Submissions to the challenge will be scored against known-good outputs of the workflow run on these inputs.  Run time should be less than two hours.  Workflow stages will automatically scale into multiple CPU cores if they are made available to Docker.  The workflow has been tested with 4 GB per core.  Disk requirements are highly-dependent on particular workflow runners and their handling of intermediate files.  In addition to cached Docker layers, CWL runs typically use approximately 3 GB of disk space.  WDL runs with cromwell consume considerably more disk space.
> &nbsp;
> To accelerate deployment and testing the workflow is also packaged with smaller test inputs.  The reads in `input_data/ENCFF000VOL_chr21.fq.gz` are chromosome 21 extracts from the same A549/CEBP experiment as above and the companion reference `input_data/reference/GRCh38_chr21_bwa.tar.gz` is a small chromosome 21-only reference.  Paths to these inputs are in the CWL parameter file `input_data/encode_mapping_workflow.cwl_test.json` and the WDL parameter file `input_data/encode_mapping_workflow.wdl_test.json`.  Using these inputs the workflow takes less than a minute to run, not counting Docker downloads if image layers are not yet cached locally.  Do not submit results from these small test files for the Challenge.  They are only for your use in rapid deployment and testing on new platforms.
> &nbsp;
> Code for this workflow can be found in [the pipeline-container GitHub repo](https://github.com/ENCODE-DCC/pipeline-container).  The full ENCODE ChIP-seq analysis pipeline code is in [the chip-seq-pipeline GitHub repo](https://github.com/ENCODE-DCC/chip-seq-pipeline).  ENCODE Uniform Processing Pipelines are runnable on [DNAnexus](https://www.dnanexus.com/) in the featured DNAnexus project called ""ENCODE Uniform Processing Pipelines"".  More information on using ENCODE pipelines is [here](https://www.encodeproject.org/tutorials/ashg-2016-uniform-processing-pipelines/).  All the data and software products from ENCODE are distributed through the [ENCODE Portal](https://www.encodeproject.org/).

### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""30Gb""
```

#### Workflow history

+ **2017-08-10**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Peter Amstutz"" # your name here
institution: ""Veritas Genetics"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> **Note:** Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-13"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""Arvados"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""arvados-cwl-runner 0d06a2984420d9d48e16ccb6d85982b3dce05644 1.0.20171127193714, arvados-python-client 0.1.20171010180436, cwltool 1.0.20171205195520"" # indicate executor version used
docker_version: ""Docker version 17.05.0-ce, build 89658be"" # from `docker --version`
environment: ""Azure"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""1"" # indicate number of cores in environment
env_memory: ""3.5 GB"" # indicate available RAM in environment
env_disk: ""100 GB"" # indicate available disk space, or note ""elastic"" for EFS et al.

```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.  Here we indicate the CPU's and memory made available _to Docker_ since that represents the maximum resources available to the workflow stages.

```YAML
date_accessed_ex: ""2017-08-16""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce, build 02c1d87""
environment_ex: ""macOS 10.12.6"" 
env_cpus_ex: ""7""
env_memory_ex: ""12Gb""
env_disk_ex: ""1Tb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.
&nbsp;

#### 1. Set up the environment

```shell
virtualenv venv
. venv/bin/activate
pip install synapseclient arvados-cwl-runner
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir encode_mapping
cd encode_mapping
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-submit` CWL tool and the files for the encode_chip_mapping_workflow:
```shell
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get -r syn10163025 # recursively downloads encode_chip_mapping_workflow files
```

#### 4. Run the main workflow

I used `arvados-cwl-runner` to run `encode_mapping_workflow.cwl` with parameters in `encode_mapping_workflow.cwl.json`.

Note: the original workflow requested 1 TB of disk.  I reduced it to 100 GB, because our cloud compute nodes do not provide 1 TB of scratch space.

```shell
arvados-cwl-runner --api=containers encode_mapping_workflow.cwl encode_mapping_workflow.cwl.json
```
Upon completion, this created a date-stamped folder of outputs.  The folder name was `7-26-2017T2H43M10S/`

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the validator on my output folder.  I first edited the file `validator.json` with the path to the outputs I want to check:
> **Note:** the `path` value here should be the relative or absolute path to the output directory your workflow run generated that contains the files `filter_qc.json`, `mapping.json`, `post_mapping.json`, and `xcor.json`.  Where these outputs are stored will depend on the workflow runner you use.  This example uses `cwltool` which saves outputs to a date-stamped folder.  Do not include a trailing slash in the folder name.
```JSON
{
  ""output_folder"": {
    ""path"": ""keep/by_id/557cb11c78f55178cb5d5ba0495c2880+2892/12-6-2017T16H30M05S"",
    ""class"": ""Directory""
  }
}
```
I then ran the validator with:
```shell
cwltool validator.cwl validator.json
cat results.json | grep overall
```
The JSON output in `results.json` indicates what outputs were checked against known-good outputs to verify that the run was successful:
```JSON
{
    ""overall"": true,
    ""steps"": {
        ""filtering_step"": {
            ""NRF"": true,
            ""PBC1"": true,
            ""PBC2"": true,
            ""duplicate_fraction"": true,
            ""n_filtered_mapped_reads"": true
        },
        ""mapping_step"": {
            ""crop_length"": true,
            ""paired_end"": true
        },
        ""post_mapping_step"": {
            ""n_mapped_reads"": true
        },
        ""xcor_step"": {
            ""NSC"": true,
            ""RSC"": true,
            ""est_frag_len"": true
        }
    }
}
```

#### 6. Submit workflow outputs

I modified the parameters in `encode_mapping_workflow_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""ENCODE DCC"",
    ""eval_id"": ""9605639"",
    ""file"": [
         {
          ""class"": ""File"",
          ""path"": ""keep/by_id/557cb11c78f55178cb5d5ba0495c2880+2892/12-6-2017T16H30M05S/mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""keep/by_id/557cb11c78f55178cb5d5ba0495c2880+2892/12-6-2017T16H30M05S/post_mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""keep/by_id/557cb11c78f55178cb5d5ba0495c2880+2892/12-6-2017T16H30M05S/filter_qc.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""keep/by_id/557cb11c78f55178cb5d5ba0495c2880+2892/12-6-2017T16H30M05S/xcor.json""
        }
    ],
    ""parent_id"": ""syn11579781""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl encode_mapping_workflow_submit.cwl.json
```
> **Thanks for running the ENCODE ChIP-seq mapping workflow!**  We look forward to learning about how you ran it in your environment.

---",9656007
encode_mapping_workflow,9657194_report.md,"## ENCODE ChIP-seq Mapping Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted files to be viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""J. Seth Strattan, ENCODE Data Coordinating Center""
workflow_handle: ""encode_mapping_workflow""
input_handle: ""A549_CEBP""
```

The following description is provided by the workflow author:
> This workflow is a containerized version of the mapping component from the ENCODE Uniform Analysis Pipeline for ChIP-seq experiments.  The analysis is specified by the ENCODE Data Analysis Center (Zhiping Weng, University of Massachusetts) and ENCODE Analysis Working Group (Anshul Kundaje, Stanford University) and implemented and run by the ENCODE Data Coordinating Center (J. Michael Cherry, Stanford University).
> &nbsp;
> The workflow takes raw reads in the form of a fastq file and a genome reference and generates quality-control (QC) metrics and a filtered bam file suitable for peak calling and signal track generation.  The QC metrics include read depth, library complexity estimates, and scores from cross-correlation analysis.  The workflow is written in both Common Workflow Language (CWL) `encode_mapping_workflow.cwl` and Workflow Description Language (WDL) `encode_mapping_workflow.wdl`.
> &nbsp;
> For this Challenge, known-good inputs are in the `input_data` folder.  The file `input_data/ENCFF000VOL.fastq.gz` are reads from one replicate of an ENCODE ChIP-seq experiment done on the human A549 cell line and targeting the CEBP transcription factor.  The standard GRCh38 reference used by ENCODE is included in `input_data/reference/ENCFF643CGH_ENCODE_GRCh38_bwa.tar.gz`.  Complete metadata and analysis results from this experiment are accessioned at the ENCODE Portal [under accession number ENCSR000DYI here](https://www.encodeproject.org/experiments/ENCSR000DYI/).  Paths to the input files are specified in the CWL parameter file `encode_mapping_workflow.cwl.json` and the WDL parameter file `encode_mapping_workflow.wdl.json`.  Submissions to the challenge will be scored against known-good outputs of the workflow run on these inputs.  Run time should be less than two hours.  Workflow stages will automatically scale into multiple CPU cores if they are made available to Docker.  The workflow has been tested with 4 GB per core.  Disk requirements are highly-dependent on particular workflow runners and their handling of intermediate files.  In addition to cached Docker layers, CWL runs typically use approximately 3 GB of disk space.  WDL runs with cromwell consume considerably more disk space.
> &nbsp;
> To accelerate deployment and testing the workflow is also packaged with smaller test inputs.  The reads in `input_data/ENCFF000VOL_chr21.fq.gz` are chromosome 21 extracts from the same A549/CEBP experiment as above and the companion reference `input_data/reference/GRCh38_chr21_bwa.tar.gz` is a small chromosome 21-only reference.  Paths to these inputs are in the CWL parameter file `input_data/encode_mapping_workflow.cwl_test.json` and the WDL parameter file `input_data/encode_mapping_workflow.wdl_test.json`.  Using these inputs the workflow takes less than a minute to run, not counting Docker downloads if image layers are not yet cached locally.  Do not submit results from these small test files for the Challenge.  They are only for your use in rapid deployment and testing on new platforms.
> &nbsp;
> Code for this workflow can be found in [the pipeline-container GitHub repo](https://github.com/ENCODE-DCC/pipeline-container).  The full ENCODE ChIP-seq analysis pipeline code is in [the chip-seq-pipeline GitHub repo](https://github.com/ENCODE-DCC/chip-seq-pipeline).  ENCODE Uniform Processing Pipelines are runnable on [DNAnexus](https://www.dnanexus.com/) in the featured DNAnexus project called ""ENCODE Uniform Processing Pipelines"".  More information on using ENCODE pipelines is [here](https://www.encodeproject.org/tutorials/ashg-2016-uniform-processing-pipelines/).  All the data and software products from ENCODE are distributed through the [ENCODE Portal](https://www.encodeproject.org/).

### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""30Gb""
```

#### Workflow history

+ **2017-08-10**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Abhishek Niroula"" # your name here
institution: ""LU"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> **Note:** Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-12-18"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170828135420"" # indicate executor version used
docker_version: ""17.06.1-ce, build 874a737"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""32Gb"" # indicate available RAM in environment
env_disk: ""2Tb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.  Here we indicate the CPU's and memory made available _to Docker_ since that represents the maximum resources available to the workflow stages.

```YAML
date_accessed_ex: ""2017-08-16""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce, build 02c1d87""
environment_ex: ""macOS 10.12.6"" 
env_cpus_ex: ""7""
env_memory_ex: ""12Gb""
env_disk_ex: ""1Tb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.
&nbsp;
> **Note:** Steps we followed to run the CWL version of the workflow on Mac OSX are included as an example here.
#### 1. Set up the environment

On a MacBook Pro running macOS 10.12.6 (Sierra) with Docker version 17.06.0-ce, build 02c1d87 installed we added these components:
```shell
pip install --upgrade pip
pip install schema-salad==2.2.20170222151604 cwltool==1.0.20170217172322
pip install synapseclient
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir encode_mapping
cd encode_mapping
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-submit` CWL tool and the files for the encode_chip_mapping_workflow:
```shell
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get -r syn10163025 # recursively downloads encode_chip_mapping_workflow files
```

#### 4. Run the main workflow

I used `cwltool` to run `encode_mapping_workflow.cwl` with parameters in `encode_mapping_workflow.cwl.json`.
```shell
cwltool --non-strict encode_mapping_workflow.cwl encode_mapping_workflow.cwl.json
```
Upon completion, this created a date-stamped folder of outputs.  The folder name was `7-26-2017T2H43M10S/`

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the validator on my output folder.  I first edited the file `validator.json` with the path to the outputs I want to check:
> **Note:** the `path` value here should be the relative or absolute path to the output directory your workflow run generated that contains the files `filter_qc.json`, `mapping.json`, `post_mapping.json`, and `xcor.json`.  Where these outputs are stored will depend on the workflow runner you use.  This example uses `cwltool` which saves outputs to a date-stamped folder.  Do not include a trailing slash in the folder name.
```JSON
{
  ""output_folder"": {
    ""path"": ""7-26-2017T2H43M10S"",
    ""class"": ""Directory""
  }
}
```
I then ran the validator with:
```shell
cwltool validator.cwl validator.json
cat results.json | grep overall
```
The JSON output in `results.json` indicates what outputs were checked against known-good outputs to verify that the run was successful:
```JSON
{
    ""overall"": true,
    ""steps"": {
        ""filtering_step"": {
            ""NRF"": true,
            ""PBC1"": true,
            ""PBC2"": true,
            ""duplicate_fraction"": true,
            ""n_filtered_mapped_reads"": true
        },
        ""mapping_step"": {
            ""crop_length"": true,
            ""paired_end"": true
        },
        ""post_mapping_step"": {
            ""n_mapped_reads"": true
        },
        ""xcor_step"": {
            ""NSC"": true,
            ""RSC"": true,
            ""est_frag_len"": true
        }
    }
}
```

#### 6. Submit workflow outputs

I modified the parameters in `encode_mapping_workflow_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""ENCODE DCC"",
    ""eval_id"": ""9605639"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""7-26-2017T2H43M10S/mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""7-26-2017T2H43M10S/post_mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""7-26-2017T2H43M10S/filter_qc.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""7-26-2017T2H43M10S/xcor.json""
        }
    ],
    ""parent_id"": ""syn10163025""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl encode_mapping_workflow_submit.cwl.json
```
> **Thanks for running the ENCODE ChIP-seq mapping workflow!**  We look forward to learning about how you ran it in your environment.

---",9657194
encode_mapping_workflow,9657197_report.md,"## ENCODE ChIP-seq Mapping Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted files to be viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""J. Seth Strattan, ENCODE Data Coordinating Center""
workflow_handle: ""encode_mapping_workflow""
input_handle: ""A549_CEBP""
```

The following description is provided by the workflow author:
> This workflow is a containerized version of the mapping component from the ENCODE Uniform Analysis Pipeline for ChIP-seq experiments.  The analysis is specified by the ENCODE Data Analysis Center (Zhiping Weng, University of Massachusetts) and ENCODE Analysis Working Group (Anshul Kundaje, Stanford University) and implemented and run by the ENCODE Data Coordinating Center (J. Michael Cherry, Stanford University).
> &nbsp;
> The workflow takes raw reads in the form of a fastq file and a genome reference and generates quality-control (QC) metrics and a filtered bam file suitable for peak calling and signal track generation.  The QC metrics include read depth, library complexity estimates, and scores from cross-correlation analysis.  The workflow is written in both Common Workflow Language (CWL) `encode_mapping_workflow.cwl` and Workflow Description Language (WDL) `encode_mapping_workflow.wdl`.
> &nbsp;
> For this Challenge, known-good inputs are in the `input_data` folder.  The file `input_data/ENCFF000VOL.fastq.gz` are reads from one replicate of an ENCODE ChIP-seq experiment done on the human A549 cell line and targeting the CEBP transcription factor.  The standard GRCh38 reference used by ENCODE is included in `input_data/reference/ENCFF643CGH_ENCODE_GRCh38_bwa.tar.gz`.  Complete metadata and analysis results from this experiment are accessioned at the ENCODE Portal [under accession number ENCSR000DYI here](https://www.encodeproject.org/experiments/ENCSR000DYI/).  Paths to the input files are specified in the CWL parameter file `encode_mapping_workflow.cwl.json` and the WDL parameter file `encode_mapping_workflow.wdl.json`.  Submissions to the challenge will be scored against known-good outputs of the workflow run on these inputs.  Run time should be less than two hours.  Workflow stages will automatically scale into multiple CPU cores if they are made available to Docker.  The workflow has been tested with 4 GB per core.  Disk requirements are highly-dependent on particular workflow runners and their handling of intermediate files.  In addition to cached Docker layers, CWL runs typically use approximately 3 GB of disk space.  WDL runs with cromwell consume considerably more disk space.
> &nbsp;
> To accelerate deployment and testing the workflow is also packaged with smaller test inputs.  The reads in `input_data/ENCFF000VOL_chr21.fq.gz` are chromosome 21 extracts from the same A549/CEBP experiment as above and the companion reference `input_data/reference/GRCh38_chr21_bwa.tar.gz` is a small chromosome 21-only reference.  Paths to these inputs are in the CWL parameter file `input_data/encode_mapping_workflow.cwl_test.json` and the WDL parameter file `input_data/encode_mapping_workflow.wdl_test.json`.  Using these inputs the workflow takes less than a minute to run, not counting Docker downloads if image layers are not yet cached locally.  Do not submit results from these small test files for the Challenge.  They are only for your use in rapid deployment and testing on new platforms.
> &nbsp;
> Code for this workflow can be found in [the pipeline-container GitHub repo](https://github.com/ENCODE-DCC/pipeline-container).  The full ENCODE ChIP-seq analysis pipeline code is in [the chip-seq-pipeline GitHub repo](https://github.com/ENCODE-DCC/chip-seq-pipeline).  ENCODE Uniform Processing Pipelines are runnable on [DNAnexus](https://www.dnanexus.com/) in the featured DNAnexus project called ""ENCODE Uniform Processing Pipelines"".  More information on using ENCODE pipelines is [here](https://www.encodeproject.org/tutorials/ashg-2016-uniform-processing-pipelines/).  All the data and software products from ENCODE are distributed through the [ENCODE Portal](https://www.encodeproject.org/).

### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""30Gb""
```

#### Workflow history

+ **2017-08-10**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Michael Kotliar""
institution: ""CCHMC, Barski Lab""
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> **Note:** Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-12-17""
platform: ""CWL-Airflow""
workflow_type: ""CWL""
runner_version: ""0.0.1""
docker_version: ""1.12.6""
environment: ""local""
env_cpus: ""64""
env_memory: ""251Gb""
env_disk: ""230Gb""
```

### Steps

### Setting up environment
Install CWL-Airflow
```
  cd /home/michael_kotliar/workspaces/airflow/
  git clone https://github.com/Barski-lab/cwl-airflow.git
  cd cwl-airflow
  git fetch --tags
  git checkout v0.0.1
  pip install -e .
```
Run mysql-server:5.7 docker container
```
  cd /home/michael_kotliar/temp/cwl_airflow
  mkdir database
  docker pull mysql/mysql-server:5.7
  docker run -v /home/michael_kotliar/temp/cwl_airflow/database:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=airflow -e MYSQL_DATABASE=airflow -e MYSQL_USER=airflow -e MYSQL_PASSWORD=airflow -p 6603:3306 -d mysql/mysql-server:5.7
```
Update Airflow configuration file `/home/michael_kotliar/airflow/airflow.cfg`
```
  executor = LocalExecutor
  sql_alchemy_conn = mysql://airflow:airflow@127.0.0.1:6603/airflow
```
Install synapse client
```
  pip install synapseclient
```
Create empty folder for workflow running
```
  cd /home/michael_kotliar/temp/cwl_airflow/
  mkdir encode_mapping
```
Create Synapse credentials file `/home/michael_kotliar/temp/cwl_airflow/encode_mapping/.synapseConfig`, put there Synapse ID and password
```
[authentication]
username: user@usermail.org
password: <user-password>
```
### Downloading required files
Download the tool to submit workflow results
```
cd /home/michael_kotliar/temp/cwl_airflow/encode_mapping
synapse -c .synapseConfig get syn9732885   # dockstore-tool-synapse-submit.cwl
```
Download workflow input data
```
cd /home/michael_kotliar/temp/cwl_airflow/encode_mapping
synapse -c .synapseConfig get -r syn10163025
```
Wait until downloading is finished

### Running workflow
```
cwl-airflow-runner --debug encode_mapping_workflow.cwl encode_mapping_workflow.cwl.json
```
### Validating results
Run checker tool
```
cd /home/michael_kotliar/temp/cwl_airflow/encode_mapping
cwltool --debug --non-strict validator.cwl validator.json
```
Check results
```
cat results.json
``` 
```json
{
    ""overall"": true,
    ""steps"": {
        ""filtering_step"": {
            ""NRF"": true,
            ""PBC1"": true,
            ""PBC2"": true,
            ""duplicate_fraction"": true,
            ""n_filtered_mapped_reads"": true
        },
        ""mapping_step"": {
            ""crop_length"": true,
            ""paired_end"": true
        },
        ""post_mapping_step"": {
            ""n_mapped_reads"": true
        },
        ""xcor_step"": {
            ""NSC"": true,
            ""RSC"": true,
            ""est_frag_len"": true
        }
    }
}
```
### Submitting results
Update `encode_mapping_workflow_submit.cwl.json` with correct
`team_name` - the name of your team in plain text format (e.g., ""GA4GH-Sage Contenders"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
Run the tool
```
cwltool --debug --non-strict dockstore-tool-synapse-submit.cwl encode_mapping_workflow_submit.cwl.json
```
***Running time:*** 43 min  
***Disk usage:*** 10.0G",9657197
encode_mapping_workflow,9657795_report.md,"## ENCODE ChIP-seq Mapping Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted files to be viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""J. Seth Strattan, ENCODE Data Coordinating Center""
workflow_handle: ""encode_mapping_workflow""
input_handle: ""A549_CEBP""
```

The following description is provided by the workflow author:
> This workflow is a containerized version of the mapping component from the ENCODE Uniform Analysis Pipeline for ChIP-seq experiments.  The analysis is specified by the ENCODE Data Analysis Center (Zhiping Weng, University of Massachusetts) and ENCODE Analysis Working Group (Anshul Kundaje, Stanford University) and implemented and run by the ENCODE Data Coordinating Center (J. Michael Cherry, Stanford University).
> &nbsp;
> The workflow takes raw reads in the form of a fastq file and a genome reference and generates quality-control (QC) metrics and a filtered bam file suitable for peak calling and signal track generation.  The QC metrics include read depth, library complexity estimates, and scores from cross-correlation analysis.  The workflow is written in both Common Workflow Language (CWL) `encode_mapping_workflow.cwl` and Workflow Description Language (WDL) `encode_mapping_workflow.wdl`.
> &nbsp;
> For this Challenge, known-good inputs are in the `input_data` folder.  The file `input_data/ENCFF000VOL.fastq.gz` are reads from one replicate of an ENCODE ChIP-seq experiment done on the human A549 cell line and targeting the CEBP transcription factor.  The standard GRCh38 reference used by ENCODE is included in `input_data/reference/ENCFF643CGH_ENCODE_GRCh38_bwa.tar.gz`.  Complete metadata and analysis results from this experiment are accessioned at the ENCODE Portal [under accession number ENCSR000DYI here](https://www.encodeproject.org/experiments/ENCSR000DYI/).  Paths to the input files are specified in the CWL parameter file `encode_mapping_workflow.cwl.json` and the WDL parameter file `encode_mapping_workflow.wdl.json`.  Submissions to the challenge will be scored against known-good outputs of the workflow run on these inputs.  Run time should be less than two hours.  Workflow stages will automatically scale into multiple CPU cores if they are made available to Docker.  The workflow has been tested with 4 GB per core.  Disk requirements are highly-dependent on particular workflow runners and their handling of intermediate files.  In addition to cached Docker layers, CWL runs typically use approximately 3 GB of disk space.  WDL runs with cromwell consume considerably more disk space.
> &nbsp;
> To accelerate deployment and testing the workflow is also packaged with smaller test inputs.  The reads in `input_data/ENCFF000VOL_chr21.fq.gz` are chromosome 21 extracts from the same A549/CEBP experiment as above and the companion reference `input_data/reference/GRCh38_chr21_bwa.tar.gz` is a small chromosome 21-only reference.  Paths to these inputs are in the CWL parameter file `input_data/encode_mapping_workflow.cwl_test.json` and the WDL parameter file `input_data/encode_mapping_workflow.wdl_test.json`.  Using these inputs the workflow takes less than a minute to run, not counting Docker downloads if image layers are not yet cached locally.  Do not submit results from these small test files for the Challenge.  They are only for your use in rapid deployment and testing on new platforms.
> &nbsp;
> Code for this workflow can be found in [the pipeline-container GitHub repo](https://github.com/ENCODE-DCC/pipeline-container).  The full ENCODE ChIP-seq analysis pipeline code is in [the chip-seq-pipeline GitHub repo](https://github.com/ENCODE-DCC/chip-seq-pipeline).  ENCODE Uniform Processing Pipelines are runnable on [DNAnexus](https://www.dnanexus.com/) in the featured DNAnexus project called ""ENCODE Uniform Processing Pipelines"".  More information on using ENCODE pipelines is [here](https://www.encodeproject.org/tutorials/ashg-2016-uniform-processing-pipelines/).  All the data and software products from ENCODE are distributed through the [ENCODE Portal](https://www.encodeproject.org/).

### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""30Gb""
```

#### Workflow history

+ **2017-08-10**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Nihar Sheth"" # your name here
institution: ""DNAnexus Inc."" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.


```YAML
date_accessed: ""2017-12-18"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""DNAnexus-CWL"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""alpha"" # indicate executor version used
docker_version: ""dx-docker"" # from `docker --version`
environment: ""DNAnexus"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""autoscale"" # indicate number of cores in environment
env_memory: ""autoscale"" # indicate available RAM in environment
env_disk: ""autoscale"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

#### 1. Set up environment

On a Linux desktop with dx-toolkit and Docker installed, log into a DNAnexus project.
Also, set environment variables for your project and authentication token.
```
dx env
```
will give you your project ID.  We will assume it's accessible via `$PROJECT`.

You can generate a token via these instructions: https://wiki.dnanexus.com/Command-Line-Client/Login-and-Logout#Authentication-Tokens

Clone the dx-cwl repository:

```
https://github.com/dnanexus/dx-cwl.git
```

This was a commit hash used around the time of submission if you'd like to check it out: 2687fe8c671c113e8a780a790a85a18396aea23e

Ensure all pre-requisites are installed using the install-prerequisites.sh script or building a Docker image from the Dockerfile in the repository.



#### 2. Download required files

I used the `synapse get` command to download the `synapse-submit` CWL tool and the files for the encode_chip_mapping_workflow:
```shell
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get -r syn10163025 # recursively downloads encode_chip_mapping_workflow files
```




#### 4. Run the main workflow

Upload downloaded files to the DNAnexus project

```
dx upload -r .
```

Compile the workflow to DNAnexus

```
dx-cwl/dx-cwl compile-workflow encode_mapping_workflow.cwl --project $PROJECT --token $TOKEN
```

Run the workflow on the platform

```
dx-cwl/dx-cwl run-workflow dx-cwl-run/encode_mapping_workflow/encode_mapping_workflow encode_mapping_workflow.cwl.json
```

Note that the file in the second argument is referring to the one you uploaded to the platform.

#### 5. Run workflow checker tool

Using the UI, or `dx describe` on the analysis ID from above, download relevant outputs using:

`dx download [filename or ID]`

To verify workflow results before submission, I used `cwltool` to run the validator on my output folder.  I first edited the file `validator.json` with the path to the outputs I want to check:
> **Note:** the `path` value here should be the relative or absolute path to the output directory your workflow run generated that contains the files `filter_qc.json`, `mapping.json`, `post_mapping.json`, and `xcor.json`.  Where these outputs are stored will depend on the workflow runner you use.  This example uses `cwltool` which saves outputs to a date-stamped folder.  Do not include a trailing slash in the folder name.
```JSON
{
  ""output_folder"": {
    ""path"": ""7-26-2017T2H43M10S"",
    ""class"": ""Directory""
  }
}
```
I then ran the validator with:
```shell
cwltool validator.cwl validator.json
cat results.json | grep overall
```
The JSON output in `results.json` indicates what outputs were checked against known-good outputs to verify that the run was successful:
```JSON
{
    ""overall"": true,
    ""steps"": {
        ""filtering_step"": {
            ""NRF"": true,
            ""PBC1"": true,
            ""PBC2"": true,
            ""duplicate_fraction"": true,
            ""n_filtered_mapped_reads"": true
        },
        ""mapping_step"": {
            ""crop_length"": true,
            ""paired_end"": true
        },
        ""post_mapping_step"": {
            ""n_mapped_reads"": true
        },
        ""xcor_step"": {
            ""NSC"": true,
            ""RSC"": true,
            ""est_frag_len"": true
        }
    }
}
```

#### 6. Submit workflow outputs

I modified the parameters in `encode_mapping_workflow_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""DNAnexus"",
    ""eval_id"": ""9605639"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""7-26-2017T2H43M10S/mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""7-26-2017T2H43M10S/post_mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""7-26-2017T2H43M10S/filter_qc.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""7-26-2017T2H43M10S/xcor.json""
        }
    ],
    ""parent_id"": ""syn11635095""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl encode_mapping_workflow_submit.cwl.json
```


---",9657795
encode_mapping_workflow,9657796_report.md,"## ENCODE ChIP-seq Mapping Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted files to be viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""J. Seth Strattan, ENCODE Data Coordinating Center""
workflow_handle: ""encode_mapping_workflow""
input_handle: ""A549_CEBP""
```

The following description is provided by the workflow author:
> This workflow is a containerized version of the mapping component from the ENCODE Uniform Analysis Pipeline for ChIP-seq experiments.  The analysis is specified by the ENCODE Data Analysis Center (Zhiping Weng, University of Massachusetts) and ENCODE Analysis Working Group (Anshul Kundaje, Stanford University) and implemented and run by the ENCODE Data Coordinating Center (J. Michael Cherry, Stanford University).
> &nbsp;
> The workflow takes raw reads in the form of a fastq file and a genome reference and generates quality-control (QC) metrics and a filtered bam file suitable for peak calling and signal track generation.  The QC metrics include read depth, library complexity estimates, and scores from cross-correlation analysis.  The workflow is written in both Common Workflow Language (CWL) `encode_mapping_workflow.cwl` and Workflow Description Language (WDL) `encode_mapping_workflow.wdl`.
> &nbsp;
> For this Challenge, known-good inputs are in the `input_data` folder.  The file `input_data/ENCFF000VOL.fastq.gz` are reads from one replicate of an ENCODE ChIP-seq experiment done on the human A549 cell line and targeting the CEBP transcription factor.  The standard GRCh38 reference used by ENCODE is included in `input_data/reference/ENCFF643CGH_ENCODE_GRCh38_bwa.tar.gz`.  Complete metadata and analysis results from this experiment are accessioned at the ENCODE Portal [under accession number ENCSR000DYI here](https://www.encodeproject.org/experiments/ENCSR000DYI/).  Paths to the input files are specified in the CWL parameter file `encode_mapping_workflow.cwl.json` and the WDL parameter file `encode_mapping_workflow.wdl.json`.  Submissions to the challenge will be scored against known-good outputs of the workflow run on these inputs.  Run time should be less than two hours.  Workflow stages will automatically scale into multiple CPU cores if they are made available to Docker.  The workflow has been tested with 4 GB per core.  Disk requirements are highly-dependent on particular workflow runners and their handling of intermediate files.  In addition to cached Docker layers, CWL runs typically use approximately 3 GB of disk space.  WDL runs with cromwell consume considerably more disk space.
> &nbsp;
> To accelerate deployment and testing the workflow is also packaged with smaller test inputs.  The reads in `input_data/ENCFF000VOL_chr21.fq.gz` are chromosome 21 extracts from the same A549/CEBP experiment as above and the companion reference `input_data/reference/GRCh38_chr21_bwa.tar.gz` is a small chromosome 21-only reference.  Paths to these inputs are in the CWL parameter file `input_data/encode_mapping_workflow.cwl_test.json` and the WDL parameter file `input_data/encode_mapping_workflow.wdl_test.json`.  Using these inputs the workflow takes less than a minute to run, not counting Docker downloads if image layers are not yet cached locally.  Do not submit results from these small test files for the Challenge.  They are only for your use in rapid deployment and testing on new platforms.
> &nbsp;
> Code for this workflow can be found in [the pipeline-container GitHub repo](https://github.com/ENCODE-DCC/pipeline-container).  The full ENCODE ChIP-seq analysis pipeline code is in [the chip-seq-pipeline GitHub repo](https://github.com/ENCODE-DCC/chip-seq-pipeline).  ENCODE Uniform Processing Pipelines are runnable on [DNAnexus](https://www.dnanexus.com/) in the featured DNAnexus project called ""ENCODE Uniform Processing Pipelines"".  More information on using ENCODE pipelines is [here](https://www.encodeproject.org/tutorials/ashg-2016-uniform-processing-pipelines/).  All the data and software products from ENCODE are distributed through the [ENCODE Portal](https://www.encodeproject.org/).

### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""30Gb""
```

#### Workflow history

+ **2017-08-10**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Nihar Sheth"" # your name here
institution: ""DNAnexus Inc."" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

```YAML
date_accessed: ""2017-12-18"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""DNAnexus-WDL"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""WDL"" # CWL or WDL
runner_version: ""0.56"" # indicate executor version used
docker_version: ""dx-docker"" # from `docker --version`
environment: ""DNAnexus"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""autoscale"" # indicate number of cores in environment
env_memory: ""autoscale"" # indicate available RAM in environment
env_disk: ""autoscale"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

#### 1. Set up environment

On a Linux desktop with dx-toolkit and Docker installed, log into a DNAnexus project.
Also, set environment variables for your project and authentication token.
```
dx env
```
will give you your project ID.  We will assume it's accessible via `$PROJECT`.

You can generate a token via these instructions: https://wiki.dnanexus.com/Command-Line-Client/Login-and-Logout#Authentication-Tokens

Obtain the jar file for the 0.56 release of DNAnexus-WDL: https://github.com/dnanexus/dxWDL/releases/download/0.56/dxWDL-0.56.jar


#### 2. Download required files

I used the `synapse get` command to download the `synapse-submit` CWL tool and the files for the encode_chip_mapping_workflow:
```shell
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get -r syn10163025 # recursively downloads encode_chip_mapping_workflow files
```

#### 4. Run the main workflow

Upload downloaded files to the DNAnexus project

```
dx upload -r .
```

Let `$INPUTS` be the JSON file corresponding to the inputs for the WDL workflow (e.g. encode_mapping_workflow.wdl.json)

Edit file names in `$INPUTS` such that they are prefixed with `dx://`, e.g:

```{
  ""encode_mapping_workflow.fastqs"": [""dx://input_data/ENCFF000VOL.fastq.gz""],
  ""encode_mapping_workflow.trimming_parameter"": ""native"",
  ""encode_mapping_workflow.reference"": ""dx://input_data/reference/ENCFF643CGH_ENCODE_GRCh38_bwa.tar.gz""
}
```

Compile the workflow to your project.

```
java -jar dxWDL-0.56.jar compile encode_mapping_workflow.wdl -input $INPUTS.json
```
The command above outputs workflow ID.  Let's call it `$WORKFLOW`.  You can also call it by name.  Use `dx ls -l` to look for the name of the workflow with that ID.

Run the workflow:

```
dx run $WORKFLOW -f $INPUTS.json
```

You can also use the UI to run it and provide the inputs manually.


#### 5. Run workflow checker tool

Using the UI, or `dx describe` on the analysis ID from above, download relevant outputs using:

`dx download [filename or ID]`

To verify workflow results before submission, I used `cwltool` to run the validator on my output folder.  I first edited the file `validator.json` with the path to the outputs I want to check:
> **Note:** the `path` value here should be the relative or absolute path to the output directory your workflow run generated that contains the files `filter_qc.json`, `mapping.json`, `post_mapping.json`, and `xcor.json`.  Where these outputs are stored will depend on the workflow runner you use.  This example uses `cwltool` which saves outputs to a date-stamped folder.  Do not include a trailing slash in the folder name.
```JSON
{
  ""output_folder"": {
    ""path"": ""7-26-2017T2H43M10S"",
    ""class"": ""Directory""
  }
}
```
I then ran the validator with:
```shell
cwltool validator.cwl validator.json
cat results.json | grep overall
```
The JSON output in `results.json` indicates what outputs were checked against known-good outputs to verify that the run was successful:
```JSON
{
    ""overall"": true,
    ""steps"": {
        ""filtering_step"": {
            ""NRF"": true,
            ""PBC1"": true,
            ""PBC2"": true,
            ""duplicate_fraction"": true,
            ""n_filtered_mapped_reads"": true
        },
        ""mapping_step"": {
            ""crop_length"": true,
            ""paired_end"": true
        },
        ""post_mapping_step"": {
            ""n_mapped_reads"": true
        },
        ""xcor_step"": {
            ""NSC"": true,
            ""RSC"": true,
            ""est_frag_len"": true
        }
    }
}
```

#### 6. Submit workflow outputs

I modified the parameters in `encode_mapping_workflow_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""DNAnexus"",
    ""eval_id"": ""9605639"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""7-26-2017T2H43M10S/mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""7-26-2017T2H43M10S/post_mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""7-26-2017T2H43M10S/filter_qc.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""7-26-2017T2H43M10S/xcor.json""
        }
    ],
    ""parent_id"": ""syn11635096""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl encode_mapping_workflow_submit.cwl.json
```

---",9657796
encode_mapping_workflow,9657911_report.md,"## ENCODE ChIP-seq Mapping Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted files to be viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""J. Seth Strattan, ENCODE Data Coordinating Center""
workflow_handle: ""encode_mapping_workflow""
input_handle: ""A549_CEBP""
```

The following description is provided by the workflow author:
> This workflow is a containerized version of the mapping component from the ENCODE Uniform Analysis Pipeline for ChIP-seq experiments.  The analysis is specified by the ENCODE Data Analysis Center (Zhiping Weng, University of Massachusetts) and ENCODE Analysis Working Group (Anshul Kundaje, Stanford University) and implemented and run by the ENCODE Data Coordinating Center (J. Michael Cherry, Stanford University).
> &nbsp;
> The workflow takes raw reads in the form of a fastq file and a genome reference and generates quality-control (QC) metrics and a filtered bam file suitable for peak calling and signal track generation.  The QC metrics include read depth, library complexity estimates, and scores from cross-correlation analysis.  The workflow is written in both Common Workflow Language (CWL) `encode_mapping_workflow.cwl` and Workflow Description Language (WDL) `encode_mapping_workflow.wdl`.
> &nbsp;
> For this Challenge, known-good inputs are in the `input_data` folder.  The file `input_data/ENCFF000VOL.fastq.gz` are reads from one replicate of an ENCODE ChIP-seq experiment done on the human A549 cell line and targeting the CEBP transcription factor.  The standard GRCh38 reference used by ENCODE is included in `input_data/reference/ENCFF643CGH_ENCODE_GRCh38_bwa.tar.gz`.  Complete metadata and analysis results from this experiment are accessioned at the ENCODE Portal [under accession number ENCSR000DYI here](https://www.encodeproject.org/experiments/ENCSR000DYI/).  Paths to the input files are specified in the CWL parameter file `encode_mapping_workflow.cwl.json` and the WDL parameter file `encode_mapping_workflow.wdl.json`.  Submissions to the challenge will be scored against known-good outputs of the workflow run on these inputs.  Run time should be less than two hours.  Workflow stages will automatically scale into multiple CPU cores if they are made available to Docker.  The workflow has been tested with 4 GB per core.  Disk requirements are highly-dependent on particular workflow runners and their handling of intermediate files.  In addition to cached Docker layers, CWL runs typically use approximately 3 GB of disk space.  WDL runs with cromwell consume considerably more disk space.
> &nbsp;
> To accelerate deployment and testing the workflow is also packaged with smaller test inputs.  The reads in `input_data/ENCFF000VOL_chr21.fq.gz` are chromosome 21 extracts from the same A549/CEBP experiment as above and the companion reference `input_data/reference/GRCh38_chr21_bwa.tar.gz` is a small chromosome 21-only reference.  Paths to these inputs are in the CWL parameter file `input_data/encode_mapping_workflow.cwl_test.json` and the WDL parameter file `input_data/encode_mapping_workflow.wdl_test.json`.  Using these inputs the workflow takes less than a minute to run, not counting Docker downloads if image layers are not yet cached locally.  Do not submit results from these small test files for the Challenge.  They are only for your use in rapid deployment and testing on new platforms.
> &nbsp;
> Code for this workflow can be found in [the pipeline-container GitHub repo](https://github.com/ENCODE-DCC/pipeline-container).  The full ENCODE ChIP-seq analysis pipeline code is in [the chip-seq-pipeline GitHub repo](https://github.com/ENCODE-DCC/chip-seq-pipeline).  ENCODE Uniform Processing Pipelines are runnable on [DNAnexus](https://www.dnanexus.com/) in the featured DNAnexus project called ""ENCODE Uniform Processing Pipelines"".  More information on using ENCODE pipelines is [here](https://www.encodeproject.org/tutorials/ashg-2016-uniform-processing-pipelines/).  All the data and software products from ENCODE are distributed through the [ENCODE Portal](https://www.encodeproject.org/).

### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""30Gb""
```

#### Workflow history

+ **2017-08-10**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Junjun Zhang"" # your name here
institution: ""Ontario Institute for Cancer Research"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-11-15"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""JTracker"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
cwltool_version: ""1.0.2017110733715""
runner_version: ""0.2.0a5"" # indicate executor version used
docker_version: ""1.12.6"" # from `docker --version`
environment: ""OpenStack VM"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""96GB"" # indicate available RAM in environment
env_disk: ""2TB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-08-31""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""1.12.6""
environment_ex: ""local"" 
env_cpus_ex: ""8""
env_memory_ex: ""96GB""
env_disk_ex: ""2TB""
```

### Write a JTracker Workflow
The JTracker workflow is written to automatically execute necessary steps to complete a Dream Challenge workflow. The JTracker workflow is named as `dream-challenge-wf-runner`, the source code is checked in Github at: https://github.com/jthub/demo-workflows/tree/master/dream-challenge-wf-runner/workflow.

Once tested out successfully, make a release of the source code. In this case, it is release version 0.0.7: https://github.com/jthub/demo-workflows/releases/tag/dream-challenge-wf-runner.0.0.7

### Register the JTracker Workflow in JTHub
#### Install JTracker command line tool

Follow the instructions here: https://github.com/icgc-dcc/jtracker

Once install successfully, you should be able to see the version number.
```
jt --version
```

#### Signup a JTHub account
Assume we choose `ga4gh_dream` as account name:
```
jt user signup -u ga4gh_dream
```
Login as `ga4gh_dream`
```
jt user login -u ga4gh_dream
```

#### Register the JTracker Dream Challenge Runner Workflow
Register a workflow is basically provide information to access the JTracker workflow source code in GitHub.
```
jt wf register --git-server https://github.com --git-account jthub --git-repo demo-workflows \
                       --git-path dream-challenge-wf-runner --git-tag dream-challenge-wf-runner.0.0.7 \
                       --wf-name dream-challenge-wf-runner --wf-version 0.0.7
```
To list all registered workflows in your account, do this:
```
jt wf ls
```

### Create a Job Queue
Once we have the workflow registered, you will be able to create a job queue for it.
```
jt queue add --wf-name dream-challenge-wf-runner --wf-version 0.0.7
```
Upon success, you will get a unique job queue ID. In my case, my queue ID is: `758b7668-0057-4ef6-a5b0-6f48acf38583`

To list all job queues you created, do this:
```
jt queue ls
```

### Add workflow job to the above queue
If we want to run `encode_mapping_workflow`, fill out the appropriate parameters in the job JSON as below:
```
jt job add -q 758b7668-0057-4ef6-a5b0-6f48acf38583 -j '
{
    ""workflow_name"": ""encode_mapping_workflow"",
    ""workflow_type"": ""CWL"",
    ""data_syn_id"": ""syn10163025"",
    ""wf_file_name"": ""encode_mapping_workflow.cwl"",
    ""job_file_name"": ""encode_mapping_workflow.cwl.json"",
    ""checker_wf_file_name"": ""validator.cwl"",
    ""checker_job_file_name"": ""validator.json"",
    ""submit_job_file_name"": ""submit.json"",
    ""team_name"": ""PCAWG-Tech"",
    ""syn_parent_id"": ""syn11639257"",
    ""eval_id"": ""9605639""
}
'
```
To list all jobs in the queue:
```
jt job ls -q 758b7668-0057-4ef6-a5b0-6f48acf38583
```
Note that the above steps can be done on any computer, it could be a normal workstation or a laptop.


### Run the above queued Sanger workflow job

To execute the workflow job you will need to set up necessary environment and tools, follow these steps:

#### Setting up environment
1. Install Docker

2. Install `cwltool` (version 1.0.20170217172322) and  `synapseclient`
```
pip install cwltool==1.0.20170217172322
pip install synapseclient
```

3. Create Synapse credentials file `.synapseConfig`
Put there Synapse ID and password
```
[authentication]
username: user@usermail.org
password: <user-password>
```
Put this file a particular place, for example under home directory, eg, `/home/ubuntu/.synapseConfig`, then export the follow environment variable:
```
export SYNCONF=/home/ubuntu/.synapseConfig
```
4. Install JTracker command line
This is the same step as the previous section. Follow installation instruction here: https://github.com/icgc-dcc/jtracker

#### Start JTracker Executor
Start the executor to run jobs in the queue as:
```
jt user login ga4gh_dream
SYNCONF=/home/ubuntu/.synapseConfig jt exec run -q 758b7668-0057-4ef6-a5b0-6f48acf38583
```
If everything goes well, in about 5 hours, the job should finish and you will see `encode_mapping_workflow` result uploaded to specified location on Synapse.

---",9657911
encode_mapping_workflow,9657923_report.md,"### Workflow description

```YAML
contributor: ""J. Seth Strattan, ENCODE Data Coordinating Center""
workflow_handle: ""encode_mapping_workflow""
input_handle: ""A549_CEBP""
```

### Participant information
```YAML
name: ""Ben Ernest""
institution: ""Digicon Corporation""
```

### Submission overview
```YAML
date_accessed: ""2017-12-06"" 
platform: ""cwltool"" 
workflow_type: ""CWL"" 
runner_version: ""1.0.20170217172322"" 
docker_version: ""17.09.0-ce"" 
environment: ""cluster"" 
env_cpus: ""12"" 
env_memory: ""62Gb"" 
env_disk: ""5Tb"" 
```

### Steps

#### 1. Set up environment, following instructions at https://dockstore.org/quick-start
##### Instructions are for Linux CentOS

Download and install dockstore.  
```shell
mkdir -p ~/bin
curl -L -o ~/bin/dockstore https://github.com/ga4gh/dockstore/releases/download/1.3.0/dockstore
chmod +x ~/bin/dockstore
echo 'export PATH=~/bin:$PATH' >> ~/.bashrc
source ~/.bashrc
```

Create configuration file
```shell
mkdir -p ~/.dockstore
printf ""token: dummy-token\nserver-url: https://dockstore.org:8443\n"" > ~/.dockstore/config
```

Install `pip`
```shell
curl -L -o ~/get-pip.py https://bootstrap.pypa.io/get-pip.py
sudo python get-pip.py
```

Install `cwltool` (**note: version 1.0.20170217172322**)
```shell
sudo pip install setuptools==36.5.0
sudo pip install cwl-runner cwltool==1.0.20170217172322 schema-salad==2.6.20170806163416 avro==1.8.1 ruamel.yaml==0.14.12 requests==2.18.4
```

Install Docker
```shell
sudo yum install -y yum-utils device-mapper-persistent-data lvm2
sudo yum-config-manager --add-repo ""https://download.docker.com/linux/centos/docker-ce.repo""
sudo yum-config-manager --enable extras
sudo yum -y install docker-ce
sudo usermod -aG docker $USER
exec newgrp docker
```

Create aliases to start and stop Docker
```shell
echo 'alias start_docker=""sudo systemctl start docker""' >> ~/.bashrc
echo `alias stop_docker=""sudo systemctl stop docker""' >> ~/.bashrc
source ~/.bashrc
```
Install `synapseclient`
```
sudo pip install synapseclient
```

Create synapse credentials file with the content below, using your own Synapse credentials (no quotes or extra characters).  It can be named anything, but I'm using `.synapseConfig`.
```
[authentication]
username: user@usermail.org
password: password
```

Create a working directory and copy synapse credentials file into that folder.
```shell
mkdir -p encode_mapping
cd encode_mapping
cp ~/.synapseConfig .
```

#### 2. Download required files
Download tools to fetch workflow input data.
```shell
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
synapse get syn10261070 # encode_mapping_workflow_get.cwl.json
```

#### 3. Provision all workflow files
Start docker, using alias created previously.
```shell
start_docker
```

Use `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `encode_mapping_workflow_get.cwl.json` to download files, data, and tools required for running the workflow and submitting results.
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl encode_mapping_workflow_get.cwl.json
```

#### 4. Run main workflow
Use `cwltool` to run the workflow, as defined in `biowardrobe_chipseq_se.cwl` and parameterized by `biowardrobe_chipseq_se.json`:
```shell
cwltool --non-strict encode_mapping_workflow.cwl encode_mapping_workflow.cwl.json
```

#### 5. Run workflow checker tool
To verify workflow results before submission, use `cwltool` to run the checker as follows:
```shell
cwltool --non-strict validator.cwl validator.json
```

#### 6. Submit workflow outputs
Modify `team_name` and `parent_id` in `encode_mapping_workflow_submit.cwl.json` as shown below, assuming Synapse credentials file is named `.synapseConfig` and located in `~/encode_mapping`.
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""BioGenLink"",
    ""eval_id"": ""9605639"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""12-30-2017T4H41M34S/mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""12-30-2017T4H41M34S/post_mapping.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""12-30-2017T4H41M34S/filter_qc.json""
        },
        {
          ""class"": ""File"",
          ""path"": ""12-30-2017T4H41M34S/xcor.json""
        }
    ],
    ""parent_id"": ""syn11639785""
}
```

Submit outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl encode_mapping_workflow_submit.cwl.json
```

Stop Docker if desired.
```shell
stop_docker
```",9657923
encode_mapping_workflow,9657924_report.md,"### Workflow description

```YAML
contributor: ""J. Seth Strattan, ENCODE Data Coordinating Center""
workflow_handle: ""encode_mapping_workflow""
input_handle: ""A549_CEBP""
```

### Participant information
```YAML
name: ""Ben Ernest""
institution: ""Digicon Corporation""
```

### Submission overview
```YAML
date_accessed: ""2017-12-12"" 
platform: ""Dockstore"" 
workflow_type: ""CWL"" 
runner_version: ""1.0.20170217172322"" 
docker_version: ""17.09.0-ce"" 
environment: ""BioGenLink"" 
env_cpus: ""1"" 
env_memory: ""8Gb"" 
env_disk: ""5Tb"" 
```

### Steps
#####This workflow was run using the [BioGenLink](http://digicon.com/biogenlink.html) platform from [Digicon](http://digicon.com/).  Click [here](http://digicon.com/biogenlink.html) or [email us](mailto:biogenlink@digiconasp.com) for more information. 

#### **Setup**

##### Create synapse credentials file.  
This only needs to be done once, and the credentials file can be used for each workflow.
1. Log into BioGenLink.  [Click here](http://digicon.com/biogenlink.html) or [email us](mailto:biogenlink@digiconasp.com) for more information. 
${image?fileName=login%5Fscreen%5Fempty%2E2017%2D12%2D19%2Epng&align=None&scale=75&responsive=true}

2. In the **files** tab, right-click on any directory in the file system, select `Create File`, give the file a name (e.g., ""synapse_config.txt""), and click `Preview` to edit the file.  
${image?fileName=create%5Ffile%5Fpreview%2E2017%2D12%2D19%2Epng&align=None&scale=75&responsive=true}
Enter the following information in the file and save it by clicking **Save** (the disk button just above the text area).
```
[authentication]
username: email
password: password
[cache]
location: biodtfs/path/to/cache
```
**Note:** the cache directory is used by synapseClient for temporary files, and we must specify it in BioGenLink to avoid permissions errors. It can be be any directory the user chooses, even a non-existing one as long as the parent directory is valid.  It is suggested to create a working directory for each workflow and keep this file in a parent directory outside of the working directories.  

#### **Provision workflow files**

1. Create a working directory.  
    - Right-click on any directory in the file system, select `Create Folder`, and enter a name for the working directory (e.g., `encode_workflow`).

2. Run the `Synapse get` tool.
    - In the **tools** tab, find and select the `Synapse get` tool.  It can be found by keyword search or browsing to `Synapse/All/Synapse get`.  Double-clicking (shown below) the tool will open it in the workspace for editing and browsing documentation and will display the menu for providing inputs and running the tool.
${image?fileName=synapse%5Fget%5Fopen%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
    - In the `Synapse IDs` field, enter `syn9732885 ` to download `dockstore-tool-synapse-submit.cwl`.  
      Drag and drop the synapse credentials file (e.g., `synapse_config.txt`) from the file system into the field called `Synapse config file`.
      Set the switch labeled `Download tools and data` to `Off`.  
      Drag and drop the working directory into the field called `Output directory`.
      Run the tool by clicking `Quick Launch`.
    - In the `Synapse IDs` field, enter `syn10163025` to recursively download workflow files.
      Drag and drop the synapse credentials file (e.g., `synapse_config.txt`) from the file system into the field called `Synapse config file`.
      Set the switch labeled `Only tools and data` to `On`.
      Drag and drop the working directory into the field called `Output directory`.
      Run the tool by clicking `Quick Launch`.  
 ${image?fileName=synapse%5Fget%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}

#### **Run the workflow**
- Run the `Dockstore launch` tool.
    1. In the **Tools** tab, find and select the `Dockstore launch` tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore launch`.  
${image?fileName=dockstore%5Flaunch%2E2018%2D01%2D04%2Epng&align=None&scale=75&responsive=true}
    2. Drag and drop the `encode_mapping_workflow.cwl` and `encode_mapping_workflow.cwl.json` files from the working directory into the fields labeled `CWL file` and `JSON file`, respectively.  `Parent directory` can be left blank, since the directory containing the two input files will be used as the parent directory by default.   
    3. Click `Quick Launch`.

#### **Validate the results**
- Run the `Dockstore checker` tool.
  1. Open `validator.json` and edit the `path` field in the `output_folder` section to match the actual output directory created by the workflow (e.g., ""1-10-2018T5H47M31S"").
  2. In the **tools** tab, find and select the `Dockstore checker` tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore checker`.  
${image?fileName=dockstore%5Fchecker%2E2017%2D12%2D25%2Epng&align=None&scale=75&responsive=true}
  3. Drag and drop the `validator.cwl` and `validator.json` files from the working directory into the fields labeled `Checker CWL file` and `Checker JSON file`, respectively.  
  4. Click `Quick Launch`.
  5. Verify that the workflow ran successfully by opening the `results.json` file and confirming that the `Overall` field is equal to `true`.
${image?fileName=results%5Fjson%2E2017%2D12%2D25%2Epng&align=None&scale=75&responsive=true}

#### **Submit the results to Synapse**
- Run the `Dockstore submit` tool.
  1. In the **Tools** tab, find and select the `Dockstore submit` tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore submit`.  
${image?fileName=dockstore%5Fsubmit%2E2017%2D12%2D26%2Epng&align=None&scale=75&responsive=true}
  2. Drag and drop the `encode_mapping_workflow_submit.cwl.json` file into the field labeled `Submit JSON file`.  
  3. Enter a team name and the Synapse parent ID into the corresponding fields.  
  4. Drag and drop the synapse credentials file (e.g., `synapse_config.txt`) into the field labeled `Synapse config file`.
  5. Click `Quick Launch`.",9657924
gdc_dnaseq_transform,9617386_report.md,"## GDC DNA-seq Transform Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Jeremiah Savage""
workflow_handle: ""gdc_dnaseq_transform""
input_handle: ""NA12878 chr20""
```

The following description is provided by the workflow author:
> The GDC DNA-Seq Workflow aligns the reads in a BAM containing mapped or unmapped reads to a reference genome (GRCh38 with added viral sequence), outputing a BAM file, a BAI file, and a sqlite file containing quality and alignment metrics. The input BAM is converted to readgroup-separated FASTQ files using BIOBAMBAM, which are aligned with BWA, and then sorted, merged and duplicate marked with PICARD. Metrics are gathered at each phase of the workflow (FastQC, PICARD and SAMTOOLS metrics). The workflow has been validated with TCGA, TARGET, CCLE and 1000Genomes BAM files. The test case is NA12878 chr20, which requires about 1 hr of CPU time, and approximately 30G of disk space to complete.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""16GB""
suggested_disk: ""30GB""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""James Eddy"" # your name here
institution: ""Sage Bionetworks"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170217172322"" # indicate executor version used
docker_version: ""17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""EC2"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""32"" # indicate number of cores in environment
env_memory: ""244Gb"" # indicate available RAM in environment
env_disk: ""elastic"" # indicate available disk space, or note ""elastic"" for EFS et al.
```
> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""EC2"" 
env_cpus_ex: ""32""
env_memory_ex: ""244Gb""
env_disk_ex: ""elastic""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessasry.

#### 1. Set up environment

##### EC2/EFS
I launched a single-node EC2 instance of type `r4.8xlarge` in `us-east-1f` (spot request) with the canonical Ubuntu 16.04 AMI (`ami-80861296`). I connected to the instance via SSH (user `ubuntu`) and installed the required nfs client for Amazon EFS:
```shell
sudo apt-get install nfs-common
```

I then mounted my EFS volume at `/efs`.
```shell
sudo mkdir /efs
sudo mount -t nfs4 -o nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2 fs-2067e169.efs.us-east-1.amazonaws.com:/ /efs
```

##### Docker
I installed Docker on the instance using the following commands:
```shell
sudo apt-get update &&
    sudo apt-get install -y \
        apt-transport-https \
        ca-certificates \
        curl \
        software-properties-common &&
    curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - &&
    sudo add-apt-repository \
        ""deb [arch=amd64] https://download.docker.com/linux/ubuntu \
        $(lsb_release -cs) \
        stable"" &&
    sudo apt-get update &&
    sudo apt-get install -y docker-ce
```

Next, I modified the Docker's default storage location to use a partition with more space available, creating the file `/etc/docker/daemon.json` with the following:
```shell
{
  ""debug"": true,
  ""graph"": ""/dev/docker-data""
}
```

Finally, I added `ubuntu` to the `docker` Linux group, exited the instance, and signed back in.

##### Anaconda/cwltool
I installed Anaconda (`miniconda`) for Python 2.7 under my EFS root directory (**note:** I think this makes `conda` operations a bit slower than usual...).
```shell
wget https://repo.continuum.io/miniconda/Miniconda2-latest-Linux-x86_64.sh -O miniconda.sh
bash miniconda.sh -b -p /efs/miniconda
export PATH=""/efs/miniconda/bin:$PATH""
```

I created and configured a virtual environment with `synapseclient` and `cwltool` as follows:
```shell
conda create -n syncwl
source activate syncwl
pip install synapseclient --no-cache-dir
pip install schema-salad==2.2.20170222151604 cwltool==1.0.20170217172322 --no-cache-dir
```

##### Workspace/config
I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir gdc_dnaseq_transform
cd gdc_dnaseq_transform
cp ~/.synapseConfig .
```

Within the working directory, I created `tmp` and `cache` folders to be used with `cwltool` in subsequent steps:
```shell
mkdir tmp cache
```
&nbsp;

*Note: I learned after running the workflow that the caching functionality of `cwltool` is not exactly stable; while it worked for me, I might not necessarily recommend it.*

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **gdc_dnaseq_transform** workflow:
```shell
synapse get syn9962438 # gdc_dnaseq_transform_get.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 4. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `gdc_dnaseq_transform_get.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --tmpdir-prefix tmp/ --cachedir cache/ --non-strict dockstore-tool-synapse-get.cwl gdc_dnaseq_transform_get.json
```

#### 5. Run main workflow

I again used `cwltool` to run the workflow, as defined in `transform.cwl` and parameterized by `transform.cwl.json`:
```shell
nohup cwltool --cachedir cache/ --tmpdir-prefix tmp/ cwl/workflows/dnaseq/transform.cwl transform.cwl.json
```

#### 6. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool gdc_dnaseq_transform_checker.cwl gdc_dnaseq_transform_checker.cwl.json
cat results.json | grep -i overall
```

#### 7. Submit workflow outputs

I modified the parameters in `gdc_dnaseq_transform_submit.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""SageWorkflowRunners"",
    ""eval_id"": ""9604596"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""123e4567-e89b-12d3-a456-426655440000.db""
        }
    ],
    ""parent_id"": ""syn9851737""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl gdc_dnaseq_transform_submit.json`
```

---",9617386
gdc_dnaseq_transform,9621458_report.md,"## GDC DNA-seq Transform Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Jeremiah Savage""
workflow_handle: ""gdc_dnaseq_transform""
input_handle: ""NA12878 chr20""
```

The following description is provided by the workflow author:
> The GDC DNA-Seq Workflow aligns the reads in a BAM containing mapped or unmapped reads to a reference genome (GRCh38 with added viral sequence), outputing a BAM file, a BAI file, and a sqlite file containing quality and alignment metrics. The input BAM is converted to readgroup-separated FASTQ files using BIOBAMBAM, which are aligned with BWA, and then sorted, merged and duplicate marked with PICARD. Metrics are gathered at each phase of the workflow (FastQC, PICARD and SAMTOOLS metrics). The workflow has been validated with TCGA, TARGET, CCLE and 1000Genomes BAM files. The test case is NA12878 chr20, which requires about 1 hr of CPU time, and approximately 30G of disk space to complete.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""16GB""
suggested_disk: ""30GB""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Denis Yuen"" # your name here
institution: ""OICR"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""dockstore"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.2.5"" # indicate executor version used
docker_version: ""17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""64GB"" # indicate available RAM in environment
env_disk: ""400GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

#### 1. Set up environment

On a personal desktop, I installed Docker, pip, cwltool, and the Dockstore command-line helper using a procedure similar to https://github.com/denis-yuen/2017-cloud-workflows-misc/blob/master/install-and-run-with-dockstore.md

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir gdc_dnaseq_files
cd gdc_dnaseq_files
cp ~/.synapseConfig .
```

#### 2. Download required files

I downloaded hello_world_get.json from the website. I then got the synapse-submit and synapse-get commands from Dockstore. 
```shell
dockstore tool cwl --entry quay.io/ga4gh-dream/dockstore-tool-synapse-submit > dockstore-tool-synapse-submit.cwl
dockstore tool cwl --entry quay.io/ga4gh-dream/dockstore-tool-synapse-get > dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `dockstore cli` to run `dockstore-tool-synapse-get.cwl` with parameters in `gdc_dnaseq_transform_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
dockstore tool launch --local-entry dockstore-tool-synapse-get.cwl --json gdc_dnaseq_transform_get.cwl.json
```

#### 5. Run main workflow

I again used `dockstore cli` to run the workflow, as defined in `transform.cwl` and parameterized by `transform.cwl.json` (this version of Dockstore cli has provisioning issues with this workflow):
```shell
cwltool cwl/workflows/dnaseq/transform.cwl transform.cwl.json
```

#### 6. Run workflow checker tool

To verify workflow results before submission, I used `dockstore cli` to run the checker as follows:
```shell
dockstore tool launch --local-entry gdc_dnaseq_transform_checker.cwl --json gdc_dnaseq_transform_checker.cwl.json
```

#### 7. Submit workflow outputs

I modified the parameters in `gdc_dnaseq_transform_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""Dockstore team"",
    ""eval_id"": ""9604596"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""123e4567-e89b-12d3-a456-426655440000.db""
        }
    ],
    ""parent_id"": ""syn9961864""
}
```

Finally, I submitted outputs using `dockstore cli` and `dockstore-tool-synapse-submit.cwl`:
```shell
dockstore tool launch --local-entry ../dockstore-tool-synapse-submit.cwl --json gdc_dnaseq_transform_submit.cwl.json
```

---",9621458
gdc_dnaseq_transform,9622398_report.md,"## GDC DNA-seq Transform Workflow

### Workflow description

```YAML
contributor: ""Lon Blauvelt""
workflow_handle: ""gdc_dnaseq_transform""
input_handle: ""NA12878 chr20""
```

The following description is provided by the workflow author:
> The GDC DNA-Seq Workflow aligns the reads in a BAM containing mapped or unmapped reads to a reference genome (GRCh38 with added viral sequence), outputing a BAM file, a BAI file, and a sqlite file containing quality and alignment metrics. The input BAM is converted to readgroup-separated FASTQ files using BIOBAMBAM, which are aligned with BWA, and then sorted, merged and duplicate marked with PICARD. Metrics are gathered at each phase of the workflow (FastQC, PICARD and SAMTOOLS metrics). The workflow has been validated with TCGA, TARGET, CCLE and 1000Genomes BAM files. The test case is NA12878 chr20, which requires about 1 hr of CPU time, and approximately 30G of disk space to complete.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""16GB""
suggested_disk: ""30GB""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Lon Blauvelt""
institution: ""UCSC""
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""cwltool""
workflow_type: ""CWL""
runner_version: ""1.0.20170217172322""
docker_version: ""17.06.0-ce, build 02c1d87""
environment: ""EC2""
env_cpus: ""8""
env_memory: ""32 Gb""
env_disk: ""50 Gb""
```
> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""EC2"" 
env_cpus_ex: ""32""
env_memory_ex: ""244Gb""
env_disk_ex: ""elastic""
```

### Steps

#### 1. Set up environment

*I launched an EC2 instance of type `t2.2xlarge` with one node, mounted a 50 Gb EFS volume.*

I used the following to update the instance:

```shell
sudo apt-get update
sudo apt-get -y upgrade
sudo apt-get -y dist-upgrade
```

Install docker:

```shell
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
sudo add-apt-repository ""deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable""
sudo apt-get update
apt-cache policy docker-ce
sudo apt-get install -y docker-ce
sudo usermod -aG docker ${USER}
sudo su - ${USER}
```

Install pip, a virtualenv, and the requisite pip installs (cwltool, schema-salad, avro, synapse, and html5lib):

```shell
sudo apt install -y python-pip
sudo pip install --upgrade pip
sudo pip install virtualenv
virtualenv --python /usr/bin/python2 cwl
source /home/ubuntu/cwl/bin/activate
pip install cwl-runner cwltool==1.0.20170217172322 schema-salad==2.6.20170630075932 avro==1.8.1  ruamel.yaml==0.14.12 --no-cache-dir
pip install synapseclient --no-cache-dir
pip install html5lib
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:

```shell
mkdir syn
cd syn
nano syn-login.synapseConfig
[PASTE] username & password
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **gdc_dnaseq_transform** workflow, and then modify the get file:
```shell
synapse get -r syn9689286
[PASTE] username & password
synapse get -r syn9689284
[PASTE] username & password

nano gdc_dnaseq_transform_get.cwl.json
[PASTE] /home/ubuntu/syn/syn-login.synapseConfig
```

#### 4. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `gdc_dnaseq_transform_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.

```shell
cwltool --tmpdir-prefix tmp/ --cachedir cache/ --non-strict dockstore-tool-synapse-get.cwl gdc_dnaseq_transform_get.cwl.json
```

#### 5. Run main workflow

I again used `cwltool` to run the workflow, as defined in `transform.cwl` and parameterized by `transform.cwl.json`:
```
cwltool --cachedir cache/ --tmpdir-prefix tmp/ --non-strict cwl/workflows/dnaseq/transform.cwl transform.cwl.json
```

#### 6. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool --non-strict gdc_dnaseq_transform_checker.cwl gdc_dnaseq_transform_checker.cwl.json
```

#### 7. Submit workflow outputs

I modified the parameters in `gdc_dnaseq_transform_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": ""/home/ubuntu/syn/syn-login.synapseConfig""
    },
    ""team_name"": ""UCSC GA4GH-DREAM Challenge Team"",
    ""eval_id"": ""9604596"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""123e4567-e89b-12d3-a456-426655440000.db""
        }
    ],
    ""parent_id"": ""syn10182019""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool dockstore-tool-synapse-submit.cwl gdc_dnaseq_transform_submit.cwl.json
```

---",9622398
gdc_dnaseq_transform,9622520_report.md,"## GDC DNA-seq Transform Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Jeremiah Savage""
workflow_handle: ""gdc_dnaseq_transform""
input_handle: ""NA12878 chr20""
```

The following description is provided by the workflow author:
> The GDC DNA-Seq Workflow aligns the reads in a BAM containing mapped or unmapped reads to a reference genome (GRCh38 with added viral sequence), outputing a BAM file, a BAI file, and a sqlite file containing quality and alignment metrics. The input BAM is converted to readgroup-separated FASTQ files using BIOBAMBAM, which are aligned with BWA, and then sorted, merged and duplicate marked with PICARD. Metrics are gathered at each phase of the workflow (FastQC, PICARD and SAMTOOLS metrics). The workflow has been validated with TCGA, TARGET, CCLE and 1000Genomes BAM files. The test case is NA12878 chr20, which requires about 1 hr of CPU time, and approximately 30G of disk space to complete.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""16GB""
suggested_disk: ""30GB""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Abraham Chavez"" # your name here
institution: ""UCSC"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170217172322"" # indicate executor version used
docker_version: ""17.06.0-ce"" # from `docker --version`
environment: ""EC2"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""32"" # indicate number of cores in environment
env_memory: ""240Gb"" # indicate available RAM in environment
env_disk: ""200"" # indicate available disk space, or note ""elastic"" for EFS et al.
```
> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""EC2"" 
env_cpus_ex: ""32""
env_memory_ex: ""244Gb""
env_disk_ex: ""elastic""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessasry.

#### 1. Set up environment
Launched an EC2 instance of type `r4.8xlarge` with one node, mounted a 200Gb volume, and installed dependencies.
#####
If you have not set up your environment and install dependencies like **cwltool**, **dockstore**, **java** and so on
I recommend you follow [**this**](https://www.synapse.org/#!Synapse:syn10220609) instructions.
#####
I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir syn9766994
cd syn9766994
cp ~/.synapseConfig .
```
Information about `.synapseConfig` can be found [**here**](https://www.synapse.org/#!Synapse:syn8507133/wiki/4514
#####
Within the working directory, I created `tmp` and `cache` folders to be used with `cwltool` in subsequent steps:
```shell
mkdir tmp cache
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **gdc_dnaseq_transform** workflow:
```shell
synapse get syn9962438 # gdc_dnaseq_transform_get.cwl.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `gdc_dnaseq_transform_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --tmpdir-prefix tmp/ --cachedir cache/ --non-strict dockstore-tool-synapse-get.cwl gdc_dnaseq_transform_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `transform.cwl` and parameterized by `transform.cwl.json`:
```
nohup cwltool --cachedir cache/ --tmpdir-prefix tmp/ cwl/workflows/dnaseq/transform.cwl transform.cwl.json &
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool gdc_dnaseq_transform_checker.cwl gdc_dnaseq_transform_checker.cwl.json
cat results.json | grep overall
```

#### 6. Submit workflow outputs

I modified the parameters in `gdc_dnaseq_transform_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""Your Team Name"",
    ""eval_id"": ""9604596"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""123e4567-e89b-12d3-a456-426655440000.db""
        }
    ],
    ""parent_id"": ""YourParentId""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl gdc_dnaseq_transform_submit.cwl.json
```

---",9622520
gdc_dnaseq_transform,9622548_report.md,"## GDC DNA-seq Transform Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Jeremiah Savage""
workflow_handle: ""gdc_dnaseq_transform""
input_handle: ""NA12878 chr20""
```

The following description is provided by the workflow author:
> The GDC DNA-Seq Workflow aligns the reads in a BAM containing mapped or unmapped reads to a reference genome (GRCh38 with added viral sequence), outputing a BAM file, a BAI file, and a sqlite file containing quality and alignment metrics. The input BAM is converted to readgroup-separated FASTQ files using BIOBAMBAM, which are aligned with BWA, and then sorted, merged and duplicate marked with PICARD. Metrics are gathered at each phase of the workflow (FastQC, PICARD and SAMTOOLS metrics). The workflow has been validated with TCGA, TARGET, CCLE and 1000Genomes BAM files. The test case is NA12878 chr20, which requires about 1 hr of CPU time, and approximately 30G of disk space to complete.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""16GB""
suggested_disk: ""30GB""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Michael Kotliar""
institution: ""CCHMC, Barski Lab""
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""cwltool""
workflow_type: ""CWL""
runner_version: ""1.0.20170718140316""
docker_version: ""1.12.6""
environment: ""local""
env_cpus: ""64""
env_memory: ""264GB""
env_disk: ""3.2TB""
```

### Steps

#### 1. Set up environment
Install `cwltool` (version 1.0.20170718140316) and  `synapseclient`
```
pip install cwltool==1.0.20170718140316
pip install synapseclient
```
Create empty folder for workflow running
```
mkdir gdc_dnaseq_transform
cd gdc_dnaseq_transform
```
Create Synapse credentials file `.synapseConfig`, put there Synapse ID and password
```
[authentication]
username: user@usermail.org
password: <user-password>
```
#### 2. Download required files
Download tools to fetch workflow input data
```
synapse -c .synapseConfig get syn9962438   # gdc_dnaseq_transform_get.cwl.json
synapse -c .synapseConfig get syn9770802   # dockstore-tool-synapse-get.cwl
synapse -c .synapseConfig get syn9732885   # dockstore-tool-synapse-submit.cwl
```
Download workflow input data
```
cwltool --debug --non-strict dockstore-tool-synapse-get.cwl gdc_dnaseq_transform_get.cwl.json
```

#### 3. Run main workflow
```
cwltool cwl/workflows/dnaseq/transform.cwl transform.cwl.json
```
#### 6. Run workflow checker tool
```shell
cwltool gdc_dnaseq_transform_checker.cwl gdc_dnaseq_transform_checker.cwl.json
cat results.json | grep overall
```

#### 4. Submit workflow outputs

Modify the parameters in `gdc_dnaseq_transform_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""BioWardrobe"",
    ""eval_id"": ""9604596"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""123e4567-e89b-12d3-a456-426655440000.db""
        }
    ],
    ""parent_id"": ""syn10204876""
}
```
Run the tool
```
cwltool dockstore-tool-synapse-submit.cwl gdc_dnaseq_transform_submit.cwl.json
```
***Running time:*** 135m18.510s  ",9622548
gdc_dnaseq_transform,9622675_report.md,"## GDC DNA-seq Transform Workflow

### Workflow description

```YAML
contributor: ""Jeremiah Savage""
workflow_handle: ""gdc_dnaseq_transform""
input_handle: ""NA12878 chr20""
```

The following description is provided by the workflow author:
> The GDC DNA-Seq Workflow aligns the reads in a BAM containing mapped or unmapped reads to a reference genome (GRCh38 with added viral sequence), outputing a BAM file, a BAI file, and a sqlite file containing quality and alignment metrics. The input BAM is converted to readgroup-separated FASTQ files using BIOBAMBAM, which are aligned with BWA, and then sorted, merged and duplicate marked with PICARD. Metrics are gathered at each phase of the workflow (FastQC, PICARD and SAMTOOLS metrics). The workflow has been validated with TCGA, TARGET, CCLE and 1000Genomes BAM files. The test case is NA12878 chr20, which requires about 1 hr of CPU time, and approximately 30G of disk space to complete.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""16GB""
suggested_disk: ""30GB""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Bogdan Gavrilovic"" # your name here
institution: ""Seven Bridges Genomics"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""rabix"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.0"" # indicate executor version used
docker_version: ""1.12.6"" # from `docker --version`
environment: ""EC2"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""32"" # indicate number of cores in environment
env_memory: ""60Gb"" # indicate available RAM in environment
env_disk: ""700Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```


### Steps

#####1. [Install rabix](https://github.com/rabix/bunny#installing) on your machine and set environment variable $BUNNY. You need docker and java installed to run rabix:
```shell
wget https://github.com/rabix/bunny/releases/download/v1.0.0/rabix-1.0.0.tar.gz -O rabix-1.0.0.tar.gz && tar -xvf rabix-1.0.0.tar.gz
export BUNNY=$PWD/rabix-cli-1.0.0/rabix
```
#####2. If you've not already retrieved the CWL and data with synapse-get, you can use the [Synapse python client](https://github.com/Sage-Bionetworks/synapsePythonClient#installation):
```shell
pip install synapseclient
synapse get -r syn9766994 # GDC DNA-Seq workflow, tools and input files
synapse get syn9732885   # dockstore-tool-synapse-submit.cwl
```
#####3. Make CWL modifications
Minor CWL modifications need to be made to make the workflow runnable using rabix. The reason for this is that some tool definitions are not in line with the CWL specification, or better said CWL specification does not provide a definite description on how the execution should behave in certain cases. The modified tools are:
- bwa_pe.cwl and bwa_se.cwl 
[Github issue](https://github.com/rabix/bunny/issues/238)

Grab the modified tools:
```shell
synapse get -r syn10245653
```
Replace the original files in `cwl/tools` folder with the downloaded modified versions.
>NOTE: The modified version of the tools will also work with cwl-tool
#####4. Run the workflow using rabix executor on your machine by typing in the terminal: $BUNNY <app> <inputs>
For example:
```shell
$BUNNY cwl/workflows/dnaseq/transform.cwl transform.cwl.json
```
### Validating results
Modify `gdc_dnaseq_transform_checker.cwl.json` to include the path to the requested output file and run checker tool
```shell
$BUNNY gdc_dnaseq_transform_checker.cwl gdc_dnaseq_transform_checker.cwl.json
```
Check results
```shell
cat ./path/to/results.json
``` 
```json
{
    ""overall"": true,
    ""steps"": {
        ""average_quality_samtools_stats"": true,
        ""bases_duplicated_samtools_stats"": true,
        ""bases_mapped_samtools_stats"": true,
        ""count_fastq_files"": true,
        ""count_files_output"": true,
        ""count_readgroups"": true,
        ""raw_total_seq_samtools_stats"": true,
        ""read_pair_dups_picard_markduplicates"": true,
        ""read_pairs_picard_markduplicates"": true,
        ""read_unmapped_samtools_stats"": true,
        ""reads_dup_samtools_stats"": true,
        ""reads_mapped_and_paired_samtools_stats"": true,
        ""reads_mapped_samtools_stats"": true,
        ""reads_paired_samtool_stats"": true,
        ""seqs_samtools_stats"": true,
        ""total_length_samtools_stats"": true
    }
}
```
### Submitting results
- Copy the synapseConfig file to the current working directory.
- Update `gdc_dnaseq_transform_submit.cwl.json` with correct
`team_name` - the name of your team in plain text format (e.g., ""GA4GH-Sage Contenders"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
`file` - paths to output files
Run the tool
```shell
$BUNNY dockstore-tool-synapse-submit.cwl gdc_dnaseq_transform_submit.cwl.json
```

---",9622675
gdc_dnaseq_transform,9623170_report.md,"## GDC DNA-seq Transform Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Jeremiah Savage""
workflow_handle: ""gdc_dnaseq_transform""
input_handle: ""NA12878 chr20""
```

The following description is provided by the workflow author:
> The GDC DNA-Seq Workflow aligns the reads in a BAM containing mapped or unmapped reads to a reference genome (GRCh38 with added viral sequence), outputing a BAM file, a BAI file, and a sqlite file containing quality and alignment metrics. The input BAM is converted to readgroup-separated FASTQ files using BIOBAMBAM, which are aligned with BWA, and then sorted, merged and duplicate marked with PICARD. Metrics are gathered at each phase of the workflow (FastQC, PICARD and SAMTOOLS metrics). The workflow has been validated with TCGA, TARGET, CCLE and 1000Genomes BAM files. The test case is NA12878 chr20, which requires about 1 hr of CPU time, and approximately 30G of disk space to complete.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""16GB""
suggested_disk: ""30GB""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Abraham Chavez"" # your name here
institution: ""UCSC"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""dockstore cli"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.2.3"" # indicate executor version used
docker_version: ""17.06.0-ce-rc4"" # from `docker --version`
environment: ""EC2"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""32"" # indicate number of cores in environment
env_memory: ""240Gb"" # indicate available RAM in environment
env_disk: ""200Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```
> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""EC2"" 
env_cpus_ex: ""32""
env_memory_ex: ""244Gb""
env_disk_ex: ""elastic""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessasry.

#### 1. Set up environment

 Launched an EC2 instance of type `r4.8xlarge` with one node, mounted an EFS volume, and installed dependencies.
#####
If you have not set up your environment and install dependencies like **cwltool**, **dockstore**, **java** and so on
I recommend you follow [**this**](https://www.synapse.org/#!Synapse:syn10220609) instructions.
#####
I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir syn9766994
cd syn9766994
cp ~/.synapseConfig .
```
Information about `.synapseConfig` can be found [**here**](https://www.synapse.org/#!Synapse:syn8507133/wiki/451408)
#####
Within the working directory, I created `tmp` and `cache` folders to be used with `cwltool` in subsequent steps:
```shell
mkdir tmp cache
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **gdc_dnaseq_transform** workflow:
```shell
synapse get syn9962438 # gdc_dnaseq_transform_get.cwl.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `gdc_dnaseq_transform_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --tmpdir-prefix tmp/ --cachedir cache/ --non-strict dockstore-tool-synapse-get.cwl gdc_dnaseq_transform_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `transform.cwl` and parameterized by `transform.cwl.json`:
```shell
dockstore workflow launch --local-entry --entry cwl/workflows/dnaseq/transform.cwl --json transform.cwl.json 
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool gdc_dnaseq_transform_checker.cwl gdc_dnaseq_transform_checker.cwl.json
cat results.json | grep overall
```

#### 6. Submit workflow outputs

I modified the parameters in `gdc_dnaseq_transform_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""Your Team Name"",
    ""eval_id"": ""9604596"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""123e4567-e89b-12d3-a456-426655440000.db""
        }
    ],
    ""parent_id"": ""yourParentId""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl gdc_dnaseq_transform_submit.cwl.json
```

---",9623170
gdc_dnaseq_transform,9623180_report.md,"## GDC DNA-seq Transform Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Jeremiah Savage""
workflow_handle: ""gdc_dnaseq_transform""
input_handle: ""NA12878 chr20""
```

The following description is provided by the workflow author:
> The GDC DNA-Seq Workflow aligns the reads in a BAM containing mapped or unmapped reads to a reference genome (GRCh38 with added viral sequence), outputing a BAM file, a BAI file, and a sqlite file containing quality and alignment metrics. The input BAM is converted to readgroup-separated FASTQ files using BIOBAMBAM, which are aligned with BWA, and then sorted, merged and duplicate marked with PICARD. Metrics are gathered at each phase of the workflow (FastQC, PICARD and SAMTOOLS metrics). The workflow has been validated with TCGA, TARGET, CCLE and 1000Genomes BAM files. The test case is NA12878 chr20, which requires about 1 hr of CPU time, and approximately 30G of disk space to complete.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""16GB""
suggested_disk: ""30GB""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Jeltje van Baren""
institution: ""UCSC""
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""cwltool""
workflow_type: ""CWL""
runner_version: ""1.0.20170704143016""
docker_version: ""1.12.1, build 23cf638""
environment: ""UCSC podcloud VM Ubuntu 16:04""
env_cpus: ""31""
env_memory: ""252 G""
env_disk: ""1 Tb""
```
> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""EC2"" 
env_cpus_ex: ""32""
env_memory_ex: ""244Gb""
env_disk_ex: ""elastic""
```

### Steps

1. Used link on [3.3 - Access Data and Tools](https://www.synapse.org/#!Synapse:syn8507134/wiki/416015) to download [gdc_dnaseq_transform_get.cwl.json](https://www.synapse.org/Portal/filehandleassociation?associatedObjectId=9771740&associatedObjectType=FileEntity&fileHandleId=16639348&xsrfToken=5D9B3FA24C29121558A6DF4048E46A16)

2. From the same page, downloaded [dockstore-tool-synapse-get.cwl](https://www.synapse.org/Portal/filehandleassociation?associatedObjectId=9770802&associatedObjectType=FileEntity&fileHandleId=15691607&xsrfToken=F397E2A807CC92157AEC380011771547) and [dockstore-tool-synapse-submit.cwl](https://www.synapse.org/Portal/filehandleassociation?associatedObjectId=9732885&associatedObjectType=FileEntity&fileHandleId=16683837&xsrfToken=F397E2A807CC92157AEC380011771547):

      dockstore-tool-synapse-get.cwl pulls quay.io/ga4gh-dream/dockstore-tool-synapse-get:1.6.2.dev--2
      dockstore-tool-synapse-submit.cwl pulls  quay.io/ga4gh-dream/dockstore-tool-synapse-submit:1.7.1--1

3. Retrieved data:

    source ~/venv/cwl/bin/activate
    export TMPDIR=/mnt/tempdir
    tmpstuff=""--tmpdir-prefix=/mnt/tempdir --tmp-outdir-prefix=/mnt/tempdir""
    ln -s ~/.synapse.key .synapseConfig
    cwltool $tmpstuff --non-strict dockstore-tool-synapse-get.cwl gdc_dnaseq_transform_get.json

4. Ran workflow:

    cwltool $tmpstuff cwl/workflows/dnaseq/transform.cwl transform.cwl.json

5. Created a synapse project for this workflow [gdc_GA4GH: syn10178811](https://www.synapse.org/#!Synapse:syn10178811), updated gdc_dnaseq_transform_submit.cwl.json with this information and submitted the output:

    cwltool $tmpstuff --non-strict dockstore-tool-synapse-submit.cwl gdc_dnaseq_transform_submit.cwl.json
Contents of gdc_dnaseq_transform_submit.cwl.json:
```
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": """",
    ""eval_id"": ""9604596"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""123e4567-e89b-12d3-a456-426655440000.db""
        }
    ],
    ""parent_id"": ""syn10178811""
}
```

---",9623180
gdc_dnaseq_transform,9624614_report.md,"## GDC DNA-seq Transform Workflow

### Workflow description

```YAML
contributor: ""Jeremiah Savage""
workflow_handle: ""gdc_dnaseq_transform""
input_handle: ""NA12878 chr20""
```

The following description is provided by the workflow author:
> The GDC DNA-Seq Workflow aligns the reads in a BAM containing mapped or unmapped reads to a reference genome (GRCh38 with added viral sequence), outputing a BAM file, a BAI file, and a sqlite file containing quality and alignment metrics. The input BAM is converted to readgroup-separated FASTQ files using BIOBAMBAM, which are aligned with BWA, and then sorted, merged and duplicate marked with PICARD. Metrics are gathered at each phase of the workflow (FastQC, PICARD and SAMTOOLS metrics). The workflow has been validated with TCGA, TARGET, CCLE and 1000Genomes BAM files. The test case is NA12878 chr20, which requires about 1 hr of CPU time, and approximately 30G of disk space to complete.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""16GB""
suggested_disk: ""30GB""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Bogdan Gavrilovic"" # your name here
institution: ""Seven Bridges Genomics"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""SevenBridges"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""latest"" # indicate executor version used
docker_version: ""1.12.6"" # from `docker --version`
environment: ""EC2"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""32"" # indicate number of cores in environment
env_memory: ""60Gb"" # indicate available RAM in environment
env_disk: ""700Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

#####1. [Install rabix](https://github.com/rabix/bunny#installing) on your machine and set environment variable $BUNNY. You need docker and java installed to run rabix:
```shell
wget https://github.com/rabix/bunny/releases/download/v1.0.0/rabix-1.0.0.tar.gz -O rabix-1.0.0.tar.gz && tar -xvf rabix-1.0.0.tar.gz
export BUNNY=$PWD/rabix-cli-1.0.0/rabix
```
#####2. If you've not already retrieved the CWL and data with synapse-get, you can use the [Synapse python client](https://github.com/Sage-Bionetworks/synapsePythonClient#installation):
```shell
pip install synapseclient
synapse get -r syn9766994 # GDC DNA-Seq workflow, tools and input files
synapse get syn9732885   # dockstore-tool-synapse-submit.cwl
```
#####3. Make CWL modifications
Minor CWL modifications need to be made to make the workflow runnable using rabix. The reason for this is that some tool definitions are not in line with the CWL specification, or better said CWL specification does not provide a definite description on how the execution should behave in certain cases. The modified tools are:
- bwa_pe.cwl and bwa_se.cwl 
[Github issue](https://github.com/rabix/bunny/issues/238)

Grab the modified tools:
```shell
synapse get -r syn10245653
```
Replace the original files in `cwl/tools` folder with the downloaded modified versions.
>NOTE: The modified version of the tools will also work with cwl-tool

#### Running on the [Cancer Genomics Cloud](https://cgc.sbgenomics.com/) 

#####3. Log in to the [Cancer Genomics Cloud](https://cgc.sbgenomics.com/) and [create a project](https://docs.cancergenomicscloud.org/docs/create-a-project) 
- Academic Users can create a free account on the Cancer Genomics Cloud (CGC). New users receive \$300 in cloud computing credits that you can apply to this challenge, and your own research. Additionally, users that leave feedback on their experience receive an additional \$1000 in cloud compute credits.
- Commercial users of the Seven Bridges Platform that wish to participate in the DREAM challenge can also create an account on the CGC to participate in this academic exercise and receive free credits to run the challenge workflows. Alternatively, commercial users are free to run DREAM challenge workflows in their commercial platform accounts, but should realize that they will incur cloud compute charges to do so. 
&nbsp;
#####4. Installing the workflow on the platform can be done using:  
**a)** [Rabix Composer app for CWL tool editing](http://rabix.io/) or   
**b)** a [CWL CommandLineTool](https://github.com/bogdang989/Import-CWL-to-SevenBridges) for importing CWL workflows to the Seven Bridges platform.  

#####4a. Rabix Composer
If you’re interested in trying out Seven Bridges’ new integrated development environment for creating CWL descriptions of tools and workflows, you can use the [Rabix Composer](http://rabix.io/) to upload the workflow to the platform. 
Use Rabix Composer to add the workflow to the platform:  
- [Install Rabix Composer](http://docs.rabix.io/rabix-composer-installation)
- [Configure Composer](http://docs.rabix.io/rabix-composer-configuration) to connect to the CGC or Seven Bridges platform
- [Add the project](http://docs.rabix.io/rabix-composer-configuration) you created for the DREAM challenge to the workspace
- [Add the local directory](http://docs.rabix.io/rabix-composer-configuration) containing the workflow to the workspace
- [Open](http://docs.rabix.io/rabix-composer-basics) the workflow with Composer
- [Save the workflow to the Platform project](http://docs.rabix.io/rabix-composer-basics) you added to the workspace
- Log into the Platform and [upload the input files](https://docs.cancergenomicscloud.org/docs/upload-to-the-cgc) to the project. 
- Run the task

> You can [upload the files manually to the platform](https://docs.cancergenomicscloud.org/docs/upload-to-the-cgc) by using either CGC Uploader app, command-line uploader, Python API or some other available upload method... All of the available methods are described in [the documentation](https://docs.cancergenomicscloud.org/docs/upload-to-the-cgc) 

#####4b. CWLtoSBG import tool
Download the CWL importing tool and **place it in the same directory with the CWL workflow** that should be installed on the platform. You can download the tool from [github](https://github.com/bogdang989/Import-CWL-to-SevenBridges) manually or from command-line by typing:
```shell
git clone https://github.com/bogdang989/Import-CWL-to-SevenBridges
```
Modify the `cwl_to_sbg-inputs.yaml` to include:

- Paths to `cwl/workflows/dnaseq/transform.cwl` and `transform.cwl.json`
- Id of your project on the platform (From project URL, in format *user-name/project-name* )
For example if project URL is https://cgc.sbgenomics.com/u/bogdang/demo-project; project_id is `bogdang/demo-project`
- Your [authentication token](http://docs.sevenbridges.com/docs/get-your-authentication-token)
- Adequate [EC2 instance type](http://www.ec2instances.info/)
&nbsp;
After modifying `cwl_to_sbg-inputs.yaml` with your information, import the workflow to the platform by running
```shell
$BUNNY cwl_to_sbg.cwl cwl_to_sbg-inputs.yaml
```
This will install the workflow and all required apps on the platform. All the files that are required for the task execution are uploaded if they are not uploaded previously. Template draft task is created. If `run_task` is set to `true` the task execution will start on the platform.
You can now open `task` page on the platform project to see task execution details.

### Validating results
[Download the output files](https://docs.cancergenomicscloud.org/docs/download-results) to your local machine.

Modify `gdc_dnaseq_transform_checker.cwl.json` to include the path to the requested output file and run checker tool
```shell
$BUNNY gdc_dnaseq_transform_checker.cwl gdc_dnaseq_transform_checker.cwl.json
```
Check results
```shell
cat ./path/to/results.json
``` 
```json
{
    ""overall"": true,
    ""steps"": {
        ""average_quality_samtools_stats"": true,
        ""bases_duplicated_samtools_stats"": true,
        ""bases_mapped_samtools_stats"": true,
        ""count_fastq_files"": true,
        ""count_files_output"": true,
        ""count_readgroups"": true,
        ""raw_total_seq_samtools_stats"": true,
        ""read_pair_dups_picard_markduplicates"": true,
        ""read_pairs_picard_markduplicates"": true,
        ""read_unmapped_samtools_stats"": true,
        ""reads_dup_samtools_stats"": true,
        ""reads_mapped_and_paired_samtools_stats"": true,
        ""reads_mapped_samtools_stats"": true,
        ""reads_paired_samtool_stats"": true,
        ""seqs_samtools_stats"": true,
        ""total_length_samtools_stats"": true
    }
}
```
### Submitting results
- Copy the synapseConfig file to the current working directory.
- Update `gdc_dnaseq_transform_submit.cwl.json` with correct
`team_name` - the name of your team in plain text format (e.g., ""GA4GH-Sage Contenders"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
`file` - paths to output files
Run the tool
```shell
$BUNNY dockstore-tool-synapse-submit.cwl gdc_dnaseq_transform_submit.cwl.json
```
---",9624614
gdc_dnaseq_transform,9629420_report.md,"## GDC DNA-seq Transform Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Jeremiah Savage""
workflow_handle: ""gdc_dnaseq_transform""
input_handle: ""NA12878 chr20""
```

The following description is provided by the workflow author:
> The GDC DNA-Seq Workflow aligns the reads in a BAM containing mapped or unmapped reads to a reference genome (GRCh38 with added viral sequence), outputing a BAM file, a BAI file, and a sqlite file containing quality and alignment metrics. The input BAM is converted to readgroup-separated FASTQ files using BIOBAMBAM, which are aligned with BWA, and then sorted, merged and duplicate marked with PICARD. Metrics are gathered at each phase of the workflow (FastQC, PICARD and SAMTOOLS metrics). The workflow has been validated with TCGA, TARGET, CCLE and 1000Genomes BAM files. The test case is NA12878 chr20, which requires about 1 hr of CPU time, and approximately 30G of disk space to complete.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""16GB""
suggested_disk: ""30GB""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Gary Luu"" # your name here
institution: ""Dockstore - OICR"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""dockstore"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.2.7"" # indicate executor version used
docker_version: ""17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""4"" # indicate number of cores in environment
env_memory: ""32 GB"" # indicate available RAM in environment
env_disk: ""470 GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```
> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""EC2"" 
env_cpus_ex: ""32""
env_memory_ex: ""244Gb""
env_disk_ex: ""elastic""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessasry.

#### 1. Set up environment

On a personal desktop, I installed Docker, pip, cwltool, and the Dockstore command-line helper using a procedure similar to https://github.com/denis-yuen/2017-cloud-workflows-misc/blob/master/install-and-run-with-dockstore.md .  
However, I used my own modified dockstore CLI (which will be 1.2.7)

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir gdc_dnaseq_files
cd gdc_dnaseq_files
cp ~/.synapseConfig .
```
#### 2. Download required files

I downloaded gdc_dnaseq_transform_get.cwl.json from the website. 


#### 3. Provision all workflow files

I used the synapse-get tool from Dockstore.
```shell
dockstore tool launch --entry quay.io/ga4gh-dream/dockstore-tool-synapse-get --json gdc_dnaseq_transform_get.cwl.json
```

#### 4. Run main workflow

I used dockstore to launch the recently downloaded transform.cwl
```shell
dockstore workflow launch --local-entry cwl/workflows/dnaseq/transform.cwl --json transform.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `dockstore` to run the checker as follows:
```shell
dockstore tool launch --local-entry gdc_dnaseq_transform_checker.cwl --json gdc_dnaseq_transform_checker.cwl.json
cat results.json | grep overall
```

#### 6. Submit workflow outputs

I modified the parameters in `gdc_dnaseq_transform_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""Dockstore Team"",
    ""eval_id"": ""9604596"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""123e4567-e89b-12d3-a456-426655440000.db""
        }
    ],
    ""parent_id"": ""syn9877725""
}
```

Finally, I submitted outputs using dockstore-tool-synapse-submit`:
```shell
dockstore tool launch --entry quay.io/ga4gh-dream/dockstore-tool-synapse-submit --json gdc_dnaseq_transform_submit.cwl.json
```

---",9629420
gdc_dnaseq_transform,9631719_report.md,"## GDC DNA-seq Transform Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Jeremiah Savage""
workflow_handle: ""gdc_dnaseq_transform""
input_handle: ""NA12878 chr20""
```

The following description is provided by the workflow author:
> The GDC DNA-Seq Workflow aligns the reads in a BAM containing mapped or unmapped reads to a reference genome (GRCh38 with added viral sequence), outputing a BAM file, a BAI file, and a sqlite file containing quality and alignment metrics. The input BAM is converted to readgroup-separated FASTQ files using BIOBAMBAM, which are aligned with BWA, and then sorted, merged and duplicate marked with PICARD. Metrics are gathered at each phase of the workflow (FastQC, PICARD and SAMTOOLS metrics). The workflow has been validated with TCGA, TARGET, CCLE and 1000Genomes BAM files. The test case is NA12878 chr20, which requires about 1 hr of CPU time, and approximately 30G of disk space to complete.

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Benjamin Story"" # your name here
institution: ""EMBL"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""08/31/2017"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""cwltool 1.0.20170413194156"" # indicate executor version used
docker_version: ""1.7.1, build 786b29d"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""12"" # indicate number of cores in environment
env_memory: ""72GB"" # indicate available RAM in environment
env_disk: ""1TB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessasry.

#### 1. Set up environment

**example:** *I launched an EC2 instance of type `r4.8xlarge` with one node, mounted an EFS volume, and installed Docker.*

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir gdc_dnaseq_transform
cd gdc_dnaseq_transform
cp ~/.synapseConfig .
```

Within the working directory, I created `tmp` and `cache` folders to be used with `cwltool` in subsequent steps:
```shell
mkdir tmp
mkdir cache
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **gdc_dnaseq_transform** workflow:
```shell
synapse get syn9962438 # gdc_dnaseq_transform_get.cwl.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `gdc_dnaseq_transform_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --tmpdir-prefix tmp/ --cachedir cache/ --non-strict dockstore-tool-synapse-get.cwl gdc_dnaseq_transform_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `transform.cwl` and parameterized by `transform.cwl.json`:
```shell
cwltool --cachedir cache/ --tmpdir-prefix tmp/ cwl/workflows/dnaseq/transform.cwl transform.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool gdc_dnaseq_transform_checker.cwl gdc_dnaseq_transform_checker.cwl.json
```

#### 6. Submit workflow outputs

I modified the parameters in `gdc_dnaseq_transform_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""EMBL GA4GH-DREAM Challenge Team"",
    ""eval_id"": ""9604596"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""123e4567-e89b-12d3-a456-426655440000.db""
        }
    ],
    ""parent_id"": ""syn10516537""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl gdc_dnaseq_transform_submit.cwl.json
```

---",9631719
gdc_dnaseq_transform,9632183_report.md,"## GDC DNA-seq Transform Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Jeremiah Savage""
workflow_handle: ""gdc_dnaseq_transform""
input_handle: ""NA12878 chr20""
```

The following description is provided by the workflow author:
> The GDC DNA-Seq Workflow aligns the reads in a BAM containing mapped or unmapped reads to a reference genome (GRCh38 with added viral sequence), outputing a BAM file, a BAI file, and a sqlite file containing quality and alignment metrics. The input BAM is converted to readgroup-separated FASTQ files using BIOBAMBAM, which are aligned with BWA, and then sorted, merged and duplicate marked with PICARD. Metrics are gathered at each phase of the workflow (FastQC, PICARD and SAMTOOLS metrics). The workflow has been validated with TCGA, TARGET, CCLE and 1000Genomes BAM files. The test case is NA12878 chr20, which requires about 1 hr of CPU time, and approximately 30G of disk space to complete.

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Jacob Silterra"" # your name here
institution: ""None"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-01"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""cwltool 1.0.20170817131858"" # indicate executor version used
docker_version: ""Docker version 1.12.6, build 78d1802"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""4"" # indicate number of cores in environment
env_memory: ""16GB"" # indicate available RAM in environment
env_disk: ""1TB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessasry.

#### 1. Set up environment

**example:** *I launched an EC2 instance of type `r4.8xlarge` with one node, mounted an EFS volume, and installed Docker.*

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir gdc_dnaseq_transform
cd gdc_dnaseq_transform
ln -s ~/.synapseConfig .
```

Within the working directory, I created `tmp` and `cache` folders to be used with `cwltool` in subsequent steps:
```shell
mkdir tmp
mkdir cache
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **gdc_dnaseq_transform** workflow:
```shell
synapse get syn9962438 # gdc_dnaseq_transform_get.cwl.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `gdc_dnaseq_transform_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --tmpdir-prefix tmp/ --cachedir cache/ --non-strict dockstore-tool-synapse-get.cwl gdc_dnaseq_transform_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `transform.cwl` and parameterized by `transform.cwl.json`:
```shell
cwltool --cachedir cache/ --tmpdir-prefix tmp/ cwl/workflows/dnaseq/transform.cwl transform.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool gdc_dnaseq_transform_checker.cwl gdc_dnaseq_transform_checker.cwl.json
```

#### 6. Submit workflow outputs

I modified the parameters in `gdc_dnaseq_transform_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": """",
    ""eval_id"": ""9604596"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""123e4567-e89b-12d3-a456-426655440000.db""
        }
    ],
    ""parent_id"": ""syn10548077""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl gdc_dnaseq_transform_submit.cwl.json
```

---",9632183
gdc_dnaseq_transform,9632303_report.md,"## GDC DNA-seq Transform Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Jeremiah Savage""
workflow_handle: ""gdc_dnaseq_transform""
input_handle: ""NA12878 chr20""
```

The following description is provided by the workflow author:
> The GDC DNA-Seq Workflow aligns the reads in a BAM containing mapped or unmapped reads to a reference genome (GRCh38 with added viral sequence), outputing a BAM file, a BAI file, and a sqlite file containing quality and alignment metrics. The input BAM is converted to readgroup-separated FASTQ files using BIOBAMBAM, which are aligned with BWA, and then sorted, merged and duplicate marked with PICARD. Metrics are gathered at each phase of the workflow (FastQC, PICARD and SAMTOOLS metrics). The workflow has been validated with TCGA, TARGET, CCLE and 1000Genomes BAM files. The test case is NA12878 chr20, which requires about 1 hr of CPU time, and approximately 30G of disk space to complete.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""16GB""
suggested_disk: ""30GB""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Jacob Silterra"" # your name here
institution: ""None"" # your institution here
```

### Submission overview

I ran the workflow on the Google Compute Engine, using an Ubuntu VM. 

```YAML
date_accessed: ""2017-09-03"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""cwltool 1.0.20170822192924"" # indicate executor version used
docker_version: ""Docker version 1.12.6, build 78d1802"" # from `docker --version`
environment: ""Google Compute Engine"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""4"" # indicate number of cores in environment
env_memory: ""16"" # indicate available RAM in environment
env_disk: ""100GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```
> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-17""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""EC2"" 
env_cpus_ex: ""32""
env_memory_ex: ""244Gb""
env_disk_ex: ""elastic""
```

### Steps

#### 1. Set up environment

#####A. Set up local environment

Install Google Cloud SDK. I used Ubuntu Linux and followed the following instructions:
```shell
 Create an environment variable for the correct distribution
export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)""

# Add the Cloud SDK distribution URI as a package source
echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | sudo tee -a /etc/apt/sources.list.d/google-cloud-sdk.list

# Import the Google Cloud Platform public key
curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -

# Update the package list and install the Cloud SDK
sudo apt-get update && sudo apt-get install google-cloud-sdk
```

Instructions for other platforms available at https://cloud.google.com/sdk/docs/quickstarts.

##### B. Create remote VM

Create an account on Google Cloud Platform, and create a VM with 4 CPUs and 16 GB based on Ubuntu 16.04. 
Instructions available at https://cloud.google.com/compute/.

##### C. Connect to VM and install required packages

Connect to the remove VM by using gcloud SSH from your local machine. On the remote machine, install required packages:

```shell
sudo apt-get update
sudo apt-get install pip docker.io
sudo pip install synapseclient
sudo pip install pysftp
sudo pip install cwltool
sudo pip install cwlref-runner
# Add user to docker group
sudo usermod -aG docker <root username>
```
I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
remote: mkdir gdc_dnaseq_transform
```
Copy the synapse credentials file from local machine to remote:
```shell
remote_instance=""my_remote_instance_name"" # e.g. ubuntu-instance-1
zone=""my_zone"" # e.g. us-central1-a
local: gcloud compute scp ~/.synapseConfig ${remote_instance}:~/gdc_dnaseq_transform --zone ${zone}
```

Within the working directory, I created `tmp` and `cache` folders to be used with `cwltool` in subsequent steps:
```shell
remote: mkdir tmp cache
```

The rest of the instructions are all executed on the remote machine, from ~/gdc_dnaseq_transform

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **gdc_dnaseq_transform** workflow:
```shell

config=.synapseConfig
synapse -c $config get syn9962438 # gdc_dnaseq_transform_get.cwl.json
synapse -c $config get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse -c $config get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `gdc_dnaseq_transform_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --tmpdir-prefix tmp/ --cachedir cache/ --non-strict dockstore-tool-synapse-get.cwl gdc_dnaseq_transform_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `transform.cwl` and parameterized by `transform.cwl.json`:
```shell
nohup cwltool --cachedir cache/ --tmpdir-prefix tmp/ cwl/workflows/dnaseq/transform.cwl transform.cwl.json &
```
Running this workflow took about 2 hours (VM charges will apply)

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool gdc_dnaseq_transform_checker.cwl gdc_dnaseq_transform_checker.cwl.json
cat results.json | grep overall
```

#### 6. Submit workflow outputs

I modified the parameters in `gdc_dnaseq_transform_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": """",
    ""eval_id"": ""9604596"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""123e4567-e89b-12d3-a456-426655440000.db""
        }
    ],
    ""parent_id"": ""<my parent ID>""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl gdc_dnaseq_transform_submit.cwl.json
```

---",9632303
gdc_dnaseq_transform,9633528_report.md,"## GDC DNA-seq Transform Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Jeremiah Savage""
workflow_handle: ""gdc_dnaseq_transform""
input_handle: ""NA12878 chr20""
```

The following description is provided by the workflow author:
> The GDC DNA-Seq Workflow aligns the reads in a BAM containing mapped or unmapped reads to a reference genome (GRCh38 with added viral sequence), outputing a BAM file, a BAI file, and a sqlite file containing quality and alignment metrics. The input BAM is converted to readgroup-separated FASTQ files using BIOBAMBAM, which are aligned with BWA, and then sorted, merged and duplicate marked with PICARD. Metrics are gathered at each phase of the workflow (FastQC, PICARD and SAMTOOLS metrics). The workflow has been validated with TCGA, TARGET, CCLE and 1000Genomes BAM files. The test case is NA12878 chr20, which requires about 1 hr of CPU time, and approximately 30G of disk space to complete.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""16GB""
suggested_disk: ""30GB""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

```YAML
name: ""Byunggil Yoo""
institution: ""Children's Mercy Kansas City""
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-05"" 
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170817131858"" # indicate executor version used
docker_version: ""17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""48"" # indicate number of cores in environment
env_memory: ""512GB"" # indicate available RAM in environment
env_disk: ""368TB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessasry.

#### 1. Set up environment

On a node (CentOS 7.2.1511) of a local cluster with Docker (17.06.0-ce) and Anaconda installed, I created and configured a virtual environment using the following YAML file:

```
channels:
  - bioconda
  - conda-forge
  - anaconda
  - r
dependencies:
  - cwltool=1.0.20170817131858
  - synapseclient
```

I created a working directory for the current workflow and created a copy of my Synapse credentials (~/.synapseConfig) in that folder:

```shell
mkdir gdc_dnaseq_transform
cd gdc_dnaseq_transform
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **gdc_dnaseq_transform** workflow:
```shell
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
synapse get syn9962438 # gdc_dnaseq_transform_get.cwl.json
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `gdc_dnaseq_transform_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --outdir gdc_dnaseq_transform --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ \
        --non-strict dockstore-tool-synapse-get.cwl gdc_dnaseq_transform_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `transform.cwl` and parameterized by `transform.cwl.json`:
```shell
cwltool --basedir gdc_dnaseq_transform/ --outdir gdc_dnaseq_transform/ \
    --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
    gdc_dnaseq_transform/cwl/workflows/dnaseq/transform.cwl gdc_dnaseq_transform/gdc_dnaseq_transform.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool --basedir gdc_dnaseq_transform/ --outdir gdc_dnaseq_transform/ \
        --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
        gdc_dnaseq_transform/gdc_dnaseq_transform_checker.cwl gdc_dnaseq_transform/gdc_dnaseq_transform_checker.cwl.json
```

#### 6. Submit workflow outputs

I modified the parameters in `gdc_dnaseq_transform_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""Childrens Mercy GA4GH-DREAM Challenge Team"",
    ""eval_id"": ""9604596"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""123e4567-e89b-12d3-a456-426655440000.db""
        }
    ],
    ""parent_id"": ""syn10290419""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --basedir gdc_dnaseq_transform/ --outdir gdc_dnaseq_transform/ \
        --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
        dockstore-tool-synapse-submit.cwl gdc_dnaseq_transform/gdc_dnaseq_transform_submit.cwl.json
```

---",9633528
gdc_dnaseq_transform,9635418_report.md,"## GDC DNA-seq Transform Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Jeremiah Savage""
workflow_handle: ""gdc_dnaseq_transform""
input_handle: ""NA12878 chr20""
```

The following description is provided by the workflow author:
> The GDC DNA-Seq Workflow aligns the reads in a BAM containing mapped or unmapped reads to a reference genome (GRCh38 with added viral sequence), outputing a BAM file, a BAI file, and a sqlite file containing quality and alignment metrics. The input BAM is converted to readgroup-separated FASTQ files using BIOBAMBAM, which are aligned with BWA, and then sorted, merged and duplicate marked with PICARD. Metrics are gathered at each phase of the workflow (FastQC, PICARD and SAMTOOLS metrics). The workflow has been validated with TCGA, TARGET, CCLE and 1000Genomes BAM files. The test case is NA12878 chr20, which requires about 1 hr of CPU time, and approximately 30G of disk space to complete.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""16GB""
suggested_disk: ""30GB""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Jeff Johnston"" # your name here
institution: ""Children's Mercy"" # your institution here
```

#### Submission overview

Provide high level summary information for workflow execution in the fields below.

```YAML
date_accessed: ""2017-09-15"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170817131858"" # indicate executor version used
docker_version: ""17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""48"" # indicate number of cores in environment
env_memory: ""512GB"" # indicate available RAM in environment
env_disk: ""368TB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

#### 1. Setup

This workflow was run on CentOS Linux release 7.2.1511. Docker and Conda 4.3.25 were installed. A conda environment was built using the following conda YAML file:

```yaml
channels:
  - bioconda
  - conda-forge
  - anaconda
  - r
dependencies:
  - cwltool=1.0.20170817131858
  - synapseclient
```

The Synapse client was configured by editing `~/.synapseConfig`.

##### 2. Download

The following commands were run within the conda environment:

```shell
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
synapse get syn9962438 # gdc_dnaseq_transform_get.cwl.json
cwltool --outdir gdc_dnaseq_transform --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ \
        --non-strict dockstore-tool-synapse-get.cwl gdc_dnaseq_transform_get.cwl.json
cp ~/.synapseConfig gdc_dnaseq_transform
```

##### 3. Run

Next, the workflow was executed in the conda environment.

```shell
cwltool --basedir gdc_dnaseq_transform/ --outdir gdc_dnaseq_transform/ \
    --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
    gdc_dnaseq_transform/cwl/workflows/dnaseq/transform.cwl gdc_dnaseq_transform/gdc_dnaseq_transform.json
```

##### 4. Validate

After running, the workflow results were validated:

```shell
cwltool --basedir gdc_dnaseq_transform/ --outdir gdc_dnaseq_transform/ \
        --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
        gdc_dnaseq_transform/gdc_dnaseq_transform_checker.cwl gdc_dnaseq_transform/gdc_dnaseq_transform_checker.cwl.json
```

##### 5. Submit

`gdc_dnaseq_transform_submit.cwl.json` was modified for submission:

```yaml
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""Childrens Mercy GA4GH-DREAM Challenge Team"",
    ""eval_id"": ""9604596"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""123e4567-e89b-12d3-a456-426655440000.db""
        }
    ],
    ""parent_id"": ""syn10290419""
}
```

Finally, results were submitted:

```shell
cwltool --basedir gdc_dnaseq_transform/ --outdir gdc_dnaseq_transform/ \
        --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
        dockstore-tool-synapse-submit.cwl gdc_dnaseq_transform/gdc_dnaseq_transform_submit.cwl.json
```

---",9635418
gdc_dnaseq_transform,9635965_report.md,"## GDC DNA-seq Transform Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Jeremiah Savage""
workflow_handle: ""gdc_dnaseq_transform""
input_handle: ""NA12878 chr20""
```

The following description is provided by the workflow author:
> The GDC DNA-Seq Workflow aligns the reads in a BAM containing mapped or unmapped reads to a reference genome (GRCh38 with added viral sequence), outputing a BAM file, a BAI file, and a sqlite file containing quality and alignment metrics. The input BAM is converted to readgroup-separated FASTQ files using BIOBAMBAM, which are aligned with BWA, and then sorted, merged and duplicate marked with PICARD. Metrics are gathered at each phase of the workflow (FastQC, PICARD and SAMTOOLS metrics). The workflow has been validated with TCGA, TARGET, CCLE and 1000Genomes BAM files. The test case is NA12878 chr20, which requires about 1 hr of CPU time, and approximately 30G of disk space to complete.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""16GB""
suggested_disk: ""30GB""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Jeff Johnston"" # your name here
institution: ""Children's Mercy"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

```YAML
date_accessed: ""2017-09-15"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170817131858"" # indicate executor version used
docker_version: ""17.06.2-ce, build cec0b72"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""1"" # indicate number of cores in environment
env_memory: ""8GB"" # indicate available RAM in environment
env_disk: ""133GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

#### 1. Setup

This workflow was run on a MacBook Pro running macOS 10.12.6. Docker and Miniconda2 were installed. Docker was configured to use 1 core and 8GB of RAM. A conda environment was built using the following conda YAML file:

```yaml
channels:
  - bioconda
  - conda-forge
  - anaconda
  - r
dependencies:
  - cwltool=1.0.20170817131858
  - synapseclient
```

The Synapse client was configured by editing `~/.synapseConfig`.

##### 2. Download

The following commands were run within the conda environment:

```shell
conda
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
synapse get syn9962438 # gdc_dnaseq_transform_get.cwl.json
cwltool --outdir gdc_dnaseq_transform --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ \
        --non-strict dockstore-tool-synapse-get.cwl gdc_dnaseq_transform_get.cwl.json
cp ~/.synapseConfig gdc_dnaseq_transform
```

##### 3. Run

Next, the workflow was executed in the conda environment.

```shell
cwltool --basedir gdc_dnaseq_transform/ --outdir gdc_dnaseq_transform/ \
    --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
    gdc_dnaseq_transform/cwl/workflows/dnaseq/transform.cwl gdc_dnaseq_transform/gdc_dnaseq_transform.json
```

##### 4. Validate

After running, the workflow results were validated:

```shell
cwltool --basedir gdc_dnaseq_transform/ --outdir gdc_dnaseq_transform/ \
        --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
        gdc_dnaseq_transform/gdc_dnaseq_transform_checker.cwl gdc_dnaseq_transform/gdc_dnaseq_transform_checker.cwl.json
```

##### 5. Submit

`gdc_dnaseq_transform_submit.cwl.json` was modified for submission:

```yaml
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""Childrens Mercy GA4GH-DREAM Challenge Team"",
    ""eval_id"": ""9604596"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""123e4567-e89b-12d3-a456-426655440000.db""
        }
    ],
    ""parent_id"": ""syn10290419""
}
```

Finally, results were submitted:

```shell
cwltool --basedir gdc_dnaseq_transform/ --outdir gdc_dnaseq_transform/ \
        --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
        dockstore-tool-synapse-submit.cwl gdc_dnaseq_transform/gdc_dnaseq_transform_submit.cwl.json
```

---
",9635965
gdc_dnaseq_transform,9636352_report.md,"## GDC DNA-seq Transform Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Jeremiah Savage""
workflow_handle: ""gdc_dnaseq_transform""
input_handle: ""NA12878 chr20""
```

The following description is provided by the workflow author:
> The GDC DNA-Seq Workflow aligns the reads in a BAM containing mapped or unmapped reads to a reference genome (GRCh38 with added viral sequence), outputing a BAM file, a BAI file, and a sqlite file containing quality and alignment metrics. The input BAM is converted to readgroup-separated FASTQ files using BIOBAMBAM, which are aligned with BWA, and then sorted, merged and duplicate marked with PICARD. Metrics are gathered at each phase of the workflow (FastQC, PICARD and SAMTOOLS metrics). The workflow has been validated with TCGA, TARGET, CCLE and 1000Genomes BAM files. The test case is NA12878 chr20, which requires about 1 hr of CPU time, and approximately 30G of disk space to complete.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""16GB""
suggested_disk: ""30GB""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Vipin T. Sreedharan""
institution: ""ETH Zürich, NEXUS Personalized Health Technologies""
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-20"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170828135420"" # indicate executor version used
docker_version: ""1.12.6"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""32Gb"" # indicate available RAM in environment
env_disk: ""140Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessasry.

#### 1. Set up environment

At our institute, on a compute machine called `wfexec` with Red Hat Enterprise Linux Server release 7.4 (Maipo), installed Docker. Created a group named ""docker"" since it was preferred to use Docker as a non-root user on this machine. The instance has a non-root user called `wfrunner`. Next added the non-root user `wfrunner` to the ""docker"" group. Then started the docker engine and all the below commands were executed using root user privileges [sudo]:
```shell
yum install docker
groupadd docker 
usermod -aG docker wfrunner  
systemctl start docker 
```
&nbsp;

As a non-root user on `wfexec` machine, installed Anaconda and cwltool to the home path of user `wfrunner`:
```shell
su - wfrunner
wget https://repo.continuum.io/archive/Anaconda2-4.4.0-Linux-x86_64.sh
bash Anaconda2-4.4.0-Linux-x86_64.sh 
conda install virtualenv
virtualenv -p python2 /home/wfrunner/venv
source /home/wfrunner/venv/bin/activate
pip install cwltools
deactivate
```
&nbsp;

Created a utilities directory for storing the `synapse-get` and `synapse-submit` CWL tools. In the same folder, created a file with my Synapse credentials. 
```shell
mkdir -p /home/wfrunner/synapse_utils
cd /home/wfrunner/synapse_utils
wget -O dockstore-tool-synapse-get.cwl https://raw.githubusercontent.com/GA4GH-DREAM/dockstore-tool-synapse-get/master/Dockstore.cwl 
wget -O dockstore-tool-synapse-submit.cwl https://raw.githubusercontent.com/GA4GH-DREAM/dockstore-tool-synapse-submit/master/Dockstore.cwl
touch .synapse_config
vim .synapse_config
[WRITE] Synapse username & password
```

#### 2. Download required files

Downloaded data config file gdc_dnaseq_transform_get.cwl.json from the website `https://www.synapse.org/#!Synapse:syn8507133/wiki/451410` for the **gdc_dnaseq_transform** workflow. Created a directory for the storing the workflow associated data downloading JSON parameter file: 
```shell
mkdir -p /home/wfrunner/data_config_files
mv ~/gdc_dnaseq_transform_get.cwl.json ~/data_config_files
cd /home/wfrunner/data_config_files
vim gdc_dnaseq_transform_get.cwl.json
[PASTE] /home/wfrunner/synapse_utils/.synapse_config
```

#### 3. Provision all workflow files

Created a working directory for the current workflow. Used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `gdc_dnaseq_transform_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
mkdir -p /home/wfrunner/gdc_dnaseq_transform
cd /home/wfrunner/gdc_dnaseq_transform
cwltool --tmpdir-prefix /home/wfrunner/tmp/ --cachedir /home/wfrunner/tmp/cache --debug --non-strict ~/synapse_utils/dockstore-tool-synapse-get.cwl ~/config_files/gdc_dnaseq_transform_get.cwl.json
```

#### 4. Run main workflow

Again `cwltool` was used to run the workflow, as defined in `cwl/workflows/dnaseq/transform.cwl` and parameterized by `transform.cwl.json `:
```shell
cd /home/wfrunner/gdc_dnaseq_transform
cwltool --tmpdir-prefix /home/wfrunner/tmp/ --cachedir /home/wfrunner/tmp/cache --debug --non-strict cwl/workflows/dnaseq/transform.cwl transform.cwl.json 
```

#### 5. Run workflow checker tool

To verify workflow results before submission, used `cwltool` to run the checker as follows:
```shell
cd /home/wfrunner/gdc_dnaseq_transform
cwltool --tmpdir-prefix /home/wfrunner/tmp/ --cachedir /home/wfrunner/tmp/cache --debug --non-strict gdc_dnaseq_transform_checker.cwl gdc_dnaseq_transform_checker.cwl.json
cat results.json | grep overall
[OUTPUT] ""overall"": true,
```

#### 6. Submit workflow outputs

Modified the parameters in `gdc_dnaseq_transform_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": ""/home/wfrunner/synapse_utils/.synapse_config""
    },
    ""team_name"": """",
    ""eval_id"": ""9604596"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""123e4567-e89b-12d3-a456-426655440000.db""
        }
    ],
    ""parent_id"": ""syn10850042""
}
```
&nbsp;

Finally, submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cd /home/wfrunner/gdc_dnaseq_transform
cwltool --tmpdir-prefix /home/wfrunner/tmp/ --cachedir /home/wfrunner/tmp/cache --debug --non-strict ~/synapse_utils/dockstore-tool-synapse-submit.cwl gdc_dnaseq_transform_submit.cwl.json
```

---",9636352
gdc_dnaseq_transform,9636460_report.md,"## GDC DNA-seq Transform Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Jeremiah Savage""
workflow_handle: ""gdc_dnaseq_transform""
input_handle: ""NA12878 chr20""
```

The following description is provided by the workflow author:
> The GDC DNA-Seq Workflow aligns the reads in a BAM containing mapped or unmapped reads to a reference genome (GRCh38 with added viral sequence), outputing a BAM file, a BAI file, and a sqlite file containing quality and alignment metrics. The input BAM is converted to readgroup-separated FASTQ files using BIOBAMBAM, which are aligned with BWA, and then sorted, merged and duplicate marked with PICARD. Metrics are gathered at each phase of the workflow (FastQC, PICARD and SAMTOOLS metrics). The workflow has been validated with TCGA, TARGET, CCLE and 1000Genomes BAM files. The test case is NA12878 chr20, which requires about 1 hr of CPU time, and approximately 30G of disk space to complete.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""16GB""
suggested_disk: ""30GB""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Gary Luu"" # your name here
institution: ""Dockstore - OICR"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-20"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""dockstore 1.2.10"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.2.10"" # indicate executor version used
docker_version: ""17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""4"" # indicate number of cores in environment
env_memory: ""32 GB"" # indicate available RAM in environment
env_disk: ""470 GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```
> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-17""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""EC2"" 
env_cpus_ex: ""32""
env_memory_ex: ""244Gb""
env_disk_ex: ""elastic""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessasry.

#### 1. Set up environment

On a personal desktop, I installed Docker, pip, cwltool, and the Dockstore command-line helper using a procedure similar to https://github.com/denis-yuen/2017-cloud-workflows-misc/blob/master/install-and-run-with-dockstore.md .  
However, I used my own modified dockstore CLI (which will be 1.2.7)

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir gdc_dnaseq_files
cd gdc_dnaseq_files
cp ~/.synapseConfig .
```
#### 2. Download required files

I downloaded gdc_dnaseq_transform_get.cwl.json from the website. 


#### 3. Provision all workflow files

I used the synapse-get tool from Dockstore.
```shell
dockstore tool launch --entry quay.io/ga4gh-dream/dockstore-tool-synapse-get --json gdc_dnaseq_transform_get.cwl.json
```

#### 4. Run main workflow

I used dockstore to launch the recently downloaded transform.cwl
```shell
dockstore workflow launch --local-entry cwl/workflows/dnaseq/transform.cwl --json transform.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `dockstore` to run the checker as follows:
```shell
dockstore tool launch --local-entry gdc_dnaseq_transform_checker.cwl --json gdc_dnaseq_transform_checker.cwl.json
cat results.json | grep overall
```

#### 6. Submit workflow outputs

I modified the parameters in `gdc_dnaseq_transform_submit.cwl.json` as follows:
```
""team_name"": ""Dockstore Team"",
""parent_id"": ""syn9877725""
```

Finally, I submitted outputs using dockstore-tool-synapse-submit`:
```shell
dockstore tool launch --entry quay.io/ga4gh-dream/dockstore-tool-synapse-submit --json gdc_dnaseq_transform_submit.cwl.json
```

---",9636460
gdc_dnaseq_transform,9636718_report.md,"## GDC DNA-seq Transform Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Jeremiah Savage""
workflow_handle: ""gdc_dnaseq_transform""
input_handle: ""NA12878 chr20""
```

The following description is provided by the workflow author:
> The GDC DNA-Seq Workflow aligns the reads in a BAM containing mapped or unmapped reads to a reference genome (GRCh38 with added viral sequence), outputing a BAM file, a BAI file, and a sqlite file containing quality and alignment metrics. The input BAM is converted to readgroup-separated FASTQ files using BIOBAMBAM, which are aligned with BWA, and then sorted, merged and duplicate marked with PICARD. Metrics are gathered at each phase of the workflow (FastQC, PICARD and SAMTOOLS metrics). The workflow has been validated with TCGA, TARGET, CCLE and 1000Genomes BAM files. The test case is NA12878 chr20, which requires about 1 hr of CPU time, and approximately 30G of disk space to complete.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""16GB""
suggested_disk: ""30GB""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Jonathon Saunders"" # your name here
institution: ""Children's Mercy Hospital"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-07-19"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170817131858"" # indicate executor version used
docker_version: ""Docker version 17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""4"" # indicate number of cores in environment
env_memory: ""16"" # indicate available RAM in environment
env_disk: ""500gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```
> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-17""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""EC2"" 
env_cpus_ex: ""32""
env_memory_ex: ""244Gb""
env_disk_ex: ""elastic""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessasry.

#### 1. Set up environment

**example:** *I launched an EC2 instance of type `r4.8xlarge` with one node, mounted an EFS volume, and installed Docker.*

I created and configured a virtual environment as follows:
```shell
mkvirtualenv --python /usr/bin/python2 cwl
pip install --upgrade pip
pip install 'requests[security]' --no-cache-dir
pip install schema-salad==2.2.20170222151604 cwltool==1.0.20170217172322 --no-cache-dir
pip install synapseclient --no-cache-dir
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir syn9766994
cd syn9766994
cp ~/.synapseConfig .
```

Within the working directory, I created `tmp` and `cache` folders to be used with `cwltool` in subsequent steps:
```shell
mkdir tmp cache
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **gdc_dnaseq_transform** workflow:
```shell
synapse get syn9962438 # gdc_dnaseq_transform_get.cwl.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `gdc_dnaseq_transform_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --tmpdir-prefix tmp/ --cachedir cache/ --non-strict dockstore-tool-synapse-get.cwl gdc_dnaseq_transform_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `transform.cwl` and parameterized by `transform.cwl.json`:
```shell
nohup cwltool --cachedir cache/ --tmpdir-prefix tmp/ cwl/workflows/dnaseq/transform.cwl transform.cwl.json &
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool gdc_dnaseq_transform_checker.cwl gdc_dnaseq_transform_checker.cwl.json
cat results.json | grep overall
```

#### 6. Submit workflow outputs

I modified the parameters in `gdc_dnaseq_transform_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""CDIS"",
    ""eval_id"": ""9604596"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""123e4567-e89b-12d3-a456-426655440000.db""
        }
    ],
    ""parent_id"": ""syn123456""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl gdc_dnaseq_transform_submit.cwl.json
```

---",9636718
gdc_dnaseq_transform,9637603_report.md,"## GDC DNA-seq Transform Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Jeremiah Savage""
workflow_handle: ""gdc_dnaseq_transform""
input_handle: ""NA12878 chr20""
```

The following description is provided by the workflow author:
> The GDC DNA-Seq Workflow aligns the reads in a BAM containing mapped or unmapped reads to a reference genome (GRCh38 with added viral sequence), outputing a BAM file, a BAI file, and a sqlite file containing quality and alignment metrics. The input BAM is converted to readgroup-separated FASTQ files using BIOBAMBAM, which are aligned with BWA, and then sorted, merged and duplicate marked with PICARD. Metrics are gathered at each phase of the workflow (FastQC, PICARD and SAMTOOLS metrics). The workflow has been validated with TCGA, TARGET, CCLE and 1000Genomes BAM files. The test case is NA12878 chr20, which requires about 1 hr of CPU time, and approximately 30G of disk space to complete.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""16GB""
suggested_disk: ""30GB""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Abraham Chavez"" # your name here
institution: ""UCSC"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170217172322"" # indicate executor version used
docker_version: ""17.06.0-ce"" # from `docker --version`
environment: ""Google CC"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""4"" # indicate number of cores in environment
env_memory: ""16Gb"" # indicate available RAM in environment
env_disk: ""200Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```
### Steps

#### 1. Set up environment

#####
If you have not set up your environment and install dependencies like **cwltool**, **dockstore**, **java** and so on
I recommend you follow [**this**](https://www.synapse.org/#!Synapse:syn10220609) instructions.
>**NOTE:** When configuring `docker` to run as root. You might encounter problems setting the credentials as directed in digital ocean, try replacing `su - ${USER}` with `sudo su -` and running `usermod -aG docker ${USER}` and `su - ${USER}` inside root terminal.

#####
I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir syn9766994
cd syn9766994
cp ~/.synapseConfig .
```
Information about `.synapseConfig` can be found [**here**](https://www.synapse.org/#!Synapse:syn8507133/wiki/4514
#####
Within the working directory, I created `tmp` and `cache` folders to be used with `cwltool` in subsequent steps:
```shell
mkdir tmp cache
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **gdc_dnaseq_transform** workflow:
```shell
synapse get syn9962438 # gdc_dnaseq_transform_get.cwl.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `gdc_dnaseq_transform_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --tmpdir-prefix tmp/ --cachedir cache/ --non-strict dockstore-tool-synapse-get.cwl gdc_dnaseq_transform_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `transform.cwl` and parameterized by `transform.cwl.json`:
```
nohup cwltool --cachedir cache/ --tmpdir-prefix tmp/ cwl/workflows/dnaseq/transform.cwl transform.cwl.json &
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool gdc_dnaseq_transform_checker.cwl gdc_dnaseq_transform_checker.cwl.json
cat results.json | grep overall
```

#### 6. Submit workflow outputs

I modified the parameters in `gdc_dnaseq_transform_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""Your Team Name"",
    ""eval_id"": ""9604596"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""123e4567-e89b-12d3-a456-426655440000.db""
        }
    ],
    ""parent_id"": ""YourParentId""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl gdc_dnaseq_transform_submit.cwl.json
```

---",9637603
gdc_dnaseq_transform,9637793_report.md,"## GDC DNA-seq Transform Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Jeremiah Savage""
workflow_handle: ""gdc_dnaseq_transform""
input_handle: ""NA12878 chr20""
```

The following description is provided by the workflow author:
> The GDC DNA-Seq Workflow aligns the reads in a BAM containing mapped or unmapped reads to a reference genome (GRCh38 with added viral sequence), outputing a BAM file, a BAI file, and a sqlite file containing quality and alignment metrics. The input BAM is converted to readgroup-separated FASTQ files using BIOBAMBAM, which are aligned with BWA, and then sorted, merged and duplicate marked with PICARD. Metrics are gathered at each phase of the workflow (FastQC, PICARD and SAMTOOLS metrics). The workflow has been validated with TCGA, TARGET, CCLE and 1000Genomes BAM files. The test case is NA12878 chr20, which requires about 1 hr of CPU time, and approximately 30G of disk space to complete.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""16GB""
suggested_disk: ""30GB""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Thomas B. Mooney"" # your name here
institution: ""MGI WUSTL"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-26"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170828135420"" # indicate executor version used
docker_version: ""17.06.2-ce"" # from `docker --version`
environment: ""local openstack VM"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""2"" # indicate number of cores in environment
env_memory: ""64 GB"" # indicate available RAM in environment
env_disk: 160 GB"""" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessasry.

#### 1. Set up environment

Spin up a new OpenStack VM with a Xenial cloud image, then install [docker](https://docs.docker.com/engine/installation/linux/docker-ce/ubuntu/) and  [pyenv](https://github.com/pyenv/pyenv-installer).
Then install the tools to obtain and run the workflows:
```shell
pyenv install 2.7.14
pyenv shell 2.7.14
pip install cwltool
pip install synapseclient
```

Create a directory to hold the results and link in the configuration for connecting to synapse:
```shell
mkdir -p ~/ga4gh/gdc_dnaseq_transform
cd ~/ga4gh/gdc_dnaseq_transform
ln -s ~/.synapseConfig .synapseConfig
```

#### 2. Download required files

Download the tools for getting/submitting workflows and the ""gdc_dnaseq_transform"" workflow data:
```shell
synapse get syn9962438 # gdc_dnaseq_transform_get.cwl.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

The dockstore tool CWL files contain extra information, so the ""get"" workflow must be run with the `--non-strict` option:
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl gdc_dnaseq_transform_get.cwl.json
```

#### 4. Run main workflow

Now run the workflow obtained in the previous step, again with `cwltool`:
```shell
cwltool  cwl/workflows/dnaseq/transform.cwl transform.cwl.json
```

#### 5. Run workflow checker tool

Then the checker workflow is run to verify the results:
```shell
cwltool gdc_dnaseq_transform_checker.cwl gdc_dnaseq_transform_checker.cwl.json
```

This produces a report, `results.json`:
```JSON
{
    ""overall"": true,
    ""steps"": {
        ""average_quality_samtools_stats"": true,
        ""bases_duplicated_samtools_stats"": true,
        ""bases_mapped_samtools_stats"": true,
        ""count_fastq_files"": true,
        ""count_files_output"": true,
        ""count_readgroups"": true,
        ""raw_total_seq_samtools_stats"": true,
        ""read_pair_dups_picard_markduplicates"": true,
        ""read_pairs_picard_markduplicates"": true,
        ""read_unmapped_samtools_stats"": true,
        ""reads_dup_samtools_stats"": true,
        ""reads_mapped_and_paired_samtools_stats"": true,
        ""reads_mapped_samtools_stats"": true,
        ""reads_paired_samtool_stats"": true,
        ""seqs_samtools_stats"": true,
        ""total_length_samtools_stats"": true
    }
}
```

#### 6. Submit workflow outputs

Modify `gdc_dnaseq_transform_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""MGI WUSTL"",
    ""eval_id"": ""9604596"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""123e4567-e89b-12d3-a456-426655440000.db""
        }
    ],
    ""parent_id"": ""syn10912238""
}
```

Finally, run the workflow to submit the results:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl gdc_dnaseq_transform_submit.cwl.json
```

---",9637793
gdc_dnaseq_transform,9638082_report.md,"## GDC DNA-seq Transform Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Jeremiah Savage""
workflow_handle: ""gdc_dnaseq_transform""
input_handle: ""NA12878 chr20""
```

The following description is provided by the workflow author:
> The GDC DNA-Seq Workflow aligns the reads in a BAM containing mapped or unmapped reads to a reference genome (GRCh38 with added viral sequence), outputing a BAM file, a BAI file, and a sqlite file containing quality and alignment metrics. The input BAM is converted to readgroup-separated FASTQ files using BIOBAMBAM, which are aligned with BWA, and then sorted, merged and duplicate marked with PICARD. Metrics are gathered at each phase of the workflow (FastQC, PICARD and SAMTOOLS metrics). The workflow has been validated with TCGA, TARGET, CCLE and 1000Genomes BAM files. The test case is NA12878 chr20, which requires about 1 hr of CPU time, and approximately 30G of disk space to complete.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""16GB""
suggested_disk: ""30GB""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Vipin T. Sreedharan"" # your name here
institution: ""ETH Zürich, NEXUS Personalized Health Technologies"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

```YAML
date_accessed: ""2017-09-28"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""Rabix"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""rabix 1.0.0"" # indicate executor version used
docker_version: ""1.12.6, build c4618fb"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""32Gb"" # indicate available RAM in environment
env_disk: ""140Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessasry.

#### 1. Set up environment

At our institute, on a compute machine called `wfexec` with Red Hat Enterprise Linux Server release 7.4 (Maipo), installed Docker. Created a group named ""docker"" since it was preferred to use Docker as a non-root user on this machine. The instance has a non-root user called `wfrunner`. Next added the non-root user `wfrunner` to the ""docker"" group. Then started the docker engine and all the below commands were executed using root user privileges [sudo]:
```shell
yum install docker
groupadd docker 
usermod -aG docker wfrunner  
systemctl start docker 
# required for Rabix
yum install java-1.8.0-openjdk-devel.x86_64 
```

As a non-root user `wfrunner` on `wfexec` machine, installed Anaconda and Rabix to the home path:
```shell
su - wfrunner
wget https://repo.continuum.io/archive/Anaconda2-4.4.0-Linux-x86_64.sh
bash Anaconda2-4.4.0-Linux-x86_64.sh 
conda install virtualenv
virtualenv -p python2 /home/wfrunner/venv
source /home/wfrunner/venv/bin/activate
pip install cwltools
deactivate
conda install -c bioconda synapseclient
wget https://github.com/rabix/bunny/releases/download/v1.0.0/rabix-1.0.0.tar.gz -O rabix-1.0.0.tar.gz
tar -xzf rabix-1.0.0.tar.gz
export PATH=$PATH:/home/wfrunner/rabix-cli-1.0.0/
```

Created a utilities directory for storing the `synapse-get` and `synapse-submit` CWL tools. In the same folder, created Synapse credential file `.synapse_config` and put there Synapse ID and password. 
```shell
mkdir -p /home/wfrunner/synapse_utils
cd /home/wfrunner/synapse_utils
wget -O dockstore-tool-synapse-get.cwl https://raw.githubusercontent.com/GA4GH-DREAM/dockstore-tool-synapse-get/master/Dockstore.cwl 
wget -O dockstore-tool-synapse-submit.cwl https://raw.githubusercontent.com/GA4GH-DREAM/dockstore-tool-synapse-submit/master/Dockstore.cwl
touch .synapse_config
vim .synapse_config
[WRITE] Synapse username & password
```

#### 2. Provision all workflow files

Created a working directory for the current workflow. 
```shell
mkdir -p /home/wfrunner/gdc_dnaseq_transform
cd /home/wfrunner/gdc_dnaseq_transform
```
Used `synapseclient ` with targetId `syn9766994` to download workflow input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
synapse get -r syn9766994
[PASTE] username & password
```
Wait until downloading is finished.

#### 3. Run main workflow

Before running the workflow, I followed some instructions from this submission `https://www.synapse.org/#!Synapse:syn10208961`. Minor modifications are performed on tools `bwa_pe.cwl` and `bwa_se.cwl`. To get the modified tools: 
```shell
cd /home/wfrunner/gdc_dnaseq_transform
synapse get -r syn10245653
[PASTE] username & password

mv bwa_se.cwl cwl/tools/bwa_se.cwl
mv bwa_pe.cwl cwl/tools/bwa_pe.cwl
```
Then use `rabix` to run the workflow, as defined in `cwl/workflows/dnaseq/transform.cwl` and parameterized by `transform.cwl.json`:
```shell
rabix --tmpdir-prefix ~/tmp/ --tmp-outdir-prefix ~/tmp/ cwl/workflows/dnaseq/transform.cwl transform.cwl.json
```
Wait for the run to finish. 

#### 4. Run workflow checker tool 

Before running the checker tool, modified the parameter in `gdc_dnaseq_transform_checker.cwl.json`:
```shell
cd /home/wfrunner/gdc_dnaseq_transform
find -iname ""*.db""
vim gdc_dnaseq_transform_checker.cwl.json 
```
Paste the correct value as: 
```JSON
{   
    ""input_json_expected_metrics"": {
        ""class"": ""File"",
        ""path"": ""checker/expected_NA12878.chrom20.ILLUMINA.bwa.CEU.low_coverage.20121211.json""
    },
    ""input_sqlite_metrics"": {
        ""class"": ""File"",
        ""path"": ""./transform-2017-09-28-120026.650/root/merge_all_sqlite/123e4567-e89b-12d3-a456-426655440000.db""
    }
}
``` 

Run checker tool to validate workflow results before submission as follows:
```shell
cd /home/wfrunner/gdc_dnaseq_transform
rabix --tmpdir-prefix ~/tmp/ --tmp-outdir-prefix ~/tmp/ gdc_dnaseq_transform_checker.cwl gdc_dnaseq_transform_checker.cwl.json
```

Check results:
```shell
cd /home/wfrunner/gdc_dnaseq_transform
cat ./gdc_dnaseq_transform_checker-2017-09-28-124934.891/root/results.json | grep -i overall 
[OUTPUT]        ""overall"": true,
```

#### 5. Submit workflow outputs

Modified the parameters in  `gdc_dnaseq_transform_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": ""/home/wfrunner/synapse_utils/.synapse_config""
    },
    ""team_name"": ""CDIS"",
    ""eval_id"": ""9604596"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""./transform-2017-09-28-120026.650/root/merge_all_sqlite/123e4567-e89b-12d3-a456-426655440000.db""
        }
    ],
    ""parent_id"": ""syn10920269""
}
```

Finally, submitted outputs using the submission tool `dockstore-tool-synapse-submit.cwl`:
```shell
cd /home/wfrunner/gdc_dnaseq_transform
rabix --tmpdir-prefix ~/tmp/ --tmp-outdir-prefix ~/tmp/ ~/synapse_utils/dockstore-tool-synapse-submit.cwl gdc_dnaseq_transform_submit.cwl.json
```
---",9638082
gdc_dnaseq_transform,9646109_report.md,"## GDC DNA-seq Transform Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Jeremiah Savage""
workflow_handle: ""gdc_dnaseq_transform""
input_handle: ""NA12878 chr20""
```

The following description is provided by the workflow author:
> The GDC DNA-Seq Workflow aligns the reads in a BAM containing mapped or unmapped reads to a reference genome (GRCh38 with added viral sequence), outputing a BAM file, a BAI file, and a sqlite file containing quality and alignment metrics. The input BAM is converted to readgroup-separated FASTQ files using BIOBAMBAM, which are aligned with BWA, and then sorted, merged and duplicate marked with PICARD. Metrics are gathered at each phase of the workflow (FastQC, PICARD and SAMTOOLS metrics). The workflow has been validated with TCGA, TARGET, CCLE and 1000Genomes BAM files. The test case is NA12878 chr20, which requires about 1 hr of CPU time, and approximately 30G of disk space to complete.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""16GB""
suggested_disk: ""30GB""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Madelyn Reyes""
institution: ""ISB-CGC/CSRA"" 
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""09/29/2017"" 
platform: ""cwltool"" 
workflow_type: ""CWL"" 
runner_version: ""1.0.20170217172322""
docker_version: ""17.09.0-ce, build afdb6d4"" 
environment: ""Google Compute"" 
env_cpus: ""8""
env_memory: ""35GB""
env_disk: ""250 GB"" 
```
> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-17""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""EC2"" 
env_cpus_ex: ""32""
env_memory_ex: ""244Gb""
env_disk_ex: ""elastic""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessasry.

#### 1. Set up environment

**example:** *I launched an EC2 instance of type `r4.8xlarge` with one node, mounted an EFS volume, and installed Docker.*

I created and configured a virtual environment as follows:
```shell
mkvirtualenv --python /usr/bin/python2 cwl
pip install --upgrade pip
pip install 'requests[security]' --no-cache-dir
pip install schema-salad==2.2.20170222151604 cwltool==1.0.20170217172322 --no-cache-dir
pip install synapseclient --no-cache-dir
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir syn9766994
cd syn9766994
cp ~/.synapseConfig .
```

Within the working directory, I created `tmp` and `cache` folders to be used with `cwltool` in subsequent steps:
```shell
mkdir tmp cache
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **gdc_dnaseq_transform** workflow:
```shell
synapse get syn9962438 # gdc_dnaseq_transform_get.cwl.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `gdc_dnaseq_transform_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --tmpdir-prefix tmp/ --cachedir cache/ --non-strict dockstore-tool-synapse-get.cwl gdc_dnaseq_transform_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `transform.cwl` and parameterized by `transform.cwl.json`:
```shell
nohup cwltool --cachedir cache/ --tmpdir-prefix tmp/ cwl/workflows/dnaseq/transform.cwl transform.cwl.json &
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool gdc_dnaseq_transform_checker.cwl gdc_dnaseq_transform_checker.cwl.json
cat results.json | grep overall
```

#### 6. Submit workflow outputs

I modified the parameters in `gdc_dnaseq_transform_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""CDIS"",
    ""eval_id"": ""9604596"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""123e4567-e89b-12d3-a456-426655440000.db""
        }
    ],
    ""parent_id"": ""syn123456""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl gdc_dnaseq_transform_submit.cwl.json
```

---",9646109
gdc_dnaseq_transform,9646311_report.md,"## GDC DNA-seq Transform Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Jeremiah Savage""
workflow_handle: ""gdc_dnaseq_transform""
input_handle: ""NA12878 chr20""
```

The following description is provided by the workflow author:
> The GDC DNA-Seq Workflow aligns the reads in a BAM containing mapped or unmapped reads to a reference genome (GRCh38 with added viral sequence), outputing a BAM file, a BAI file, and a sqlite file containing quality and alignment metrics. The input BAM is converted to readgroup-separated FASTQ files using BIOBAMBAM, which are aligned with BWA, and then sorted, merged and duplicate marked with PICARD. Metrics are gathered at each phase of the workflow (FastQC, PICARD and SAMTOOLS metrics). The workflow has been validated with TCGA, TARGET, CCLE and 1000Genomes BAM files. The test case is NA12878 chr20, which requires about 1 hr of CPU time, and approximately 30G of disk space to complete.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""16GB""
suggested_disk: ""30GB""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Todd Pihl"" # your name here
institution: ""ISB-CGC/CSRA Inc."" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-10-19"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""cwl"" # CWL or WDL
runner_version: ""1.0.20170217172322"" # indicate executor version used
docker_version: ""17.06.2-ce, build cec0b72"" # from `docker --version`
environment: ""Google Compute"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""35M"" # indicate available RAM in environment
env_disk: ""250G"" # indicate available disk space, or note ""elastic"" for EFS et al.
```
> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-17""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""EC2"" 
env_cpus_ex: ""32""
env_memory_ex: ""244Gb""
env_disk_ex: ""elastic""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessasry.

#### 1. Set up environment

**example:** *I launched an EC2 instance of type `r4.8xlarge` with one node, mounted an EFS volume, and installed Docker.*

I created and configured a virtual environment as follows:
```shell
mkvirtualenv --python /usr/bin/python2 cwl
pip install --upgrade pip
pip install 'requests[security]' --no-cache-dir
pip install schema-salad==2.2.20170222151604 cwltool==1.0.20170217172322 --no-cache-dir
pip install synapseclient --no-cache-dir
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir syn9766994
cd syn9766994
cp ~/.synapseConfig .
```

Within the working directory, I created `tmp` and `cache` folders to be used with `cwltool` in subsequent steps:
```shell
mkdir tmp cache
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **gdc_dnaseq_transform** workflow:
```shell
synapse get syn9962438 # gdc_dnaseq_transform_get.cwl.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `gdc_dnaseq_transform_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --tmpdir-prefix tmp/ --cachedir cache/ --non-strict dockstore-tool-synapse-get.cwl gdc_dnaseq_transform_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `transform.cwl` and parameterized by `transform.cwl.json`:
```shell
nohup cwltool --cachedir cache/ --tmpdir-prefix tmp/ cwl/workflows/dnaseq/transform.cwl transform.cwl.json &
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool gdc_dnaseq_transform_checker.cwl gdc_dnaseq_transform_checker.cwl.json
cat results.json | grep overall
```

#### 6. Submit workflow outputs

I modified the parameters in `gdc_dnaseq_transform_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""CDIS"",
    ""eval_id"": ""9604596"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""123e4567-e89b-12d3-a456-426655440000.db""
        }
    ],
    ""parent_id"": ""syn123456""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl gdc_dnaseq_transform_submit.cwl.json
```

---",9646311
gdc_dnaseq_transform,9647057_report.md,"## GDC DNA-seq Transform Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Jeremiah Savage""
workflow_handle: ""gdc_dnaseq_transform""
input_handle: ""NA12878 chr20""
```

The following description is provided by the workflow author:
> The GDC DNA-Seq Workflow aligns the reads in a BAM containing mapped or unmapped reads to a reference genome (GRCh38 with added viral sequence), outputing a BAM file, a BAI file, and a sqlite file containing quality and alignment metrics. The input BAM is converted to readgroup-separated FASTQ files using BIOBAMBAM, which are aligned with BWA, and then sorted, merged and duplicate marked with PICARD. Metrics are gathered at each phase of the workflow (FastQC, PICARD and SAMTOOLS metrics). The workflow has been validated with TCGA, TARGET, CCLE and 1000Genomes BAM files. The test case is NA12878 chr20, which requires about 1 hr of CPU time, and approximately 30G of disk space to complete.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""16GB""
suggested_disk: ""30GB""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Joe Slagel"" # your name here
institution: ""Institute for Systems Biology"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""10/28/2017"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170822192924"" # indicate executor version used
docker_version: ""1.12.6, build 78d1802"" # from `docker --version`
environment: ""Google Compute"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""30 GB"" # indicate available RAM in environment
env_disk: ""250 GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```
> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-17""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""EC2"" 
env_cpus_ex: ""32""
env_memory_ex: ""244Gb""
env_disk_ex: ""elastic""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessasry.

#### 1. Set up environment

Using the Google Console I launched an Ubuntu 16.04 LTS ubuntu based virtual machine.  I then ran the following commands:

```shell
sudo apt-get update
sudo apt-get install docker.io
sudo apt-get install python-pip
sudo apt-get pip install cwltool
sudo pip install --upgrade synapseclient 
```

Next I created Synapse credentials file in my home directory:

```shell
vi ~/.synapseConfig
```


#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **gdc_dnaseq_transform** workflow:
```shell
synapse get syn9962438 # gdc_dnaseq_transform_get.cwl.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `gdc_dnaseq_transform_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --tmpdir-prefix tmp/ --cachedir cache/ --non-strict dockstore-tool-synapse-get.cwl gdc_dnaseq_transform_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `transform.cwl` and parameterized by `transform.cwl.json`:
```shell
 sudo cwltool  cwl/workflows/dnaseq/transform.cwl transform.cwl.json > run.log 2>&1 &
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
sudo cwltool gdc_dnaseq_transform_checker.cwl gdc_dnaseq_transform_checker.cwl.json
cat results.json | grep overall
```

#### 6. Submit workflow outputs

I modified the parameters in `gdc_dnaseq_transform_submit.cwl.json` to include the parent_id of a folder I created under our project.

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
sudo cwltool dockstore-tool-synapse-submit.cwl gdc_dnaseq_transform_submit.cwl.json
```

---",9647057
gdc_dnaseq_transform,9653520_report.md,"## GDC DNA-seq Transform Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Jeremiah Savage""
workflow_handle: ""gdc_dnaseq_transform""
input_handle: ""NA12878 chr20""
```

The following description is provided by the workflow author:
> The GDC DNA-Seq Workflow aligns the reads in a BAM containing mapped or unmapped reads to a reference genome (GRCh38 with added viral sequence), outputing a BAM file, a BAI file, and a sqlite file containing quality and alignment metrics. The input BAM is converted to readgroup-separated FASTQ files using BIOBAMBAM, which are aligned with BWA, and then sorted, merged and duplicate marked with PICARD. Metrics are gathered at each phase of the workflow (FastQC, PICARD and SAMTOOLS metrics). The workflow has been validated with TCGA, TARGET, CCLE and 1000Genomes BAM files. The test case is NA12878 chr20, which requires about 1 hr of CPU time, and approximately 30G of disk space to complete.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""16GB""
suggested_disk: ""30GB""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Karl Sebby"" # your name here
institution: ""xD Bio"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-11-15"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""cwl"" # CWL or WDL
runner_version: ""cwltool==1.0.20171107133715"" # indicate executor version used
docker_version: ""17.09.0-ce, build afdb6d4"" # from `docker --version`
environment: ""Google Compute"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""54Gb"" # indicate available RAM in environment
env_disk: ""75Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```
> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-17""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""EC2"" 
env_cpus_ex: ""32""
env_memory_ex: ""244Gb""
env_disk_ex: ""elastic""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

**Ran everything as root to make docker happy and not have to keep changing permissions.**

```shell
sudo bash
```
#### 1. Set up environment

ssh  to google compute engine instance from local machine (linux mint with cinnamon desktop running in virtual box on Macbook pro.)
```shell
screen
ssh `external_ip`
```

On  google instance, install docker, pip3, cwltool (with pip3).
Set up directory structure from ~:
```shell
mkdir -p projects/dreamChallenge/gdc_dnaseq_transform
cd projects/dreamChallenge
```
Create .synapseConfig file and paste in text from synapse website. Change username and password.
```shell 
vi .synapseConfig
```



I created `tmp` and `cache` as subdirectories of gdc_dnaseq_transform/ to be used with `cwltool` in subsequent steps:

```shell
mkdir gdc_dnaseq_transform/tmp
mkdir gdc_dnaseq_transform/cache
```



#### 2. Download required files

Steps completed in the projects/dreamChallenge directory unless specified otherwise.

Use curl to get the dockstore-tool-synapse-get.cwl and dockstore-tool-synapse-submit.cwl:
```shell
curl https://raw.githubusercontent.com/GA4GH-DREAM/dockstore-tool-synapse-get/master/Dockstore.cwl > dockstore-tool-synapse-get.cwl
curl https://raw.githubusercontent.com/GA4GH-DREAM/dockstore-tool-synapse-submit/master/Dockstore.cwl > dockstore-tool-synapse-submit.cwl
```
Downloaded the `gdc_dnaseq_transform_get.cwl.json` file to my local machine from synapse website:  Opened the file in TextEdit and copied contents. In google compute shell create the `gdc_dnaseq_transform_get.cwl.json`  file and paste the contents and save:
```shell
vi gdc_dnaseq_transform_get.cwl.json
```

Get the files:
```shell
cd gdc_dnaseq_transform
cwltool ../dockstore-tool-synapse-get.cwl ../gdc_dnaseq_transform_get.cwl.json
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `gdc_dnaseq_transform_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --tmpdir-prefix tmp/ --cachedir cache/ --non-strict ../dockstore-tool-synapse-get.cwl ../gdc_dnaseq_transform_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `transform.cwl` and parameterized by `transform.cwl.json`:
```shell
cwltool --cachedir cache/ --tmpdir-prefix tmp/ cwl/workflows/dnaseq/transform.cwl transform.cwl.json
```

#### 5. Run workflow checker tool

I used `cwltool` to run the checker  follows:
```shell
cwltool gdc_dnaseq_transform_checker.cwl gdc_dnaseq_transform_checker.cwl.json
cat results.json | grep overall
```

#### 6. Submit workflow outputs

I modified the parameters in `gdc_dnaseq_transform_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": ""../.synapseConfig""
    },
    ""team_name"": """",
    ""eval_id"": ""9604596"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""123e4567-e89b-12d3-a456-426655440000.db""
        }
    ],
    ""parent_id"": ""syn123456""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool  ../dockstore-tool-synapse-submit.cwl gdc_dnaseq_transform_submit.cwl.json
```

---",9653520
gdc_dnaseq_transform,9653787_report.md,"## GDC DNA-seq Transform Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Jeremiah Savage""
workflow_handle: ""gdc_dnaseq_transform""
input_handle: ""NA12878 chr20""
```

The following description is provided by the workflow author:
> The GDC DNA-Seq Workflow aligns the reads in a BAM containing mapped or unmapped reads to a reference genome (GRCh38 with added viral sequence), outputing a BAM file, a BAI file, and a sqlite file containing quality and alignment metrics. The input BAM is converted to readgroup-separated FASTQ files using BIOBAMBAM, which are aligned with BWA, and then sorted, merged and duplicate marked with PICARD. Metrics are gathered at each phase of the workflow (FastQC, PICARD and SAMTOOLS metrics). The workflow has been validated with TCGA, TARGET, CCLE and 1000Genomes BAM files. The test case is NA12878 chr20, which requires about 1 hr of CPU time, and approximately 30G of disk space to complete.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""16GB""
suggested_disk: ""30GB""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Azza E. Ahmed"" # your name here
institution: ""University of Khartoum, Sudan"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-11-14"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170217172322"" # indicate executor version used
docker_version: ""17.09.0-ce, build afdb6d4"" # from `docker --version`
environment: ""EGI FedCloud"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""4"" # indicate number of cores in environment
env_memory: ""16GB"" # indicate available RAM in environment
env_disk: ""50GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```
> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-17""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""EC2"" 
env_cpus_ex: ""32""
env_memory_ex: ""244Gb""
env_disk_ex: ""elastic""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessasry.

#### 1. Set up environment


I launched a VM instance from EGI FedCloud resources ( EGI Ubuntu 16.04 LTS from CESNET MetaCloud (IaaS Cloud)) with large memory,  as per challenge needed computational infrastructure. Then:

```shell
pip install --upgrade pip
pip install schema-salad==2.2.20170222151604 cwltool==1.0.20170217172322 --no-cache-dir
pip install synapseclient --no-cache-dir
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir syn9766994
cd syn9766994
cp ~/.synapseConfig .
```

Within the working directory, I created `tmp` and `cache` folders to be used with `cwltool` in subsequent steps:
```shell
mkdir tmp cache
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **gdc_dnaseq_transform** workflow:
```shell
synapse get syn9962438 # gdc_dnaseq_transform_get.cwl.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `gdc_dnaseq_transform_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results. I wrapped these in a script, and `nohup` as it takes a bit long to run:
```shell
cwltool --tmpdir-prefix tmp/ --cachedir cache/ --non-strict dockstore-tool-synapse-get.cwl gdc_dnaseq_transform_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `transform.cwl` and parameterized by `transform.cwl.json`:
```shell
nohup cwltool --cachedir cache/ --tmpdir-prefix tmp/ cwl/workflows/dnaseq/transform.cwl transform.cwl.json &
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool gdc_dnaseq_transform_checker.cwl gdc_dnaseq_transform_checker.cwl.json
cat results.json | grep overall
```

#### 6. Submit workflow outputs

I modified the parameters in `gdc_dnaseq_transform_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""CBSB_pipelines"",
    ""eval_id"": ""9604596"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""123e4567-e89b-12d3-a456-426655440000.db""
        }
    ],
    ""parent_id"": ""syn10893666""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl gdc_dnaseq_transform_submit.cwl.json
```

---",9653787
gdc_dnaseq_transform,9655281_report.md,"## GDC DNA-seq Transform Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Jeremiah Savage""
workflow_handle: ""gdc_dnaseq_transform""
input_handle: ""NA12878 chr20""
```

The following description is provided by the workflow author:
> The GDC DNA-Seq Workflow aligns the reads in a BAM containing mapped or unmapped reads to a reference genome (GRCh38 with added viral sequence), outputing a BAM file, a BAI file, and a sqlite file containing quality and alignment metrics. The input BAM is converted to readgroup-separated FASTQ files using BIOBAMBAM, which are aligned with BWA, and then sorted, merged and duplicate marked with PICARD. Metrics are gathered at each phase of the workflow (FastQC, PICARD and SAMTOOLS metrics). The workflow has been validated with TCGA, TARGET, CCLE and 1000Genomes BAM files. The test case is NA12878 chr20, which requires about 1 hr of CPU time, and approximately 30G of disk space to complete.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""16GB""
suggested_disk: ""30GB""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Azza E Ahmed"" # your name here
institution: ""University of Khartoum"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-11-29"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""Rabix"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.0"" # indicate executor version used
docker_version: ""17.03.1-ce, build c6d412e"" # from `docker --version`
environment: ""EGI FedCloud"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""32Gb"" # indicate available RAM in environment
env_disk: ""50GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```
> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-17""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""EC2"" 
env_cpus_ex: ""32""
env_memory_ex: ""244Gb""
env_disk_ex: ""elastic""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessasry.

#### 1. Set up environment

I launched an EGI FedCloud instance of type `EGI Docker (Ubuntu 16.04)` as provided by `CESNET MetaCloud (IaaS Cloud)` with one node, mounted a 50GB volume, and Docker pre-installed.

I created and configured a virtual environment as follows:
```shell
# Adding my user to the docker group
sudo usermod -a -G docker $USER

# Installing java:
sudo apt-get update
sudo apt-get install default-jre
sudo apt-get install default-jdk

# Installing Rabix:
wget https://github.com/rabix/bunny/releases/download/v1.0.0/rabix-1.0.0.tar.gz
tar -xvzf rabix-1.0.0.tar.gz
export PATH=$PATH://home/azza/software/rabix-cli-1.0.0
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder. To assure sufficient memory, I download the data in the mounted storage:
```shell
cd /mnt/storage01
mkdir  gdc_dnaseq_transform
cd gdc_dnaseq_transform
vi .synapseConfig # [Adding in my Synapse credentials]
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **gdc_dnaseq_transform** workflow:
```shell
synapse  -c .synapseConfig get syn9962438 # gdc_dnaseq_transform_get.cwl.json
synapse  -c .synapseConfig get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse  -c .synapseConfig get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `rabix` to run `dockstore-tool-synapse-get.cwl` with parameters in `gdc_dnaseq_transform_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
rabix dockstore-tool-synapse-get.cwl gdc_dnaseq_transform_get.cwl.json
```

#### 4. Run main workflow

Rabix creates a new directory (and tree) named after the script being called and appended by date-time stamp. Within this directory the downloaded files can be found, and therefore, I go to the location of the these files and use `rabix` again to run the workflow from there:

```shell
cd dockstore-tool-synapse-get-2017-11-28-233023.717/root/synapse_files

rabix cwl/workflows/dnaseq/transform.cwl transform.cwl.json
```

#### 5. Run workflow checker tool
Again, the newly generated files have their own directory tree (`transform-2017-11-29-003315.338/root`), and therefore, I modify the checker options file to point to the output file for checking:

```shell
$ vi gdc_dnaseq_transform_checker.cwl.json
# Modify the path of ""input_sqlite_metrics"" as follows:
#        ""path"": ""/mnt/storage01/gdc_dnaseq_transform/dockstore-tool-synapse-get-2017-11-28-233023.717/root/synapse_files/transform-2017-11-29-003315.338/root/merge_all_sqlite/123e4567-e89b-12d3-a456-426655440000.db""

$ rabix gdc_dnaseq_transform_checker.cwl gdc_dnaseq_transform_checker.cwl.json

$ cat  gdc_dnaseq_transform_checker-2017-11-29-064224.633/root/results.json | grep overall
""overall"": true,
```

#### 6. Submit workflow outputs

I modified the parameters in `gdc_dnaseq_transform_submit.cwl.json` such that it points to the correct path of ""input_sqlite_metrics""  as above, and also added the `team_name`, and `parent_id` to where I wish to upload my submission. Once done, I'm ready to submit as in:


```shell
cp ../../../.synapseConfig .
cp ../../../dockstore-tool-synapse-submit.cwl .

rabix dockstore-tool-synapse-submit.cwl gdc_dnaseq_transform_submit.cwl.json

```

---",9655281
gdc_dnaseq_transform,9655739_report.md,"## GDC DNA-seq Transform Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Jeremiah Savage""
workflow_handle: ""gdc_dnaseq_transform""
input_handle: ""NA12878 chr20""
```

The following description is provided by the workflow author:
> The GDC DNA-Seq Workflow aligns the reads in a BAM containing mapped or unmapped reads to a reference genome (GRCh38 with added viral sequence), outputing a BAM file, a BAI file, and a sqlite file containing quality and alignment metrics. The input BAM is converted to readgroup-separated FASTQ files using BIOBAMBAM, which are aligned with BWA, and then sorted, merged and duplicate marked with PICARD. Metrics are gathered at each phase of the workflow (FastQC, PICARD and SAMTOOLS metrics). The workflow has been validated with TCGA, TARGET, CCLE and 1000Genomes BAM files. The test case is NA12878 chr20, which requires about 1 hr of CPU time, and approximately 30G of disk space to complete.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""16GB""
suggested_disk: ""30GB""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Joe Slagel"" # your name here
institution: ""ISB"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-11-28"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""ISB-CGC dsub/cwltool/cwl_runner.sh"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""cwltool-1.0.20171107133715"" # indicate executor version used
docker_version: ""17.11.0"" # from `docker --version`
environment: ""Google Compute"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""4"" # indicate number of cores in environment
env_memory: ""15"" # indicate available RAM in environment
env_disk: ""200"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

I was curious as to how much of the challenge I could do using only dsub and cwl_runner.sh.  On a personal Google Cloud VM with gcloud, gsutil, dsub and cwl_runner.sh installed I :

#### 1. Set up environment

```shell
gsutil cp ~/.synapseConfig gs://isb-ga4gh-dream/gdc_dnaseq_transform/data/.synapseConfig
dsub \
   --name dream-setup-gdc_dnaseq_transform \
   --project cgc-05-0026 \
   --zones 'us-*' \
   --image quay.io/ga4gh-dream/dockstore-tool-synapse-get \
   --input  'CFG=gs://isb-ga4gh-dream/gdc_dnaseq_transform/data/.synapseConfig' \
   --output-recursive 'OUT=gs://isb-ga4gh-dream/gdc_dnaseq_transform/data/' \
   --logging 'gs://isb-ga4gh-dream/gdc_dnaseq_transform/log' \
   --wait \
   --command 'cd ${OUT}; \
              synapse -c ${CFG} get syn9770802; \
              synapse -c ${CFG} get syn9732885; \
              synapse -c ${CFG} get syn9962438; \
             '
```

#### 2. Download required files

```shell
./cwl_runner.sh \
   -m n1-standard-2 \
   -i gs://isb-ga4gh-dream/gdc_dnaseq_transform/data/.synapseConfig \
   -w gs://isb-ga4gh-dream/gdc_dnaseq_transform/data/dockstore-tool-synapse-get.cwl \
   -s gs://isb-ga4gh-dream/gdc_dnaseq_transform/data/gdc_dnaseq_transform_get.cwl.json \
   -o gs://isb-ga4gh-dream/gdc_dnaseq_transform/data
```

#### 3. Run main workflow

```shell
./cwl_runner.sh \
   -m n1-standard-4 \
   -r gs://isb-ga4gh-dream/gdc_dnaseq_transform/data/ \
   -w gs://isb-ga4gh-dream/gdc_dnaseq_transform/data/cwl/workflows/dnaseq/transform.cwl \
   -s gs://isb-ga4gh-dream/gdc_dnaseq_transform/data/transform.cwl.json \
   -o gs://isb-ga4gh-dream/gdc_dnaseq_transform/data
```

#### 4. Run workflow checker tool

```shell
./cwl_runner.sh \
   -m n1-standard-2 \
   -r gs://isb-ga4gh-dream/gdc_dnaseq_transform/data/ \
   -w gs://isb-ga4gh-dream/gdc_dnaseq_transform/data/gdc_dnaseq_transform_checker.cwl \
   -s gs://isb-ga4gh-dream/gdc_dnaseq_transform/data/gdc_dnaseq_transform_checker.cwl.json \
   -o gs://isb-ga4gh-dream/gdc_dnaseq_transform/data
```

#### 5. Submit workflow outputs

```shell
gsutil cat gs://isb-ga4gh-dream/gdc_dnaseq_transform/data/gdc_dnaseq_transform_submit.cwl.json \
   | jq '.team_name=""ISB-CGC"" | .parent_id=""syn11413164""' \
   | gsutil cp - gs://isb-ga4gh-dream/gdc_dnaseq_transform/data/gdc_dnaseq_transform_submit.cwl.json
./cwl_runner.sh \
   -m n1-standard-2 \
   -r gs://isb-ga4gh-dream/gdc_dnaseq_transform/data/ \
   -w gs://isb-ga4gh-dream/gdc_dnaseq_transform/data/dockstore-tool-synapse-submit.cwl \
   -s gs://isb-ga4gh-dream/gdc_dnaseq_transform/data/gdc_dnaseq_transform_submit.cwl.json \
   -o gs://isb-ga4gh-dream/gdc_dnaseq_transform/data
```

---",9655739
gdc_dnaseq_transform,9656028_report.md,"### Workflow description

```YAML
contributor: ""Jeremiah Savage""
workflow_handle: ""gdc_dnaseq_transform""
input_handle: ""NA12878 chr20""
```

### Participant information
```YAML
name: ""Ben Ernest""
institution: ""Digicon Corporation""
```

### Submission overview
```YAML
date_accessed: ""2017-12-08"" 
platform: ""cwltool"" 
workflow_type: ""CWL"" 
runner_version: ""1.0.20170217172322"" 
docker_version: ""17.09.0-ce"" 
environment: ""cluster"" 
env_cpus: ""12"" 
env_memory: ""62Gb"" 
env_disk: ""5Tb"" 
```

### Steps

#### 1. Set up environment, following instructions at https://dockstore.org/quick-start
##### Instructions are for Linux CentOS

Download and install dockstore.  
```shell
mkdir -p ~/bin
curl -L -o ~/bin/dockstore https://github.com/ga4gh/dockstore/releases/download/1.3.0/dockstore
chmod +x ~/bin/dockstore
echo 'export PATH=~/bin:$PATH' >> ~/.bashrc
source ~/.bashrc
```

Create configuration file
```shell
mkdir -p ~/.dockstore
printf ""token: dummy-token\nserver-url: https://dockstore.org:8443\n"" > ~/.dockstore/config
```

Install `pip`
```shell
curl -L -o ~/get-pip.py https://bootstrap.pypa.io/get-pip.py
sudo python get-pip.py
```

Install `cwltool` (**note: version 1.0.20170217172322**)
```shell
sudo pip install setuptools==36.5.0
sudo pip install cwl-runner cwltool==1.0.20170217172322 schema-salad==2.6.20170806163416 avro==1.8.1 ruamel.yaml==0.14.12 requests==2.18.4
```

Install Docker
```shell
sudo yum install -y yum-utils device-mapper-persistent-data lvm2
sudo yum-config-manager --add-repo ""https://download.docker.com/linux/centos/docker-ce.repo""
sudo yum-config-manager --enable extras
sudo yum -y install docker-ce
sudo usermod -aG docker $USER
exec newgrp docker
```

Create aliases to start and stop Docker
```shell
echo 'alias start_docker=""sudo systemctl start docker""' >> ~/.bashrc
echo `alias stop_docker=""sudo systemctl stop docker""' >> ~/.bashrc
source ~/.bashrc
```
Install `synapseclient`
```
sudo pip install synapseclient
```

Create synapse credentials file with the content below, using your own Synapse credentials (no quotes or extra characters).  It can be named anything, but I'm using `.synapseConfig`.
```
[authentication]
username: email
password: password
```

Create a working directory and copy synapse credentials file into that folder.
```shell
mkdir -p gdc_dnaseq_transform_run
cd gdc_dnaseq_transform_run
cp ~/.synapseConfig .
```

#### 2. Download required files
Download tools to fetch workflow input data.
```shell
synapse get syn9962438 # gdc_dnaseq_transform_get.cwl.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files
Start docker, using alias created previously.
```shell
start_docker
```

Within the working directory, create `tmp` and `cache` folders to be used with `cwltool` in subsequent steps:
```shell
mkdir tmp cache
```

Use `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `gdc_dnaseq_transform_get.cwl.json` to download tools and data needed for running the workflow and submitting results.
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl gdc_dnaseq_transform_get.cwl.json
```

#### 4. Run main workflow
Use `cwltool` to run the workflow, as defined in `transform.cwl` and parameterized by `transform.cwl.json`:
```shell
nohup cwltool --non-strict cwl/workflows/dnaseq/transform.cwl transform.cwl.json &
```

#### 5. Run workflow checker tool
To verify workflow results before submission, use `cwltool` to run the checker as follows:
```shell
cwltool --non-strict gdc_dnaseq_transform_checker.cwl gdc_dnaseq_transform_checker.cwl.json
```

#### 6. Submit workflow outputs
Modify `team_name` and `parent_id` in `gdc_dnaseq_transform_submit.cwl.json` as shown below, assuming Synapse credentials file is named `.synapseConfig` and located in `~/gdc_dnaseq_transform_run`.
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""BioGenLink"",
    ""eval_id"": ""9604596"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""123e4567-e89b-12d3-a456-426655440000.db""
        }
    ],
    ""parent_id"": ""syn11565351""
}
```

Submit outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl gdc_dnaseq_transform_submit.cwl.json
```

Stop Docker if desired.
```shell
stop_docker
```
---
",9656028
gdc_dnaseq_transform,9656030_report.md,"### Workflow description

```YAML
contributor: ""Jeremiah Savage""
workflow_handle: ""gdc_dnaseq_transform""
input_handle: ""NA12878 chr20""
```

### Participant information
```YAML
name: ""Ben Ernest""
institution: ""Digicon Corporation""
```

### Submission overview
```YAML
date_accessed: ""2017-12-12"" 
platform: ""Dockstore"" 
workflow_type: ""CWL"" 
runner_version: ""1.0.20170217172322"" 
docker_version: ""17.09.0-ce"" 
environment: ""BioGenLink"" 
env_cpus: ""1"" 
env_memory: ""8Gb"" 
env_disk: ""5Tb"" 
```

### Steps
#####This workflow was run using the [BioGenLink](http://digicon.com/biogenlink.html) platform from [Digicon](http://digicon.com/).  Click [here](http://digicon.com/biogenlink.html) or [email us](mailto:biogenlink@digiconasp.com) for more information. 

#### **Setup**

##### Create synapse credentials file.  
This only needs to be done once, and the credentials file can be used for each workflow.
1. Log into BioGenLink.  [Click here](http://digicon.com/biogenlink.html) or [email us](mailto:biogenlink@digiconasp.com) for more information. 
${image?fileName=login%5Fscreen%5Fempty%2E2017%2D12%2D19%2Epng&align=None&scale=75&responsive=true}

2. In the **files** tab, right-click on any directory in the file system, select `Create File`, give the file a name (e.g., ""synapse_config.txt""), and click `Preview` to edit the file.  
${image?fileName=create%5Ffile%5Fpreview%2E2017%2D12%2D19%2Epng&align=None&scale=75&responsive=true}

Enter the following information in the file and save it by clicking **Save** (the disk button just above the text area).
```
[authentication]
username: email
password: password
[cache]
location: biodtfs/path/to/cache
```
**Note:** the cache directory is used by synapseClient for temporary files, and we must specify it in BioGenLink to avoid permissions errors. It can be be any directory the user chooses, even a non-existing one as long as the parent directory is valid.  It is suggested to create a working directory for each workflow and keep this file in a parent directory outside of the working directories.  

#### **Provision workflow files**

1. Create a working directory.  
    - Right-click on any directory in the file system, select `Create Folder`, and enter a name for the working directory (e.g., `gdc_workflow`).

2. Run the `Synapse get` tool.
    - In the **tools** tab, find and select the `Synapse get` tool.  It can be found by keyword search or browsing to `Synapse/All/Synapse get`.  Double-clicking (shown below) the tool will open it in the workspace for editing and browsing documentation and will display the menu for providing inputs and running the tool.
${image?fileName=synapse%5Fget%5Fopen%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
    - In the `Synapse IDs` field, enter the Synapse IDs for files to be downloaded.  In this case, the synapse IDs include the following, which correspond to `gdc_dnaseq_transform_get.cwl.json`, `dockstore-tool-synapse-submit.cwl`, and `dockstore-tool-synapse-get.cwl`:
```shell
syn9962438 
syn9770802   
syn9732885   
```   
${image?fileName=synapse%5Fget%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
    - Drag and drop the synapse credentials file (e.g., `synapse_config.txt`) from the file system into the field called `Synapse config file`.
    - Drag and drop the working directory into the field called `Output directory`.
    - Run the tool by clicking `Quick Launch`.

#### **Run the workflow**
- Run the `Dockstore launch` tool.
    1. In the **Tools** tab, find and select the `Dockstore launch` tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore launch`.  
${image?fileName=dockstore%5Flaunch%2E2018%2D01%2D04%2Epng&align=None&scale=75&responsive=true}
    2. Drag and drop the `cwl/workflows/dnaseq/transform.cwl` and `transform.cwl.json` files from the working directory into the fields labeled `CWL file` and `JSON file`, respectively.  Drag and drop the parent directory (e.g., `gdc_workflow`) into the field labeled `Parent directory`.   
    3. Click `Quick Launch`.

#### **Validate the results**
- Run the `Dockstore checker` tool.
1. In the **tools** tab, find and select the `Dockstore checker` tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore checker`.  
${image?fileName=dockstore%5Fchecker%2E2017%2D12%2D25%2Epng&align=None&scale=75&responsive=true}
  2. Drag and drop the `gdc_dnaseq_transform_checker.cwl` and `gdc_dnaseq_transform_checker.cwl.json` files from the working directory into the fields labeled `Checker CWL file` and `Checker JSON file`, respectively.  
  3. Click `Quick Launch`.
  4. Verify that the workflow ran successfully by opening the `results.json` file and confirming that the `Overall` field is equal to `true`.
${image?fileName=results%5Fjson%2E2017%2D12%2D25%2Epng&align=None&scale=75&responsive=true}

#### **Submit the results to Synapse**
- Run the `Dockstore submit` tool.
  1. In the **Tools** tab, find and select the `Dockstore submit` tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore submit`.  
${image?fileName=dockstore%5Fsubmit%2E2017%2D12%2D26%2Epng&align=None&scale=75&responsive=true}
  2. Drag and drop the `gdc_dnaseq_transform_submit.cwl.json` file into the field labeled `Submit JSON file`.  
  3. Enter a team name and the Synapse parent ID into the corresponding fields.  
  4. Drag and drop the synapse credentials file (e.g., `synapse_config.txt`) into the field labeled `Synapse config file`.
  5. Click `Quick Launch`.
---",9656030
gdc_dnaseq_transform,9657472_report.md,"## GDC DNA-seq Transform Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Jeremiah Savage""
workflow_handle: ""gdc_dnaseq_transform""
input_handle: ""NA12878 chr20""
```

The following description is provided by the workflow author:
> The GDC DNA-Seq Workflow aligns the reads in a BAM containing mapped or unmapped reads to a reference genome (GRCh38 with added viral sequence), outputing a BAM file, a BAI file, and a sqlite file containing quality and alignment metrics. The input BAM is converted to readgroup-separated FASTQ files using BIOBAMBAM, which are aligned with BWA, and then sorted, merged and duplicate marked with PICARD. Metrics are gathered at each phase of the workflow (FastQC, PICARD and SAMTOOLS metrics). The workflow has been validated with TCGA, TARGET, CCLE and 1000Genomes BAM files. The test case is NA12878 chr20, which requires about 1 hr of CPU time, and approximately 30G of disk space to complete.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""16GB""
suggested_disk: ""30GB""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Abhishek Niroula"" # your name here
institution: ""LU"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-12-19"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170828135420"" # indicate executor version used
docker_version: ""17.06.1-ce, build 874a737"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""32Gb"" # indicate available RAM in environment
env_disk: ""2TB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```
> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-17""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""EC2"" 
env_cpus_ex: ""32""
env_memory_ex: ""244Gb""
env_disk_ex: ""elastic""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessasry.

#### 1. Set up environment

**example:** *I launched an EC2 instance of type `r4.8xlarge` with one node, mounted an EFS volume, and installed Docker.*

I created and configured a virtual environment as follows:
```shell
mkvirtualenv --python /usr/bin/python2 cwl
pip install --upgrade pip
pip install 'requests[security]' --no-cache-dir
pip install schema-salad==2.2.20170222151604 cwltool==1.0.20170217172322 --no-cache-dir
pip install synapseclient --no-cache-dir
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir syn9766994
cd syn9766994
cp ~/.synapseConfig .
```

Within the working directory, I created `tmp` and `cache` folders to be used with `cwltool` in subsequent steps:
```shell
mkdir tmp cache
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **gdc_dnaseq_transform** workflow:
```shell
synapse get syn9962438 # gdc_dnaseq_transform_get.cwl.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `gdc_dnaseq_transform_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --tmpdir-prefix tmp/ --cachedir cache/ --non-strict dockstore-tool-synapse-get.cwl gdc_dnaseq_transform_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `transform.cwl` and parameterized by `transform.cwl.json`:
```shell
nohup cwltool --cachedir cache/ --tmpdir-prefix tmp/ cwl/workflows/dnaseq/transform.cwl transform.cwl.json &
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool gdc_dnaseq_transform_checker.cwl gdc_dnaseq_transform_checker.cwl.json
cat results.json | grep overall
```

#### 6. Submit workflow outputs

I modified the parameters in `gdc_dnaseq_transform_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""CDIS"",
    ""eval_id"": ""9604596"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""123e4567-e89b-12d3-a456-426655440000.db""
        }
    ],
    ""parent_id"": ""syn123456""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl gdc_dnaseq_transform_submit.cwl.json
```

---",9657472
gdc_dnaseq_transform,9657902_report.md,"## GDC DNA-seq Transform Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Jeremiah Savage""
workflow_handle: ""gdc_dnaseq_transform""
input_handle: ""NA12878 chr20""
```

The following description is provided by the workflow author:
> The GDC DNA-Seq Workflow aligns the reads in a BAM containing mapped or unmapped reads to a reference genome (GRCh38 with added viral sequence), outputing a BAM file, a BAI file, and a sqlite file containing quality and alignment metrics. The input BAM is converted to readgroup-separated FASTQ files using BIOBAMBAM, which are aligned with BWA, and then sorted, merged and duplicate marked with PICARD. Metrics are gathered at each phase of the workflow (FastQC, PICARD and SAMTOOLS metrics). The workflow has been validated with TCGA, TARGET, CCLE and 1000Genomes BAM files. The test case is NA12878 chr20, which requires about 1 hr of CPU time, and approximately 30G of disk space to complete.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""16GB""
suggested_disk: ""30GB""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Junjun Zhang"" # your name here
institution: ""Ontario Institute for Cancer Research"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-11-15"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""JTracker"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
cwltool_version: ""1.0.2017110733715""
runner_version: ""0.2.0a4"" # indicate executor version used
docker_version: ""1.12.6"" # from `docker --version`
environment: ""OpenStack VM"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""96GB"" # indicate available RAM in environment
env_disk: ""2TB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-08-31""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""1.12.6""
environment_ex: ""local"" 
env_cpus_ex: ""8""
env_memory_ex: ""96GB""
env_disk_ex: ""2TB""
```

### Write a JTracker Workflow
The JTracker workflow is written to automatically execute necessary steps to complete a Dream Challenge workflow. The JTracker workflow is named as `dream-challenge-wf-runner`, the source code is checked in Github at: https://github.com/jthub/demo-workflows/tree/master/dream-challenge-wf-runner/workflow.

Once tested out successfully, make a release of the source code. In this case, it is release version 0.0.7: https://github.com/jthub/demo-workflows/releases/tag/dream-challenge-wf-runner.0.0.7

### Register the JTracker Workflow in JTHub
#### Install JTracker command line tool

Follow the instructions here: https://github.com/icgc-dcc/jtracker

Once install successfully, you should be able to see the version number.
```
jt --version
```

#### Signup a JTHub account
Assume we choose `ga4gh_dream` as account name:
```
jt user signup -u ga4gh_dream
```
Login as `ga4gh_dream`
```
jt user login -u ga4gh_dream
```

#### Register the JTracker Dream Challenge Runner Workflow
Register a workflow is basically provide information to access the JTracker workflow source code in GitHub.
```
jt wf register --git-server https://github.com --git-account jthub --git-repo demo-workflows \
                       --git-path dream-challenge-wf-runner --git-tag dream-challenge-wf-runner.0.0.7 \
                       --wf-name dream-challenge-wf-runner --wf-version 0.0.7
```
To list all registered workflows in your account, do this:
```
jt wf ls
```

### Create a Job Queue
Once we have the workflow registered, you will be able to create a job queue for it.
```
jt queue add --wf-name dream-challenge-wf-runner --wf-version 0.0.7
```
Upon success, you will get a unique job queue ID. In my case, my queue ID is: `758b7668-0057-4ef6-a5b0-6f48acf38583`

To list all job queues you created, do this:
```
jt queue ls
```

### Add workflow job to the above queue
If we want to run `gdc_dnaseq_transform`, fill out the appropriate parameters in the job JSON as below:
```
jt job add -q 758b7668-0057-4ef6-a5b0-6f48acf38583 -j '
{
    ""workflow_name"": ""gdc_dnaseq_transform"",
    ""workflow_type"": ""CWL"",
    ""data_syn_id"": ""syn9766994"",
    ""wf_file_name"": ""cwl/workflows/dnaseq/transform.cwl"",
    ""job_file_name"": ""transform.cwl.json"",
    ""checker_wf_file_name"": ""gdc_dnaseq_transform_checker.cwl"",
    ""checker_job_file_name"": ""gdc_dnaseq_transform_checker.cwl.json"",
    ""submit_job_file_name"": ""submit.json"",
    ""team_name"": ""PCAWG-Tech"",
    ""syn_parent_id"": ""syn11638876"",
    ""eval_id"": ""9604596""
}
'
```
To list all jobs in the queue:
```
jt job ls -q 758b7668-0057-4ef6-a5b0-6f48acf38583
```
Note that the above steps can be done on any computer, it could be a normal workstation or a laptop.


### Run the above queued Sanger workflow job

To execute the workflow job you will need to set up necessary environment and tools, follow these steps:

#### Setting up environment
1. Install Docker

2. Install `cwltool` (version 1.0.20170217172322) and  `synapseclient`
```
pip install cwltool==1.0.20170217172322
pip install synapseclient
pip install 'requests[security]'
```

3. Create Synapse credentials file `.synapseConfig`
Put there Synapse ID and password
```
[authentication]
username: user@usermail.org
password: <user-password>
```
Put this file a particular place, for example under home directory, eg, `/home/ubuntu/.synapseConfig`, then export the follow environment variable:
```
export SYNCONF=/home/ubuntu/.synapseConfig
```
4. Install JTracker command line
This is the same step as the previous section. Follow installation instruction here: https://github.com/icgc-dcc/jtracker

#### Start JTracker Executor
Start the executor to run jobs in the queue as:
```
jt user login ga4gh_dream
SYNCONF=/home/ubuntu/.synapseConfig jt exec run -q 758b7668-0057-4ef6-a5b0-6f48acf38583
```
If everything goes well, in about 5 hours, the job should finish and you will see `pcawg-sanger-variant-caller` result uploaded to specified location on Synapse.


---",9657902
hello_world,9615870_report.md,"## GA4GH/DREAM Hello World Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""James Eddy""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This simple ""hello world"" workflow that is designed to capture most of the basic elements of workflows that will be tested in this challenge. The workflow runs a single tool ([`dockstore-tool-helloworld`](https://dockstore.org/containers/quay.io/ga4gh-dream/dockstore-tool-helloworld)), which uses a reference file containing a single template format string (""Hello ____!"" when printed) and an input file containing a single plain string (e.g., ""World""). When the workflow is run, the input string is inserted into the template and written to a new file, now containing the string ""Hello World!"". The input is a text file containing the word ""Hello""; running the workflow requires < 1M of disk space (not counting Docker images) and should take < 1s of CPU time to complete.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Denis Yuen""
institution: ""OICR""
```

### Submission overview

```YAML
platform: ""dockstore"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.2.5"" # indicate executor version used
docker_version: ""17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""64GB"" # indicate available RAM in environment
env_disk: ""400GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

On a personal desktop, I installed Docker, pip, cwltool, and the Dockstore command-line helper using a procedure similar to https://github.com/denis-yuen/2017-cloud-workflows-misc/blob/master/install-and-run-with-dockstore.md

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir hello_world_run
cd hello_world_run
cp ~/.synapseConfig .
```

#### 2. Download required files

I downloaded hello_world_get.json from the website. I then got the synapse-submit and synapse-get commands from Dockstore. 
```shell
dockstore tool cwl --entry quay.io/ga4gh-dream/dockstore-tool-synapse-submit > dockstore-tool-synapse-submit.cwl
dockstore tool cwl --entry quay.io/ga4gh-dream/dockstore-tool-synapse-get > dockstore-tool-synapse-get.cwl
```

#### 4. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `hello_world_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl hello_world_get.cwl.json
```

#### 5. Run main workflow

I used the `dockstore cli` to run the workflow, as defined in `hello_world.cwl` and parameterized by `hello_world.cwl.json`:
```shell
dockstore workflow launch --local-entry hello_world.cwl  --json hello_world.cwl.json
```

#### 6. Run workflow checker tool

To verify workflow results before submission, I used `dockstore cli` to run the checker as follows:
```shell
dockstore tool launch --local-entry hello_world_checker.cwl --json hello_world_checker.cwl.json
```

#### 7. Submit workflow outputs

I modified the parameters in `hello_world_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""Dockstore_team_3_no_spaces"",
    ""eval_id"": ""9603665"",
    ""file"": [
        {
            ""class"": ""File"",
            ""path"": ""helloworld.txt""
        }
    ],
    ""parent_id"": ""syn9961864""
}
```

Finally, I submitted outputs using `dockstore cli` and `dockstore-tool-synapse-submit.cwl`:
```shell
dockstore tool launch --local-entry dockstore-tool-synapse-submit.cwl --json hello_world_submit.cwl.json`
```

---",9615870
hello_world,9621852_report.md,"## GA4GH/DREAM Hello World Workflow

### Workflow description

```YAML
contributor: ""James Eddy""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This simple ""hello world"" workflow that is designed to capture most of the basic elements of workflows that will be tested in this challenge. The workflow runs a single tool ([`dockstore-tool-helloworld`](https://dockstore.org/containers/quay.io/ga4gh-dream/dockstore-tool-helloworld)), which uses a reference file containing a single template format string (""Hello ____!"" when printed) and an input file containing a single plain string (e.g., ""World""). When the workflow is run, the input string is inserted into the template and written to a new file, now containing the string ""Hello World!"". The input is a text file containing the word ""Hello""; running the workflow requires < 1M of disk space (not counting Docker images) and should take < 1s of CPU time to complete.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Bogdan Gavrilovic"" # your name here
institution: ""Seven Bridges Genomics"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""rabix"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.0"" # indicate executor version used
docker_version: ""17.06.0-ce"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""4"" # indicate number of cores in environment
env_memory: ""16GB"" # indicate available RAM in environment
env_disk: ""200GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

#####1. [Install rabix](https://github.com/rabix/bunny#installing) on your machine and set environment variable $BUNNY. You need docker and java installed to run rabix:
```shell
wget https://github.com/rabix/bunny/releases/download/v1.0.0/rabix-1.0.0.tar.gz -O rabix-1.0.0.tar.gz && tar -xvf rabix-1.0.0.tar.gz
export BUNNY=$PWD/rabix-cli-1.0.0/rabix
```
#####2. If you've not already retrieved the CWL and data with synapse-get, you can use the [Synapse python client](https://github.com/Sage-Bionetworks/synapsePythonClient#installation):
```shell
pip install synapseclient
synapse get -r syn9630940 # hello world workflow, tools and input files
synapse get syn9732885   # dockstore-tool-synapse-submit.cwl
```
#####3. Run the workflow using rabix executor on your machine by typing in the terminal: $BUNNY <app> <inputs>
For example:
```shell
$BUNNY ./hello_world.cwl ./hello_world.cwl.json
```

### Validating results
Modify the `hello_world_checker.cwl.json` to include the path to the requested output file and run checker tool
```shell
$BUNNY hello_world_checker.cwl hello_world_checker.cwl.json
```
Check results
```shell
cat ./path/to/results.json
``` 
```json
{
    ""overall"": true,
    ""steps"": {
        ""md5_check"": true
    }
}
```
### Submitting results
- Copy the synapseConfig file to the current working directory.
- Update `hello_world_submit.cwl.json` with correct
`team_name` - the name of your team in plain text format (e.g., ""GA4GH-Sage Contenders"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
`file` - paths to output files
Run the tool
```shell
$BUNNY dockstore-tool-synapse-submit.cwl hello_world_submit.cwl.json
```

---",9621852
hello_world,9621938_report.md,"## GA4GH/DREAM Hello World Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""James Eddy""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This simple ""hello world"" workflow that is designed to capture most of the basic elements of workflows that will be tested in this challenge. The workflow runs a single tool ([`dockstore-tool-helloworld`](https://dockstore.org/containers/quay.io/ga4gh-dream/dockstore-tool-helloworld)), which uses a reference file containing a single template format string (""Hello ____!"" when printed) and an input file containing a single plain string (e.g., ""World""). When the workflow is run, the input string is inserted into the template and written to a new file, now containing the string ""Hello World!"". The input is a text file containing the word ""Hello""; running the workflow requires < 1M of disk space (not counting Docker images) and should take < 1s of CPU time to complete.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Jeltje van Baren""
institution: ""UCSC""
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""cwltool""
workflow_type: ""CWL""
runner_version: ""1.0.20170704143016""
docker_version: ""1.12.1, build 23cf638""
environment: ""UCSC podcloud VM Ubuntu 16:04""
env_cpus: ""31""
env_memory: ""252 G""
env_disk: ""1 Tb""
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

1. Used link on [3.3 - Access Data and Tools](https://www.synapse.org/#!Synapse:syn8507134/wiki/416015) to download [hello_world_get.cwl.json](https://www.synapse.org/Portal/filehandleassociation?associatedObjectId=9733811&associatedObjectType=FileEntity&fileHandleId=16653582&xsrfToken=5D9B3FA24C29121558A6DF4048E46A16)

2. From the same page, downloaded [dockstore-tool-synapse-get.cwl](https://www.synapse.org/Portal/filehandleassociation?associatedObjectId=9770802&associatedObjectType=FileEntity&fileHandleId=15691607&xsrfToken=F397E2A807CC92157AEC380011771547) and [dockstore-tool-synapse-submit.cwl](https://www.synapse.org/Portal/filehandleassociation?associatedObjectId=9732885&associatedObjectType=FileEntity&fileHandleId=16683837&xsrfToken=F397E2A807CC92157AEC380011771547):

      dockstore-tool-synapse-get.cwl pulls quay.io/ga4gh-dream/dockstore-tool-synapse-get:1.6.2.dev--2
      dockstore-tool-synapse-submit.cwl pulls  quay.io/ga4gh-dream/dockstore-tool-synapse-submit:1.7.1--1

3. Retrieved data:

    source ~/venv/cwl/bin/activate
    export TMPDIR=/mnt/tempdir
    tmpstuff=""--tmpdir-prefix=/mnt/tempdir --tmp-outdir-prefix=/mnt/tempdir""
    ln -s ~/.synapse.key .synapseConfig
    cwltool $tmpstuff --non-strict dockstore-tool-synapse-get.cwl hello_world_get.cwl.json

4. Ran workflow:

    cwltool $tmpstuff --non-strict hello_world.cwl  hello_world.cwl.json

5. Created a synapse project for this workflow [helloworld_GA4GH: syn10145695](https://www.synapse.org/#!Synapse:syn10145695/wiki/448396), updated hello_world_submit.cwl.json with this information and submitted the output:

    cwltool $tmpstuff --non-strict dockstore-tool-synapse-submit.cwl hello_world_submit.cwl.json

Contents of hello_world_submit.cwl.json
```
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": """",
    ""eval_id"": ""9603665"",
    ""file"": [
        {
            ""class"": ""File"",
            ""path"": ""helloworld.txt""
        }
    ],
    ""parent_id"": ""syn10145695""
}
```


---",9621938
hello_world,9622066_report.md,"## GA4GH/DREAM Hello World Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""James Eddy""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This simple ""hello world"" workflow that is designed to capture most of the basic elements of workflows that will be tested in this challenge. The workflow runs a single tool ([`dockstore-tool-helloworld`](https://dockstore.org/containers/quay.io/ga4gh-dream/dockstore-tool-helloworld)), which uses a reference file containing a single template format string (""Hello ____!"" when printed) and an input file containing a single plain string (e.g., ""World""). When the workflow is run, the input string is inserted into the template and written to a new file, now containing the string ""Hello World!"". The input is a text file containing the word ""Hello""; running the workflow requires < 1M of disk space (not counting Docker images) and should take < 1s of CPU time to complete.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Lon Blauvelt""
institution: ""UCSC""
```

### Submission overview

```YAML
platform: ""cwltool""
workflow_type: ""CWL""
runner_version: ""1.0.20170217172322""
docker_version: ""17.06.0-ce, build 02c1d87""
environment: ""EC2""
env_cpus: ""8""
env_memory: ""32 Gb""
env_disk: ""50 Gb""
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

### Steps

*I launched an EC2 instance of type `t2.xlarge` with one node, mounted a 50 Gb EFS volume.*

I used the following to update the instance:

```shell
sudo apt-get update
sudo apt-get -y upgrade
sudo apt-get -y dist-upgrade
```

Install docker:

```shell
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
sudo add-apt-repository ""deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable""
sudo apt-get update
apt-cache policy docker-ce
sudo apt-get install -y docker-ce
sudo usermod -aG docker ${USER}
sudo su - ${USER}
```

Install pip, a virtualenv, and the requisite pip installs (cwltool, schema-salad, avro, synapse, and html5lib):

```shell
sudo apt install -y python-pip
sudo pip install --upgrade pip
sudo pip install virtualenv
virtualenv --python /usr/bin/python2 cwl
source /home/ubuntu/cwl/bin/activate
pip install cwl-runner cwltool==1.0.20170217172322 schema-salad==2.6.20170630075932 avro==1.8.1  ruamel.yaml==0.14.12 --no-cache-dir
pip install synapseclient --no-cache-dir
pip install html5lib
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:

```shell
mkdir syn
cd syn
nano syn-login.synapseConfig
[PASTE] username & password
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **gdc_dnaseq_transform** workflow, and then modify the get file:

```shell
synapse get -r syn9689286
[PASTE] username & password
synapse get -r syn9689284
[PASTE] username & password
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `hello_world_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.

```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl hello_world_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `hello_world.cwl` and parameterized by `hello_world.cwl.json`:

```shell
cwltool --non-strict hello_world.cwl hello_world.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:

```shell
cwltool --non-strict hello_world_checker.cwl hello_world_checker.cwl.json
```

#### 6. Submit workflow outputs

I modified the parameters in `hello_world_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": ""/home/ubuntu/syn/syn-login.synapseConfig""
    },
    ""team_name"": ""UCSC GA4GH-DREAM Challenge Team"",
    ""eval_id"": ""syn10182019"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""helloworld.txt""
        }
    ],
    ""parent_id"": ""syn9851737""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool dockstore-tool-synapse-submit.cwl hello_world_submit.cwl.json`
```

---",9622066
hello_world,9622067_report.md,"## GA4GH/DREAM Hello World Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""James Eddy""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This simple ""hello world"" workflow that is designed to capture most of the basic elements of workflows that will be tested in this challenge. The workflow runs a single tool ([`dockstore-tool-helloworld`](https://dockstore.org/containers/quay.io/ga4gh-dream/dockstore-tool-helloworld)), which uses a reference file containing a single template format string (""Hello ____!"" when printed) and an input file containing a single plain string (e.g., ""World""). When the workflow is run, the input string is inserted into the template and written to a new file, now containing the string ""Hello World!"". The input is a text file containing the word ""Hello""; running the workflow requires < 1M of disk space (not counting Docker images) and should take < 1s of CPU time to complete.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Lon Blauvelt""
institution: ""UCSC""
```

### Submission overview

```YAML
platform: ""cwltool""
workflow_type: ""CWL""
runner_version: ""1.0.20170217172322""
docker_version: ""17.06.0-ce, build 02c1d87""
environment: ""EC2""
env_cpus: ""8""
env_memory: ""32 Gb""
env_disk: ""50 Gb""
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

### Steps

*I launched an EC2 instance of type `t2.xlarge` with one node, mounted a 50 Gb EFS volume.*

I used the following to update the instance:

```shell
sudo apt-get update
sudo apt-get -y upgrade
sudo apt-get -y dist-upgrade
```

Install docker:

```shell
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
sudo add-apt-repository ""deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable""
sudo apt-get update
apt-cache policy docker-ce
sudo apt-get install -y docker-ce
sudo usermod -aG docker ${USER}
sudo su - ${USER}
```

Install pip, a virtualenv, and the requisite pip installs (cwltool, schema-salad, avro, synapse, and html5lib):

```shell
sudo apt install -y python-pip
sudo pip install --upgrade pip
sudo pip install virtualenv
virtualenv --python /usr/bin/python2 cwl
source /home/ubuntu/cwl/bin/activate
pip install cwl-runner cwltool==1.0.20170217172322 schema-salad==2.6.20170630075932 avro==1.8.1  ruamel.yaml==0.14.12 --no-cache-dir
pip install synapseclient --no-cache-dir
pip install html5lib
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:

```shell
mkdir syn
cd syn
nano syn-login.synapseConfig
[PASTE] username & password
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **gdc_dnaseq_transform** workflow, and then modify the get file:

```shell
synapse get -r syn9689286
[PASTE] username & password
synapse get -r syn9689284
[PASTE] username & password
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `hello_world_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.

```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl hello_world_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `hello_world.cwl` and parameterized by `hello_world.cwl.json`:

```shell
cwltool --non-strict hello_world.cwl hello_world.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:

```shell
cwltool --non-strict hello_world_checker.cwl hello_world_checker.cwl.json
```

#### 6. Submit workflow outputs

I modified the parameters in `hello_world_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": ""/home/ubuntu/syn/syn-login.synapseConfig""
    },
    ""team_name"": ""UCSC GA4GH-DREAM Challenge Team"",
    ""eval_id"": ""syn10182019"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""helloworld.txt""
        }
    ],
    ""parent_id"": ""syn9851737""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool dockstore-tool-synapse-submit.cwl hello_world_submit.cwl.json`
```

---",9622067
hello_world,9622074_report.md,"## GA4GH/DREAM Hello World Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""James Eddy""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This simple ""hello world"" workflow that is designed to capture most of the basic elements of workflows that will be tested in this challenge. The workflow runs a single tool ([`dockstore-tool-helloworld`](https://dockstore.org/containers/quay.io/ga4gh-dream/dockstore-tool-helloworld)), which uses a reference file containing a single template format string (""Hello ____!"" when printed) and an input file containing a single plain string (e.g., ""World""). When the workflow is run, the input string is inserted into the template and written to a new file, now containing the string ""Hello World!"". The input is a text file containing the word ""Hello""; running the workflow requires < 1M of disk space (not counting Docker images) and should take < 1s of CPU time to complete.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Abraham Chavez"" # your name here
institution: ""UCSC"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170217172322"" # indicate executor version used
docker_version: ""1.12.6"" # from `docker --version`
environment: ""local OS X"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""4"" # indicate number of cores in environment
env_memory: ""16"" # indicate available RAM in environment
env_disk: ""250"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

If you have not set up your environment and install dependencies like **cwltool**, **dockstore**, **java** and so on
I recommend you follow [**this**](https://www.synapse.org/#!Synapse:syn10220609) instructions.

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir hello_world_cwltool
cd hello_world_cwltool
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **hello_world** workflow:
```shell
synapse get syn9733811 # hello_world_get_get.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `hello_world_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl hello_world_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `hello_world.cwl` and parameterized by `hello_world.cwl.json`:
```shell
cwltool --non-strict hello_world.cwl hello_world.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool --non-strict hello_world_checker.cwl hello_world_checker.cwl.json
cat results.json | grep overall
```

#### 6. Submit workflow outputs

I modified the parameters in `hello_world_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""Your Team Name"",
    ""eval_id"": ""9603665"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""helloworld.txt""
        }
    ],
    ""parent_id"": ""yourSynapseId""
}
```
Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl hello_world_submit.cwl.json`
```

---",9622074
hello_world,9622782_report.md,"## GA4GH/DREAM Hello World Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""James Eddy""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This simple ""hello world"" workflow that is designed to capture most of the basic elements of workflows that will be tested in this challenge. The workflow runs a single tool ([`dockstore-tool-helloworld`](https://dockstore.org/containers/quay.io/ga4gh-dream/dockstore-tool-helloworld)), which uses a reference file containing a single template format string (""Hello ____!"" when printed) and an input file containing a single plain string (e.g., ""World""). When the workflow is run, the input string is inserted into the template and written to a new file, now containing the string ""Hello World!"". The input is a text file containing the word ""Hello""; running the workflow requires < 1M of disk space (not counting Docker images) and should take < 1s of CPU time to complete.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Abraham Chavez"" 
institution: ""UCSC"" 
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""dockstore cli"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.2.3"" # indicate executor version used
docker_version: ""17.06.0-ce"" # from `docker --version`
environment: ""EC2"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""32"" # indicate number of cores in environment
env_memory: ""240Gb"" # indicate available RAM in environment
env_disk: ""200Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

f you have not set up your environment and install dependencies like **cwltool**, **dockstore**, **java** and so on
I recommend you follow [**this**](https://www.synapse.org/#!Synapse:syn10220609) instructions.


I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir hello_world_dockstore
cd hello_world_dockstore
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **hello_world** workflow:
```shell
synapse get syn9732887 #  hello_world_submit.cwl.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn8568933 # template.txt
synapse get syn8568931 # input.txt
synapse get syn8568932 # knownoutput.txt
```

#### 3. Provision all workflow files

Run the following command to provision the JSON runner file
```shell
dockstore tool convert entry2json --entry quay.io/ga4gh-dream/dockstore-tool-helloworld:1.0.2 > Dockstore.json
```

#### 4. Modify your `Dockstore.json` file as follows in order to run the hello-world workflow successfully
```JSON
{ 
""output"": { ""path"": ""output.txt"", ""class"": ""File"" },
""input_file"": { ""path"": ""input.txt"", ""class"": ""File""},
 ""template_file"": { ""path"": ""template.txt"", ""class"":""File"" }
 }
```

#### 5. Run main workflow

Using dockstore command, run the main workflow
```shell
dockstore tool launch --entry quay.io/ga4gh-dream/dockstore-tool-helloworld:1.0.2 --json Dockstore.json
```

#### 6. Run workflow checker tool
Create a file named `test.cwl.json` with the following input
```JSON
{
    ""knowngood_file"": {
        ""class"": ""File"",
        ""path"": ""knownoutput.txt""
    },
    ""helloworld_file"": {
        ""class"": ""File"",
        ""path"": ""helloworld.txt""
    }
}
```
Then run the following command to check the workflow using dockstore 
```shell
dockstore tool launch --entry quay.io/ga4gh-dream/dockstore-tool-helloworld-checker:1.1.2 --json test.cwl.json
cat results.json | grep overall
```

#### 7. Submit workflow outputs

I modified the parameters in `hello_world_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""Your Team Name"",
    ""eval_id"": ""AutAssign"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""helloworld.txt""
        }
    ],
    ""parent_id"": ""YourParentId""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl hello_world_submit.cwl.json
```

---",9622782
hello_world,9622802_report.md,"## GA4GH/DREAM Hello World Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""James Eddy""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This simple ""hello world"" workflow that is designed to capture most of the basic elements of workflows that will be tested in this challenge. The workflow runs a single tool ([`dockstore-tool-helloworld`](https://dockstore.org/containers/quay.io/ga4gh-dream/dockstore-tool-helloworld)), which uses a reference file containing a single template format string (""Hello ____!"" when printed) and an input file containing a single plain string (e.g., ""World""). When the workflow is run, the input string is inserted into the template and written to a new file, now containing the string ""Hello World!"". The input is a text file containing the word ""Hello""; running the workflow requires < 1M of disk space (not counting Docker images) and should take < 1s of CPU time to complete.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""James Eddy"" # your name here
institution: ""Sage Bionetworks"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170217172322"" # indicate executor version used
docker_version: ""17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""4"" # indicate number of cores in environment
env_memory: ""16Gb"" # indicate available RAM in environment
env_disk: ""300Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

#### 1. Set up environment

On a personal laptop with Docker and Anaconda already installed, I created and configured a virtual environment  with `synapseclient` and `cwltool` as follows:
```shell
conda create -n syncwl
source activate syncwl
pip install synapseclient --no-cache-dir
pip install schema-salad==2.2.20170222151604 cwltool==1.0.20170217172322 --no-cache-dir
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir hello_world
cd hello_world
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **hello_world** workflow:
```shell
synapse get syn9733811 # hello_world_get_get.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 4. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `hello_world_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl hello_world_get.cwl.json
```

#### 5. Run main workflow

I again used `cwltool` to run the workflow, as defined in `hello_world.cwl` and parameterized by `hello_world.cwl.json`:
```shell
cwltool --non-strict hello_world.cwl hello_world.cwl.json
```

#### 6. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool --non-strict hello_world_checker.cwl hello_world_checker.cwl.json
cat results.json | grep -i overall
```

#### 7. Submit workflow outputs

I modified the parameters in `hello_world_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""SageWorkflowRunners"",
    ""eval_id"": ""9603665"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""helloworld.txt""
        }
    ],
    ""parent_id"": ""syn9851737""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl hello_world_submit.cwl.json`
```

---",9622802
hello_world,9623072_report.md,"## GA4GH/DREAM Hello World Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""James Eddy""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This simple ""hello world"" workflow that is designed to capture most of the basic elements of workflows that will be tested in this challenge. The workflow runs a single tool ([`dockstore-tool-helloworld`](https://dockstore.org/containers/quay.io/ga4gh-dream/dockstore-tool-helloworld)), which uses a reference file containing a single template format string (""Hello ____!"" when printed) and an input file containing a single plain string (e.g., ""World""). When the workflow is run, the input string is inserted into the template and written to a new file, now containing the string ""Hello World!"". The input is a text file containing the word ""Hello""; running the workflow requires < 1M of disk space (not counting Docker images) and should take < 1s of CPU time to complete.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Lon Blauvelt""
institution: ""UCSC""
```

### Submission overview

```YAML
platform: ""Toil""
workflow_type: ""CWL""
runner_version: ""3.10.0a1""
docker_version: ""17.06.0-ce, build 02c1d87""
environment: ""EC2""
env_cpus: ""8""
env_memory: ""32 Gb""
env_disk: ""50 Gb""
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

### Steps

*I launched an EC2 instance of type `t2.xlarge` with one node, mounted a 50 Gb EFS volume.*

I used the following to update the instance:

```shell
sudo apt-get update
sudo apt-get -y upgrade
sudo apt-get -y dist-upgrade
```

Install docker:

```shell
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
sudo add-apt-repository ""deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable""
sudo apt-get update
apt-cache policy docker-ce
sudo apt-get install -y docker-ce
sudo usermod -aG docker ${USER}
sudo su - ${USER}
```

Install pip, a virtualenv, and the requisite pip installs (cwltool, schema-salad, avro, synapse, and html5lib):

```shell
sudo apt install -y python-pip
sudo pip install --upgrade pip
sudo pip install virtualenv
virtualenv --python /usr/bin/python2 cwl
source /home/ubuntu/cwl/bin/activate
pip install cwl-runner cwltool==1.0.20170217172322 schema-salad==2.6.20170630075932 avro==1.8.1  ruamel.yaml==0.14.12 --no-cache-dir
pip install toil
pip install synapseclient --no-cache-dir
pip install html5lib
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:

```shell
mkdir syn
cd syn
nano syn-login.synapseConfig
[PASTE] username & password
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **gdc_dnaseq_transform** workflow, and then modify the get file:

```shell
synapse get -r syn9689286
[PASTE] username & password
synapse get -r syn9689284
[PASTE] username & password
```

#### 3. Provision all workflow files

I used `cwltoil` to run `dockstore-tool-synapse-get.cwl` with parameters in `hello_world_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.

```shell
cwltoil dockstore-tool-synapse-get.cwl hello_world_get.cwl.json
```

#### 4. Run main workflow
cwltoil puts the template.txt file in the current working directory and does not make the proper directory association, so you'll need to edit hello_world.cwl.json as follows:
```shell
nano hello_world.cwl.json
```
And change:
```shell
{
    ""template_file"": {
        ""class"": ""File"",
        ""path"": ""hello_world_ref/ref_subfolder/template.txt""
    },
    ""input_file"": {
        ""class"": ""File"",
        ""path"": ""input.txt""
    }
}
```
To this:
```shell
{
    ""template_file"": {
        ""class"": ""File"",
        ""path"": ""template.txt""
    },
    ""input_file"": {
        ""class"": ""File"",
        ""path"": ""input.txt""
    }
}
```
I again used `cwltoil` to run the workflow, as defined in `hello_world.cwl` and parameterized by `hello_world.cwl.json`:

```shell
cwltoil hello_world.cwl hello_world.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:

```shell
cwltoil hello_world_checker.cwl hello_world_checker.cwl.json
```

#### 6. Submit workflow outputs

I modified the parameters in `hello_world_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": ""/home/ubuntu/syn/syn-login.synapseConfig""
    },
    ""team_name"": ""UCSC GA4GH-DREAM Challenge Team"",
    ""eval_id"": ""syn10182019"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""helloworld.txt""
        }
    ],
    ""parent_id"": ""syn9851737""
}
```

Finally, I submitted outputs using `cwltoil` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltoil dockstore-tool-synapse-submit.cwl hello_world_submit.cwl.json`
```

---",9623072
hello_world,9623074_report.md,"## GA4GH/DREAM Hello World Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""James Eddy""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This simple ""hello world"" workflow that is designed to capture most of the basic elements of workflows that will be tested in this challenge. The workflow runs a single tool ([`dockstore-tool-helloworld`](https://dockstore.org/containers/quay.io/ga4gh-dream/dockstore-tool-helloworld)), which uses a reference file containing a single template format string (""Hello ____!"" when printed) and an input file containing a single plain string (e.g., ""World""). When the workflow is run, the input string is inserted into the template and written to a new file, now containing the string ""Hello World!"". The input is a text file containing the word ""Hello""; running the workflow requires < 1M of disk space (not counting Docker images) and should take < 1s of CPU time to complete.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Lon Blauvelt""
institution: ""UCSC""
```

### Submission overview

```YAML
platform: ""Toil""
workflow_type: ""CWL""
runner_version: ""3.10.0a1""
docker_version: ""17.06.0-ce, build 02c1d87""
environment: ""EC2""
env_cpus: ""8""
env_memory: ""32 Gb""
env_disk: ""50 Gb""
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

### Steps

*I launched an EC2 instance of type `t2.xlarge` with one node, mounted a 50 Gb EFS volume.*

I used the following to update the instance:

```shell
sudo apt-get update
sudo apt-get -y upgrade
sudo apt-get -y dist-upgrade
```

Install docker:

```shell
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
sudo add-apt-repository ""deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable""
sudo apt-get update
apt-cache policy docker-ce
sudo apt-get install -y docker-ce
sudo usermod -aG docker ${USER}
sudo su - ${USER}
```

Install pip, a virtualenv, and the requisite pip installs (cwltool, schema-salad, avro, synapse, and html5lib):

```shell
sudo apt install -y python-pip
sudo pip install --upgrade pip
sudo pip install virtualenv
virtualenv --python /usr/bin/python2 cwl
source /home/ubuntu/cwl/bin/activate
pip install cwl-runner cwltool==1.0.20170217172322 schema-salad==2.6.20170630075932 avro==1.8.1  ruamel.yaml==0.14.12 --no-cache-dir
pip install toil
pip install synapseclient --no-cache-dir
pip install html5lib
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:

```shell
mkdir syn
cd syn
nano syn-login.synapseConfig
[PASTE] username & password
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **gdc_dnaseq_transform** workflow, and then modify the get file:

```shell
synapse get -r syn9689286
[PASTE] username & password
synapse get -r syn9689284
[PASTE] username & password
```

#### 3. Provision all workflow files

I used `cwltoil` to run `dockstore-tool-synapse-get.cwl` with parameters in `hello_world_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.

```shell
cwltoil dockstore-tool-synapse-get.cwl hello_world_get.cwl.json
```

#### 4. Run main workflow
cwltoil puts the template.txt file in the current working directory and does not make the proper directory association, so you'll need to edit hello_world.cwl.json as follows:
```shell
nano hello_world.cwl.json
```
And change:
```shell
{
    ""template_file"": {
        ""class"": ""File"",
        ""path"": ""hello_world_ref/ref_subfolder/template.txt""
    },
    ""input_file"": {
        ""class"": ""File"",
        ""path"": ""input.txt""
    }
}
```
To this:
```shell
{
    ""template_file"": {
        ""class"": ""File"",
        ""path"": ""template.txt""
    },
    ""input_file"": {
        ""class"": ""File"",
        ""path"": ""input.txt""
    }
}
```
I again used `cwltoil` to run the workflow, as defined in `hello_world.cwl` and parameterized by `hello_world.cwl.json`:

```shell
cwltoil hello_world.cwl hello_world.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:

```shell
cwltoil hello_world_checker.cwl hello_world_checker.cwl.json
```

#### 6. Submit workflow outputs

I modified the parameters in `hello_world_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": ""/home/ubuntu/syn/syn-login.synapseConfig""
    },
    ""team_name"": ""UCSC GA4GH-DREAM Challenge Team"",
    ""eval_id"": ""syn10182019"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""helloworld.txt""
        }
    ],
    ""parent_id"": ""syn9851737""
}
```

Finally, I submitted outputs using `cwltoil` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltoil dockstore-tool-synapse-submit.cwl hello_world_submit.cwl.json`
```

---",9623074
hello_world,9623202_report.md,"## GA4GH/DREAM Hello World Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Zhicheng Ji""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This simple ""hello world"" workflow that is designed to capture most of the basic elements of workflows that will be tested in this challenge. The workflow runs a single tool ([`dockstore-tool-helloworld`](https://dockstore.org/containers/quay.io/ga4gh-dream/dockstore-tool-helloworld)), which uses a reference file containing a single template format string (""Hello ____!"" when printed) and an input file containing a single plain string (e.g., ""World""). When the workflow is run, the input string is inserted into the template and written to a new file, now containing the string ""Hello World!"". The input is a text file containing the word ""Hello""; running the workflow requires < 1M of disk space (not counting Docker images) and should take < 1s of CPU time to complete.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Zhicheng Ji"" 
institution: ""Johns Hopkins University""
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""cwltool""
workflow_type: ""CWL""
runner_version: ""1.0.20170217172322""
docker_version: ""17.06.0-ce""
environment: ""EC2""
env_cpus: ""1""
env_memory: ""1GB""
env_disk: ""8GB""
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

On an EC2 Ubuntu environment with Docker installed, I created and configured a virtual environment as follows:
```shell
pip install --upgrade pip
pip install schema-salad==2.2.20170222151604 cwltool==1.0.20170217172322
pip install synapseclient
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir hello_world_run
cd hello_world_run
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **hello_world** workflow:
```shell
synapse get syn9733811 # hello_world_get_get.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `hello_world_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl hello_world_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `hello_world.cwl` and parameterized by `hello_world.cwl.json`:
```shell
cwltool --non-strict hello_world.cwl hello_world.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool --non-strict hello_world_checker.cwl hello_world_checker.cwl.json
cat results.json | grep -i overall
```

#### 6. Submit workflow outputs

I modified the parameters in `hello_world_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": ""../.synapseConfig""
    },
    ""team_name"": ""zji90"",
    ""eval_id"": ""9603665"",
    ""file"": [
        {
            ""class"": ""File"",
            ""path"": ""helloworld.txt""
        }
    ],
    ""parent_id"": ""syn10221523""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool dockstore-tool-synapse-submit.cwl hello_world_submit.cwl.json
```

---",9623202
hello_world,9623660_report.md,"## GA4GH/DREAM Hello World Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""James Eddy""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This simple ""hello world"" workflow that is designed to capture most of the basic elements of workflows that will be tested in this challenge. The workflow runs a single tool ([`dockstore-tool-helloworld`](https://dockstore.org/containers/quay.io/ga4gh-dream/dockstore-tool-helloworld)), which uses a reference file containing a single template format string (""Hello ____!"" when printed) and an input file containing a single plain string (e.g., ""World""). When the workflow is run, the input string is inserted into the template and written to a new file, now containing the string ""Hello World!"". The input is a text file containing the word ""Hello""; running the workflow requires < 1M of disk space (not counting Docker images) and should take < 1s of CPU time to complete.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Han Hu"" # your name here
institution: ""Curacloud Corporation"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170721160741"" # indicate executor version used
docker_version: ""17.05.0-ce, build 89658be"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""40"" # indicate number of cores in environment
env_memory: ""128Gb"" # indicate available RAM in environment
env_disk: ""2.4Tb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

On a personal laptop with Docker and Anaconda installed, I created and configured a virtual environment as follows:
```shell
conda create -n hello_world
source activate hello_world
pip install --upgrade pip
pip install schema-salad==2.2.20170222151604 cwltool==1.0.20170217172322
pip install synapseclient
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir hello_world_run
cd hello_world_run
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **hello_world** workflow:
```shell
synapse get syn9733811 # hello_world_get_get.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `hello_world_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl hello_world_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `hello_world.cwl` and parameterized by `hello_world.cwl.json`:
```shell
cwltool --non-strict hello_world.cwl hello_world.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool --non-strict hello_world_checker.cwl hello_world_checker.cwl.json
cat results.json | grep -i overall
```

#### 6. Submit workflow outputs

I modified the parameters in `hello_world_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""BirdsEyeView"",
    ""eval_id"": ""9603665"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""helloworld.txt""
        }
    ],
    ""parent_id"": ""syn10226123""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl hello_world_submit.cwl.json
```

---",9623660
hello_world,9624612_report.md,"## GA4GH/DREAM Hello World Workflow

### Workflow description

```YAML
contributor: ""James Eddy""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This simple ""hello world"" workflow that is designed to capture most of the basic elements of workflows that will be tested in this challenge. The workflow runs a single tool ([`dockstore-tool-helloworld`](https://dockstore.org/containers/quay.io/ga4gh-dream/dockstore-tool-helloworld)), which uses a reference file containing a single template format string (""Hello ____!"" when printed) and an input file containing a single plain string (e.g., ""World""). When the workflow is run, the input string is inserted into the template and written to a new file, now containing the string ""Hello World!"". The input is a text file containing the word ""Hello""; running the workflow requires < 1M of disk space (not counting Docker images) and should take < 1s of CPU time to complete.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Bogdan Gavrilovic"" # your name here
institution: ""Seven Bridges Genomics"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""SevenBridges"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""latest"" # indicate executor version used
docker_version: ""1.12.6"" # from `docker --version`
environment: ""EC2"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""15Gb"" # indicate available RAM in environment
env_disk: ""700Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```
### Steps

#####1. [Install rabix](https://github.com/rabix/bunny#installing) on your machine and set environment variable $BUNNY. You need docker and java installed to run rabix:
```shell
wget https://github.com/rabix/bunny/releases/download/v1.0.0/rabix-1.0.0.tar.gz -O rabix-1.0.0.tar.gz && tar -xvf rabix-1.0.0.tar.gz
export BUNNY=$PWD/rabix-cli-1.0.0/rabix
```
#####2. If you've not already retrieved the CWL and data with synapse-get, you can use the [Synapse python client](https://github.com/Sage-Bionetworks/synapsePythonClient#installation):
```shell
pip install synapseclient
synapse get -r syn9630940 # hello world workflow, tools and input files
synapse get syn9732885   # dockstore-tool-synapse-submit.cwl
```

#### Running on the [Cancer Genomics Cloud](https://cgc.sbgenomics.com/) 

#####3. Log in to the [Cancer Genomics Cloud](https://cgc.sbgenomics.com/) and [create a project](https://docs.cancergenomicscloud.org/docs/create-a-project) 
- Academic Users can create a free account on the Cancer Genomics Cloud (CGC). New users receive \$300 in cloud computing credits that you can apply to this challenge, and your own research. Additionally, users that leave feedback on their experience receive an additional \$1000 in cloud compute credits.
- Commercial users of the Seven Bridges Platform that wish to participate in the DREAM challenge can also create an account on the CGC to participate in this academic exercise and receive free credits to run the challenge workflows. Alternatively, commercial users are free to run DREAM challenge workflows in their commercial platform accounts, but should realize that they will incur cloud compute charges to do so. 
&nbsp;
#####4. Installing the workflow on the platform can be done using:  
**a)** [Rabix Composer app for CWL tool editing](http://rabix.io/) or   
**b)** a [CWL CommandLineTool](https://github.com/bogdang989/Import-CWL-to-SevenBridges) for importing CWL workflows to the Seven Bridges platform.  

#####4a. Rabix Composer
If you’re interested in trying out Seven Bridges’ new integrated development environment for creating CWL descriptions of tools and workflows, you can use the [Rabix Composer](http://rabix.io/) to upload the workflow to the platform. 
Use Rabix Composer to add the workflow to the platform:  
- [Install Rabix Composer](http://docs.rabix.io/rabix-composer-installation)
- [Configure Composer](http://docs.rabix.io/rabix-composer-configuration) to connect to the CGC or Seven Bridges platform
- [Add the project](http://docs.rabix.io/rabix-composer-configuration) you created for the DREAM challenge to the workspace
- [Add the local directory](http://docs.rabix.io/rabix-composer-configuration) containing the workflow to the workspace
- [Open](http://docs.rabix.io/rabix-composer-basics) the workflow with Composer
- [Save the workflow to the Platform project](http://docs.rabix.io/rabix-composer-basics) you added to the workspace
- Log into the Platform and [upload the input files](https://docs.cancergenomicscloud.org/docs/upload-to-the-cgc) to the project. 
- Run the task

> You can [upload the files manually to the platform](https://docs.cancergenomicscloud.org/docs/upload-to-the-cgc) by using either CGC Uploader app, command-line uploader, Python API or some other available upload method... All of the available methods are described in [the documentation](https://docs.cancergenomicscloud.org/docs/upload-to-the-cgc) 

#####4b. CWLtoSBG import tool
Download the CWL importing tool and **place it in the same directory with the CWL workflow** that should be installed on the platform. You can download the tool from [github](https://github.com/bogdang989/Import-CWL-to-SevenBridges) manually or from command-line by typing:
```shell
git clone https://github.com/bogdang989/Import-CWL-to-SevenBridges
```
Modify the `cwl_to_sbg-inputs.yaml` to include:

- Paths to `hello_world.cwl` and `hello_world.cwl.json`
- Id of your project on the platform (From project URL, in format *user-name/project-name* )
For example if project URL is https://cgc.sbgenomics.com/u/bogdang/demo-project; project_id is `bogdang/demo-project`
- Your [authentication token](http://docs.sevenbridges.com/docs/get-your-authentication-token)
- Adequate [EC2 instance type](http://www.ec2instances.info/)
&nbsp;
After modifying `cwl_to_sbg-inputs.yaml` with your information, import the workflow to the platform by running
```shell
$BUNNY cwl_to_sbg.cwl cwl_to_sbg-inputs.yaml
```
This will install the workflow and all required apps on the platform. All the files that are required for the task execution are uploaded if they are not uploaded previously. Template draft task is created. If `run_task` is set to `true` the task execution will start on the platform.
You can now open `task` page on the platform project to see task execution details.

### Validating results
[Download the output files](https://docs.cancergenomicscloud.org/docs/download-results) to your local machine.

Modify the `hello_world_checker.cwl.json` to include the path to the requested output file and run checker tool
```shell
$BUNNY hello_world_checker.cwl hello_world_checker.cwl.json
```
Check results
```shell
cat ./path/to/results.json
``` 
```json
{
    ""overall"": true,
    ""steps"": {
        ""md5_check"": true
    }
}
```
### Submitting results
- Copy the synapseConfig file to the current working directory.
- Update `hello_world_submit.cwl.json` with correct
`team_name` - the name of your team in plain text format (e.g., ""GA4GH-Sage Contenders"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
`file` - paths to output files
Run the tool
```shell
$BUNNY dockstore-tool-synapse-submit.cwl hello_world_submit.cwl.json
```

---",9624612
hello_world,9627509_report.md,"## GA4GH/DREAM Hello World Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""James Eddy""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This simple ""hello world"" workflow that is designed to capture most of the basic elements of workflows that will be tested in this challenge. The workflow runs a single tool ([`dockstore-tool-helloworld`](https://dockstore.org/containers/quay.io/ga4gh-dream/dockstore-tool-helloworld)), which uses a reference file containing a single template format string (""Hello ____!"" when printed) and an input file containing a single plain string (e.g., ""World""). When the workflow is run, the input string is inserted into the template and written to a new file, now containing the string ""Hello World!"". The input is a text file containing the word ""Hello""; running the workflow requires < 1M of disk space (not counting Docker images) and should take < 1s of CPU time to complete.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Lon Blauvelt""
institution: ""UCSC""
```

### Submission overview

```YAML
platform: ""Toil (new cwltoil branch)""
workflow_type: ""CWL""
runner_version: ""3.10.0a1""
docker_version: ""17.06.0-ce, build 02c1d87""
environment: ""EC2""
env_cpus: ""8""
env_memory: ""32 Gb""
env_disk: ""50 Gb""
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

### Steps

*I launched an EC2 instance of type `t2.xlarge` with one node, mounted a 50 Gb EFS volume.*

I used the following to update the instance:

```shell
sudo apt-get update
sudo apt-get -y upgrade
sudo apt-get -y dist-upgrade
```

Install docker:

```shell
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
sudo add-apt-repository ""deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable""
sudo apt-get update
apt-cache policy docker-ce
sudo apt-get install -y docker-ce
sudo usermod -aG docker ${USER}
sudo su - ${USER}
```

Install pip, a virtualenv, and the requisite pip installs (cwltool, schema-salad, avro, synapse, and html5lib):

```shell
sudo apt install -y python-pip
sudo pip install --upgrade pip
sudo pip install virtualenv
virtualenv --python /usr/bin/python2 cwl
source /home/ubuntu/cwl/bin/activate
pip install cwl-runner schema-salad==2.6.20170630075932 avro==1.8.1  ruamel.yaml==0.14.12 --no-cache-dir
pip install cwltool==1.0.20170815202200
pip install git+https://github.com/BD2KGenomics/toil.git@9cf913bf53
pip install synapseclient --no-cache-dir
pip install html5lib
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:

```shell
mkdir syn
cd syn
nano syn-login.synapseConfig
[PASTE] username & password
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **gdc_dnaseq_transform** workflow, and then modify the get file:

```shell
synapse get -r syn9689286
[PASTE] username & password
synapse get -r syn9689284
[PASTE] username & password
```

#### 3. Provision all workflow files

I used `cwltoil` to run `dockstore-tool-synapse-get.cwl` with parameters in `hello_world_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.

```shell
cwltoil dockstore-tool-synapse-get.cwl hello_world_get.cwl.json
```

#### 4. Run main workflow
I used `cwltoil` to run the workflow, as defined in `hello_world.cwl` and parameterized by `hello_world.cwl.json`:
```shell
cwltoil hello_world.cwl hello_world.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltoil hello_world_checker.cwl hello_world_checker.cwl.json
```

#### 6. Submit workflow outputs

I modified the parameters in `hello_world_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": ""/home/ubuntu/syn/syn-login.synapseConfig""
    },
    ""team_name"": ""UCSC GA4GH-DREAM Challenge Team"",
    ""eval_id"": ""syn10182019"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""helloworld.txt""
        }
    ],
    ""parent_id"": ""syn9851737""
}
```

Finally, I submitted outputs using `cwltoil` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltoil dockstore-tool-synapse-submit.cwl hello_world_submit.cwl.json`
```

---",9627509
hello_world,9630783_report.md,"## GA4GH/DREAM Hello World Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Benjamin Story""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This simple ""hello world"" workflow that is designed to capture most of the basic elements of workflows that will be tested in this challenge. The workflow runs a single tool ([`dockstore-tool-helloworld`](https://dockstore.org/containers/quay.io/ga4gh-dream/dockstore-tool-helloworld)), which uses a reference file containing a single template format string (""Hello ____!"" when printed) and an input file containing a single plain string (e.g., ""World""). When the workflow is run, the input string is inserted into the template and written to a new file, now containing the string ""Hello World!"". The input is a text file containing the word ""Hello""; running the workflow requires < 1M of disk space (not counting Docker images) and should take < 1s of CPU time to complete.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Benjamin Story"" # your name here
institution: ""European Molecular Biology Laboratory, Heidelberg"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-08-27""
platform: ""cwltool"" 
workflow_type: ""CWL"" 
runner_version: ""1.0.20170217172322""
docker_version: ""1.7.1, build 786b29d""
environment: ""local"" 
env_cpus: ""12""
env_memory: ""72Gb""
env_disk: ""10Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

On a personal laptop with Docker and Anaconda installed, I created and configured a virtual environment as follows:
```shell
conda create -n hello_world
source activate hello_world
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir hello_world_run
cd hello_world_run
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **hello_world** workflow:
```shell
synapse get syn9733811 # hello_world_get_get.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `hello_world_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl hello_world_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `hello_world.cwl` and parameterized by `hello_world.cwl.json`:
```shell
cwltool --non-strict hello_world.cwl hello_world.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool --non-strict hello_world_checker.cwl hello_world_checker.cwl.json
cat results.json | grep -i overall
```

#### 6. Submit workflow outputs

I modified the parameters in `hello_world_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""EMBL GA4GH-DREAM Challenge Team"",
    ""eval_id"": ""9603665"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""helloworld.txt""
        }
    ],
    ""parent_id"": ""syn10478161""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl hello_world_submit.cwl.json
```

---",9630783
hello_world,9632471_report.md,"## GA4GH/DREAM Hello World Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""James Eddy""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This simple ""hello world"" workflow that is designed to capture most of the basic elements of workflows that will be tested in this challenge. The workflow runs a single tool ([`dockstore-tool-helloworld`](https://dockstore.org/containers/quay.io/ga4gh-dream/dockstore-tool-helloworld)), which uses a reference file containing a single template format string (""Hello ____!"" when printed) and an input file containing a single plain string (e.g., ""World""). When the workflow is run, the input string is inserted into the template and written to a new file, now containing the string ""Hello World!"". The input is a text file containing the word ""Hello""; running the workflow requires < 1M of disk space (not counting Docker images) and should take < 1s of CPU time to complete.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Gary Luu"" # your name here
institution: ""Dockstore - OICR"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-05"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""dockstore"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.2.7"" # indicate executor version used
docker_version: ""17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""4"" # indicate number of cores in environment
env_memory: ""32"" # indicate available RAM in environment
env_disk: ""470 GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-20""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

On a personal desktop, I installed Docker, pip, cwltool, and the Dockstore command-line helper using a procedure similar to https://github.com/denis-yuen/2017-cloud-workflows-misc/blob/master/install-and-run-with-dockstore.md .  
However, I used my own modified dockstore CLI (which will be 1.2.7)

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir hello_world
cd hello_world
cp ~/.synapseConfig .
```
#### 2. Download required files

I downloaded hello_world_get.cwl.json from the website. 


#### 3. Provision all workflow files

I used the synapse-get tool from Dockstore.
```shell
dockstore tool launch --entry quay.io/ga4gh-dream/dockstore-tool-synapse-get --json hello_world_get.cwl.json
```

#### 4. Run main workflow

I used dockstore to launch the recently downloaded hello_world.cwl 
```shell
dockstore workflow launch --local-entry hello_world.cwl --json hello_world.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `dockstore` to run the checker as follows:
```shell
dockstore tool launch --local-entry hello_world_checker.cwl --json hello_world_checker.cwl.json
cat results.json | grep Overall
```

#### 6. Submit workflow outputs

I modified the parameters in `hello_world_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""Dockstore Team"",
    ""eval_id"": ""9603665"",
    ""file"": [
        {
            ""class"": ""File"",
            ""path"": ""helloworld.txt""
        }
    ],
    ""parent_id"": ""syn9877725""
}
```

Finally, I submitted outputs using dockstore-tool-synapse-submit`:
```shell
dockstore tool launch --entry quay.io/ga4gh-dream/dockstore-tool-synapse-submit --json hello_world_submit.cwl.json
```

---",9632471
hello_world,9634044_report.md,"## GA4GH/DREAM Hello World Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""James Eddy""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This simple ""hello world"" workflow that is designed to capture most of the basic elements of workflows that will be tested in this challenge. The workflow runs a single tool ([`dockstore-tool-helloworld`](https://dockstore.org/containers/quay.io/ga4gh-dream/dockstore-tool-helloworld)), which uses a reference file containing a single template format string (""Hello ____!"" when printed) and an input file containing a single plain string (e.g., ""World""). When the workflow is run, the input string is inserted into the template and written to a new file, now containing the string ""Hello World!"". The input is a text file containing the word ""Hello""; running the workflow requires < 1M of disk space (not counting Docker images) and should take < 1s of CPU time to complete.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Byunggil Yoo""
institution: ""Children's Mercy Kansas City""
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-05"" 
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170817131858"" # indicate executor version used
docker_version: ""17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""48"" # indicate number of cores in environment
env_memory: ""512GB"" # indicate available RAM in environment
env_disk: ""368TB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

On a node (CentOS 7.2.1511) of a local cluster with Docker (17.06.0-ce) and Anaconda installed, I created and configured a virtual environment using the following YAML file:

```
channels:
  - bioconda
  - conda-forge
  - anaconda
  - r
dependencies:
  - cwltool=1.0.20170817131858
  - synapseclient
```

I created a working directory for the current workflow and created a copy of my Synapse credentials (~/.synapseConfig) in that folder:

```shell
mkdir hello_world
cd hello_world
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **hello_world** workflow:
```shell
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
synapse get syn9733811 # hello_world_get.cwl.json
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `hello_world_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --outdir hellow_world --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ \
        --non-strict dockstore-tool-synapse-get.cwl hello_world_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `hello_world.cwl` and parameterized by `hello_world.cwl.json`:
```shell
cwltool --basedir hello_world/ --outdir hello_world/ \
    --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
    hello_world/hello_world.cwl hello_world/hello_world.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool --basedir hello_world/ --outdir hello_world/ \
        --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
        hello_world/hello_world_checker.cwl hello_world/hello_world_checker.cwl.json
```

#### 6. Submit workflow outputs

I modified the parameters in `hello_world_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""Childrens Mercy GA4GH-DREAM Challenge Team"",
    ""eval_id"": ""9603665"",
    ""file"": [
        {
            ""class"": ""File"",
            ""path"": ""helloworld.txt""
        }
    ],
    ""parent_id"": ""syn10290419""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --basedir hello_world/ --outdir hello_world/ \
        --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
        dockstore-tool-synapse-submit.cwl hello_world/hello_world_submit.cwl.json
```

---",9634044
hello_world,9634727_report.md,"## GA4GH/DREAM Hello World Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""James Eddy""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This simple ""hello world"" workflow that is designed to capture most of the basic elements of workflows that will be tested in this challenge. The workflow runs a single tool ([`dockstore-tool-helloworld`](https://dockstore.org/containers/quay.io/ga4gh-dream/dockstore-tool-helloworld)), which uses a reference file containing a single template format string (""Hello ____!"" when printed) and an input file containing a single plain string (e.g., ""World""). When the workflow is run, the input string is inserted into the template and written to a new file, now containing the string ""Hello World!"". The input is a text file containing the word ""Hello""; running the workflow requires < 1M of disk space (not counting Docker images) and should take < 1s of CPU time to complete.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Denis Yuen""
institution: ""OICR""
```

### Submission overview

```YAML
platform: ""dockstore 1.2.8"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.2.8"" # indicate executor version used
docker_version: ""17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""64GB"" # indicate available RAM in environment
env_disk: ""400GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

On a personal desktop, I installed Docker, pip, cwltool, and the Dockstore command-line helper using a procedure similar to https://github.com/denis-yuen/2017-cloud-workflows-misc/blob/master/install-and-run-with-dockstore.md

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir hello_world_run
cd hello_world_run
cp ~/.synapseConfig .
```

#### 2. Download required files

I downloaded hello_world_get.json from the website. I then got the synapse-submit and synapse-get commands from Dockstore. 
```shell
dockstore tool cwl --entry quay.io/ga4gh-dream/dockstore-tool-synapse-submit > dockstore-tool-synapse-submit.cwl
dockstore tool cwl --entry quay.io/ga4gh-dream/dockstore-tool-synapse-get > dockstore-tool-synapse-get.cwl
```

#### 4. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `hello_world_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl hello_world_get.cwl.json
```

#### 5. Run main workflow

I used the `dockstore cli` to run the workflow, as defined in `hello_world.cwl` and parameterized by `hello_world.cwl.json`:
```shell
dockstore workflow launch --local-entry hello_world.cwl  --json hello_world.cwl.json
```

#### 6. Run workflow checker tool

To verify workflow results before submission, I used `dockstore cli` to run the checker as follows:
```shell
dockstore tool launch --local-entry hello_world_checker.cwl --json hello_world_checker.cwl.json
```

#### 7. Submit workflow outputs

I modified the parameters in `hello_world_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""Dockstore Team"",
    ""eval_id"": ""9603665"",
    ""file"": [
        {
            ""class"": ""File"",
            ""path"": ""helloworld.txt""
        }
    ],
    ""parent_id"": ""syn9961864""
}
```

Finally, I submitted outputs using `dockstore cli` and `dockstore-tool-synapse-submit.cwl`:
```shell
dockstore tool launch --local-entry dockstore-tool-synapse-submit.cwl --json hello_world_submit.cwl.json`
```

---",9634727
hello_world,9635414_report.md,"## GA4GH/DREAM Hello World Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""James Eddy""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This simple ""hello world"" workflow that is designed to capture most of the basic elements of workflows that will be tested in this challenge. The workflow runs a single tool ([`dockstore-tool-helloworld`](https://dockstore.org/containers/quay.io/ga4gh-dream/dockstore-tool-helloworld)), which uses a reference file containing a single template format string (""Hello ____!"" when printed) and an input file containing a single plain string (e.g., ""World""). When the workflow is run, the input string is inserted into the template and written to a new file, now containing the string ""Hello World!"". The input is a text file containing the word ""Hello""; running the workflow requires < 1M of disk space (not counting Docker images) and should take < 1s of CPU time to complete.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Jeff Johnston"" # your name here
institution: ""Children's Mercy"" # your institution here
```

#### Submission overview

Provide high level summary information for workflow execution in the fields below.

```YAML
date_accessed: ""2017-09-15"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170817131858"" # indicate executor version used
docker_version: ""17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""48"" # indicate number of cores in environment
env_memory: ""512GB"" # indicate available RAM in environment
env_disk: ""368TB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

#### 1. Setup

This workflow was run on CentOS Linux release 7.2.1511. Docker and Conda 4.3.25 were installed. A conda environment was built using the following conda YAML file:

```yaml
channels:
  - bioconda
  - conda-forge
  - anaconda
  - r
dependencies:
  - cwltool=1.0.20170817131858
  - synapseclient
```

The Synapse client was configured by editing `~/.synapseConfig`.

##### 2. Download

The following commands were run within the conda environment:

```shell
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
synapse get syn9733811 # hello_world_get.cwl.json
cwltool --outdir hellow_world --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ \
        --non-strict dockstore-tool-synapse-get.cwl hello_world_get.cwl.json
cp ~/.synapseConfig hello_world
```

##### 3. Run

Next, the workflow was executed in the conda environment.

```shell
cwltool --basedir hello_world/ --outdir hello_world/ \
    --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
    hello_world/hello_world.cwl hello_world/hello_world.cwl.json
```

##### 4. Validate

After running, the workflow results were validated:

```shell
cwltool --basedir hello_world/ --outdir hello_world/ \
        --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
        hello_world/hello_world_checker.cwl hello_world/hello_world_checker.cwl.json
```

##### 5. Submit

`hello_world_submit.cwl.json` was modified for submission:

```yaml
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""Childrens Mercy GA4GH-DREAM Challenge Team"",
    ""eval_id"": ""9603665"",
    ""file"": [
        {
            ""class"": ""File"",
            ""path"": ""helloworld.txt""
        }
    ],
    ""parent_id"": ""syn10290419""
}
```

Finally, results were submitted:

```shell
cwltool --basedir hello_world/ --outdir hello_world/ \
        --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
        dockstore-tool-synapse-submit.cwl hello_world/hello_world_submit.cwl.json
```

---",9635414
hello_world,9635833_report.md,"## GA4GH/DREAM Hello World Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""James Eddy""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This simple ""hello world"" workflow that is designed to capture most of the basic elements of workflows that will be tested in this challenge. The workflow runs a single tool ([`dockstore-tool-helloworld`](https://dockstore.org/containers/quay.io/ga4gh-dream/dockstore-tool-helloworld)), which uses a reference file containing a single template format string (""Hello ____!"" when printed) and an input file containing a single plain string (e.g., ""World""). When the workflow is run, the input string is inserted into the template and written to a new file, now containing the string ""Hello World!"". The input is a text file containing the word ""Hello""; running the workflow requires < 1M of disk space (not counting Docker images) and should take < 1s of CPU time to complete.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Michael Kotliar""
institution: ""CCHMC, Barski Lab""
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-18""
platform: ""CWL-Airflow""
workflow_type: ""CWL""
runner_version: ""0.0.1""
docker_version: ""1.12.6""
environment: ""local""
env_cpus: ""64""
env_memory: ""251Gb""
env_disk: ""230Gb""
```

### Steps

### Setting up environment
Install CWL-Airflow
```
  cd /home/michael_kotliar/workspaces/airflow/
  git clone https://github.com/Barski-lab/cwl-airflow.git
  cd cwl-airflow
  git checkout v0.0.1
  pip install -e .
```
Run mysql-server:5.7 docker container
```
  cd /home/michael_kotliar/temp/cwl_airflow
  mkdir database
  docker pull mysql/mysql-server:5.7
  docker run -v /home/michael_kotliar/temp/cwl_airflow/database:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=airflow -e MYSQL_DATABASE=airflow -e MYSQL_USER=airflow -e MYSQL_PASSWORD=airflow -p 6603:3306 -d mysql/mysql-server:5.7
```
Update Airflow configuration file `/home/michael_kotliar/airflow/airflow.cfg`
```
  executor = LocalExecutor
  sql_alchemy_conn = mysql://airflow:airflow@127.0.0.1:6603/airflow
```
Install synapse client
```
  pip install synapseclient
```
Create empty folder for workflow running
```
  cd /home/michael_kotliar/temp/cwl_airflow/
  mkdir hello_world
```
Create Synapse credentials file `/home/michael_kotliar/temp/cwl_airflow/hello_world/.synapseConfig`, put there Synapse ID and password
```
[authentication]
username: user@usermail.org
password: <user-password>
```
### Downloading required files
Download tools to fetch workflow input data
```
cd /home/michael_kotliar/temp/cwl_airflow/hello_world
synapse -c .synapseConfig get syn9733811  # hello_world_get_get.json
synapse -c .synapseConfig get syn9732885   # dockstore-tool-synapse-submit.cwl
synapse -c .synapseConfig get syn9770802   # dockstore-tool-synapse-get.cwl
```
Download workflow input data
```
cd /home/michael_kotliar/temp/cwl_airflow/hello_world
cwltool --debug --non-strict dockstore-tool-synapse-get.cwl hello_world_get_get.json
```
Wait until downloading is finished

### Running workflow
Run the workflow
```
cwl-airflow-runner --debug hello_world.cwl hello_world.cwl.json
```

### Validating results
Run checker tool
```
cd /home/michael_kotliar/temp/cwl_airflow/hello_world
cwltool --debug --non-strict hello_world_checker.cwl hello_world_checker.cwl.json
```
Check results
```
cat results.json
``` 
```json
{
    ""overall"": true, 
    ""steps"": {
        ""md5_check"": true
    }
}
```

### Submitting results
Update `hello_world_submit.cwl.json` with correct
`team_name` - the name of your team in plain text format (e.g., ""GA4GH-Sage Contenders"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
Run the tool
```
cwltool --debug --non-strict dockstore-tool-synapse-submit.cwl hello_world_submit.cwl.json
```
***Running time:*** 20 sec  
***Disk usage:*** 76K",9635833
hello_world,9635966_report.md,"## GA4GH/DREAM Hello World Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""James Eddy""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This simple ""hello world"" workflow that is designed to capture most of the basic elements of workflows that will be tested in this challenge. The workflow runs a single tool ([`dockstore-tool-helloworld`](https://dockstore.org/containers/quay.io/ga4gh-dream/dockstore-tool-helloworld)), which uses a reference file containing a single template format string (""Hello ____!"" when printed) and an input file containing a single plain string (e.g., ""World""). When the workflow is run, the input string is inserted into the template and written to a new file, now containing the string ""Hello World!"". The input is a text file containing the word ""Hello""; running the workflow requires < 1M of disk space (not counting Docker images) and should take < 1s of CPU time to complete.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Jeff Johnston"" # your name here
institution: ""Children's Mercy"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

```YAML
date_accessed: ""2017-09-15"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170817131858"" # indicate executor version used
docker_version: ""17.06.2-ce, build cec0b72"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""1"" # indicate number of cores in environment
env_memory: ""8GB"" # indicate available RAM in environment
env_disk: ""133GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

#### 1. Setup

This workflow was run on a MacBook Pro running macOS 10.12.6. Docker and Miniconda2 were installed. Docker was configured to use 1 core and 8GB of RAM. A conda environment was built using the following conda YAML file:

```yaml
channels:
  - bioconda
  - conda-forge
  - anaconda
  - r
dependencies:
  - cwltool=1.0.20170817131858
  - synapseclient
```

The Synapse client was configured by editing `~/.synapseConfig`.

##### 2. Download

The following commands were run within the conda environment:

```shell
conda
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
synapse get syn9733811 # hello_world_get.cwl.json
cwltool --outdir hellow_world --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ \
        --non-strict dockstore-tool-synapse-get.cwl hello_world_get.cwl.json
cp ~/.synapseConfig hello_world
```

##### 3. Run

Next, the workflow was executed in the conda environment.

```shell
cwltool --basedir hello_world/ --outdir hello_world/ \
    --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
    hello_world/hello_world.cwl hello_world/hello_world.cwl.json
```

##### 4. Validate

After running, the workflow results were validated:

```shell
cwltool --basedir hello_world/ --outdir hello_world/ \
        --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
        hello_world/hello_world_checker.cwl hello_world/hello_world_checker.cwl.json
```

##### 5. Submit

`hello_world_submit.cwl.json` was modified for submission:

```yaml
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""Childrens Mercy GA4GH-DREAM Challenge Team"",
    ""eval_id"": ""9603665"",
    ""file"": [
        {
            ""class"": ""File"",
            ""path"": ""helloworld.txt""
        }
    ],
    ""parent_id"": ""syn10290419""
}
```

Finally, results were submitted:

```shell
cwltool --basedir hello_world/ --outdir hello_world/ \
        --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
        dockstore-tool-synapse-submit.cwl hello_world/hello_world_submit.cwl.json
```

---",9635966
hello_world,9636175_report.md,"## GA4GH/DREAM Hello World Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""James Eddy""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This simple ""hello world"" workflow that is designed to capture most of the basic elements of workflows that will be tested in this challenge. The workflow runs a single tool ([`dockstore-tool-helloworld`](https://dockstore.org/containers/quay.io/ga4gh-dream/dockstore-tool-helloworld)), which uses a reference file containing a single template format string (""Hello ____!"" when printed) and an input file containing a single plain string (e.g., ""World""). When the workflow is run, the input string is inserted into the template and written to a new file, now containing the string ""Hello World!"". The input is a text file containing the word ""Hello""; running the workflow requires < 1M of disk space (not counting Docker images) and should take < 1s of CPU time to complete.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Vipin T. Sreedharan""
institution: ""ETH Zürich, NEXUS Personalized Health Technologies""
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-14"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170828135420"" # indicate executor version used
docker_version: ""1.12.6"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""32Gb"" # indicate available RAM in environment
env_disk: ""140Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

At our institute, on a compute machine called `wfexec` with Red Hat Enterprise Linux Server release 7.4 (Maipo), installed Docker. Created a group named ""docker"" since it was preferred to use Docker as a non-root user on this machine. The instance has a non-root user called `wfrunner`. Next added the non-root user `wfrunner` to the ""docker"" group. Then started the docker engine and all the below commands were executed using root user privileges [sudo]:
```shell
yum install docker
groupadd docker 
usermod -aG docker wfrunner  
systemctl start docker 
```

As a non-root user on `wfexec` machine, installed Anaconda and cwltool to the home path of user `wfrunner`:
```shell
su - wfrunner
wget https://repo.continuum.io/archive/Anaconda2-4.4.0-Linux-x86_64.sh
bash Anaconda2-4.4.0-Linux-x86_64.sh 
conda install virtualenv
virtualenv -p python2 /home/wfrunner/venv
source /home/wfrunner/venv/bin/activate
pip install cwltools
deactivate
```

Created a utilities directory for storing the `synapse-get` and `synapse-submit` CWL tools. In the same folder, created a file with my Synapse credentials. 
```shell
mkdir -p /home/wfrunner/synapse_utils
cd /home/wfrunner/synapse_utils
wget -O dockstore-tool-synapse-get.cwl https://raw.githubusercontent.com/GA4GH-DREAM/dockstore-tool-synapse-get/master/Dockstore.cwl 
wget -O dockstore-tool-synapse-submit.cwl https://raw.githubusercontent.com/GA4GH-DREAM/dockstore-tool-synapse-submit/master/Dockstore.cwl
touch .synapse_config
vim .synapse_config
[WRITE] Synapse username & password
```

#### 2. Download required files

Downloaded data config file hello_world_get.cwl.json from the website `https://www.synapse.org/#!Synapse:syn8507133/wiki/451410` for the **hello_world** workflow. Created a directory for the storing the workflow associated data downloading JSON parameter file: 
```shell
mkdir -p /home/wfrunner/data_config_files
mv ~/hello_world_get.cwl.json ~/data_config_files
cd /home/wfrunner/data_config_files
vim hello_world_get.cwl.json
[PASTE] /home/wfrunner/synapse_utils/.synapse_config
```

#### 3. Provision all workflow files

Created a working directory for the current workflow. Used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in ` hello_world_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
mkdir -p /home/wfrunner/hello_world
cd /home/wfrunner/hello_world
cwltool --debug --non-strict ~/synapse_utils/dockstore-tool-synapse-get.cwl ~/data_config_files/hello_world_get.cwl.json
```

#### 4. Run main workflow

Again `cwltool` was used to run the workflow, as defined in `hello_world.cwl` and parameterized by `hello_world.cwl.json`:
```shell
cd /home/wfrunner/hello_world
cwltool --debug --non-strict hello_world.cwl hello_world.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, used `cwltool` to run the checker as follows:
```shell
cd /home/wfrunner/hello_world
cwltool --debug  --non-strict hello_world_checker.cwl hello_world_checker.cwl.json
cat results.json | grep -i overall
```

#### 6. Submit workflow outputs

Modified the parameters in `hello_world_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": ""/home/wfrunner/synapse_utils/.synapse_config""
    },
    ""team_name"": """",
    ""eval_id"": ""9603665"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""helloworld.txt""
        }
    ],
    ""parent_id"": ""syn10843233""
}
```

Finally, submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cd /home/wfrunner/hello_world
cwltool --non-strict ~/synapse_utils/dockstore-tool-synapse-submit.cwl hello_world_submit.cwl.json
```

---",9636175
hello_world,9636370_report.md,"## GA4GH/DREAM Hello World Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""James Eddy""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This simple ""hello world"" workflow that is designed to capture most of the basic elements of workflows that will be tested in this challenge. The workflow runs a single tool ([`dockstore-tool-helloworld`](https://dockstore.org/containers/quay.io/ga4gh-dream/dockstore-tool-helloworld)), which uses a reference file containing a single template format string (""Hello ____!"" when printed) and an input file containing a single plain string (e.g., ""World""). When the workflow is run, the input string is inserted into the template and written to a new file, now containing the string ""Hello World!"". The input is a text file containing the word ""Hello""; running the workflow requires < 1M of disk space (not counting Docker images) and should take < 1s of CPU time to complete.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Gary Luu"" # your name here
institution: ""Dockstore - OICR"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-20"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""dockstore 1.2.10"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.2.10"" # indicate executor version used
docker_version: ""17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""4"" # indicate number of cores in environment
env_memory: ""32"" # indicate available RAM in environment
env_disk: ""470 GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-20""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

On a personal desktop, I installed Docker, pip, cwltool, and the Dockstore command-line helper using a procedure similar to https://github.com/denis-yuen/2017-cloud-workflows-misc/blob/master/install-and-run-with-dockstore.md .  
However, I used my own modified dockstore CLI (which will be 1.2.7)

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir hello_world
cd hello_world
cp ~/.synapseConfig .
```
#### 2. Download required files

I downloaded hello_world_get.cwl.json from the website. 


#### 3. Provision all workflow files

I used the synapse-get tool from Dockstore.
```shell
dockstore tool launch --entry quay.io/ga4gh-dream/dockstore-tool-synapse-get --json hello_world_get.cwl.json
```

#### 4. Run main workflow

I used dockstore to launch the recently downloaded hello_world.cwl 
```shell
dockstore workflow launch --local-entry hello_world.cwl --json hello_world.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `dockstore` to run the checker as follows:
```shell
dockstore tool launch --local-entry hello_world_checker.cwl --json hello_world_checker.cwl.json
cat results.json | grep overall
```

#### 6. Submit workflow outputs

I modified the parameters in `hello_world_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""Dockstore Team"",
    ""eval_id"": ""9603665"",
    ""file"": [
        {
            ""class"": ""File"",
            ""path"": ""helloworld.txt""
        }
    ],
    ""parent_id"": ""syn9877725""
}
```

Finally, I submitted outputs using dockstore-tool-synapse-submit`:
```shell
dockstore tool launch --entry quay.io/ga4gh-dream/dockstore-tool-synapse-submit --json hello_world_submit.cwl.json
```

---",9636370
hello_world,9636719_report.md,"## GA4GH/DREAM Hello World Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""James Eddy""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This simple ""hello world"" workflow that is designed to capture most of the basic elements of workflows that will be tested in this challenge. The workflow runs a single tool ([`dockstore-tool-helloworld`](https://dockstore.org/containers/quay.io/ga4gh-dream/dockstore-tool-helloworld)), which uses a reference file containing a single template format string (""Hello ____!"" when printed) and an input file containing a single plain string (e.g., ""World""). When the workflow is run, the input string is inserted into the template and written to a new file, now containing the string ""Hello World!"". The input is a text file containing the word ""Hello""; running the workflow requires < 1M of disk space (not counting Docker images) and should take < 1s of CPU time to complete.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Jonathon Saunders"" # your name here
institution: ""Children's Mercy Hospital"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-07-19"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170817131858"" # indicate executor version used
docker_version: ""Docker version 17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""4"" # indicate number of cores in environment
env_memory: ""16"" # indicate available RAM in environment
env_disk: ""500gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-20""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

On a personal laptop with Docker and Anaconda installed, I created and configured a virtual environment as follows:
```shell
conda create -n hello_world
source activate hello_world
pip install --upgrade pip
pip install schema-salad==2.2.20170222151604 cwltool==1.0.20170217172322
pip install synapseclient
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir hello_world_run
cd hello_world_run
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **hello_world** workflow:
```shell
synapse get syn9733811 # hello_world_get_get.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `hello_world_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl hello_world_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `hello_world.cwl` and parameterized by `hello_world.cwl.json`:
```shell
cwltool --non-strict hello_world.cwl hello_world.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool --non-strict hello_world_checker.cwl hello_world_checker.cwl.json
cat results.json | grep -i overall
```

#### 6. Submit workflow outputs

I modified the parameters in `hello_world_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""SageWorkflowRunners"",
    ""eval_id"": ""9603665"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""helloworld.txt""
        }
    ],
    ""parent_id"": ""syn9851737""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl hello_world_submit.cwl.json
```

---",9636719
hello_world,9636906_report.md,"## GA4GH/DREAM Hello World Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""James Eddy""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This simple ""hello world"" workflow that is designed to capture most of the basic elements of workflows that will be tested in this challenge. The workflow runs a single tool ([`dockstore-tool-helloworld`](https://dockstore.org/containers/quay.io/ga4gh-dream/dockstore-tool-helloworld)), which uses a reference file containing a single template format string (""Hello ____!"" when printed) and an input file containing a single plain string (e.g., ""World""). When the workflow is run, the input string is inserted into the template and written to a new file, now containing the string ""Hello World!"". The input is a text file containing the word ""Hello""; running the workflow requires < 1M of disk space (not counting Docker images) and should take < 1s of CPU time to complete.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Azza E. Ahmed"" # your name here
institution: ""University of Khartoum, Sudan"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-22"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170217172322"" # indicate executor version used
docker_version: ""1.13.1, build 092cba3"" # from `docker --version`
environment: ""stand alone server"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""24"" # indicate number of cores in environment
env_memory: ""125G"" # indicate available RAM in environment
env_disk: ""7.5T"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-20""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

I created a working directory for the current workflow with a folder of all workflows. My Synapse credentials are in this parent folder, along with ` dockstore-tool-synapse-get.cwl` and `dockstore-tool-synapse-submit.cwl`
```shell
mkdir GA4GH_phase2_dream
vi .synapseConfig   # Create the file of my synapse credentials
mkdir hello_world
cd hello_world
```

#### 2. Download required files

Manually, I copied the JSON parameters to download data for the **hello_world** workflow:
```shell
vi hello_world_get_get.json # Create the json file for downloading the hello_world workflow
synapse get syn9770802 # Download dockstore-tool-synapse-get.cwl
synapse get syn9732885 # Download dockstore-tool-synapse-submit.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `hello_world_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl hello_world_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `hello_world.cwl` and parameterized by `hello_world.cwl.json`:
```shell
cwltool --non-strict hello_world.cwl hello_world.cwl.json
```
Including `--non-strict` is essential. Otherwise, an error: `Object `dockstore-tool-helloworld.cwl` is not valid` is generated on my system.

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool --non-strict hello_world_checker.cwl hello_world_checker.cwl.json
vi  results.json
```

#### 6. Submit workflow outputs

I modified the parameters in `hello_world_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": ""/home/aeahmed/GA4GH_phase2_dream/.synapseConfig""
    },
    ""team_name"": ""SageWorkflowRunners"",
    ""eval_id"": ""9603665"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""helloworld.txt""
        }
    ],
    ""parent_id"": ""syn10888019""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl hello_world_submit.cwl.json
```

---",9636906
hello_world,9637538_report.md,"## GA4GH/DREAM Hello World Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""James Eddy""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This simple ""hello world"" workflow that is designed to capture most of the basic elements of workflows that will be tested in this challenge. The workflow runs a single tool ([`dockstore-tool-helloworld`](https://dockstore.org/containers/quay.io/ga4gh-dream/dockstore-tool-helloworld)), which uses a reference file containing a single template format string (""Hello ____!"" when printed) and an input file containing a single plain string (e.g., ""World""). When the workflow is run, the input string is inserted into the template and written to a new file, now containing the string ""Hello World!"". The input is a text file containing the word ""Hello""; running the workflow requires < 1M of disk space (not counting Docker images) and should take < 1s of CPU time to complete.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Abraham Chavez"" # your name here
institution: ""UCSC"" # your institution here
```

### Submission overview

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170217172322"" # indicate executor version used
docker_version: ""1.12.6"" # from `docker --version`
environment: ""Google CC"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""4"" # indicate number of cores in environment
env_memory: ""16GB"" # indicate available RAM in environment
env_disk: ""200GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps


#### 1. Set up environment

If you have not set up your environment and install dependencies like **cwltool**, **dockstore**, **java** and so on
I recommend you follow [**this**](https://www.synapse.org/#!Synapse:syn10220609) instructions.

>**NOTE:** When configuring `docker` to run as root. You might encounter problems setting the credentials as directed in digital ocean, try replacing `su - ${USER}` with `sudo su -` and running `usermod -aG docker ${USER}` and `su - ${USER}` inside root terminal.

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir hello_world_cwltool
cd hello_world_cwltool
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **hello_world** workflow:
```shell
synapse get syn9733811 # hello_world_get_get.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `hello_world_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl hello_world_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `hello_world.cwl` and parameterized by `hello_world.cwl.json`:
```shell
cwltool --non-strict hello_world.cwl hello_world.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool --non-strict hello_world_checker.cwl hello_world_checker.cwl.json
cat results.json | grep overall
```

#### 6. Submit workflow outputs

I modified the parameters in `hello_world_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""Your Team Name"",
    ""eval_id"": ""9603665"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""helloworld.txt""
        }
    ],
    ""parent_id"": ""yourSynapseId""
}
```
Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl hello_world_submit.cwl.json`
```

---",9637538
hello_world,9637640_report.md,"## GA4GH/DREAM Hello World Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""James Eddy""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This simple ""hello world"" workflow that is designed to capture most of the basic elements of workflows that will be tested in this challenge. The workflow runs a single tool ([`dockstore-tool-helloworld`](https://dockstore.org/containers/quay.io/ga4gh-dream/dockstore-tool-helloworld)), which uses a reference file containing a single template format string (""Hello ____!"" when printed) and an input file containing a single plain string (e.g., ""World""). When the workflow is run, the input string is inserted into the template and written to a new file, now containing the string ""Hello World!"". The input is a text file containing the word ""Hello""; running the workflow requires < 1M of disk space (not counting Docker images) and should take < 1s of CPU time to complete.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Thomas B. Mooney"" # your name here
institution: ""MGI WUSTL"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-26"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170828135420"" # indicate executor version used
docker_version: ""17.06.2-ce"" # from `docker --version`
environment: ""local openstack VM"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""2"" # indicate number of cores in environment
env_memory: ""64 GB"" # indicate available RAM in environment
env_disk: ""160 GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

Spin up a new OpenStack VM with a Xenial cloud image, then install [docker](https://docs.docker.com/engine/installation/linux/docker-ce/ubuntu/) and  [pyenv](https://github.com/pyenv/pyenv-installer).
Then install the tools to obtain and run the workflows:
```shell
pyenv install 2.7.14
pyenv shell 2.7.14
pip install cwltool
pip install synapseclient
```

Create a directory to hold the results and link in the configuration for connecting to synapse:
```shell
mkdir -p ~/ga4gh/hello_world
cd ~/ga4gh/hello_world
ln -s ~/.synapseConfig .synapseConfig
```

#### 2. Download required files

Download the tools for getting/submitting workflows and the JSON to pull in the ""hello world"" workflow data:
```shell
synapse get syn9733811 # hello_world_get.cwl.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

The dockstore tool CWL files contain extra information, so the ""get"" workflow must be run with the `--non-strict` option:
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl hello_world_get.cwl.json
```

#### 4. Run main workflow

Now run the workflow obtained in the previous step, again with `cwltool`:
```shell
cwltool --non-strict hello_world.cwl hello_world.cwl.json
```

#### 5. Run workflow checker tool

This completes quickly, so then the checker workflow is run to verify the results:
```shell
cwltool --non-strict hello_world_checker.cwl hello_world_checker.cwl.json
```
This produces a report, `results.json`:
```JSON
{
    ""overall"": true, 
    ""steps"": {
        ""md5_check"": true
    }
}
```

#### 6. Submit workflow outputs

Modify `hello_world_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""MGI WUSTL"",
    ""eval_id"": ""9603665"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""helloworld.txt""
        }
    ],
    ""parent_id"": ""syn10907649""
}
```

Finally, run the workflow to submit the results:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl hello_world_submit.cwl.json
```
---",9637640
hello_world,9637735_report.md,"## GA4GH/DREAM Hello World Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""James Eddy""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This simple ""hello world"" workflow that is designed to capture most of the basic elements of workflows that will be tested in this challenge. The workflow runs a single tool ([`dockstore-tool-helloworld`](https://dockstore.org/containers/quay.io/ga4gh-dream/dockstore-tool-helloworld)), which uses a reference file containing a single template format string (""Hello ____!"" when printed) and an input file containing a single plain string (e.g., ""World""). When the workflow is run, the input string is inserted into the template and written to a new file, now containing the string ""Hello World!"". The input is a text file containing the word ""Hello""; running the workflow requires < 1M of disk space (not counting Docker images) and should take < 1s of CPU time to complete.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""John Chilton"" # your name here
institution: ""Galaxy Project"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-26"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""Galaxy via Planemo"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""Planemo 0.46.1"" # indicate executor version used
docker_version: ""Docker version 17.06.2-ce, build cec0b72"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""16Gb"" # indicate available RAM in environment
env_disk: ""200Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-10""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

I have documented the steps on this page - https://github.com/galaxyproject/planemo/tree/master/project_templates/ga4gh_execution_challenge_phase_2 including general information about setting up Synapse user information and installing Planemo at the top and specific information regarding this workflow further down at https://github.com/galaxyproject/planemo/tree/master/project_templates/ga4gh_execution_challenge_phase_2#hello_world.

---",9637735
hello_world,9638106_report.md,"## GA4GH/DREAM Hello World Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""James Eddy""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This simple ""hello world"" workflow that is designed to capture most of the basic elements of workflows that will be tested in this challenge. The workflow runs a single tool ([`dockstore-tool-helloworld`](https://dockstore.org/containers/quay.io/ga4gh-dream/dockstore-tool-helloworld)), which uses a reference file containing a single template format string (""Hello ____!"" when printed) and an input file containing a single plain string (e.g., ""World""). When the workflow is run, the input string is inserted into the template and written to a new file, now containing the string ""Hello World!"". The input is a text file containing the word ""Hello""; running the workflow requires < 1M of disk space (not counting Docker images) and should take < 1s of CPU time to complete.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Thomas B. Mooney"" # your name here
institution: ""MGI WUSTL"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-28"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""toil"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""3.11.0"" # indicate executor version used
docker_version: ""17.06.2-ce"" # from `docker --version`
environment: ""local openstack VM"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""2"" # indicate number of cores in environment
env_memory: ""64 GB"" # indicate available RAM in environment
env_disk: ""160 GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

Spin up a new OpenStack VM with a Xenial cloud image, then install [docker](https://docs.docker.com/engine/installation/linux/docker-ce/ubuntu/) and  [pyenv](https://github.com/pyenv/pyenv-installer).
Then install the tools to obtain and run the workflows:
```shell
pyenv install 2.7.14
pyenv shell 2.7.14
pip install synapseclient
pip install toil[cwl]
```

Create a directory to hold the results and link in the configuration for connecting to synapse:
```shell
mkdir -p ~/ga4gh/hello_world.toil
cd ~/ga4gh/hello_world.toil
ln -s ~/.synapseConfig .synapseConfig
```

#### 2. Download required files

Download the tools for getting/submitting workflows and the JSON to pull in the ""hello world"" workflow data:
```shell
synapse get syn9733811 # hello_world_get.cwl.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

Run the tool to download the ""hello world"" workflow and data.
```shell
cwltoil dockstore-tool-synapse-get.cwl hello_world_get.cwl.json
```

#### 4. Run main workflow

Now run the workflow obtained in the previous step, again with `cwltoil`:
```shell
cwltoil hello_world.cwl hello_world.cwl.json
```
#### 5. Run workflow checker tool

This completes quickly, so then the checker workflow is run to verify the results:
```shell
cwltoil hello_world_checker.cwl hello_world_checker.cwl.json
```
This produces a report, `results.json`:
```JSON
{
    ""overall"": true, 
    ""steps"": {
        ""md5_check"": true
    }
}
```

#### 6. Submit workflow outputs

Modify `hello_world_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""MGI WUSTL"",
    ""eval_id"": ""9603665"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""helloworld.txt""
        }
    ],
    ""parent_id"": ""syn10921177""
}
```

Finally, run the workflow to submit the results:
```shell
cwltoil dockstore-tool-synapse-submit.cwl hello_world_submit.cwl.json
```

---",9638106
hello_world,9640313_report.md,"## GA4GH/DREAM Hello World Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""James Eddy""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This simple ""hello world"" workflow that is designed to capture most of the basic elements of workflows that will be tested in this challenge. The workflow runs a single tool ([`dockstore-tool-helloworld`](https://dockstore.org/containers/quay.io/ga4gh-dream/dockstore-tool-helloworld)), which uses a reference file containing a single template format string (""Hello ____!"" when printed) and an input file containing a single plain string (e.g., ""World""). When the workflow is run, the input string is inserted into the template and written to a new file, now containing the string ""Hello World!"". The input is a text file containing the word ""Hello""; running the workflow requires < 1M of disk space (not counting Docker images) and should take < 1s of CPU time to complete.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Joe Slagel"" # your name here
institution: ""Institute for Systems Biology"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-28"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170822192924"" # indicate executor version used
docker_version: ""Docker version 1.12.6, build 78d1802"" # from `docker --version`
environment: ""Google Compute"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""30 GB"" # indicate available RAM in environment
env_disk: ""250 GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-20""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

Using the Google Console I launched an Ubuntu 16.04 LTS ubuntu based virtual machine.  I then ran the following commands:

```shell
sudo apt-get update
sudo apt-get install docker.io
sudo apt-get install python-pip
sudo apt-get pip install cwltool
sudo pip install --upgrade synapseclient 
```

Next I created Synapse credentials file in my home directory:

```shell
vi ~/.synapseConfig
```


#### 2. Download required files

I copied the contents of the hello_world_get_get.json file onto the system (wasn't sure/aware of using the synapse get tool).

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `hello_world_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
sudo cwltool --non-strict dockstore-tool-synapse-get.cwl hello_world_get.cwl.json > get.log 2>&1
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `hello_world.cwl` and parameterized by `hello_world.cwl.json`:
```shell
sudo cwltool --non-strict hello_world.cwl hello_world.cwl.json > run.log 2>&1
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
sudo cwltool --non-strict hello_world_checker.cwl hello_world_checker.cwl.json > check.log 2>&1
grep Final check.log
```

#### 6. Submit workflow outputs

I modified the parameters in `hello_world_submit.cwl.json` to include the parent_id of a folder I created under our project.

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
sudo cwltool --non-strict dockstore-tool-synapse-submit.cwl hello_world_submit.cwl.json > submit.log 2>&1
```

---",9640313
hello_world,9643879_report.md,"## GA4GH/DREAM Hello World Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""James Eddy""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This simple ""hello world"" workflow that is designed to capture most of the basic elements of workflows that will be tested in this challenge. The workflow runs a single tool ([`dockstore-tool-helloworld`](https://dockstore.org/containers/quay.io/ga4gh-dream/dockstore-tool-helloworld)), which uses a reference file containing a single template format string (""Hello ____!"" when printed) and an input file containing a single plain string (e.g., ""World""). When the workflow is run, the input string is inserted into the template and written to a new file, now containing the string ""Hello World!"". The input is a text file containing the word ""Hello""; running the workflow requires < 1M of disk space (not counting Docker images) and should take < 1s of CPU time to complete.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Michael Krause"" # your name here
institution: ""UCSC Genomics Institute"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-10-10"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170217172322"" # indicate executor version used
docker_version: ""17.09.0-ce, build afdb6d4"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""2"" # indicate number of cores in environment
env_memory: ""4GB"" # indicate available RAM in environment
env_disk: ""125GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

On a personal laptop running Ubuntu 14.04 LTS Desktop I first I installed Oracle's Java, following [this tutorial](https://www.digitalocean.com/community/tutorials/how-to-install-java-with-apt-get-on-ubuntu-16-04).

```shell
$ java version ""1.8.0_144""
Java(TM) SE Runtime Environment (build 1.8.0_144-b01)
Java HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode)
```
Then I installed Docker community edition according to [this manual](https://www.digitalocean.com/community/tutorials/how-to-install-and-use-docker-on-ubuntu-16-04):
```shell
$ docker --version
Docker version 17.09.0-ce, build afdb6d4
```
Next I installed the following:
```shell
sudo apt-get install python-pip python-dev build-essential
sudo pip install --upgrade pip
sudo pip install --upgrade virtualenv
pip install setuptools==28.8.0
pip install 'requests[security]' --no-cache-dir
pip install cwl-runner cwltool==1.0.20170217172322 schema-salad==2.2.20170222151604 avro==1.8.1 --no-cache-dir
pip install synapseclient --no-cache-dir
```
Then I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder (note: the username in the settings on the Synapse website needs to match the username in .synapseConfig):
```shell
mkdir hello_world_run
cd hello_world_run
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **hello_world** workflow:
```shell
synapse get syn9733811 # hello_world_get_get.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `hello_world_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl hello_world_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `hello_world.cwl` and parameterized by `hello_world.cwl.json`:
```shell
cwltool --non-strict hello_world.cwl hello_world.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool --non-strict hello_world_checker.cwl hello_world_checker.cwl.json
cat results.json | grep -i overall
```

#### 6. Submit workflow outputs

I modified the parameters in `hello_world_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": """",
    ""eval_id"": ""9603665"",
    ""file"": [
        {
            ""class"": ""File"",
            ""path"": ""helloworld.txt""
        }
    ],
    ""parent_id"": ""syn11189507""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl hello_world_submit.cwl.json
```

---",9643879
hello_world,9646112_report.md,"## GA4GH/DREAM Hello World Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""James Eddy""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This simple ""hello world"" workflow that is designed to capture most of the basic elements of workflows that will be tested in this challenge. The workflow runs a single tool ([`dockstore-tool-helloworld`](https://dockstore.org/containers/quay.io/ga4gh-dream/dockstore-tool-helloworld)), which uses a reference file containing a single template format string (""Hello ____!"" when printed) and an input file containing a single plain string (e.g., ""World""). When the workflow is run, the input string is inserted into the template and written to a new file, now containing the string ""Hello World!"". The input is a text file containing the word ""Hello""; running the workflow requires < 1M of disk space (not counting Docker images) and should take < 1s of CPU time to complete.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Madelyn Reyes""
institution: ""ISB-CGC/CSRA"" 
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""09/27/2017"" 
platform: ""cwltool"" 
workflow_type: ""CWL"" 
runner_version: ""1.0.20170217172322""
docker_version: ""17.09.0-ce, build afdb6d4"" 
environment: ""Google Compute"" 
env_cpus: ""8""
env_memory: ""35GB""
env_disk: ""250 GB"" 
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-20""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

On a personal laptop with Docker and Anaconda installed, I created and configured a virtual environment as follows:
```shell
conda create -n hello_world
source activate hello_world
pip install --upgrade pip
pip install schema-salad==2.2.20170222151604 cwltool==1.0.20170217172322
pip install synapseclient
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir hello_world_run
cd hello_world_run
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **hello_world** workflow:
```shell
synapse get syn9733811 # hello_world_get_get.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `hello_world_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl hello_world_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `hello_world.cwl` and parameterized by `hello_world.cwl.json`:
```shell
cwltool --non-strict hello_world.cwl hello_world.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool --non-strict hello_world_checker.cwl hello_world_checker.cwl.json
cat results.json | grep -i overall
```

#### 6. Submit workflow outputs

I modified the parameters in `hello_world_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""SageWorkflowRunners"",
    ""eval_id"": ""9603665"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""helloworld.txt""
        }
    ],
    ""parent_id"": ""syn9851737""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl hello_world_submit.cwl.json
```

---",9646112
hello_world,9655734_report.md,"## GA4GH/DREAM Hello World Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""James Eddy""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This simple ""hello world"" workflow that is designed to capture most of the basic elements of workflows that will be tested in this challenge. The workflow runs a single tool ([`dockstore-tool-helloworld`](https://dockstore.org/containers/quay.io/ga4gh-dream/dockstore-tool-helloworld)), which uses a reference file containing a single template format string (""Hello ____!"" when printed) and an input file containing a single plain string (e.g., ""World""). When the workflow is run, the input string is inserted into the template and written to a new file, now containing the string ""Hello World!"". The input is a text file containing the word ""Hello""; running the workflow requires < 1M of disk space (not counting Docker images) and should take < 1s of CPU time to complete.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Joe Slagel"" # your name here
institution: ""Institute for Systems Biology"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-11-28"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""ISB-CGC dsub/cwltool/cwl_runner.sh"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""cwltool-1.0.20171107133715"" # indicate executor version used
docker_version: ""17.11.0"" # from `docker --version`
environment: ""Google Compute"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""2"" # indicate number of cores in environment
env_memory: ""7.5"" # indicate available RAM in environment
env_disk: ""200"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

I was curious as to how much of the challenge I could do using only dsub and cwl_runner.sh.

#### 1. Set up environment

On a personal Google Cloud VM with gcloud, gsutil, dsub and cwl_runner.sh installed:

```shell
gsutil cp ~/.synapseConfig gs://isb-ga4gh-dream/hello_world/data/.synapseConfig
dsub \
   --name dream-setup-hello_world \
   --project cgc-05-0026 \
   --zones 'us-*' \
   --image quay.io/ga4gh-dream/dockstore-tool-synapse-get \
   --input  'CFG=gs://isb-ga4gh-dream/hello_world/data/.synapseConfig' \
   --output-recursive 'OUT=gs://isb-ga4gh-dream/hello_world/data/' \
   --logging 'gs://isb-ga4gh-dream/hello_world/log' \
   --wait \
   --command 'cd ${OUT}; \
              synapse -c ${CFG} get syn9770802; \
              synapse -c ${CFG} get syn9732885; \
              synapse -c ${CFG} get syn9733811; \
             '
```

#### 2. Download required files

```shell
./cwl_runner.sh \
   -m n1-standard-2 \
   -i gs://isb-ga4gh-dream/hello_world/data/.synapseConfig \
   -w gs://isb-ga4gh-dream/hello_world/data/dockstore-tool-synapse-get.cwl \
   -s gs://isb-ga4gh-dream/hello_world/data/hello_world_get.cwl.json \
   -o gs://isb-ga4gh-dream/hello_world/data
```

#### 3. Run main workflow

```shell
./cwl_runner.sh -k \
   -m n1-standard-2 \
   -r gs://isb-ga4gh-dream/hello_world/data/ \
   -w gs://isb-ga4gh-dream/hello_world/data/hello_world.cwl \
   -s gs://isb-ga4gh-dream/hello_world/data/hello_world.cwl.json \
   -o gs://isb-ga4gh-dream/hello_world/data
```

#### 4. Run workflow checker tool

```shell
./cwl_runner.sh \
   -m n1-standard-2 \
   -r gs://isb-ga4gh-dream/hello_world/data/ \
   -w gs://isb-ga4gh-dream/hello_world/data/hello_world_checker.cwl \
   -s gs://isb-ga4gh-dream/hello_world/data/hello_world_checker.cwl.json \
   -o gs://isb-ga4gh-dream/hello_world/data
```

#### 5. Submit workflow outputs

```shell
gsutil cat gs://isb-ga4gh-dream/hello_world/data/hello_world_submit.cwl.json \
   | jq '.team_name=""ISB-CGC"" | .parent_id=""syn11413167""' \
   | gsutil cp - gs://isb-ga4gh-dream/hello_world/data/hello_world_submit.cwl.json
./cwl_runner.sh \
   -m n1-standard-2 \
   -r gs://isb-ga4gh-dream/hello_world/data/ \
   -w gs://isb-ga4gh-dream/hello_world/data/dockstore-tool-synapse-submit.cwl \
   -s gs://isb-ga4gh-dream/hello_world/data/hello_world_submit.cwl.json \
   -o gs://isb-ga4gh-dream/hello_world/data
```

---",9655734
hello_world,9655812_report.md,"### Workflow description
```YAML
contributor: ""James Eddy""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

### Participant information
```YAML
name: ""Ben Ernest""
institution: ""Digicon Corporation""
```

### Submission overview
```YAML
date_accessed: ""2017-12-05"" 
platform: ""cwltool"" 
workflow_type: ""CWL"" 
runner_version: ""1.0.20170217172322"" 
docker_version: ""17.09.0-ce"" 
environment: ""cluster"" 
env_cpus: ""12"" 
env_memory: ""62Gb"" 
env_disk: ""5Tb"" 
```

### Steps

#### 1. Set up environment, following instructions at https://dockstore.org/quick-start.  These only need to be done once for all workflows that use `cwltool`.
##### Instructions are for Linux CentOS

Download and install dockstore.  
```shell
mkdir -p ~/bin
curl -L -o ~/bin/dockstore https://github.com/ga4gh/dockstore/releases/download/1.3.0/dockstore
chmod +x ~/bin/dockstore
echo 'export PATH=~/bin:$PATH' >> ~/.bashrc
source ~/.bashrc
```

Create configuration file
```shell
mkdir -p ~/.dockstore
printf ""token: dummy-token\nserver-url: https://dockstore.org:8443\n"" > ~/.dockstore/config
```

Install `pip`
```shell
curl -L -o ~/get-pip.py https://bootstrap.pypa.io/get-pip.py
sudo python get-pip.py
```

Install `cwltool` (**note: version 1.0.20170217172322**)
```shell
sudo pip install setuptools==36.5.0
sudo pip install cwl-runner cwltool==1.0.20170217172322 schema-salad==2.6.20170806163416 avro==1.8.1 ruamel.yaml==0.14.12 requests==2.18.4
```

Install Docker
```shell
sudo yum install -y yum-utils device-mapper-persistent-data lvm2
sudo yum-config-manager --add-repo ""https://download.docker.com/linux/centos/docker-ce.repo""
sudo yum-config-manager --enable extras
sudo yum -y install docker-ce
sudo usermod -aG docker $USER
exec newgrp docker
```

Create aliases to start and stop Docker
```shell
echo 'alias start_docker=""sudo systemctl start docker""' >> ~/.bashrc
echo `alias stop_docker=""sudo systemctl stop docker""' >> ~/.bashrc
source ~/.bashrc
```
Install `synapseclient`
```
sudo pip install synapseclient
```

Create synapse credentials file with the content below, using your own Synapse credentials (no quotes or extra characters).  It can be named anything, but I'm using `.synapseConfig`.
```
[authentication]
username: email
password: password
```

Create a working directory and copy synapse credentials file into that folder.
```shell
mkdir -p hello_world_run
cd hello_world_run
cp ~/.synapseConfig .
```

#### 2. Download required files
Download tools to fetch workflow input data.
```shell
synapse get syn9733811 # hello_world_get_get.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files
Start docker, using alias created previously.
```shell
start_docker
```

Use `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `hello_world_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl hello_world_get.cwl.json
```

#### 4. Run main workflow
Use `cwltool` to run the workflow, as defined in `hello_world.cwl` and parameterized by `hello_world.cwl.json`:
```shell
cwltool --non-strict hello_world.cwl hello_world.cwl.json
```

#### 5. Run workflow checker tool
To verify workflow results before submission, use `cwltool` to run the checker as follows:
```shell
cwltool --non-strict hello_world_checker.cwl hello_world_checker.cwl.json
```

#### 6. Submit workflow outputs
Modify `team_name` and `parent_id` in `hello_world_submit.cwl.json` as shown below, assuming Synapse credentials file is named `.synapseConfig` and located in `~/hello_world_run`.
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""BioGenLink"",
    ""eval_id"": ""9603665"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""helloworld.txt""
        }
    ],
    ""parent_id"": ""syn11565347""
}
```

Submit outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl hello_world_submit.cwl.json
```

Stop Docker if desired.
```shell
stop_docker
```
",9655812
hello_world,9655864_report.md,"## GA4GH/DREAM Hello World Workflow with arvados-cwl-runner

Arvados container record: https://cloud.curoverse.com/container_requests/qr1hi-xvhdp-x6uri7rlojrlfa7

### Workflow description

```YAML
contributor: ""James Eddy""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This simple ""hello world"" workflow that is designed to capture most of the basic elements of workflows that will be tested in this challenge. The workflow runs a single tool ([`dockstore-tool-helloworld`](https://dockstore.org/containers/quay.io/ga4gh-dream/dockstore-tool-helloworld)), which uses a reference file containing a single template format string (""Hello ____!"" when printed) and an input file containing a single plain string (e.g., ""World""). When the workflow is run, the input string is inserted into the template and written to a new file, now containing the string ""Hello World!"". The input is a text file containing the word ""Hello""; running the workflow requires < 1M of disk space (not counting Docker images) and should take < 1s of CPU time to complete.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Peter Amstutz"" # your name here
institution: ""Veritas Genetics"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-13"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""Arvados"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""arvados-cwl-runner 0d06a2984420d9d48e16ccb6d85982b3dce05644 1.0.20171127193714, arvados-python-client 0.1.20171010180436, cwltool 1.0.20171205195520"" # indicate executor version used
docker_version: ""Docker version 17.05.0-ce, build 89658be"" # from `docker --version`
environment: ""Azure"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""1"" # indicate number of cores in environment
env_memory: ""3.5 GB"" # indicate available RAM in environment
env_disk: ""50 GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-20""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

On a personal laptop with Docker and Anaconda installed, I created and configured a virtual environment as follows:
```shell
virtualenv venv
. venv/bin/activate
pip install synapseclient arvados-cwl-runner
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir hello_world_run
cd hello_world_run
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **hello_world** workflow:
```shell
synapse get syn9733811 # hello_world_get_get.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `hello_world_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
arvados-cwl-runner dockstore-tool-synapse-get.cwl hello_world_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `hello_world.cwl` and parameterized by `hello_world.cwl.json`:
```shell
cwltool --non-strict hello_world.cwl hello_world.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool --non-strict hello_world_checker.cwl hello_world_checker.cwl.json
cat results.json | grep -i overall
```

#### 6. Submit workflow outputs

I modified the parameters in `hello_world_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""Arvados Project"",
    ""eval_id"": ""9603665"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""keep/by_id/7bb574b011deade8fb40950cdeb4fffd+119/helloworld.txt""
        }
    ],
    ""parent_id"": ""syn11568426""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl hello_world_submit.cwl.json
```

---",9655864
hello_world,9656947_report.md,"### Workflow description
```YAML
contributor: ""James Eddy""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

### Participant information
```YAML
name: ""Ben Ernest""
institution: ""Digicon Corporation""
```

### Submission overview
```YAML
date_accessed: ""2017-12-12"" 
platform: ""BioGenLink"" 
workflow_type: ""CWL"" 
runner_version: ""1.0.20170217172322"" 
docker_version: ""17.09.0-ce, build afdb6d4"" 
environment: ""Hadoop"" 
env_cpus: ""12"" 
env_memory: ""62Gb"" 
env_disk: ""5Tb"" 
```

### Steps

#### Setup

##### **(1) Create synapse credentials file**.  
This only needs to be done once, and the credentials file can be used for each workflow.
- Log into BioGenLink by going to http://biogenlink.digicon.com and entering your user name and password.
${image?fileName=login%5Fscreen%5Fempty%2E2017%2D12%2D19%2Epng&align=None&scale=50&responsive=true}

- In the **Files** tab, right-click on a directory, select **Create File**, name the file (e.g., ""synapse_config.txt"") and click on **Preview** to edit a new file in the workspace.  
${image?fileName=create%5Ffile%5Fpreview%2E2017%2D12%2D19%2Epng&align=None&scale=50&responsive=true}

Enter the following information in the file and save it by clicking **Save** (the disk button just above the text area).
```
[authentication]
username: email
password: password
[cache]
location: biodtfs/path/to/cache
```
**Note:** the cache directory is used by synapseClient for temporary files, and we must specify it in BioGenLink to avoid permissions errors. It can be be any directory the user chooses, even a non-existing one as long as the parent directory is valid.  It is suggested to create a working directory for each workflow and keep this file in a parent directory outside of the working directories.  

##### **(2) Import workflow tools and data into BioGenLink.**
- Create a working directory.  
Right-click on any directory in the file system, select `Create Folder`, and enter a name for the working directory (e.g., `hello_world`).

- Run the `Synapse get` tool.
In the **Tools** tab, find and select the **Synapse get** tool.  It can be found by keyword search or browsing to `Synapse/All/Synapse get`.  Double-clicking (shown below) the tool will open it in the workspace for editing and browsing documentation and will display the menu for providing inputs and running the tool.
${image?fileName=synapse%5Fget%5Fopen%2E2017%2D12%2D20%2Epng&align=None&scale=50&responsive=true}.

In the `Synapse IDs` field, enter the Synapse IDs for files to be downloaded.  
${image?fileName=synapse%5Fget%2E2017%2D12%2D20%2Epng&align=None&scale=50&responsive=true}

Drag and drop the synapse credentials file (e.g., `synapse_config.txt`) from the file system into the field called `Synapse config file`.

Drag and drop the working directory into the field called `Output directory`.

Run the tool by clicking `Quick Launch`.

#### Run the workflow

#### Validate the results
- Run the `Dockstore checker` tool.
In the **Tools** tab, find and select the **Dockstore checker** tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore checker`.  
${image?fileName=dockstore%5Fchecker%2E2017%2D12%2D25%2Epng&align=None&scale=50&responsive=true}
Drag and drop the `hello_world_checker.cwl` and `hello_world_checker.cwl.json` files from the working directory into the fields labeled `Checker CWL file` and `Checker JSON file`, respectively.  Then click `Quick Launch`.
Verify that the workflow ran successfully by opening the `results.json` file and confirming that the `Overall` field is equal to `true`.
${image?fileName=results%5Fjson%2E2017%2D12%2D25%2Epng&align=None&scale=50&responsive=true}

#### Submit the results to Synapse
- Run the `Dockstore submit` tool.
In the **Tools** tab, find and select the **Dockstore submit** tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore submit`.  
${image?fileName=dockstore%5Fsubmit%2E2017%2D12%2D26%2Epng&align=None&scale=50&responsive=true}
Drag and drop the `hello_world_submit.cwl.json` file into the field labeled `Submit JSON file`.  
Enter a team name and the Synapse parent ID into the corresponding fields.  
Drag and drop the synapse credentials file (e.g., `synapse_config.txt`) into the field labeled `Synapse config file`.
Click `Quick Launch`.",9656947
hello_world,9657238_report.md,"## GA4GH/DREAM Hello World Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""James Eddy""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This simple ""hello world"" workflow that is designed to capture most of the basic elements of workflows that will be tested in this challenge. The workflow runs a single tool ([`dockstore-tool-helloworld`](https://dockstore.org/containers/quay.io/ga4gh-dream/dockstore-tool-helloworld)), which uses a reference file containing a single template format string (""Hello ____!"" when printed) and an input file containing a single plain string (e.g., ""World""). When the workflow is run, the input string is inserted into the template and written to a new file, now containing the string ""Hello World!"". The input is a text file containing the word ""Hello""; running the workflow requires < 1M of disk space (not counting Docker images) and should take < 1s of CPU time to complete.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Joe Slagel"" # your name here
institution: ""ISB"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-12-18"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""ISB-CGC dsub/rabix/cwl_runner.sh"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.3"" # indicate executor version used
docker_version: ""17.11.0"" # from `docker --version`
environment: ""Google Compute"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""2"" # indicate number of cores in environment
env_memory: ""7.5"" # indicate available RAM in environment
env_disk: ""200"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Trying the challenge using only dsub,  cwl_runner.sh with rabix.

#### 1. Set up environment

On a personal Google Cloud VM with gcloud, gsutil, dsub and cwl_runner.sh installed:

```shell
gsutil cp ~/.synapseConfig gs://isb-ga4gh-dream/rabix/hello_world/data/.synapseConfig
dsub \
   --name dream-setup-hello_world \
   --project cgc-05-0026 \
   --zones 'us-*' \
   --image quay.io/ga4gh-dream/dockstore-tool-synapse-get \
   --input  'CFG=gs://isb-ga4gh-dream/rabix/hello_world/data/.synapseConfig' \
   --output-recursive 'OUT=gs://isb-ga4gh-dream/rabix/hello_world/data/' \
   --logging 'gs://isb-ga4gh-dream/rabix/hello_world/log' \
   --wait \
   --command 'cd ${OUT}; \
              synapse -c ${CFG} get syn9770802; \
              synapse -c ${CFG} get syn9732885; \
              synapse -c ${CFG} get syn9733811; \
             '
```
NOTE: I did have to update cwl_runner.sh to download the latest release of rabix.

### 2. Download required files

```shell
./cwl_runner.sh -r rabix \
   -m n1-standard-2 \
   -i gs://isb-ga4gh-dream/rabix/hello_world/data/.synapseConfig \
   -w gs://isb-ga4gh-dream/rabix/hello_world/data/dockstore-tool-synapse-get.cwl \
   -s gs://isb-ga4gh-dream/rabix/hello_world/data/hello_world_get.cwl.json \
   -o gs://isb-ga4gh-dream/rabix/hello_world/data
```

#### 3. Run main workflow

```shell
gsutil cp -r gs://isb-ga4gh-dream/rabix/hello_world/data/dockstore-tool-synapse-get-*/root/synapse_files/* gs://isb-ga4gh-dream/rabix/hello_world/data/
./cwl_runner.sh -r rabix \
   -m n1-standard-2 \
   -I gs://isb-ga4gh-dream/rabix/hello_world/data/ \
   -w gs://isb-ga4gh-dream/rabix/hello_world/data/hello_world.cwl \
   -s gs://isb-ga4gh-dream/rabix/hello_world/data/hello_world.cwl.json \
   -o gs://isb-ga4gh-dream/rabix/hello_world/data
```

#### 4. Run workflow checker tool

```shell
gsutil cp -r gs://isb-ga4gh-dream/rabix/hello_world/data/hello_world-*/root/hello_world/* gs://isb-ga4gh-dream/rabix/hello_world/data/
./cwl_runner.sh -r rabix \
   -m n1-standard-2 \
   -I gs://isb-ga4gh-dream/rabix/hello_world/data/ \
   -w gs://isb-ga4gh-dream/rabix/hello_world/data/hello_world_checker.cwl \
   -s gs://isb-ga4gh-dream/rabix/hello_world/data/hello_world_checker.cwl.json \
   -o gs://isb-ga4gh-dream/rabix/hello_world/data
```

#### 5. Submit workflow outputs

```shell
gsutil cp -r gs://isb-ga4gh-dream/rabix/hello_world/data/hello_world_checker-*/root/* gs://isb-ga4gh-dream/rabix/hello_world/data/
gsutil cat gs://isb-ga4gh-dream/rabix/hello_world/data/hello_world_submit.cwl.json \
   | jq '.team_name=""ISB-CGC"" | .parent_id=""syn11615762""' \
   | gsutil cp - gs://isb-ga4gh-dream/rabix/hello_world/data/hello_world_submit.cwl.json
./cwl_runner.sh -r rabix \
   -m n1-standard-2 \
   -I gs://isb-ga4gh-dream/rabix/hello_world/data/ \
   -w gs://isb-ga4gh-dream/rabix/hello_world/data/dockstore-tool-synapse-submit.cwl \
   -s gs://isb-ga4gh-dream/rabix/hello_world/data/hello_world_submit.cwl.json \
   -o gs://isb-ga4gh-dream/rabix/hello_world/data
```
--",9657238
hello_world,9657473_report.md,"## GA4GH/DREAM Hello World Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""James Eddy""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This simple ""hello world"" workflow that is designed to capture most of the basic elements of workflows that will be tested in this challenge. The workflow runs a single tool ([`dockstore-tool-helloworld`](https://dockstore.org/containers/quay.io/ga4gh-dream/dockstore-tool-helloworld)), which uses a reference file containing a single template format string (""Hello ____!"" when printed) and an input file containing a single plain string (e.g., ""World""). When the workflow is run, the input string is inserted into the template and written to a new file, now containing the string ""Hello World!"". The input is a text file containing the word ""Hello""; running the workflow requires < 1M of disk space (not counting Docker images) and should take < 1s of CPU time to complete.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Nihar Sheth"" # your name here
institution: ""DNAnexus Inc."" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.


```YAML
date_accessed: ""2017-12-18"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20171107133715"" # indicate executor version used
docker_version: ""17.09.0-ce"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""2"" # indicate number of cores in environment
env_memory: ""16Gb"" # indicate available RAM in environment
env_disk: ""512Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

On a personal laptop with Docker installed, I created and configured a virtual environment as follows:
```shell
virtualenv -p python dream
source dream/bin/activate
pip install --upgrade pip
pip install cwltool
```

I created a working directory for dream workflows  and created  my Synapse credentials file in that folder:
```shell
mkdir  dreamworkflows
cd dreamworkflows
emacs ~/.synapseConfig .
```

#### 2. Download required files
I downloaded synapse get/submit cwl files using curl  in my working directory for dream workflows 
```shell
curl https://raw.githubusercontent.com/GA4GH-DREAM/dockstore-tool-synapse-get/master/Dockstore.cwl > dockstore-tool-synapse-get.cwl
curl https://raw.githubusercontent.com/GA4GH-DREAM/dockstore-tool-synapse-submit/master/Dockstore.cwl > dockstore-tool-synapse-submit.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `hello_world_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl hello_world_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `hello_world.cwl` and parameterized by `hello_world.cwl.json`:
```shell
cwltool --non-strict hello_world.cwl hello_world.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool --non-strict hello_world_checker.cwl hello_world_checker.cwl.json
cat results.json | grep -i overall
```

#### 6. Submit workflow outputs

I modified the parameters in `hello_world_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""DNAnexus"",
    ""eval_id"": ""9603665"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""helloworld.txt""
        }
    ],
    ""parent_id"": ""syn11617438""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl hello_world_submit.cwl.json
```

---",9657473
hello_world,9657791_report.md,"## GA4GH/DREAM Hello World Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""James Eddy""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This simple ""hello world"" workflow that is designed to capture most of the basic elements of workflows that will be tested in this challenge. The workflow runs a single tool ([`dockstore-tool-helloworld`](https://dockstore.org/containers/quay.io/ga4gh-dream/dockstore-tool-helloworld)), which uses a reference file containing a single template format string (""Hello ____!"" when printed) and an input file containing a single plain string (e.g., ""World""). When the workflow is run, the input string is inserted into the template and written to a new file, now containing the string ""Hello World!"". The input is a text file containing the word ""Hello""; running the workflow requires < 1M of disk space (not counting Docker images) and should take < 1s of CPU time to complete.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Nihar Sheth"" # your name here
institution: ""DNAnexus Inc."" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

```YAML
date_accessed: ""2018-12-18"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""DNAnexus-CWL"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""alpha"" # indicate executor version used
docker_version: ""dx-docker"" # from `docker --version`
environment: ""DNAnexus"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""autoscale"" # indicate number of cores in environment
env_memory: ""autoscale"" # indicate available RAM in environment
env_disk: ""autoscale"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

On a Linux desktop with dx-toolkit and Docker installed, log into a DNAnexus project.
Also, set environment variables for your project and authentication token.
```
dx env
```
will give you your project ID.  We will assume it's accessible via `$PROJECT`.

You can generate a token via these instructions: https://wiki.dnanexus.com/Command-Line-Client/Login-and-Logout#Authentication-Tokens

Clone the dx-cwl repository:

```
https://github.com/dnanexus/dx-cwl.git
```

This was a commit hash used around the time of submission if you'd like to check it out: 2687fe8c671c113e8a780a790a85a18396aea23e

Ensure all pre-requisites are installed using the install-prerequisites.sh script or building a Docker image from the Dockerfile in the repository.

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **hello_world** workflow:
```shell
synapse get syn9733811 # hello_world_get_get.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `hello_world_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl hello_world_get.cwl.json
```

#### 4. Run main workflow

Upload downloaded files to the DNAnexus project

```
dx upload -r .
```

Compile the workflow to DNAnexus

```
dx-cwl/dx-cwl compile-workflow md5sum.cwl --project $PROJECT --token $TOKEN
```

Run the workflow on the platform

```
dx-cwl/dx-cwl run-workflow dx-cwl-run/hello_world/hello_workd hello_world.cwl.json
```
Note that the file in the second argument is referring to the one you uploaded to the platform.


#### 5. Run workflow checker tool

Using the UI, or `dx describe` on the analysis ID from above, download relevant outputs using:

`dx download [filename or ID]`

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool --non-strict hello_world_checker.cwl hello_world_checker.cwl.json
cat results.json | grep -i overall
```

#### 6. Submit workflow outputs

I modified the parameters in `hello_world_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""DNAnexus"",
    ""eval_id"": ""9603665"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""helloworld.txt""
        }
    ],
    ""parent_id"": ""syn11633762""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl hello_world_submit.cwl.json
```

---",9657791
hello_world,9657801_report.md,"### Workflow description
```YAML
contributor: ""James Eddy""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

### Participant information
```YAML
name: ""Ben Ernest""
institution: ""Digicon Corporation""
```

### Submission overview
```YAML
date_accessed: ""2017-12-12"" 
platform: ""BioGenLink"" 
workflow_type: ""CWL"" 
runner_version: ""1.0.20170217172322"" 
docker_version: ""17.09.0-ce"" 
environment: ""BioGenLink"" 
env_cpus: ""1"" 
env_memory: ""8Gb"" 
env_disk: ""5Tb"" 
```

### Steps
#####This workflow was run using the [BioGenLink](http://digicon.com/biogenlink.html) platform from [Digicon](http://digicon.com/).  Click [here](http://digicon.com/biogenlink.html) or [email us](mailto:biogenlink@digiconasp.com) for more information. 

#### **Setup**

##### Create synapse credentials file.  
This only needs to be done once, and the credentials file can be used for each workflow.
1. Log into BioGenLink.  [Click here](http://digicon.com/biogenlink.html) or [email us](mailto:biogenlink@digiconasp.com) for more information.
${image?fileName=login%5Fscreen%5Fempty%2E2017%2D12%2D19%2Epng&align=None&scale=75&responsive=true}

2. In the **files** tab, right-click on any directory in the file system, select `Create File`, give the file a name (e.g., ""synapse_config.txt""), and click `Preview` to edit the file.  
${image?fileName=create%5Ffile%5Fpreview%2E2017%2D12%2D19%2Epng&align=None&scale=75&responsive=true}

Enter the following information in the file and save it by clicking **Save** (the disk button just above the text area).
```
[authentication]
username: email
password: password
[cache]
location: biodtfs/path/to/cache
```
**Note:** the cache directory is used by `synapseClient` for temporary files, and we must specify it in BioGenLink to avoid permissions errors. It can be any directory the user chooses, even a non-existing one as long as the parent directory is valid.  It is suggested to create a working directory for each workflow and keep this file in a parent directory outside of the working directories.  

#### **Provision workflow files**

1. Create a working directory.  
    - Right-click on any directory in the file system, select `Create Folder`, and enter a name for the working directory (e.g., `hello_world`).

2. Run the `Synapse get` tool.
    - In the **tools** tab, find and select the `Synapse get` tool.  It can be found by keyword search or browsing to `Synapse/All/Synapse get`.  Double-clicking (shown below) the tool will open it in the workspace for editing and browsing documentation and will display the menu for providing inputs and running the tool.
${image?fileName=synapse%5Fget%5Fopen%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
    - In the `Synapse IDs` field, enter the Synapse IDs for files to be downloaded.  In this case, the synapse IDs include the following, which correspond to `hello_world_get.cwl.json`, `dockstore-tool-synapse-submit.cwl`, and `dockstore-tool-synapse-get.cwl`:
```shell
syn9733811
syn9732885
syn9770802
```
${image?fileName=synapse%5Fget%2E2017%2D12%2D20%2Epng&align=None&scale=75&responsive=true}
    - Drag and drop the synapse credentials file (e.g., `synapse_config.txt`) from the file system into the field called `Synapse config file`.
    - Drag and drop the working directory into the field called `Output directory`.
    - Run the tool by clicking `Quick Launch`.

#### **Import the workflow**
- If the workflow has not been imported yet, go to the **files** tab and find the `CWL` file corresponding to the workflow you want to build (e.g., `hello_world.cwl`).  Right-click on the file, and select `Import CWL File`.  This will automatically build a workflow which can be edited and run within the BioGenLink platform. 
${image?fileName=import%5Fcwl%5Ffile%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
The `hello_world` workflow is automatically created and placed in the **workflows** tab, under `CWL/Autogenerated`. 

#### **Run the workflow**
1. In the **workflows** tab, find and select the `hello_world` workflow.  The previous step automatically places it in the `CWL/Autogenerated` folder.  Double-clicking (shown below) opens the workflow in the workspace for editing and will display the menu for providing inputs and running the workflow.
${image?fileName=hello%5Fworld%5Fworkflow%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
If the run parameters aren't visible, right-click the orange ""play button"" at top right of the workspace to open them.
${image?fileName=hello%5Fworld%5Fworkflow%5Frun%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
The default inputs should already be set, but if they aren't then drag and drop the `input.txt` and `template.txt` files into the `input_file` and `template_file` fields, respectively.
2. Drag and drop a directory from the file system into the `Output Directory` field.
3. Run the workflow by clicking the `RUN WITH SKIPPING` button.


#### **Validate the results**
- Run the `Dockstore checker` tool.
1. In the **tools** tab, find and select the `Dockstore checker` tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore checker`.  
${image?fileName=dockstore%5Fchecker%2E2017%2D12%2D25%2Epng&align=None&scale=75&responsive=true}
2. Drag and drop the `hello_world_checker.cwl` and `hello_world_checker.cwl.json` files from the working directory into the fields labeled `Checker CWL file` and `Checker JSON file`, respectively.  
3. Click `Quick Launch`.
4. Verify that the workflow ran successfully by opening the `results.json` file and confirming that the `Overall` field is equal to `true`.
${image?fileName=results%5Fjson%2E2017%2D12%2D25%2Epng&align=None&scale=75&responsive=true}

#### **Submit the results to Synapse**
- Run the `Dockstore submit` tool.
1. In the **tools** tab, find and select the `Dockstore submit` tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore submit`.  
${image?fileName=dockstore%5Fsubmit%2E2017%2D12%2D26%2Epng&align=None&scale=75&responsive=true}
2. Drag and drop the `hello_world_submit.cwl.json` file into the field labeled `Submit JSON file`.  
3. Enter a team name and the Synapse parent ID into the corresponding fields.  
4. Drag and drop the synapse credentials file (e.g., `synapse_config.txt`) into the field labeled `Synapse config file`.
5. Click `Quick Launch`.",9657801
hello_world,9657806_report.md,"## GA4GH/DREAM Hello World Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""James Eddy""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This simple ""hello world"" workflow that is designed to capture most of the basic elements of workflows that will be tested in this challenge. The workflow runs a single tool ([`dockstore-tool-helloworld`](https://dockstore.org/containers/quay.io/ga4gh-dream/dockstore-tool-helloworld)), which uses a reference file containing a single template format string (""Hello ____!"" when printed) and an input file containing a single plain string (e.g., ""World""). When the workflow is run, the input string is inserted into the template and written to a new file, now containing the string ""Hello World!"". The input is a text file containing the word ""Hello""; running the workflow requires < 1M of disk space (not counting Docker images) and should take < 1s of CPU time to complete.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Junjun Zhang"" # your name here
institution: ""Ontario Institute for Cancer Research"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-12-27"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""JTracker"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
cwltool_version: ""1.0.2017110733715""
runner_version: ""0.2.0a4"" # indicate executor version used
docker_version: ""1.12.6"" # from `docker --version`
environment: ""OpenStack VM"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""96GB"" # indicate available RAM in environment
env_disk: ""2TB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-12-27""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""1.12.6""
environment_ex: ""local"" 
env_cpus_ex: ""8""
env_memory_ex: ""96GB""
env_disk_ex: ""2TB""
```

### Write a JTracker Workflow
The JTracker workflow is written to automatically execute necessary steps to complete a Dream Challenge workflow. The JTracker workflow is named as `dream-challenge-wf-runner`, the source code is checked in Github at: https://github.com/jthub/demo-workflows/tree/master/dream-challenge-wf-runner/workflow.

Once tested out successfully, make a release of the source code. In this case, it is release version 0.0.6: https://github.com/jthub/demo-workflows/releases/tag/dream-challenge-wf-runner.0.0.6

### Register the JTracker Workflow in JTHub
#### Install JTracker command line tool

Follow the instructions here: https://github.com/icgc-dcc/jtracker

Once install successfully, you should be able to see the version number.
```
jt --version
```

#### Signup a JTHub account
Assume we choose `ga4gh_dream` as account name:
```
jt user signup -u ga4gh_dream
```
Login as `ga4gh_dream`
```
jt user login -u ga4gh_dream
```

#### Register the JTracker Dream Challenge Runner Workflow
Register a workflow is basically provide information to access the JTracker workflow source code in GitHub.
```
jt wf register --git-server https://github.com --git-account jthub --git-repo demo-workflows \
                       --git-path dream-challenge-wf-runner --git-tag dream-challenge-wf-runner.0.0.6 \
                       --wf-name dream-challenge-wf-runner --wf-version 0.0.6
```
To list all registered workflows in your account, do this:
```
jt wf ls
```

### Create a Job Queue
Once we have the workflow registered, you will be able to create a job queue for it.
```
jt queue add --wf-name dream-challenge-wf-runner --wf-version 0.0.6
```
Upon success, you will get a unique job queue ID. In my case, my queue ID is: `758b7668-0057-4ef6-a5b0-6f48acf38583`

To list all job queues you created, do this:
```
jt queue ls
```

### Add workflow job to the above queue
If we want to run `pcawg-sanger-variant-caller`, fill out the appropriate parameters in the job JSON as below:
```
jt job add -q 758b7668-0057-4ef6-a5b0-6f48acf38583 -j '
{
    ""workflow_name"": ""hello_world"",
    ""workflow_type"": ""CWL"",
    ""data_syn_id"": ""syn9630940"",
    ""wf_file_name"": ""hello_world.cwl"",
    ""job_file_name"": ""hello_world.cwl.json"",
    ""checker_wf_file_name"": ""hello_world_checker.cwl"",
    ""checker_job_file_name"": ""hello_world_checker.cwl.json"",
    ""submit_job_file_name"": ""submit.json"",
    ""team_name"": ""PCAWG-Tech"",
    ""syn_parent_id"": ""syn11638604"",
    ""eval_id"": ""9603665""
}
'
```
To list all jobs in the queue:
```
jt job ls -q 758b7668-0057-4ef6-a5b0-6f48acf38583
```
Note that the above steps can be done on any computer, it could be a normal workstation or a laptop.


### Run the above queued Sanger workflow job

To execute the workflow job you will need to set up necessary environment and tools, follow these steps:

#### Setting up environment
1. Install Docker

2. Install `cwltool` (version 1.0.20170217172322) and  `synapseclient`
```
pip install cwltool==1.0.20170217172322
pip install synapseclient
```

3. Create Synapse credentials file `.synapseConfig`
Put there Synapse ID and password
```
[authentication]
username: user@usermail.org
password: <user-password>
```
Put this file a particular place, for example under home directory, eg, `/home/ubuntu/.synapseConfig`, then export the follow environment variable:
```
export SYNCONF=/home/ubuntu/.synapseConfig
```
4. Install JTracker command line
This is the same step as the previous section. Follow installation instruction here: https://github.com/icgc-dcc/jtracker

#### Start JTracker Executor
Start the executor to run jobs in the queue as:
```
jt user login ga4gh_dream
SYNCONF=/home/ubuntu/.synapseConfig jt exec run -q 758b7668-0057-4ef6-a5b0-6f48acf38583
```
If everything goes well, in about 5 hours, the job should finish and you will see `pcawg-sanger-variant-caller` result uploaded to specified location on Synapse.



---",9657806
hello_world,9657809_report.md,"### Workflow description
```YAML
contributor: ""James Eddy""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

### Participant information
```YAML
name: ""Ben Ernest""
institution: ""Digicon Corporation""
```

### Submission overview
```YAML
date_accessed: ""2017-12-12"" 
platform: ""Dockstore"" 
workflow_type: ""CWL"" 
runner_version: ""1.0.20170217172322"" 
docker_version: ""17.09.0-ce"" 
environment: ""BioGenLink"" 
env_cpus: ""1"" 
env_memory: ""8Gb"" 
env_disk: ""5Tb"" 
```

### Steps
#####This workflow was run using the [BioGenLink](http://digicon.com/biogenlink.html) platform from [Digicon](http://digicon.com/).  Click [here](http://digicon.com/biogenlink.html) or [email us](mailto:biogenlink@digiconasp.com) for more information. 

#### **Setup**

##### Create synapse credentials file.  
This only needs to be done once, and the credentials file can be used for each workflow.
1. Log into BioGenLink.  [Click here](http://digicon.com/biogenlink.html) or [email us](mailto:biogenlink@digiconasp.com) for more information. 
${image?fileName=login%5Fscreen%5Fempty%2E2017%2D12%2D19%2Epng&align=None&scale=75&responsive=true}

2. In the **files** tab, right-click on any directory in the file system, select `Create File`, give the file a name (e.g., ""synapse_config.txt""), and click `Preview` to edit the file.  
${image?fileName=create%5Ffile%5Fpreview%2E2017%2D12%2D19%2Epng&align=None&scale=75&responsive=true}

Enter the following information in the file and save it by clicking **Save** (the disk button just above the text area).
```
[authentication]
username: email
password: password
[cache]
location: biodtfs/path/to/cache
```
**Note:** the cache directory is used by synapseClient for temporary files, and we must specify it in BioGenLink to avoid permissions errors. It can be be any directory the user chooses, even a non-existing one as long as the parent directory is valid.  It is suggested to create a working directory for each workflow and keep this file in a parent directory outside of the working directories.  

#### **Provision workflow files**

1. Create a working directory.  
    - Right-click on any directory in the file system, select `Create Folder`, and enter a name for the working directory (e.g., `hello_world`).

2. Run the `Synapse get` tool.
    - In the **tools** tab, find and select the `Synapse get` tool.  It can be found by keyword search or browsing to `Synapse/All/Synapse get`.  Double-clicking (shown below) the tool will open it in the workspace for editing and browsing documentation and will display the menu for providing inputs and running the tool.
${image?fileName=synapse%5Fget%5Fopen%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
    - In the `Synapse IDs` field, enter the Synapse IDs for files to be downloaded.  In this case, the synapse IDs include the following, which correspond to `hello_world_get_get.json`, `dockstore-tool-synapse-submit.cwl`, and `dockstore-tool-synapse-get.cwl`:
```shell
syn9733811
syn9732885
syn9770802
```   
${image?fileName=synapse%5Fget%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
    - Drag and drop the synapse credentials file (e.g., `synapse_config.txt`) from the file system into the field called `Synapse config file`.
    - Drag and drop the working directory into the field called `Output directory`.
    - Run the tool by clicking `Quick Launch`.

#### **Run the workflow**
- Run the `Dockstore launch` tool.
    1. In the **Tools** tab, find and select the `Dockstore launch` tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore launch`.  
${image?fileName=dockstore%5Flaunch%2E2018%2D01%2D04%2Epng&align=None&scale=75&responsive=true}
    2. Drag and drop the `hello_world.cwl` and `hello_world.cwl.json` files from the working directory into the fields labeled `CWL file` and `JSON file`, respectively.  `Parent directory` can be left blank, since the directory containing the two input files will be used as the parent directory by default.   
    3. Click `Quick Launch`.

#### **Validate the results**
- Run the `Dockstore checker` tool.
1. In the **tools** tab, find and select the `Dockstore checker` tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore checker`.  
${image?fileName=dockstore%5Fchecker%2E2017%2D12%2D25%2Epng&align=None&scale=75&responsive=true}
  2. Drag and drop the `hello_world_checker.cwl` and `hello_world_checker.cwl.json` files from the working directory into the fields labeled `Checker CWL file` and `Checker JSON file`, respectively.  
  3. Click `Quick Launch`.
  4. Verify that the workflow ran successfully by opening the `results.json` file and confirming that the `Overall` field is equal to `true`.
${image?fileName=results%5Fjson%2E2017%2D12%2D25%2Epng&align=None&scale=75&responsive=true}

#### **Submit the results to Synapse**
- Run the `Dockstore submit` tool.
  1. In the **Tools** tab, find and select the `Dockstore submit` tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore submit`.  
${image?fileName=dockstore%5Fsubmit%2E2017%2D12%2D26%2Epng&align=None&scale=75&responsive=true}
  2. Drag and drop the `hello_world_submit.cwl.json` file into the field labeled `Submit JSON file`.  
  3. Enter a team name and the Synapse parent ID into the corresponding fields.  
  4. Drag and drop the synapse credentials file (e.g., `synapse_config.txt`) into the field labeled `Synapse config file`.
  5. Click `Quick Launch`.",9657809
hello_world,9657905_report.md,"## GA4GH/DREAM Hello World Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""James Eddy""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This simple ""hello world"" workflow that is designed to capture most of the basic elements of workflows that will be tested in this challenge. The workflow runs a single tool ([`dockstore-tool-helloworld`](https://dockstore.org/containers/quay.io/ga4gh-dream/dockstore-tool-helloworld)), which uses a reference file containing a single template format string (""Hello ____!"" when printed) and an input file containing a single plain string (e.g., ""World""). When the workflow is run, the input string is inserted into the template and written to a new file, now containing the string ""Hello World!"". The input is a text file containing the word ""Hello""; running the workflow requires < 1M of disk space (not counting Docker images) and should take < 1s of CPU time to complete.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Azza E Ahmed"" # your name here
institution: ""University of Khartoum"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-12-29"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""Dockstore"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170828135420"" # indicate executor version used
docker_version: ""17.03.1-ce, build c6d412e"" # from `docker --version`
environment: ""EGI FedCloud"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""32GB"" # indicate available RAM in environment
env_disk: ""100GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-20""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment
0. I launched a VM instance from EGI FedCloud resources (EGI Docker (Ubuntu 14.04) from CESNET MetaCloud (IaaS Cloud)) with extra large memory (32GB ram, 100GB disk, 8 cores). Docker is pre-installed, so I only needed to add the $USER to the `docker` group

1. [Install dockstore](https://dockstore.org) on my machine. This also needs cwltool and java installed beforehand:

```shell
sudo pip install setuptools==36.5.0
sudo pip install cwl-runner cwltool==1.0.20170828135420 schema-salad==2.6.20170806163416 avro==1.8.1 ruamel.yaml==0.14.12 requests==2.18.4

sudo add-apt-repository ppa:webupd8team/java
sudo apt-get update && sudo apt-get install -y oracle-java8-set-default

mkdir -p ~/bin
curl -L -o ~/bin/dockstore https://github.com/ga4gh/dockstore/releases/download/1.3.1/dockstore
chmod +x ~/bin/dockstore
echo 'export PATH=~/bin:$PATH' >> ~/.bashrc
source ~/.bashrc
 mkdir -p ~/.dockstore
printf ""token: eaed4f494bb41e6b78c19786a7ab5feb06c1e02f6f75315d9347f6d066be3719\nserver-url: https://dockstore.org:8443\n"" > ~/.dockstore/config
```

2. Now, I install synapseclient

```shell
pip install synapseclient
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir hello_world_run
cd hello_world_run
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the `synapse get` command to download the JSON parameters file to download data for the **hello_world** workflow:
```shell
synapse get syn9733811 # hello_world_get_get.json

```

#### 3. Provision all workflow files

I used `dockstore` to run `dockstore-tool-synapse-get.cwl` with parameters in `hello_world_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results. I used the quay.io image of the command as below:

```shell
dockstore tool launch --entry quay.io/ga4gh-dream/dockstore-tool-synapse-get --json hello_world_get.cwl.json
```

#### 4. Run main workflow

I again used `dockstore` to run the workflow, as defined in `hello_world.cwl` and parameterized by `hello_world.cwl.json`:
```shell
dockstore workflow launch --local-entry hello_world.cwl --json hello_world.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `dockstore` to run the checker as follows:
```shell
dockstore tool launch --local-entry hello_world_checker.cwl --json hello_world_checker.cwl.json
cat results.json | grep -i overall
```

#### 6. Submit workflow outputs

I modified the parameters in `hello_world_submit.cwl.json` to refer to the right `team_name` and `parent_id`, then submitted as follows:

```shell
dockstore tool launch --entry quay.io/ga4gh-dream/dockstore-tool-synapse-submit --json hello_world_submit.cwl.json
```

---",9657905
hello_world,9657914_report.md,"## GA4GH/DREAM Hello World Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""James Eddy""
workflow_handle: ""hello_world""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This simple ""hello world"" workflow that is designed to capture most of the basic elements of workflows that will be tested in this challenge. The workflow runs a single tool ([`dockstore-tool-helloworld`](https://dockstore.org/containers/quay.io/ga4gh-dream/dockstore-tool-helloworld)), which uses a reference file containing a single template format string (""Hello ____!"" when printed) and an input file containing a single plain string (e.g., ""World""). When the workflow is run, the input string is inserted into the template and written to a new file, now containing the string ""Hello World!"". The input is a text file containing the word ""Hello""; running the workflow requires < 1M of disk space (not counting Docker images) and should take < 1s of CPU time to complete.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Faisal M. Fadlelmola"" # your name here
institution: ""University of Khartoum"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-12-30"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwl-tes"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""cwl-tes 0.2.0 with cwltool 1.0.20171107133715"" # indicate executor version used
docker_version: ""17.03.1-ce, build c6d412e"" # from `docker --version`
environment: ""EGI FedCloud"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""32GB"" # indicate available RAM in environment
env_disk: ""100GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-20""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment
0. I launched a VM instance from EGI FedCloud resources (EGI Docker (Ubuntu 14.04) from CESNET MetaCloud (IaaS Cloud)) with extra large memory (32GB ram, 100GB disk, 8 cores). Docker is pre-installed, so I only needed to add the $USER to the `docker` group

1. [Install cwl-tes](https://github.com/common-workflow-language/cwl-tes) on my machine. 

```shell
wget https://github.com/ohsu-comp-bio/funnel/releases/download/0.4.1/funnel-linux-amd64-0.4.1.tar.gz

tar -xvzf funnel-linux-amd64-0.4.1.tar.gz
```

2. Do the installation in a virtual machine, as per advised:

```shell
sudo pip install virtualenv
virtualenv tes-installation

source tes-installation/bin/activate

pip install cwl-tes
pip install synapseclient
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir hello_world_run
cd hello_world_run
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the `synapse get` command to download the JSON parameters file to download data for the **hello_world** workflow:
```shell
synapse get syn9733811 # hello_world_get_get.json

```

#### 3. Provision all workflow files

I used `cwl-tes` to run `dockstore-tool-synapse-get.cwl` with parameters in `hello_world_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results. First, I needed to run the funnel server though, and send it to the background:

```shell
funnel server run &
cwl-tes --tes http://localhost:8000  dockstore-tool-synapse-get.cwl hello_world_get.cwl.json
```
The tool creates a new folder tree, `funnel-work-dir`, within which all `cwl-tes` outputs and temp files are saved within files named after the job id. For this command, it is:

```
funnel-work-dir/b93e5rarisrhersc3vrg/var/spool/cwl/synapse_files
```

#### 4. Run main workflow

`cwl-tes` seems to not accept a path along with the `*.cwl` or `*.json` file, so I move to the directory of the tools to run the main workflow first:

```shell
cd funnel-work-dir/b93e5rarisrhersc3vrg/var/spool/cwl/synapse_files
cwl-tes --tes http://localhost:8000 hello_world.cwl hello_world.cwl.json
```

Again, all outputs are saved within that same `funnel-work-dir` folder, but under a different job number this time.

```
funnel-work-dir/b93e7c2risrhersc3vs0/var/spool/cwl/helloworld.txt
```

Concerning however, is that after running the command above, an error message is displayed, and I had to ctrl+C to exit it:

```
The job reports the following error:
[job hello-world] FINAL JOB STATE: SYSTEM_ERROR ------------------
[job hello-world] task id: b93e7c2risrhersc3vs0
Exception in thread hello-world:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/threading.py"", line 810, in __bootstrap_inner
    self.run()
  File ""../../../../../local/lib/python2.7/site-packages/cwl_tes/tes.py"", line 460, in run
    while not self.is_done(self.state):
  File ""../../../../../local/lib/python2.7/site-packages/cwl_tes/tes.py"", line 503, in is_done
    self.client.get_task(self.id, ""FULL"").logs
  File ""../../../../../local/lib/python2.7/site-packages/tes/client.py"", line 64, in get_task
    return unmarshal(response.json(), Task)
  File ""../../../../../local/lib/python2.7/site-packages/tes/utils.py"", line 73, in unmarshal
    field = _unmarshal(v, obj)
  File ""../../../../../local/lib/python2.7/site-packages/tes/utils.py"", line 58, in _unmarshal
    field.append(unmarshal(item, obj))
  File ""../../../../../local/lib/python2.7/site-packages/tes/utils.py"", line 85, in unmarshal
    raise UnmarshalError(msg)


UnmarshalError: {u'endTime': u'2017-12-30T01:54:11.648355066+01:00', u'logs': [{u'endTime': u'2017-12-30T01:54:11.619192514+01:00', u'startTime': u'2017-12-30T01:54:09.046102205+01:00'}], u'startTime': u'2017-12-30T01:54:09.017329174+01:00'} could not be unmarshalled to type: ExecutorLog
TypeError: __init__() got an unexpected keyword argument 'logs'

^Crecieved control-c signal
terminating thread(s)...
remote TES processes ['b93e7c2risrhersc3vs0'] may keep running
```

#### 5. Run workflow checker tool

To run the checker, first I needed to adjust the path of the workflow output, and also the knownoutput expected in the `hellow_world_checker.cwl.json` file as below. It should be noted that the docker image seems to have created the file as a root, so I need to sudo to edit:
```shell
$ cat hello_world_checker.cwl.json 
{
    ""knowngood_file"": {
        ""class"": ""File"",
        ""path"": ""../../../../../funnel-work-dir/b93e5rarisrhersc3vrg/var/spool/cwl/synapse_files/knownoutput.txt""
    },
    ""helloworld_file"": {
        ""class"": ""File"",
        ""path"": ""../../../../hello_world_run/funnel-work-dir/b93e7c2risrhersc3vs0/var/spool/cwl/helloworld.txt""
    }
}

$ cwl-tes --tes http://localhost:8000  hello_world_checker.cwl hello_world_checker.cwl.json

$ cat ~/cwl-tes/hello_world_run/funnel-work-dir/b93eekarisrhersc3vsg/var/spool/cwl/results.json | grep -i overall
""overall"": true
```
As before, The output from the checker again seems like failure, but in reality the job has concluded successfully. I think I could have avoided this by calling the tool in a bit different way, but I can't figure out how. Below is the error log for completion:

```
[job hello_world_checker.cwl] FINAL JOB STATE: SYSTEM_ERROR ------------------
[job hello_world_checker.cwl] task id: b93eekarisrhersc3vsg
[job hello_world_checker.cwl] logs: [TaskLog(start_time=datetime.datetime(2017, 12, 30, 2, 9, 37, 658300, tzinfo=tzoffset(None, 3600)), end_time=datetime.datetime(2017, 12, 30, 2, 9, 40, 431083, tzinfo=tzoffset(None, 3600)), metadata=None, logs=[ExecutorLog(start_time=datetime.datetime(2017, 12, 30, 2, 9, 37, 680940, tzinfo=tzoffset(None, 3600)), end_time=datetime.datetime(2017, 12, 30, 2, 9, 40, 405594, tzinfo=tzoffset(None, 3600)), stdout=None, stderr=""INFO:helloworld_check:getting MD5 checksum for file '/var/lib/cwl/stgfb6ef25f-12bb-48fa-a4f5-d3beeINFO:helloworld_check:getting MD5 checksum for file '/var/lib/cwl/stgfb6ef25f-12bb-48fa-a4f5-d3beedd855c2/knownoutput.txt'\nINFO:helloworld_check:getting MD5 checksum for file '/var/lib/cwl/stgb633ec4f-06da-4eb6-9cd3-3787c3b46a17/helloworld.txt'\nINFO:helloworld_check:passing status of step 'md5_chINFO:helloworld_check:passing status of step 'md5_check' was 'True'\nINFO:helloworld_check:overall passing status was 'True'\nINFO:helloworld_check:results saved to 'results.json'\n"", exit_code=None)], outputs=None, system_logs=None)]
[job hello_world_checker.cwl] job error:
Error collecting output for parameter 'log_file':
hello_world_checker.cwl:41:7: Did not find output file with glob pattern: '['log.txt']'
{}
Final process status is permanentFail
```

#### 6. Submit workflow outputs

I modified the parameters in `hello_world_submit.cwl.json` to refer to the right `team_name` and `parent_id`; and also the right output path (the `helloworld_file` as in the checking stage above). This file also needed to be in the same directory as the `synapse submit` tool so that `cwl-tes` works smoothly. These steps are below:

```shell
cd ../../../../../../

cp funnel-work-dir/b93e5rarisrhersc3vrg/var/spool/cwl/synapse_files/hello_world_submit.cwl.json .

sudo vi hello_world_submit.cwl.json

$ cwl-tes --tes http://localhost:8000 dockstore-tool-synapse-submit.cwl hello_world_submit.cwl.json
```

---",9657914
knoweng_gene_prioritization,9632567_report.md,"## KnowEnG Gene Prioritization Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Milt Epstein""
workflow_handle: ""knoweng_gene_prioritization""
input_handle: ""knoweng_gene_prioritization""
```

The following description is provided by the workflow author (see https://knoweng.org/pipelines/):
> You submit a spreadsheet of gene-level transcriptomic (or other omics) profiles of a collection of biological samples. Each sample is also annotated with a numeric  phenotype (e.g., drug response, patient survival, etc.) or categorical phenotype (e.g., cancer  subtype, metastatic status). This pipeline scores each gene by the correlation between its “omic” value (e.g., expression) and the phenotype, and reports the top phenotype-related genes. Gene prioritization can be done in a Knowledge Network-guided mode, and with optional use of bootstrapping to achieve robust prioritization.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""4Gb""
suggested_disk: ""4Gb""
```

#### Workflow history

* **2017-08-23**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""James Eddy"" # your name here
institution: ""Sage Bionetworks"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-05"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170217172322"" # indicate executor version used
docker_version: ""17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""EC2"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""61Gb"" # indicate available RAM in environment
env_disk: ""elastic"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed: ""2017-08-23"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0""
docker_version_ex: ""17.06.0-ce""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""500Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

##### EC2/EFS
I launched a single-node EC2 instance of type `r4.2xlarge` in `us-east-1f` (spot request) with the canonical Ubuntu 16.04 AMI (`ami-80861296`). I connected to the instance via SSH (user `ubuntu`) and installed the required nfs client for Amazon EFS:
```shell
sudo apt-get install nfs-common
```

I then mounted my EFS volume at `/efs`.
```shell
sudo mkdir /efs
sudo mount -t nfs4 -o nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2 fs-2067e169.efs.us-east-1.amazonaws.com:/ /efs
```

##### Docker
I installed Docker on the instance using the following commands:
```shell
sudo apt-get update &&
    sudo apt-get install -y \
        apt-transport-https \
        ca-certificates \
        curl \
        software-properties-common &&
    curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - &&
    sudo add-apt-repository \
        ""deb [arch=amd64] https://download.docker.com/linux/ubuntu \
        $(lsb_release -cs) \
        stable"" &&
    sudo apt-get update &&
    sudo apt-get install -y docker-ce
```

Next, I modified the Docker's default storage location to use a partition with more space available, creating the file `/etc/docker/daemon.json` with the following:
```shell
{
  ""debug"": true,
  ""graph"": ""/dev/docker-data""
}
```

Finally, I added `ubuntu` to the `docker` Linux group, exited the instance, and signed back in.

##### Anaconda/cwltool
I installed Anaconda (`miniconda`) for Python 2.7 under my EFS root directory (**note:** I think this makes `conda` operations a bit slower than usual...).
```shell
wget https://repo.continuum.io/miniconda/Miniconda2-latest-Linux-x86_64.sh -O miniconda.sh
bash miniconda.sh -b -p /efs/miniconda
export PATH=""/efs/miniconda/bin:$PATH""
```

I created and configured a virtual environment with `synapseclient` and `cwltool` as follows:
```shell
conda create -n syncwl
source activate syncwl
pip install synapseclient --no-cache-dir
pip install schema-salad==2.2.20170222151604 cwltool==1.0.20170217172322 --no-cache-dir
```

##### Workspace/config
I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir /efs/knoweng_gene_prioritization
cd /efs/knoweng_gene_prioritization
cp ~/.synapseConfig .
```

Within the working directory, I created a `tmp` folder to be used with `cwltool` in subsequent steps:
```shell
mkdir tmp
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **knoweng_gene_prioritization** workflow:
```shell
synapse get syn10611751 # knoweng_gene_prioritization_get.cwl.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `knoweng_gene_prioritization_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or parameter (JSON or YAML) files required for running the workflow and submitting results.
```shell
cwltool --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict dockstore-tool-synapse-get.cwl knoweng_gene_prioritization_get.cwl.json
```

#### 3. Run main workflow

Use `cwltool` to run the workflow, as defined in `gp_workflow.cwl` and parameterized by `gp_workflow_job.yml`:
```shell
cwltool gp_workflow.cwl gp_workflow_job.yml
```

#### 4. Run workflow checker tool

To verify the workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool check_results.cwl check_results_job.yml
cat log.txt
cat results.json
```

#### 5. Submit workflow outputs

I modified the parameters in `submit_results.yml` (filling in `team_name`, `parent_id` fields) as follows:
```YAML
config_file:
  class: File
  location: .synapseConfig
team_name: ""SageWorkflowRunners""
eval_id: ""9606345""
file:
  - class: File
    location: ./ranked_genes_download.tsv
  - class: File
    location: ./top_genes_download.tsv
  - class: File
    location: ./combo_results.txt
  - class: File
    location: ./9606.STRING_experimental.edge
parent_id: ""syn10611056""
```

Finally, I submitted the outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl submit_results.yml
```

---",9632567
knoweng_gene_prioritization,9632581_report.md,"## KnowEnG Gene Prioritization Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Milt Epstein""
workflow_handle: ""knoweng_gene_prioritization""
input_handle: ""knoweng_gene_prioritization""
```

The following description is provided by the workflow author (see https://knoweng.org/pipelines/):
> You submit a spreadsheet of gene-level transcriptomic (or other omics) profiles of a collection of biological samples. Each sample is also annotated with a numeric  phenotype (e.g., drug response, patient survival, etc.) or categorical phenotype (e.g., cancer  subtype, metastatic status). This pipeline scores each gene by the correlation between its “omic” value (e.g., expression) and the phenotype, and reports the top phenotype-related genes. Gene prioritization can be done in a Knowledge Network-guided mode, and with optional use of bootstrapping to achieve robust prioritization.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""4Gb""
suggested_disk: ""4Gb""
```

#### Workflow history

* **2017-08-23**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Lon Blauvelt"" # your name here
institution: ""UCSC"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-05"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170217172322"" # indicate executor version used
docker_version: ""17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""EC2"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""16Gb"" # indicate available RAM in environment
env_disk: ""50Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed: ""2017-08-23"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0""
docker_version_ex: ""17.06.0-ce""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""500Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

*I launched an EC2 instance of type `t2.2xlarge` with one node, mounted a 50 Gb EFS volume.*

I used the following to update the instance:

```shell
sudo apt-get update
sudo apt-get -y upgrade
sudo apt-get -y dist-upgrade
```

Install docker:

```shell
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
sudo add-apt-repository ""deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable""
sudo apt-get update
apt-cache policy docker-ce
sudo apt-get install -y docker-ce
sudo usermod -aG docker ${USER}
sudo su - ${USER}
```

Install pip, a virtualenv, and the requisite pip installs (cwltool, schema-salad, avro, synapse, and html5lib):

```shell
sudo apt install -y python-pip
sudo pip install --upgrade pip
sudo pip install virtualenv
virtualenv --python /usr/bin/python2 cwl
source /home/ubuntu/cwl/bin/activate
pip install cwl-runner cwltool==1.0.20170217172322 schema-salad==2.6.20170630075932 avro==1.8.1  ruamel.yaml==0.14.12 --no-cache-dir
pip install synapseclient --no-cache-dir
pip install html5lib
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:

```shell
mkdir syn
cd syn
nano syn-login.synapseConfig
[PASTE] username & password
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **knoweng_gene_prioritization** workflow:
```shell
synapse get syn10611751 # knoweng_gene_prioritization_get.cwl.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```
I also edited the `knoweng_gene_prioritization_get.cwl.json` file to contain the synapse credentials path:
```shell
nano knoweng_gene_prioritization_get.cwl.json
[PASTE] /home/ubuntu/syn/syn-login.synapseConfig
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `knoweng_gene_prioritization_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or parameter (JSON or YAML) files required for running the workflow and submitting results.
```shell
cwltool --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict dockstore-tool-synapse-get.cwl knoweng_gene_prioritization_get.cwl.json
```

#### 3. Run main workflow

Use `cwltool` to run the workflow, as defined in `gp_workflow.cwl` and parameterized by `gp_workflow_job.yml`:
```shell
cwltool gp_workflow.cwl gp_workflow_job.yml
```

#### 4. Run workflow checker tool

To verify the workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool check_results.cwl check_results_job.yml
```

#### 5. Submit workflow outputs

I modified the parameters in `submit_results.yml` (filling in `team_name`, `parent_id` fields) as follows:
```YAML
config_file:
  class: File
  location: /home/ubuntu/syn/syn-login.synapseConfig
team_name: ""UCSC GA4GH-DREAM Challenge Team""
eval_id: ""9606345""
file:
  - class: File
    location: ./ranked_genes_download.tsv
  - class: File
    location: ./top_genes_download.tsv
  - class: File
    location: ./combo_results.txt
  - class: File
    location: ./9606.STRING_experimental.edge
parent_id: ""syn10182019""
```

Finally, I submitted the outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl submit_results.yml
```

---",9632581
knoweng_gene_prioritization,9632621_report.md,"## KnowEnG Gene Prioritization Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Milt Epstein""
workflow_handle: ""knoweng_gene_prioritization""
input_handle: ""knoweng_gene_prioritization""
```

The following description is provided by the workflow author (see https://knoweng.org/pipelines/):
> You submit a spreadsheet of gene-level transcriptomic (or other omics) profiles of a collection of biological samples. Each sample is also annotated with a numeric  phenotype (e.g., drug response, patient survival, etc.) or categorical phenotype (e.g., cancer  subtype, metastatic status). This pipeline scores each gene by the correlation between its “omic” value (e.g., expression) and the phenotype, and reports the top phenotype-related genes. Gene prioritization can be done in a Knowledge Network-guided mode, and with optional use of bootstrapping to achieve robust prioritization.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""4Gb""
suggested_disk: ""4Gb""
```

#### Workflow history

* **2017-08-23**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Abraham Chavez"" # your name here
institution: ""UCSC GI"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-05"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""cwl"" # CWL or WDL
runner_version: ""1.0.20170217172322"" # indicate executor version used
docker_version: ""1.12.6"" # from `docker --version`
environment: ""EC2"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""32"" # indicate number of cores in environment
env_memory: ""240Gb"" # indicate available RAM in environment
env_disk: ""200Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed: ""2017-08-23"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0""
docker_version_ex: ""17.06.0-ce""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""500Gb""
```

### Steps

#### 1. Set up environment

If you have not set up your environment and install dependencies like **cwltool**, **dockstore**, **java** and so on
I recommend you follow [**this**](https://www.synapse.org/#!Synapse:syn10220609) instructions.

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir KE_GP_run1
cd KE_GP_run1
cp ~/.synapseConfig .
```

#### 2. Download required files

Use the `synapse get` command to recursively download all of the required files from the knoweng_gene_prioritization folder on synapse -- the CWL files for the workflow and to check the results, the associated parameters files (in YAML format), and the input data files:
```shell
synapse get -r syn10235824 # the knoweng_gene_prioritization folder
```

#### 3. Run main workflow

Use `cwltool` to run the workflow, as defined in `gp_workflow.cwl` and parameterized by `gp_workflow_job.yml`:
```shell
cwltool --non-strict gp_workflow.cwl gp_workflow_job.yml
```

#### 4. Run workflow checker tool

To verify the workflow results before submission, use `cwltool` to run the checker as follows:
```shell
cwltool --non-strict check_results.cwl check_results_job.yml
cat log.txt
cat results.json
```
Note: The default check_results parameters file `check_results_job.yml` expects the results files to be in the working directory (i.e., the current directory).  If you need to change that, you can edit the parameters file and modify the locations of the results files.

#### 5. Submit workflow outputs

Use the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools:
```shell
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
```

Modify the parameters in `submit_results.yml` appropriately; in particular, you will need to fill in the `team_name` (optional) and `parent_id` (required) fields; you may also need to modify the locations of the results files:
```YAML
config_file:
  class: File
  location: .synapseConfig
team_name: ""My Team Name""
eval_id: ""9606345""
file:
  - class: File
    location: ./ranked_genes_download.tsv
  - class: File
    location: ./top_genes_download.tsv
  - class: File
    location: ./combo_results.txt
  - class: File
    location: ./9606.STRING_experimental.edge
parent_id: ""syn12345678""
```

Finally, submit the outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl submit_results.yml
```

---",9632621
knoweng_gene_prioritization,9632776_report.md,"## KnowEnG Gene Prioritization Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Milt Epstein""
workflow_handle: ""knoweng_gene_prioritization""
input_handle: ""knoweng_gene_prioritization""
```

The following description is provided by the workflow author (see https://knoweng.org/pipelines/):
> You submit a spreadsheet of gene-level transcriptomic (or other omics) profiles of a collection of biological samples. Each sample is also annotated with a numeric  phenotype (e.g., drug response, patient survival, etc.) or categorical phenotype (e.g., cancer  subtype, metastatic status). This pipeline scores each gene by the correlation between its “omic” value (e.g., expression) and the phenotype, and reports the top phenotype-related genes. Gene prioritization can be done in a Knowledge Network-guided mode, and with optional use of bootstrapping to achieve robust prioritization.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""4Gb""
suggested_disk: ""4Gb""
```

#### Workflow history

* **2017-08-23**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Abraham Chavez"" # your name here
institution: ""UCSC GI"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-06"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""dockstore cli"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.2.5"" # indicate executor version used
docker_version: ""1.12.6"" # from `docker --version`
environment: ""EC2"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""32"" # indicate number of cores in environment
env_memory: ""240Gb"" # indicate available RAM in environment
env_disk: ""200Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed: ""2017-08-23"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0""
docker_version_ex: ""17.06.0-ce""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""500Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment
Launched an EC2 instance of type `r4.8xlarge` with one node, mounted an EFS volume, and installed dependencies.
#####
If you have not set up your environment and install dependencies like **cwltool**, **dockstore**, **java** and so on
I recommend you follow [**this**](https://www.synapse.org/#!Synapse:syn10220609) instructions.

##### Create empty folder for workflow running
```
mkdir KE_GP_run1
cd KE_GP_run1
```
Create Synapse credentials file `.synapseConfig`, put there Synapse ID and password
```
[authentication]
username: user@usermail.org
password: <user-password>
```
Information about `.synapseConfig` can be found [**here**](https://www.synapse.org/#!Synapse:syn8507133/wiki/451408)

#### 2. Download required files

Use the `synapse get` command to recursively download all of the required files from the knoweng_gene_prioritization folder on synapse -- the CWL files for the workflow and to check the results, the associated parameters files (in JSON/YAML format), and the input data files:
```shell
synapse get -r syn10235824 # the knoweng_gene_prioritization folder
```

#### 3. Run main workflow
Edit a new file, and call it `gp_workflow_job.json`

Parametrize the file as follows:
```JSON
{
   ""genomic_spreadsheet_file"": {
      ""class"": ""File"",
      ""path"": ""data/Hsap.ccle.G.qnorm_probe.pos.df""
   },
   ""phenotypic_spreadsheet_file"": {
      ""class"": ""File"",
      ""path"": ""data/Hsap.ccle.P.cyto_ic50.pos.df""
   },
   ""correlation_measure"": ""pearson"",
   ""num_bootstraps"": 8,
   ""use_network"": true,
   ""edge_type"": ""STRING_experimental"",
   ""network_type"": ""Gene"",
   ""taxonid"": ""9606"",
   ""redis_host"": ""knowredis.knoweng.org"",
   ""redis_port"": 6379
}
```
Use `dockstore` to run the workflow, as defined in `gp_workflow.cwl` and parameterized by `gp_workflow_job.json`:
```shell
dockstore workflow launch --local-entry gp_workflow.cwl --json gp_workflow_job.json
```

#### 4. Run workflow checker tool

To verify the workflow results before submission, use `cwltool` to run the checker as follows:
```shell
cwltool check_results.cwl check_results_job.yml
cat log.txt
cat results.json
```
Note: The default check_results parameters file `check_results_job.yml` expects the results files to be in the working directory (i.e., the current directory).  If you need to change that, you can edit the parameters file and modify the locations of the results files.

#### 5. Submit workflow outputs

Use the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools:
```shell
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
```

Modify the parameters in `submit_results.yml` appropriately; in particular, you will need to fill in the `team_name` (optional) and `parent_id` (required) fields; you may also need to modify the locations of the results files:
```YAML
config_file:
  class: File
  location: .synapseConfig
team_name:
eval_id: ""9606345""
file:
  - class: File
    location: ./ranked_genes_download.tsv
  - class: File
    location: ./top_genes_download.tsv
  - class: File
    location: ./combo_results.txt
  - class: File
    location: ./9606.STRING_experimental.edge
parent_id:
```

Finally, submit the outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl submit_results.yml
```

---",9632776
knoweng_gene_prioritization,9632817_report.md,"## KnowEnG Gene Prioritization Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Milt Epstein""
workflow_handle: ""knoweng_gene_prioritization""
input_handle: ""knoweng_gene_prioritization""
```

The following description is provided by the workflow author (see https://knoweng.org/pipelines/):
> You submit a spreadsheet of gene-level transcriptomic (or other omics) profiles of a collection of biological samples. Each sample is also annotated with a numeric  phenotype (e.g., drug response, patient survival, etc.) or categorical phenotype (e.g., cancer  subtype, metastatic status). This pipeline scores each gene by the correlation between its “omic” value (e.g., expression) and the phenotype, and reports the top phenotype-related genes. Gene prioritization can be done in a Knowledge Network-guided mode, and with optional use of bootstrapping to achieve robust prioritization.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""4Gb""
suggested_disk: ""4Gb""
```

#### Workflow history

* **2017-08-23**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Gary Luu"" # your name here
institution: ""Dockstore - OICR"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-08-23"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""dockstore"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.2.7"" # indicate executor version used
docker_version: ""17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""4"" # indicate number of cores in environment
env_memory: ""32 GB"" # indicate available RAM in environment
env_disk: ""470 GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed: ""2017-08-23"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0""
docker_version_ex: ""17.06.0-ce""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""500Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessasry.

#### 1. Set up environment

On a personal desktop, I installed Docker, pip, cwltool, and the Dockstore command-line helper using a procedure similar to https://github.com/denis-yuen/2017-cloud-workflows-misc/blob/master/install-and-run-with-dockstore.md .  
However, I used my own modified dockstore CLI (which will be 1.2.7)

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir knoweng
cd knoweng
cp ~/.synapseConfig .
```
#### 2. Download required files

I downloaded knoweng_gene_prioritization_get.cwl.json from the website. 


#### 3. Provision all workflow files

I used the synapse-get tool from Dockstore.
```shell
dockstore tool launch --entry quay.io/ga4gh-dream/dockstore-tool-synapse-get --json knoweng_gene_prioritization_get.cwl.json
```

#### 4. Run main workflow

I used dockstore to launch the recently downloaded gp_workflow.cwl . 
```shell
dockstore workflow launch --local-entry gp_workflow.cwl --yaml gp_workflow_job.yml
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `dockstore` to run the checker as follows:
```shell
dockstore tool launch --local-entry check_results.cwl --yaml check_results_job.yml
cat results.json | grep overall
```

#### 6. Submit workflow outputs

I modified the parameters in `submit_results.yml` as follows:
```
config_file:
  class: File
  location: .synapseConfig
team_name: """"
eval_id: ""9606345""
file:
  - class: File
    path: ./ranked_genes_download.tsv
  - class: File
    path: ./top_genes_download.tsv
  - class: File
    path: ./combo_results.txt
  - class: File
    path: ./9606.STRING_experimental.edge
parent_id: ""syn9877725""
```

Finally, I submitted outputs using dockstore-tool-synapse-submit`:
```shell
dockstore tool launch --entry quay.io/ga4gh-dream/dockstore-tool-synapse-submit --yaml submit_results.yml
```

---",9632817
knoweng_gene_prioritization,9634093_report.md,"## KnowEnG Gene Prioritization Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Milt Epstein""
workflow_handle: ""knoweng_gene_prioritization""
input_handle: ""knoweng_gene_prioritization""
```

The following description is provided by the workflow author (see https://knoweng.org/pipelines/):
> You submit a spreadsheet of gene-level transcriptomic (or other omics) profiles of a collection of biological samples. Each sample is also annotated with a numeric  phenotype (e.g., drug response, patient survival, etc.) or categorical phenotype (e.g., cancer  subtype, metastatic status). This pipeline scores each gene by the correlation between its “omic” value (e.g., expression) and the phenotype, and reports the top phenotype-related genes. Gene prioritization can be done in a Knowledge Network-guided mode, and with optional use of bootstrapping to achieve robust prioritization.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""4Gb""
suggested_disk: ""4Gb""
```

#### Workflow history

* **2017-08-23**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Benjamin Story"" # your name here
institution: ""EMBL"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-12"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""cwltool 1.0.20170413194156"" # indicate executor version used
docker_version: ""1.7.1, build 786b29d"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""12"" # indicate number of cores in environment
env_memory: ""72GB"" # indicate available RAM in environment
env_disk: ""1TB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

On a local machine, with docker, cwltool, and the synapse client installed, create a working directory to use for the run, and cd to that directory:
```shell
mkdir knoweng
cd knoweng
cp ~/.synapseConfig .
```

#### 2. Download required files

Use the `synapse get` command to recursively download all of the required files from the knoweng_gene_prioritization folder on synapse -- the CWL files for the workflow and to check the results, the associated parameters files (in YAML format), the `synapse-get` and `synapse-submit` CWL tools, and the input data files:
```shell
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
synapse get -r syn10235824 # the knoweng_gene_prioritization folder
```

#### 3. Run main workflow

Use `cwltool` to run the workflow, as defined in `gp_workflow.cwl` and parameterized by `gp_workflow_job.yml`:
```shell
cwltool --tmpdir-prefix tmp/ --cachedir cache/ --non-strict gp_workflow.cwl gp_workflow_job.yml
```

#### 4. Run workflow checker tool

To verify the workflow results before submission, use `cwltool` to run the checker as follows:
```shell
cwltool --tmpdir-prefix tmp/ --cachedir cache/ --non-strict check_results.cwl check_results_job.yml
cat log.txt
cat results.json
```
Note: The default check_results parameters file `check_results_job.yml` expects the results files to be in the working directory (i.e., the current directory).  If you need to change that, you can edit the parameters file and modify the locations of the results files.

#### 5. Submit workflow outputs

Modify the parameters in `submit_results.yml` appropriately; in particular, you will need to fill in the `team_name` (optional) and `parent_id` (required) fields; you may also need to modify the locations of the results files:
```YAML
config_file:
  class: File
  location: .synapseConfig
team_name: ""EMBL GA4GH-DREAM Challenge Team""
eval_id: ""9606345""
file:
  - class: File
    location: ./ranked_genes_download.tsv
  - class: File
    location: ./top_genes_download.tsv
  - class: File
    location: ./combo_results.txt
  - class: File
    location: ./9606.STRING_experimental.edge
parent_id: ""syn10723289""
```

Finally, submit the outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl submit_results.yml
```

---",9634093
knoweng_gene_prioritization,9636362_report.md,"## KnowEnG Gene Prioritization Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Milt Epstein""
workflow_handle: ""knoweng_gene_prioritization""
input_handle: ""knoweng_gene_prioritization""
```

The following description is provided by the workflow author (see https://knoweng.org/pipelines/):
> You submit a spreadsheet of gene-level transcriptomic (or other omics) profiles of a collection of biological samples. Each sample is also annotated with a numeric  phenotype (e.g., drug response, patient survival, etc.) or categorical phenotype (e.g., cancer  subtype, metastatic status). This pipeline scores each gene by the correlation between its “omic” value (e.g., expression) and the phenotype, and reports the top phenotype-related genes. Gene prioritization can be done in a Knowledge Network-guided mode, and with optional use of bootstrapping to achieve robust prioritization.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""4Gb""
suggested_disk: ""4Gb""
```

#### Workflow history

* **2017-08-23**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Vipin T. Sreedharan""
institution: ""ETH Zürich, NEXUS Personalized Health Technologies""
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-20"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170828135420"" # indicate executor version used
docker_version: ""1.12.6"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""32Gb"" # indicate available RAM in environment
env_disk: ""140Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

At our institute, on a compute machine called `wfexec` with Red Hat Enterprise Linux Server release 7.4 (Maipo), installed Docker. Created a group named ""docker"" since it was preferred to use Docker as a non-root user on this machine. The instance has a non-root user called `wfrunner`. Next added the non-root user `wfrunner` to the ""docker"" group. Then started the docker engine and all the below commands were executed using root user privileges [sudo]:
```shell
yum install docker
groupadd docker 
usermod -aG docker wfrunner  
systemctl start docker 
```
&nbsp;
As a non-root user on `wfexec` machine, installed Anaconda and cwltool to the home path of user `wfrunner`:
```shell
su - wfrunner
wget https://repo.continuum.io/archive/Anaconda2-4.4.0-Linux-x86_64.sh
bash Anaconda2-4.4.0-Linux-x86_64.sh 
conda install virtualenv
virtualenv -p python2 /home/wfrunner/venv
source /home/wfrunner/venv/bin/activate
pip install cwltools
deactivate
```
&nbsp;
Created a utilities directory for storing the `synapse-get` and `synapse-submit` CWL tools. In the same folder, created a file with my Synapse credentials. 
```shell
mkdir -p /home/wfrunner/synapse_utils
cd /home/wfrunner/synapse_utils
wget -O dockstore-tool-synapse-get.cwl https://raw.githubusercontent.com/GA4GH-DREAM/dockstore-tool-synapse-get/master/Dockstore.cwl 
wget -O dockstore-tool-synapse-submit.cwl https://raw.githubusercontent.com/GA4GH-DREAM/dockstore-tool-synapse-submit/master/Dockstore.cwl
touch .synapse_config
vim .synapse_config
[WRITE] Synapse username & password
```

#### 2. Download required files

Downloaded data config file knoweng_gene_prioritization_get.cwl.json from the website `https://www.synapse.org/#!Synapse:syn8507133/wiki/451410` for the **knoweng_gene_prioritization** workflow. Created a directory for the storing the workflow associated data downloading JSON parameter file: 
```shell
mkdir -p /home/wfrunner/data_config_files
mv ~/knoweng_gene_prioritization_get.cwl.json ~/data_config_files
cd /home/wfrunner/data_config_files
vim knoweng_gene_prioritization_get.cwl.json
[PASTE] /home/wfrunner/synapse_utils/.synapse_config
```

#### 3. Provision all workflow files

Created a working directory for the current workflow. Used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `knoweng_gene_prioritization_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
mkdir -p /home/wfrunner/knoweng_gene_prioritization
cd /home/wfrunner/knoweng_gene_prioritization
cwltool --tmpdir-prefix /home/wfrunner/tmp/ --cachedir /home/wfrunner/tmp/cache --debug --non-strict ~/synapse_utils/dockstore-tool-synapse-get.cwl ~/config_files/knoweng_gene_prioritization_get.cwl.json
```

#### 4. Run main workflow

Use `cwltool` to run the workflow, as defined in `gp_workflow.cwl` and parameterized by `gp_workflow_job.yml`:
```shell
cd /home/wfrunner/knoweng_gene_prioritization
cwltool --tmpdir-prefix /home/wfrunner/tmp/ --cachedir /home/wfrunner/tmp/cache --debug --non-strict gp_workflow.cwl gp_workflow_job.yml
```

#### 4. Run workflow checker tool

To verify the workflow results before submission, use `cwltool` to run the checker as follows:
```shell
cd /home/wfrunner/knoweng_gene_prioritization
cwltool --tmpdir-prefix /home/wfrunner/tmp/ --cachedir /home/wfrunner/tmp/cache --debug --non-strict check_results.cwl check_results_job.yml
cat log.txt
cat results.json
```
Note: The default check_results parameters file `check_results_job.yml` expects the results files to be in the working directory (i.e., the current directory).  If you need to change that, you can edit the parameters file and modify the locations of the results files.

#### 5. Submit workflow outputs

Modified the parameters in `submit_results.yml` appropriately:
```YAML
config_file:
  class: File
  location: /home/wfrunner/dream_challenge/2017/workflow_execution/synapse_utils/.synapse_config
team_name:
eval_id: ""9606345""
file:
  - class: File
    location: ./ranked_genes_download.tsv
  - class: File
    location: ./top_genes_download.tsv
  - class: File
    location: ./combo_results.txt
  - class: File
    location: ./9606.STRING_experimental.edge
parent_id: ""syn10850677""
```
&nbsp;

Finally, submitted the outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cd /home/wfrunner/knoweng_gene_prioritization
cwltool --tmpdir-prefix /home/wfrunner/tmp/ --cachedir /home/wfrunner/tmp/cache --debug --non-strict ~/synapse_utils/dockstore-tool-synapse-submit.cwl submit_results.yml
```

---",9636362
knoweng_gene_prioritization,9636471_report.md,"## KnowEnG Gene Prioritization Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Milt Epstein""
workflow_handle: ""knoweng_gene_prioritization""
input_handle: ""knoweng_gene_prioritization""
```

The following description is provided by the workflow author (see https://knoweng.org/pipelines/):
> You submit a spreadsheet of gene-level transcriptomic (or other omics) profiles of a collection of biological samples. Each sample is also annotated with a numeric  phenotype (e.g., drug response, patient survival, etc.) or categorical phenotype (e.g., cancer  subtype, metastatic status). This pipeline scores each gene by the correlation between its “omic” value (e.g., expression) and the phenotype, and reports the top phenotype-related genes. Gene prioritization can be done in a Knowledge Network-guided mode, and with optional use of bootstrapping to achieve robust prioritization.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""4Gb""
suggested_disk: ""4Gb""
```

#### Workflow history

* **2017-08-23**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Denis Yuen"" # your name here
institution: ""OICR"" # your institution here
```

### Submission overview

```YAML
platform: ""dockstore 1.2.10"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.2.10"" # indicate executor version used
docker_version: ""17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""64GB"" # indicate available RAM in environment
env_disk: ""400GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

On a local machine, with docker, cwltool, and the synapse client installed, create a working directory to use for the run, and cd to that directory:
```shell
mkdir knoweng
cd knoweng
cp ~/.synapseConfig .
cp ../md5sum/.synapseConfig .
```

#### 2. Download required files

Use the `synapse get` command to recursively download all of the required files from the knoweng_gene_prioritization folder on synapse -- the CWL files for the workflow and to check the results, the associated parameters files (in YAML format), and the input data files:
```shell
dockstore tool launch --entry quay.io/ga4gh-dream/dockstore-tool-synapse-get --json knoweng_gene_prioritization_get.cwl.json
dockstore workflow launch --local-entry gp_workflow.cwl --yaml gp_workflow_job.yml
dockstore tool launch --local-entry check_results.cwl --yaml check_results_job.yml
```

#### 3. Run main workflow

Use `dockstore` to run the workflow, as defined in `gp_workflow.cwl` and parameterized by `gp_workflow_job.yml`:
```shell
dockstore workflow launch --local-entry gp_workflow.cwl --yaml gp_workflow_job.yml
```

#### 4. Run workflow checker tool

To verify the workflow results before submission, use `dockstore` to run the checker as follows:
```shell
dockstore tool launch --local-entry check_results.cwl --yaml check_results_job.yml
```

#### 5. Submit workflow outputs

Modify the parameters in `submit_results.yml` appropriately; in particular, you will need to fill in the `team_name` (optional) and `parent_id` (required) fields; you may also need to modify the locations of the results files.
Note that location changes to path:
```YAML
config_file:
  class: File
  location: .synapseConfig
team_name: ""Dockstore Team""
eval_id: ""9606345""
file:
  - class: File
    path: ./ranked_genes_download.tsv
  - class: File
    path: ./top_genes_download.tsv
  - class: File
    path: ./combo_results.txt
  - class: File
    path: ./9606.STRING_experimental.edge
parent_id: ""syn9961864""
```

Finally, submit the outputs using `dockstore` and `dockstore-tool-synapse-submit.cwl`:
```shell
dockstore tool launch --entry quay.io/ga4gh-dream/dockstore-tool-synapse-submit --yaml submit_results.yml
```",9636471
knoweng_gene_prioritization,9636926_report.md,"## KnowEnG Gene Prioritization Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Milt Epstein""
workflow_handle: ""knoweng_gene_prioritization""
input_handle: ""knoweng_gene_prioritization""
```

The following description is provided by the workflow author (see https://knoweng.org/pipelines/):
> You submit a spreadsheet of gene-level transcriptomic (or other omics) profiles of a collection of biological samples. Each sample is also annotated with a numeric  phenotype (e.g., drug response, patient survival, etc.) or categorical phenotype (e.g., cancer  subtype, metastatic status). This pipeline scores each gene by the correlation between its “omic” value (e.g., expression) and the phenotype, and reports the top phenotype-related genes. Gene prioritization can be done in a Knowledge Network-guided mode, and with optional use of bootstrapping to achieve robust prioritization.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""4Gb""
suggested_disk: ""4Gb""
```

#### Workflow history

* **2017-08-23**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Azza E. Ahmed"" # your name here
institution: ""University of Khartoum, Sudan"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-22"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170217172322"" # indicate executor version used
docker_version: ""1.13.1, build 092cba3"" # from `docker --version`
environment: ""stand alone server"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""24"" # indicate number of cores in environment
env_memory: ""125G"" # indicate available RAM in environment
env_disk: ""7.5T"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-20""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```


### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

On a local machine, with docker, cwltool, and the synapse client installed, create a working directory to use for the run, and cd to that directory:
```shell
mkdir KE_GP_run1
cd KE_GP_run1
```

#### 2. Download required files

Use the `synapse get` command to recursively download all of the required files from the knoweng_gene_prioritization folder on synapse -- the CWL files for the workflow and to check the results, the associated parameters files (in YAML format), and the input data files:
```shell
synapse get -r syn10235824 # the knoweng_gene_prioritization folder
```

#### 3. Run main workflow

Use `cwltool` to run the workflow, as defined in `gp_workflow.cwl` and parameterized by `gp_workflow_job.yml`:
```shell
cwltool gp_workflow.cwl gp_workflow_job.yml
```

#### 4. Run workflow checker tool

To verify the workflow results before submission, use `cwltool` to run the checker as follows:
```shell
cwltool check_results.cwl check_results_job.yml
cat log.txt
cat results.json
```
Note: The default check_results parameters file `check_results_job.yml` expects the results files to be in the working directory (i.e., the current directory).  If you need to change that, you can edit the parameters file and modify the locations of the results files.

#### 5. Submit workflow outputs

Modify the parameters in `submit_results.yml` appropriately; in particular, you will need to fill in the `team_name` (optional) and `parent_id` (required) fields; you may also need to modify the locations of the results files:
```YAML
config_file:
  class: File
  location: ""/home/aeahmed/GA4GH_phase2_dream/.synapseConfig""
team_name: CBSB_pipelines
eval_id: ""9606345""
file:
  - class: File
    location: ./ranked_genes_download.tsv
  - class: File
    location: ./top_genes_download.tsv
  - class: File
    location: ./combo_results.txt
  - class: File
    location: ./9606.STRING_experimental.edge
parent_id: syn10888997
```

Finally, submit the outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl submit_results.yml
```

---",9636926
knoweng_gene_prioritization,9637442_report.md,"## KnowEnG Gene Prioritization Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Milt Epstein""
workflow_handle: ""knoweng_gene_prioritization""
input_handle: ""knoweng_gene_prioritization""
```

The following description is provided by the workflow author (see https://knoweng.org/pipelines/):
> You submit a spreadsheet of gene-level transcriptomic (or other omics) profiles of a collection of biological samples. Each sample is also annotated with a numeric  phenotype (e.g., drug response, patient survival, etc.) or categorical phenotype (e.g., cancer  subtype, metastatic status). This pipeline scores each gene by the correlation between its “omic” value (e.g., expression) and the phenotype, and reports the top phenotype-related genes. Gene prioritization can be done in a Knowledge Network-guided mode, and with optional use of bootstrapping to achieve robust prioritization.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""4Gb""
suggested_disk: ""4Gb""
```

#### Workflow history

* **2017-08-23**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Vipin T. Sreedharan"" # your name here
institution: ""ETH Zürich, NEXUS Personalized Health Technologies"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

```YAML
date_accessed: ""2017-09-25"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""Toil"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""cwltoil 3.11.0"" # indicate executor version used
docker_version: ""1.12.6, build c4618fb"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""32Gb"" # indicate available RAM in environment
env_disk: ""140Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

At our institute, on a compute machine called `wfexec` with Red Hat Enterprise Linux Server release 7.4 (Maipo), installed Docker. Created a group named ""docker"" since it was preferred to use Docker as a non-root user on this machine. The instance has a non-root user called `wfrunner`. Next added the non-root user `wfrunner` to the ""docker"" group. Then started the docker engine and all the below commands were executed using root user privileges [sudo]:
```shell
yum install docker
groupadd docker 
usermod -aG docker wfrunner  
systemctl start docker 
```
&nbsp;

As a non-root user `wfrunner` on `wfexec` machine, installed Anaconda and Toil to the home path:
```shell
su - wfrunner
wget https://repo.continuum.io/archive/Anaconda2-4.4.0-Linux-x86_64.sh
bash Anaconda2-4.4.0-Linux-x86_64.sh 
conda install virtualenv
virtualenv -p python2 /home/wfrunner/venv
source /home/wfrunner/venv/bin/activate
pip install toil
deactivate
```
&nbsp;

Created a utilities directory for storing the `synapse-get` and `synapse-submit` CWL tools. In the same folder, created Synapse credential file `.synapse_config` and put there Synapse ID and password. 
```shell
mkdir -p /home/wfrunner/synapse_utils
cd /home/wfrunner/synapse_utils
wget -O dockstore-tool-synapse-get.cwl https://raw.githubusercontent.com/GA4GH-DREAM/dockstore-tool-synapse-get/master/Dockstore.cwl 
wget -O dockstore-tool-synapse-submit.cwl https://raw.githubusercontent.com/GA4GH-DREAM/dockstore-tool-synapse-submit/master/Dockstore.cwl
touch .synapse_config
vim .synapse_config
[WRITE] Synapse username & password
```

#### 2. Downloading required files

Downloaded data config file  knoweng_gene_prioritization_get.cwl.json from the website `https://www.synapse.org/#!Synapse:syn8507133/wiki/451410` for the **knoweng_gene_prioritization** workflow. Created a directory for the storing the workflow associated data downloading JSON parameter file: 
```shell
mkdir -p /home/wfrunner/data_config_files
mv ~/knoweng_gene_prioritization_get.cwl.json ~/data_config_files
cd /home/wfrunner/data_config_files
vim knoweng_gene_prioritization_get.cwl.json
[PASTE] /home/wfrunner/synapse_utils/.synapse_config
```

#### 3. Provision all workflow files

Created a working directory for the current workflow. 
```shell
mkdir -p /home/wfrunner/knoweng_gene_prioritization
cd /home/wfrunner/knoweng_gene_prioritization
```
&nbsp;

Used `cwltoil` to run `dockstore-tool-synapse-get.cwl` with parameters in `knoweng_gene_prioritization_get.cwl.json` to download workflow input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltoil --workDir /home/wfrunner/tmp/ ~/synapse_utils/dockstore-tool-synapse-get.cwl ~/config_files/knoweng_gene_prioritization_get.cwl.json
```
Wait until downloading is finished

#### 4. Run main workflow

Before running the workflow, I have to change the amount of disk space (`outdirMin` variable) requested by `Toil` specified in individual CWL stages of the workflow. I have to specifically modify the default value (512000)  of the variable `outdirMin` to 50000 (account for 50Gb) in the following CWL files check_results.cwl, data_cleaning.cwl, gp_runner.cwl, and kn_fetcher.cwl as: 
```
  - class: ResourceRequirement
    coresMin: 1
    ramMin: 2000 #the process requires at least 1G of RAM
-    outdirMin: 512000 #default cwl definition is for 5TB 
+    outdirMin: 50000 #50Gb space 
````
Depends of the free disk space available on your machine you can adjust the value. 

Then use `cwltoil` to run the workflow, as defined in `gp_workflow.cwl` and parameterized by `gp_workflow_job.yml`:
```shell
cd /home/wfrunner/knoweng_gene_prioritization
cwltoil --workDir /home/wfrunner/tmp/ gp_workflow.cwl gp_workflow_job.yml 
```
Wait for the run to finish. 

#### 5. Run workflow checker tool

To verify the workflow results before submission, use `cwltoil` to run the checker as follows:
```shell
cd /home/wfrunner/knoweng_gene_prioritization
cwltoil --workDir /home/wfrunner/tmp/ check_results.cwl check_results_job.yml 
```
Note: The default check_results parameters file `check_results_job.yml` expects the results files to be in the working directory (i.e., the current directory).  If you need to change that, you can edit the parameters file and modify the locations of the results files.
Wait for the run to finish. 

Check results:
```shell
cd /home/wfrunner/knoweng_gene_prioritization
cat results.json | grep -i overall
[OUTPUT]
{""overall"": true, ""steps"": {""ranked_genes_download.tsv"": true, ""top_genes_download.tsv"": true, ""combo_results.txt"": true, ""9606.STRING_experimental.edge"": true}}
``` 

#### 6. Submit workflow outputs

Modify the parameters in `submit_results.yml` appropriately as follows: 
```YAML
config_file:
  class: File
  location: /home/wfrunner/synapse_utils/.synapse_config
team_name:
eval_id: ""9606345""
file:
  - class: File
    location: ./ranked_genes_download.tsv
  - class: File
    location: ./top_genes_download.tsv
  - class: File
    location: ./combo_results.txt
  - class: File
    location: ./9606.STRING_experimental.edge
parent_id: syn10901338
```

Finally, submitted outputs using the submission tool `dockstore-tool-synapse-submit.cwl`:
```shell
cd /home/wfrunner/knoweng_gene_prioritization
cwltoil ~/synapse_utils/dockstore-tool-synapse-submit.cwl submit_results.yml
```

---",9637442
knoweng_gene_prioritization,9637571_report.md,"## KnowEnG Gene Prioritization Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Milt Epstein""
workflow_handle: ""knoweng_gene_prioritization""
input_handle: ""knoweng_gene_prioritization""
```

The following description is provided by the workflow author (see https://knoweng.org/pipelines/):
> You submit a spreadsheet of gene-level transcriptomic (or other omics) profiles of a collection of biological samples. Each sample is also annotated with a numeric  phenotype (e.g., drug response, patient survival, etc.) or categorical phenotype (e.g., cancer  subtype, metastatic status). This pipeline scores each gene by the correlation between its “omic” value (e.g., expression) and the phenotype, and reports the top phenotype-related genes. Gene prioritization can be done in a Knowledge Network-guided mode, and with optional use of bootstrapping to achieve robust prioritization.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""4Gb""
suggested_disk: ""4Gb""
```

#### Workflow history

* **2017-08-23**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Abraham Chavez"" # your name here
institution: ""UCSC Genomics Institute"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-26T13:30:15+00:00"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""GCC cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170413194156"" # indicate executor version used
docker_version: ""17.06.2-ce"" # from `docker --version`
environment: ""Google CC"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""4"" # indicate number of cores in environment
env_memory: ""16Gb"" # indicate available RAM in environment
env_disk: ""200Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

#### 1. Set up environment

If you have not set up your environment and install dependencies like **cwltool**, **dockstore**, **java** and so on
I recommend you follow [**this**](https://www.synapse.org/#!Synapse:syn10220609) instructions.
>**NOTE:** When configuring `docker` to run as root. You might encounter problems setting the credentials as directed in digital ocean, try replacing `su - ${USER}` with `sudo su -` and running `usermod -aG docker ${USER}` and `su - ${USER}` inside root terminal.

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir KE_GP_run1
cd KE_GP_run1
cp ~/.synapseConfig .
```

#### 2. Download required files

Use the `synapse get` command to recursively download all of the required files from the knoweng_gene_prioritization folder on synapse -- the CWL files for the workflow and to check the results, the associated parameters files (in YAML format), and the input data files:
```shell
synapse get -r syn10235824 # the knoweng_gene_prioritization folder
```

#### 3. Run main workflow

Use `cwltool` to run the workflow, as defined in `gp_workflow.cwl` and parameterized by `gp_workflow_job.yml`:
```shell
cwltool gp_workflow.cwl gp_workflow_job.yml
```

#### 4. Run workflow checker tool

To verify the workflow results before submission, use `cwltool` to run the checker as follows:
```shell
cwltool check_results.cwl check_results_job.yml
cat log.txt
cat results.json
```
Note: The default check_results parameters file `check_results_job.yml` expects the results files to be in the working directory (i.e., the current directory).  If you need to change that, you can edit the parameters file and modify the locations of the results files.

#### 5. Submit workflow outputs

Use the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools:
```shell
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
```

Modify the parameters in `submit_results.yml` appropriately; in particular, you will need to fill in the `team_name` (optional) and `parent_id` (required) fields; you may also need to modify the locations of the results files:
```YAML
config_file:
  class: File
  location: .synapseConfig
team_name:
eval_id: ""9606345""
file:
  - class: File
    location: ./ranked_genes_download.tsv
  - class: File
    location: ./top_genes_download.tsv
  - class: File
    location: ./combo_results.txt
  - class: File
    location: ./9606.STRING_experimental.edge
parent_id:
```

Finally, submit the outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl submit_results.yml
```

---",9637571
knoweng_gene_prioritization,9637639_report.md,"## KnowEnG Gene Prioritization Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Milt Epstein""
workflow_handle: ""knoweng_gene_prioritization""
input_handle: ""knoweng_gene_prioritization""
```

The following description is provided by the workflow author (see https://knoweng.org/pipelines/):
> You submit a spreadsheet of gene-level transcriptomic (or other omics) profiles of a collection of biological samples. Each sample is also annotated with a numeric  phenotype (e.g., drug response, patient survival, etc.) or categorical phenotype (e.g., cancer  subtype, metastatic status). This pipeline scores each gene by the correlation between its “omic” value (e.g., expression) and the phenotype, and reports the top phenotype-related genes. Gene prioritization can be done in a Knowledge Network-guided mode, and with optional use of bootstrapping to achieve robust prioritization.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""4Gb""
suggested_disk: ""4Gb""
```

#### Workflow history

* **2017-08-23**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Thomas B. Mooney"" # your name here
institution: ""MGI WUSTL"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-25"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170828135420"" # indicate executor version used
docker_version: ""17.06.2-ce"" # from `docker --version`
environment: ""local openstack VM"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""2"" # indicate number of cores in environment
env_memory: ""64 GB"" # indicate available RAM in environment
env_disk: ""160 GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

Spin up a new OpenStack VM with a Xenial cloud image, then install [docker](https://docs.docker.com/engine/installation/linux/docker-ce/ubuntu/) and  [pyenv](https://github.com/pyenv/pyenv-installer).
Then install the tools to obtain and run the workflows:
```shell
pyenv install 2.7.14
pyenv shell 2.7.14
pip install cwltool
pip install synapseclient
```

Create a directory to hold the results and link in the configuration for connecting to synapse:
```shell
mkdir -p ~/ga4gh/knoweng_gene_prioritization
cd ~/ga4gh/knoweng_gene_prioritization
ln -s ~/.synapseConfig .synapseConfig
```

#### 2. Download required files

Download the tools for getting/submitting workflows and the ""knoweng_gene_prioritization"" workflow data:
```shell
synapse get -r syn10235824 # knoweng_gene_prioritization
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
```

#### 3. Run main workflow

Run the workflow downloaded in the previous step.
```shell
cwltool gp_workflow.cwl gp_workflow_job.yml
```

#### 4. Run workflow checker tool

Then the checker workflow is run to verify the results:
```shell
cwltool check_results.cwl check_results_job.yml
```

This produces a report, `results.json`:
```JSON
{""overall"": true, ""steps"": {""ranked_genes_download.tsv"": true, ""top_genes_download.tsv"": true, ""combo_results.txt"": true, ""9606.STRING_experimental.edge"": true}}
```

#### 5. Submit workflow outputs

Modify `submit_results.yml` as follows:
```YAML
config_file:
  class: File
  location: .synapseConfig
team_name: ""MGI WUSTL""
eval_id: ""9606345""
file:
  - class: File
    location: ./ranked_genes_download.tsv
  - class: File
    location: ./top_genes_download.tsv
  - class: File
    location: ./combo_results.txt
  - class: File
    location: ./9606.STRING_experimental.edge
parent_id: ""syn10907585""
```

Finally, run the workflow to submit the results. The dockstore tool CWL files contain extra information, so the ""submit"" workflow must be run with the `--non-strict` option:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl submit_results.yml
```

---",9637639
knoweng_gene_prioritization,9638110_report.md,"## KnowEnG Gene Prioritization Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Milt Epstein""
workflow_handle: ""knoweng_gene_prioritization""
input_handle: ""knoweng_gene_prioritization""
```

The following description is provided by the workflow author (see https://knoweng.org/pipelines/):
> You submit a spreadsheet of gene-level transcriptomic (or other omics) profiles of a collection of biological samples. Each sample is also annotated with a numeric  phenotype (e.g., drug response, patient survival, etc.) or categorical phenotype (e.g., cancer  subtype, metastatic status). This pipeline scores each gene by the correlation between its “omic” value (e.g., expression) and the phenotype, and reports the top phenotype-related genes. Gene prioritization can be done in a Knowledge Network-guided mode, and with optional use of bootstrapping to achieve robust prioritization.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""4Gb""
suggested_disk: ""4Gb""
```

#### Workflow history

* **2017-08-23**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Thomas B. Mooney"" # your name here
institution: ""MGI WUSTL"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-28"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""toil"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""3.11.0"" # indicate executor version used
docker_version: ""17.06.2-ce"" # from `docker --version`
environment: ""local openstack VM"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""2"" # indicate number of cores in environment
env_memory: ""64 GB"" # indicate available RAM in environment
env_disk: ""160 GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

Spin up a new OpenStack VM with a Xenial cloud image, then install [docker](https://docs.docker.com/engine/installation/linux/docker-ce/ubuntu/) and  [pyenv](https://github.com/pyenv/pyenv-installer).
Then install the tools to obtain and run the workflows:
```shell
pyenv install 2.7.14
pyenv shell 2.7.14
pip install toil[cwl]
pip install synapseclient
```

Create a directory to hold the results and link in the configuration for connecting to synapse:
```shell
mkdir -p ~/ga4gh/knoweng_gene_prioritization.toil
cd ~/ga4gh/knoweng_gene_prioritization.toil
ln -s ~/.synapseConfig .synapseConfig
```

#### 2. Download required files

Download the tool for submitting workflows and the ""knoweng_gene_prioritization"" workflow data:
```shell
synapse get -r syn10235824 # knoweng_gene_prioritization
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
```

#### 3. Run main workflow

Since this environment has less available disk than the `outdirMin` specified in the CWL files, edit the resource requirements for each of `data_cleaning.cwl`, `kn_fetcher.cwl`, `gp_runner.cwl` and  `check_results.cwl` to 
```YAML
outdirMin: 512
```
Then run the workflow.
```shell
cwltoil gp_workflow.cwl gp_workflow_job.yml
```

#### 4. Run workflow checker tool

Then the checker workflow is run to verify the results:
```shell
cwltoil check_results.cwl check_results_job.yml
```

This produces a report, `results.json`:
```JSON
{""overall"": true, ""steps"": {""ranked_genes_download.tsv"": true, ""top_genes_download.tsv"": true, ""combo_results.txt"": true, ""9606.STRING_experimental.edge"": true}}
```

#### 5. Submit workflow outputs

Modify `submit_results.yml` as follows:
```YAML
config_file:
  class: File
  location: .synapseConfig
team_name: ""MGI WUSTL""
eval_id: ""9606345""
file:
  - class: File
    location: ./ranked_genes_download.tsv
  - class: File
    location: ./top_genes_download.tsv
  - class: File
    location: ./combo_results.txt
  - class: File
    location: ./9606.STRING_experimental.edge
parent_id: ""syn10921402""
```

Finally, run the workflow to submit the results:
```shell
cwltoil dockstore-tool-synapse-submit.cwl submit_results.yml
```

---",9638110
knoweng_gene_prioritization,9645964_report.md,"## KnowEnG Gene Prioritization Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Milt Epstein""
workflow_handle: ""knoweng_gene_prioritization""
input_handle: ""knoweng_gene_prioritization""
```

The following description is provided by the workflow author (see https://knoweng.org/pipelines/):
> You submit a spreadsheet of gene-level transcriptomic (or other omics) profiles of a collection of biological samples. Each sample is also annotated with a numeric  phenotype (e.g., drug response, patient survival, etc.) or categorical phenotype (e.g., cancer  subtype, metastatic status). This pipeline scores each gene by the correlation between its “omic” value (e.g., expression) and the phenotype, and reports the top phenotype-related genes. Gene prioritization can be done in a Knowledge Network-guided mode, and with optional use of bootstrapping to achieve robust prioritization.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""4Gb""
suggested_disk: ""4Gb""
```

#### Workflow history

* **2017-08-23**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Bogdan Gavrilovic"" # your name here
institution: ""Seven Bridges Genomics"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-10-17"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""rabix"" 
workflow_type: ""CWL"" 
runner_version: ""1.0.3""
docker_version: ""17.05.0-ce""
environment: ""local"" 
env_cpus: ""4""
env_memory: ""16Gb""
env_disk: ""900Gb""
```

### Steps

#####1. [Install rabix](https://github.com/rabix/bunny#installing) on your machine and set environment variable $BUNNY. You need docker and java installed to run rabix:
```shell
wget https://github.com/rabix/bunny/releases/download/v1.0.3/rabix-1.0.3.tar.gz -O rabix-1.0.3.tar.gz && tar -xvf rabix-1.0.3.tar.gz
export BUNNY=$PWD/rabix-cli-1.0.3/rabix
```
#####2. If you've not already retrieved the CWL and data with synapse-get, you can use the [Synapse python client](https://github.com/Sage-Bionetworks/synapsePythonClient#installation):
```shell
pip install synapseclient
synapse get -r syn10235824 # the knoweng_gene_prioritization folder
synapse get syn9732885   # dockstore-tool-synapse-submit.cwl
```

#####3. Run the workflow using rabix executor on your machine by typing in the terminal: $BUNNY <app> <inputs>
For example:
```shell
$BUNNY gp_workflow.cwl gp_workflow_job.yml
```

### Validating results
Modify `check_results_job.yml` to include the paths to the requested output files and run checker tool
```shell
$BUNNY check_results.cwl check_results_job.yml
```
Check results
```shell
cat ./path/to/results.json
```
```json
{
  ""overall"": true,
  ""steps"": {
    ""ranked_genes_download.tsv"": true,
    ""top_genes_download.tsv"": true,
    ""combo_results.txt"": true,
    ""9606.STRING_experimental.edge"": true
  }
}
```
### Submitting results
- Copy the synapseConfig file to the current working directory.
- Update `submit_results.yml` with correct
`team_name` - the name of your team in plain text format (e.g., ""GA4GH-Sage Contenders"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
`file` - paths to output files
Run the tool
```shell
$BUNNY dockstore-tool-synapse-submit.cwl submit_results.yml
```

---",9645964
knoweng_gene_prioritization,9646102_report.md,"## KnowEnG Gene Prioritization Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Milt Epstein""
workflow_handle: ""knoweng_gene_prioritization""
input_handle: ""knoweng_gene_prioritization""
```

The following description is provided by the workflow author (see https://knoweng.org/pipelines/):
> You submit a spreadsheet of gene-level transcriptomic (or other omics) profiles of a collection of biological samples. Each sample is also annotated with a numeric  phenotype (e.g., drug response, patient survival, etc.) or categorical phenotype (e.g., cancer  subtype, metastatic status). This pipeline scores each gene by the correlation between its “omic” value (e.g., expression) and the phenotype, and reports the top phenotype-related genes. Gene prioritization can be done in a Knowledge Network-guided mode, and with optional use of bootstrapping to achieve robust prioritization.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""4Gb""
suggested_disk: ""4Gb""
```

#### Workflow history

* **2017-08-23**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Todd Pihl"" # your name here
institution: ""ISB-CGC/CSRA Inc"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-18"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170217172322"" # indicate executor version used
docker_version: ""17.06.2-ce, build cec0b72"" # from `docker --version`
environment: ""Google Compute"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""35M"" # indicate available RAM in environment
env_disk: ""250G"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed: ""2017-08-23"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0""
docker_version_ex: ""17.06.0-ce""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""500Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

On a local machine, with docker, cwltool, and the synapse client installed, create a working directory to use for the run, and cd to that directory:
```shell
mkdir KE_GP_run1
cd KE_GP_run1
```

#### 2. Download required files

Use the `synapse get` command to recursively download all of the required files from the knoweng_gene_prioritization folder on synapse -- the CWL files for the workflow and to check the results, the associated parameters files (in YAML format), and the input data files:
```shell
synapse get -r syn10235824 # the knoweng_gene_prioritization folder
```

#### 3. Run main workflow

Use `cwltool` to run the workflow, as defined in `gp_workflow.cwl` and parameterized by `gp_workflow_job.yml`:
```shell
cwltool gp_workflow.cwl gp_workflow_job.yml
```

#### 4. Run workflow checker tool

To verify the workflow results before submission, use `cwltool` to run the checker as follows:
```shell
cwltool check_results.cwl check_results_job.yml
cat log.txt
cat results.json
```
Note: The default check_results parameters file `check_results_job.yml` expects the results files to be in the working directory (i.e., the current directory).  If you need to change that, you can edit the parameters file and modify the locations of the results files.

#### 5. Submit workflow outputs

Use the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools:
```shell
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
```

Modify the parameters in `submit_results.yml` appropriately; in particular, you will need to fill in the `team_name` (optional) and `parent_id` (required) fields; you may also need to modify the locations of the results files:
```YAML
config_file:
  class: File
  location: .synapseConfig
team_name:
eval_id: ""9606345""
file:
  - class: File
    location: ./ranked_genes_download.tsv
  - class: File
    location: ./top_genes_download.tsv
  - class: File
    location: ./combo_results.txt
  - class: File
    location: ./9606.STRING_experimental.edge
parent_id:
```

Finally, submit the outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl submit_results.yml
```

---",9646102
knoweng_gene_prioritization,9646432_report.md,"## KnowEnG Gene Prioritization Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Milt Epstein""
workflow_handle: ""knoweng_gene_prioritization""
input_handle: ""knoweng_gene_prioritization""
```

The following description is provided by the workflow author (see https://knoweng.org/pipelines/):
> You submit a spreadsheet of gene-level transcriptomic (or other omics) profiles of a collection of biological samples. Each sample is also annotated with a numeric  phenotype (e.g., drug response, patient survival, etc.) or categorical phenotype (e.g., cancer  subtype, metastatic status). This pipeline scores each gene by the correlation between its “omic” value (e.g., expression) and the phenotype, and reports the top phenotype-related genes. Gene prioritization can be done in a Knowledge Network-guided mode, and with optional use of bootstrapping to achieve robust prioritization.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""4Gb""
suggested_disk: ""4Gb""
```

#### Workflow history

* **2017-08-23**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Madelyn Reyes""
institution: ""ISB-CGC/CSRA"" 
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""09/28/2017"" 
platform: ""cwltool"" 
workflow_type: ""CWL"" 
runner_version: ""1.0.20170217172322""
docker_version: ""17.09.0-ce, build afdb6d4"" 
environment: ""Google Compute"" 
env_cpus: ""8""
env_memory: ""35GB""
env_disk: ""250 GB"" 
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed: ""2017-08-23"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0""
docker_version_ex: ""17.06.0-ce""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""500Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

On a local machine, with docker, cwltool, and the synapse client installed, create a working directory to use for the run, and cd to that directory:
```shell
mkdir KE_GP_run1
cd KE_GP_run1
```

#### 2. Download required files

Use the `synapse get` command to recursively download all of the required files from the knoweng_gene_prioritization folder on synapse -- the CWL files for the workflow and to check the results, the associated parameters files (in YAML format), and the input data files:
```shell
synapse get -r syn10235824 # the knoweng_gene_prioritization folder
```

#### 3. Run main workflow

Use `cwltool` to run the workflow, as defined in `gp_workflow.cwl` and parameterized by `gp_workflow_job.yml`:
```shell
cwltool gp_workflow.cwl gp_workflow_job.yml
```

#### 4. Run workflow checker tool

To verify the workflow results before submission, use `cwltool` to run the checker as follows:
```shell
cwltool check_results.cwl check_results_job.yml
cat log.txt
cat results.json
```
Note: The default check_results parameters file `check_results_job.yml` expects the results files to be in the working directory (i.e., the current directory).  If you need to change that, you can edit the parameters file and modify the locations of the results files.

#### 5. Submit workflow outputs

Use the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools:
```shell
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
```

Modify the parameters in `submit_results.yml` appropriately; in particular, you will need to fill in the `team_name` (optional) and `parent_id` (required) fields; you may also need to modify the locations of the results files:
```YAML
config_file:
  class: File
  location: .synapseConfig
team_name:
eval_id: ""9606345""
file:
  - class: File
    location: ./ranked_genes_download.tsv
  - class: File
    location: ./top_genes_download.tsv
  - class: File
    location: ./combo_results.txt
  - class: File
    location: ./9606.STRING_experimental.edge
parent_id:
```

Finally, submit the outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl submit_results.yml
```

---",9646432
knoweng_gene_prioritization,9647060_report.md,"## KnowEnG Gene Prioritization Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Milt Epstein""
workflow_handle: ""knoweng_gene_prioritization""
input_handle: ""knoweng_gene_prioritization""
```

The following description is provided by the workflow author (see https://knoweng.org/pipelines/):
> You submit a spreadsheet of gene-level transcriptomic (or other omics) profiles of a collection of biological samples. Each sample is also annotated with a numeric  phenotype (e.g., drug response, patient survival, etc.) or categorical phenotype (e.g., cancer  subtype, metastatic status). This pipeline scores each gene by the correlation between its “omic” value (e.g., expression) and the phenotype, and reports the top phenotype-related genes. Gene prioritization can be done in a Knowledge Network-guided mode, and with optional use of bootstrapping to achieve robust prioritization.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""4Gb""
suggested_disk: ""4Gb""
```

#### Workflow history

* **2017-08-23**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Joe Slagel"" # your name here
institution: ""Institute for Systems Biology"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""9/28/2017"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170822192924"" # indicate executor version used
docker_version: ""1.12.6, build 78d1802"" # from `docker --version`
environment: ""Google Compute"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""32"" # indicate number of cores in environment
env_memory: ""30 GB"" # indicate available RAM in environment
env_disk: ""250 GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed: ""2017-08-23"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0""
docker_version_ex: ""17.06.0-ce""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""500Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

Installed pip, synapse client, and docker.

#### 2. Followed workflow instructions

Simply entered the same commands as in the workflow instructions.

---",9647060
knoweng_gene_prioritization,9652156_report.md,"## KnowEnG Gene Prioritization Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Milt Epstein""
workflow_handle: ""knoweng_gene_prioritization""
input_handle: ""knoweng_gene_prioritization""
```

The following description is provided by the workflow author (see https://knoweng.org/pipelines/):
> You submit a spreadsheet of gene-level transcriptomic (or other omics) profiles of a collection of biological samples. Each sample is also annotated with a numeric  phenotype (e.g., drug response, patient survival, etc.) or categorical phenotype (e.g., cancer  subtype, metastatic status). This pipeline scores each gene by the correlation between its “omic” value (e.g., expression) and the phenotype, and reports the top phenotype-related genes. Gene prioritization can be done in a Knowledge Network-guided mode, and with optional use of bootstrapping to achieve robust prioritization.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""4Gb""
suggested_disk: ""4Gb""
```

#### Workflow history

* **2017-08-23**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Bogdan Gavrilovic"" # your name here
institution: ""Seven Bridges Genomics"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.


```YAML
date_accessed: ""2017-10-17"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""SevenBridges"" 
workflow_type: ""CWL"" 
runner_version: ""latest""
docker_version: ""1.12.6""
environment: ""EC2""  # c4.2xlarge instance
env_cpus: ""8""
env_memory: ""15Gb""
env_disk: ""700Gb""
```

### Steps

#####1. [Install rabix](https://github.com/rabix/bunny#installing) on your machine and set environment variable $BUNNY. You need docker and java installed to run rabix:
```shell
wget https://github.com/rabix/bunny/releases/download/v1.0.1/rabix-1.0.1.tar.gz -O rabix-1.0.1.tar.gz && tar -xvf rabix-1.0.1.tar.gz
export BUNNY=$PWD/rabix-cli-1.0.1/rabix
```
#####2. If you've not already retrieved the CWL and data with synapse-get, you can use the [Synapse python client](https://github.com/Sage-Bionetworks/synapsePythonClient#installation):
```shell
pip install synapseclient
synapse get -r syn10235824 # the knoweng_gene_prioritization folder
synapse get syn9732885   # dockstore-tool-synapse-submit.cwl
```

#### Running on the [Cancer Genomics Cloud](https://cgc.sbgenomics.com/) 

#####3. Log in to the [Cancer Genomics Cloud](https://cgc.sbgenomics.com/) and [create a project](https://docs.cancergenomicscloud.org/docs/create-a-project) 
- Academic Users can create a free account on the Cancer Genomics Cloud (CGC). New users receive \$300 in cloud computing credits that you can apply to this challenge, and your own research. Additionally, users that leave feedback on their experience receive an additional \$1000 in cloud compute credits.
- Commercial users of the Seven Bridges Platform that wish to participate in the DREAM challenge can also create an account on the CGC to participate in this academic exercise and receive free credits to run the challenge workflows. Alternatively, commercial users are free to run DREAM challenge workflows in their commercial platform accounts, but should realize that they will incur cloud compute charges to do so. 
&nbsp;
#####4. Installing the workflow on the platform can be done using:  
**a)** [Rabix Composer app for CWL tool editing](http://rabix.io/) or   
**b)** a [CWL CommandLineTool](https://github.com/bogdang989/Import-CWL-to-SevenBridges) for importing CWL workflows to the Seven Bridges platform.  

#####4a. Rabix Composer
If you’re interested in trying out Seven Bridges’ new integrated development environment for creating CWL descriptions of tools and workflows, you can use the [Rabix Composer](http://rabix.io/) to upload the workflow to the platform. 
Use Rabix Composer to add the workflow to the platform:  
- [Install Rabix Composer](http://docs.rabix.io/rabix-composer-installation)
- [Configure Composer](http://docs.rabix.io/rabix-composer-configuration) to connect to the CGC or Seven Bridges platform
- [Add the project](http://docs.rabix.io/rabix-composer-configuration) you created for the DREAM challenge to the workspace
- [Add the local directory](http://docs.rabix.io/rabix-composer-configuration) containing the workflow to the workspace
- [Open](http://docs.rabix.io/rabix-composer-basics) the workflow with Composer
- [Save the workflow to the Platform project](http://docs.rabix.io/rabix-composer-basics) you added to the workspace
- Log into the Platform and [upload the input files](https://docs.cancergenomicscloud.org/docs/upload-to-the-cgc) to the project. 
- Run the task

> You can [upload the files manually to the platform](https://docs.cancergenomicscloud.org/docs/upload-to-the-cgc) by using either CGC Uploader app, command-line uploader, Python API or some other available upload method... All of the available methods are described in [the documentation](https://docs.cancergenomicscloud.org/docs/upload-to-the-cgc) 

#####4b. CWLtoSBG import tool
Download the CWL importing tool and **place it in the same directory with the CWL workflow** that should be installed on the platform. You can download the tool from [github](https://github.com/bogdang989/Import-CWL-to-SevenBridges) manually or from command-line by typing:
```shell
git clone https://github.com/bogdang989/Import-CWL-to-SevenBridges
```
Modify the `cwl_to_sbg-inputs.yaml` to include:

- Paths to `gp_workflow.cwl` and `gp_workflow_job.yml`
- Id of your project on the platform (From project URL, in format *user-name/project-name* )
For example if project URL is https://cgc.sbgenomics.com/u/bogdang/demo-project; project_id is `bogdang/demo-project`
- Your [authentication token](http://docs.sevenbridges.com/docs/get-your-authentication-token)
- Adequate [EC2 instance type](http://www.ec2instances.info/)
&nbsp;
After modifying `cwl_to_sbg-inputs.yaml` with your information, import the workflow to the platform by running
```shell
$BUNNY cwl_to_sbg.cwl cwl_to_sbg-inputs.yaml
```
This will install the workflow and all required apps on the platform. All the files that are required for the task execution are uploaded if they are not uploaded previously. Template draft task is created. If `run_task` is set to `true` the task execution will start on the platform.
You can now open `task` page on the platform project to see task execution details.

Completed task should look something like this:${image?synapseId=syn11414027&align=None&scale=100&responsive=true}

### Validating results
[Download the output files](https://docs.cancergenomicscloud.org/docs/download-results) to your local machine.

Modify `check_results_job.yml` to include the paths to the requested output files and run checker tool
```shell
$BUNNY check_results.cwl check_results_job.yml
```
Check results
```shell
cat ./path/to/results.json
```json
{
  ""overall"": true,
  ""steps"": {
    ""ranked_genes_download.tsv"": true,
    ""top_genes_download.tsv"": true,
    ""combo_results.txt"": true,
    ""9606.STRING_experimental.edge"": true
  }
}
```

### Submitting results
- Copy the synapseConfig file to the current working directory.
- Update `submit_results.yml` with correct
`team_name` - the name of your team in plain text format (e.g., ""GA4GH-Sage Contenders"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
`file` - paths to output files
Run the tool
```shell
$BUNNY dockstore-tool-synapse-submit.cwl submit_results.yml
```

---",9652156
knoweng_gene_prioritization,9653536_report.md,"## KnowEnG Gene Prioritization Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Milt Epstein""
workflow_handle: ""knoweng_gene_prioritization""
input_handle: ""knoweng_gene_prioritization""
```

The following description is provided by the workflow author (see https://knoweng.org/pipelines/):
> You submit a spreadsheet of gene-level transcriptomic (or other omics) profiles of a collection of biological samples. Each sample is also annotated with a numeric  phenotype (e.g., drug response, patient survival, etc.) or categorical phenotype (e.g., cancer  subtype, metastatic status). This pipeline scores each gene by the correlation between its “omic” value (e.g., expression) and the phenotype, and reports the top phenotype-related genes. Gene prioritization can be done in a Knowledge Network-guided mode, and with optional use of bootstrapping to achieve robust prioritization.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""4Gb""
suggested_disk: ""4Gb""
```

#### Workflow history

* **2017-08-23**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Karl Sebby"" # your name here
institution: ""xD Bio"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-11-15"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""cwl"" # CWL or WDL
runner_version: ""cwltool==1.0.20171107133715"" # indicate executor version used
docker_version: ""17.09.0-ce, build afdb6d4"" # from `docker --version`
environment: ""Google Compute"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""54Gb"" # indicate available RAM in environment
env_disk: ""50Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed: ""2017-08-23"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0""
docker_version_ex: ""17.06.0-ce""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""500Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary. 
**Ran everything as root to make docker happy and not have to keep changing permissions.**

```shell
sudo bash
```

#### 1. Set up environment
ssh  to google compute engine instance from local machine (linux mint with cinnamon desktop running in virtual box on Macbook pro.)
```shell
screen
ssh `external_ip`
```

On google instance, install docker, pip3, cwltool (with pip3).
Set up directory structure from ~:
```shell
mkdir -p projects/dreamChallenge/knoweng_gene-prioritization
cd projects/dreamChallenge
```
Create .synapseConfig file and paste in text from synapse website. Change username and password.
```shell 
vi .synapseConfig
```

#### 2. Download required files

Steps completed in the projects/dreamChallenge directory unless specified otherwise.

Use curl to get the dockstore-tool-synapse-get.cwl and dockstore-tool-synapse-submit.cwl:
```shell
curl https://raw.githubusercontent.com/GA4GH-DREAM/dockstore-tool-synapse-get/master/Dockstore.cwl > dockstore-tool-synapse-get.cwl
curl https://raw.githubusercontent.com/GA4GH-DREAM/dockstore-tool-synapse-submit/master/Dockstore.cwl > dockstore-tool-synapse-submit.cwl
```
Downloaded the knoweng_gene_prioritization_get.cwl.json file to my local machine from synapse website: https://www.synapse.org/Portal/filehandleassociation?associatedObjectId=10611751&associatedObjectType=FileEntity&fileHandleId=17825614. Opened the file in TextEdit and copied contents. In google compute shell create the knoweng_gene_prioritization_get.cwl.json file and paste the contents and save:
```shell
vi knoweng_gene_prioritization_get.cwl.json
```

Get the files:
```shell
cd knoweng_gene-prioritization
cwltool ../dockstore-tool-synapse-get.cwl ../knoweng_gene_prioritization_get.cwl.json
```
#### 3. Run main workflow

Use `cwltool` to run the workflow with timer, as defined in `gp_workflow.cwl` and parameterized by `gp_workflow_job.yml`:
```shell
time cwltool gp_workflow.cwl gp_workflow_job.yml
```
took 6m23s

#### 4. Run workflow checker tool

To verify the workflow results before submission, use `cwltool` to run the checker as follows:
```shell
cwltool check_results.cwl check_results_job.yml
cat results.json
```
Note: The default check_results parameters file `check_results_job.yml` expects the results files to be in the working directory (i.e., the current directory).  If you need to change that, you can edit the parameters file and modify the locations of the results files.

#### 5. Submit workflow outputs

Modify the parameters in `submit_results.yml` appropriately: `parent_id` and config_file path (to parent directory):
```YAML
config_file:
  class: File
  location: ../.synapseConfig
team_name:
eval_id: ""9606345""
file:
  - class: File
    location: ./ranked_genes_download.tsv
  - class: File
    location: ./top_genes_download.tsv
  - class: File
    location: ./combo_results.txt
  - class: File
    location: ./9606.STRING_experimental.edge
parent_id: ""syn114****""
```

Finally, submit the outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool ../dockstore-tool-synapse-submit.cwl submit_results.yml
```

---",9653536
knoweng_gene_prioritization,9655740_report.md,"## KnowEnG Gene Prioritization Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Milt Epstein""
workflow_handle: ""knoweng_gene_prioritization""
input_handle: ""knoweng_gene_prioritization""
```

The following description is provided by the workflow author (see https://knoweng.org/pipelines/):
> You submit a spreadsheet of gene-level transcriptomic (or other omics) profiles of a collection of biological samples. Each sample is also annotated with a numeric  phenotype (e.g., drug response, patient survival, etc.) or categorical phenotype (e.g., cancer  subtype, metastatic status). This pipeline scores each gene by the correlation between its “omic” value (e.g., expression) and the phenotype, and reports the top phenotype-related genes. Gene prioritization can be done in a Knowledge Network-guided mode, and with optional use of bootstrapping to achieve robust prioritization.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""4Gb""
suggested_disk: ""4Gb""
```

#### Workflow history

* **2017-08-23**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Joe Slagel"" # your name here
institution: ""ISB"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-11-28"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""ISB-CGC dsub/cwltool/cwl_runner.sh"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""cwltool-1.0.20171107133715"" # indicate executor version used
docker_version: ""17.11.0"" # from `docker --version`
environment: ""Google Compute"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""4"" # indicate number of cores in environment
env_memory: ""15"" # indicate available RAM in environment
env_disk: ""200"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

I was curious as to how much of the challenge I could do using only dsub and cwl_runner.sh.  On a personal Google Cloud VM with gcloud, gsutil, dsub and cwl_runner.sh installed I:

#### 1. Set up environment

```shell
gsutil cp ~/.synapseConfig gs://isb-ga4gh-dream/knoweng_gene_prioritization/data/.synapseConfig
dsub \
   --name dream-setup-knoweng_gene_prioritization \
   --project cgc-05-0026 \
   --zones 'us-*' \
   --image quay.io/ga4gh-dream/dockstore-tool-synapse-get \
   --input  'CFG=gs://isb-ga4gh-dream/knoweng_gene_prioritization/data/.synapseConfig' \
   --output-recursive 'OUT=gs://isb-ga4gh-dream/knoweng_gene_prioritization/data/' \
   --logging 'gs://isb-ga4gh-dream/knoweng_gene_prioritization/log' \
   --wait \
   --command 'cd ${OUT}; \
              synapse -c ${CFG} get syn9770802; \
              synapse -c ${CFG} get syn9732885; \
              synapse -c ${CFG} get -r syn10235824; \
             '
```

#### 2. Download required files

nothing to do

#### 3. Run main workflow

```shell
./cwl_runner.sh \
   -m n1-standard-4 \
   -r gs://isb-ga4gh-dream/knoweng_gene_prioritization/data/ \
   -w gs://isb-ga4gh-dream/knoweng_gene_prioritization/data/gp_workflow.cwl \
   -s gs://isb-ga4gh-dream/knoweng_gene_prioritization/data/gp_workflow_job.yml \
   -o gs://isb-ga4gh-dream/knoweng_gene_prioritization/data
```

#### 4. Run workflow checker tool

```shell
./cwl_runner.sh \
   -m n1-standard-2 \
   -r gs://isb-ga4gh-dream/knoweng_gene_prioritization/data/ \
   -w gs://isb-ga4gh-dream/knoweng_gene_prioritization/data/check_results.cwl \
   -s gs://isb-ga4gh-dream/knoweng_gene_prioritization/data/check_results_job.yml \
   -o gs://isb-ga4gh-dream/knoweng_gene_prioritization/data
```

#### 5. Submit workflow outputs

```shell
gsutil cat gs://isb-ga4gh-dream/knoweng_gene_prioritization/data/submit_results.yml \
   | sed /team_name/s/\"".*\""/\""ISB-CGC\""/\;/parent_id/s/\"".*\""/\""syn11413174\""/ \
   | gsutil cp - gs://isb-ga4gh-dream/knoweng_gene_prioritization/data/submit_results.yml
./cwl_runner.sh \
   -m n1-standard-2 \
   -r gs://isb-ga4gh-dream/knoweng_gene_prioritization/data/ \
   -w gs://isb-ga4gh-dream/knoweng_gene_prioritization/data/dockstore-tool-synapse-submit.cwl \
   -s gs://isb-ga4gh-dream/knoweng_gene_prioritization/data/submit_results.yml \
   -o gs://isb-ga4gh-dream/knoweng_gene_prioritization/data
```
---",9655740
knoweng_gene_prioritization,9656008_report.md,"## KnowEnG Gene Prioritization Workflow

Arvados container record https://cloud.curoverse.com/container_requests/qr1hi-xvhdp-yku5l0lbe95e4nb

### Workflow description

```YAML
contributor: ""Milt Epstein""
workflow_handle: ""knoweng_gene_prioritization""
input_handle: ""knoweng_gene_prioritization""
```

The following description is provided by the workflow author (see https://knoweng.org/pipelines/):
> You submit a spreadsheet of gene-level transcriptomic (or other omics) profiles of a collection of biological samples. Each sample is also annotated with a numeric  phenotype (e.g., drug response, patient survival, etc.) or categorical phenotype (e.g., cancer  subtype, metastatic status). This pipeline scores each gene by the correlation between its “omic” value (e.g., expression) and the phenotype, and reports the top phenotype-related genes. Gene prioritization can be done in a Knowledge Network-guided mode, and with optional use of bootstrapping to achieve robust prioritization.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""4Gb""
suggested_disk: ""4Gb""
```

#### Workflow history

* **2017-08-23**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Peter Amstutz"" # your name here
institution: ""Veritas Genetics"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-13"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""Arvados"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""arvados-cwl-runner 0d06a2984420d9d48e16ccb6d85982b3dce05644 1.0.20171127193714, arvados-python-client 0.1.20171010180436, cwltool 1.0.20171205195520"" # indicate executor version used
docker_version: ""Docker version 17.05.0-ce, build 89658be"" # from `docker --version`
environment: ""Azure"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""1"" # indicate number of cores in environment
env_memory: ""3.5 GB"" # indicate available RAM in environment
env_disk: ""50 GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed: ""2017-08-23"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0""
docker_version_ex: ""17.06.0-ce""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""500Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

On a local machine, with docker, cwltool, and the synapse client installed, create a working directory to use for the run, and cd to that directory:
```shell
mkdir KE_GP_run1
cd KE_GP_run1
```

#### 2. Download required files

Use the `synapse get` command to recursively download all of the required files from the knoweng_gene_prioritization folder on synapse -- the CWL files for the workflow and to check the results, the associated parameters files (in YAML format), and the input data files:
```shell
synapse get -r syn10235824 # the knoweng_gene_prioritization folder
```

#### 3. Run main workflow

Use `cwltool` to run the workflow, as defined in `gp_workflow.cwl` and parameterized by `gp_workflow_job.yml`:
```shell
arvados-cwl-runner --api=containers gp_workflow.cwl gp_workflow_job.yml
```

#### 4. Run workflow checker tool

To verify the workflow results before submission, use `cwltool` to run the checker as follows:
```shell
cwltool check_results.cwl check_results_job.yml
cat log.txt
cat results.json
```
Note: The default check_results parameters file `check_results_job.yml` expects the results files to be in the working directory (i.e., the current directory).  If you need to change that, you can edit the parameters file and modify the locations of the results files.

#### 5. Submit workflow outputs

Use the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools:
```shell
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
```

Modify the parameters in `submit_results.yml` appropriately; in particular, you will need to fill in the `team_name` (optional) and `parent_id` (required) fields; you may also need to modify the locations of the results files:
```YAML
config_file:
  class: File
  location: .synapseConfig
team_name: Arvados Project
eval_id: ""9606345""
  - class: File
    location: keep/by_id/e7ad41de39b38792a0e9473cbe54c925+1052/ranked_genes_download.tsv
  - class: File
    location: keep/by_id/e7ad41de39b38792a0e9473cbe54c925+1052/top_genes_download.tsv
  - class: File
    location: keep/by_id/e7ad41de39b38792a0e9473cbe54c925+1052/combo_results.txt
  - class: File
    location: keep/by_id/e7ad41de39b38792a0e9473cbe54c925+1052/9606.STRING_experimental.edge
parent_id: ""syn11579827""

```

Finally, submit the outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl submit_results.yml
```

---",9656008
knoweng_gene_prioritization,9657150_report.md,"## KnowEnG Gene Prioritization Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Milt Epstein""
workflow_handle: ""knoweng_gene_prioritization""
input_handle: ""knoweng_gene_prioritization""
```

The following description is provided by the workflow author (see https://knoweng.org/pipelines/):
> You submit a spreadsheet of gene-level transcriptomic (or other omics) profiles of a collection of biological samples. Each sample is also annotated with a numeric  phenotype (e.g., drug response, patient survival, etc.) or categorical phenotype (e.g., cancer  subtype, metastatic status). This pipeline scores each gene by the correlation between its “omic” value (e.g., expression) and the phenotype, and reports the top phenotype-related genes. Gene prioritization can be done in a Knowledge Network-guided mode, and with optional use of bootstrapping to achieve robust prioritization.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""4Gb""
suggested_disk: ""4Gb""
```

#### Workflow history

* **2017-08-23**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Vipin T. Sreedharan"" # your name here
institution: ""ETH Zürich, NEXUS Personalized Health Technologies"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-12-14"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""Rabix"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""rabix-cli-1.0.1"" # indicate executor version used
docker_version: ""1.12.6, build c4618fb"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""32Gb"" # indicate available RAM in environment
env_disk: ""100Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```


### Steps
-----------------------------

#### 1. Set up environment

At our institute, on a compute machine called `wfexec` with Red Hat Enterprise Linux Server release 7.4 (Maipo), installed Docker. Created a group named ""docker"" since it was preferred to use Docker as a non-root user on this machine. The instance has a non-root user called `wfrunner`. Next added the non-root user `wfrunner` to the ""docker"" group. Then started the docker engine and all the below commands were executed using root user privileges [sudo]:
```shell
yum install docker
groupadd docker 
usermod -aG docker wfrunner  
systemctl start docker 
# required for Rabix
yum install java-1.8.0-openjdk-devel.x86_64 
```

As a non-root user `wfrunner` on `wfexec` machine, installed Anaconda and Rabix to the home path:
```shell
su - wfrunner
wget https://repo.continuum.io/archive/Anaconda2-4.4.0-Linux-x86_64.sh
bash Anaconda2-4.4.0-Linux-x86_64.sh 
conda install virtualenv
virtualenv -p python2 /home/wfrunner/venv
source /home/wfrunner/venv/bin/activate
pip install cwltools
deactivate
conda install -c bioconda synapseclient
wget https://github.com/rabix/bunny/releases/download/v1.0.1/rabix-1.0.1.tar.gz -O rabix-1.0.1.tar.gz
tar -xzf rabix-1.0.1.tar.gz
export PATH=$PATH:/home/wfrunner/rabix-cli-1.0.1/
```

By installing the `synapseclient` we can provision some basic files that can help us provision the rest of our workflow, and the submit file that will put the workflow results back on synapse.
Created a utilities directory for storing the `synapse-get` and `synapse-submit` CWL tools. In the same folder, created Synapse credential file `.synapse_config` and put there Synapse ID and password. 

```shell
mkdir -p /home/wfrunner/synapse_utils
cd /home/wfrunner/synapse_utils
touch .synapse_config
vim .synapse_config
[WRITE]
[authentication]
username: user@usermail.org
password: <user-password>

synapse -c .synapse_config get syn9770802   # dockstore-tool-synapse-get.cwl
synapse -c .synapse_config get syn9732885   # dockstore-tool-synapse-submit.cwl
```

#### 2. Download required files

Downloaded data config file `knoweng_gene_prioritization_get.cwl.json` for the **knoweng_gene_prioritization** workflow. Created a directory for storing the workflow associated data downloading JSON parameter file:

```shell
mkdir -p /home/wfrunner/data_config_files
cd /home/wfrunner/data_config_files
synapse -c ~/synapse_utils/.synapse_config get syn10235824 # knoweng_gene_prioritization
```

#### 3. Download workflow input data

Since we already have the file with the information about the files to run our workflow, by running the following command, we can provisioned in our machine. Created a working directory for the current workflow.

```shell
mkdir -p /home/wfrunner/knoweng_gene_prioritization
cd /home/wfrunner/knoweng_gene_prioritization
```

Used `rabix` to run `dockstore-tool-synapse-get.cwl` with parameters in `knoweng_gene_prioritization_get.cwl.json` to download workflow input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.

```shell
rabix-cli-1.0.1/rabix --tmpdir-prefix ~/tmp/ --tmp-outdir-prefix ~/tmp/ ~/synapse_utils/dockstore-tool-synapse-get.cwl ~/config_files/knoweng_gene_prioritization_get.cwl.json
```
Wait until downloading is finished. Some reason the downloaded files were present in the subfolder `~/data_config_files` path. 

```shell
cd /home/wfrunner/knoweng_gene_prioritization
mv  ~/data_config_files/dockstore-tool-synapse-get-2017-12-14-213015.158/root/synapse_files/* . 
```

#### 4. Run main workflow

Use `rabix` to run the workflow, as defined in `gp_workflow.cwl` and parameterized by `gp_workflow_job.yml`:
```shell
cd /home/wfrunner/knoweng_gene_prioritization
~/rabix-cli-1.0.1/rabix --tmpdir-prefix ~/tmp/ --tmp-outdir-prefix ~/tmp/  gp_workflow.cwl gp_workflow_job.yml
```
Wait for the run to finish.


#### 5. Run workflow checker tool

To verify the workflow results before submission, use `rabix` to run the checker as follows:
Before running the Checker Tool, update the file location parameters with `gp_workflow-2017-12-14-213433.301/root/gp_runner/` in file `check_results_job.yml`. 

```shell
cd /home/wfrunner/knoweng_gene_prioritization
cp gp_workflow-2017-12-14-213433.301/root/kn_fetcher/9606.STRING_experimental.* gp_workflow-2017-12-14-213433.301/root/gp_runner/
~/rabix-cli-1.0.1/rabix --tmpdir-prefix ~/tmp/ --tmp-outdir-prefix ~/tmp/  check_results.cwl check_results_job.yml
```
This should take just a few minutes. Check results: 

```shell 
cd /home/wfrunner/knoweng_gene_prioritization
cat  check_results-2017-12-14-214426.749/root/results.json
[STDOUT]
{""overall"": true, ""steps"": {""ranked_genes_download.tsv"": true, ""top_genes_download.tsv"": true, ""combo_results.txt"": true, ""9606.STRING_experimental.edge"": true}}
```

#### 6. Submit workflow outputs

Modify the parameters in `submit_results.yml` appropriately; in particular, you will need to fill in the `team_name` (optional) and `parent_id` (required) fields; you may also need to modify the locations of the results files:
```YAML
config_file:
  class: File
  location: /home/wfrunner/synapse_utils/.synapse_config
team_name: ""ETH Zurich NEXUS Workflow Handler""
eval_id: ""9606345""
file:
  - class: File
    location: ./gp_workflow-2017-12-14-213433.301/root/gp_runner/ranked_genes_download.tsv
  - class: File
    location: ./gp_workflow-2017-12-14-213433.301/root/gp_runner/top_genes_download.tsv
  - class: File
    location: ./gp_workflow-2017-12-14-213433.301/root/gp_runner/combo_results.txt
  - class: File
    location: ./gp_workflow-2017-12-14-213433.301/root/gp_runner/9606.STRING_experimental.edge
parent_id: ""syn11612525""
```

Finally, submit the outputs using `rabix` and `dockstore-tool-synapse-submit.cwl`:
```shell
cd /home/wfrunner/knoweng_gene_prioritization
~/rabix-cli-1.0.1/rabix --tmpdir-prefix ~/tmp/ --tmp-outdir-prefix ~/tmp/ ~/synapse_utils/dockstore-tool-synapse-submit.cwl submit_results.yml
```

---",9657150
knoweng_gene_prioritization,9657284_report.md,"## KnowEnG Gene Prioritization Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Milt Epstein""
workflow_handle: ""knoweng_gene_prioritization""
input_handle: ""knoweng_gene_prioritization""
```

The following description is provided by the workflow author (see https://knoweng.org/pipelines/):
> You submit a spreadsheet of gene-level transcriptomic (or other omics) profiles of a collection of biological samples. Each sample is also annotated with a numeric  phenotype (e.g., drug response, patient survival, etc.) or categorical phenotype (e.g., cancer  subtype, metastatic status). This pipeline scores each gene by the correlation between its “omic” value (e.g., expression) and the phenotype, and reports the top phenotype-related genes. Gene prioritization can be done in a Knowledge Network-guided mode, and with optional use of bootstrapping to achieve robust prioritization.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""4Gb""
suggested_disk: ""4Gb""
```

#### Workflow history

* **2017-08-23**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Abhishek Niroula"" # your name here
institution: ""LU"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-12-19"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170828135420"" # indicate executor version used
docker_version: ""17.06.1-ce, build 874a737"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""32Gb"" # indicate available RAM in environment
env_disk: ""2TB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed: ""2017-08-23"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0""
docker_version_ex: ""17.06.0-ce""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""500Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

On a local machine, with docker, cwltool, and the synapse client installed, create a working directory to use for the run, and cd to that directory:
```shell
mkdir KE_GP_run1
cd KE_GP_run1
```

#### 2. Download required files

Use the `synapse get` command to recursively download all of the required files from the knoweng_gene_prioritization folder on synapse -- the CWL files for the workflow and to check the results, the associated parameters files (in YAML format), and the input data files:
```shell
synapse get -r syn10235824 # the knoweng_gene_prioritization folder
```

#### 3. Run main workflow

Use `cwltool` to run the workflow, as defined in `gp_workflow.cwl` and parameterized by `gp_workflow_job.yml`:
```shell
cwltool gp_workflow.cwl gp_workflow_job.yml
```

#### 4. Run workflow checker tool

To verify the workflow results before submission, use `cwltool` to run the checker as follows:
```shell
cwltool check_results.cwl check_results_job.yml
cat log.txt
cat results.json
```
Note: The default check_results parameters file `check_results_job.yml` expects the results files to be in the working directory (i.e., the current directory).  If you need to change that, you can edit the parameters file and modify the locations of the results files.

#### 5. Submit workflow outputs

Use the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools:
```shell
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
```

Modify the parameters in `submit_results.yml` appropriately; in particular, you will need to fill in the `team_name` (optional) and `parent_id` (required) fields; you may also need to modify the locations of the results files:
```YAML
config_file:
  class: File
  location: .synapseConfig
team_name:
eval_id: ""9606345""
file:
  - class: File
    location: ./ranked_genes_download.tsv
  - class: File
    location: ./top_genes_download.tsv
  - class: File
    location: ./combo_results.txt
  - class: File
    location: ./9606.STRING_experimental.edge
parent_id:
```

Finally, submit the outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl submit_results.yml
```

---",9657284
knoweng_gene_prioritization,9657298_report.md,"## KnowEnG Gene Prioritization Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Milt Epstein""
workflow_handle: ""knoweng_gene_prioritization""
input_handle: ""knoweng_gene_prioritization""
```

The following description is provided by the workflow author (see https://knoweng.org/pipelines/):
> You submit a spreadsheet of gene-level transcriptomic (or other omics) profiles of a collection of biological samples. Each sample is also annotated with a numeric  phenotype (e.g., drug response, patient survival, etc.) or categorical phenotype (e.g., cancer  subtype, metastatic status). This pipeline scores each gene by the correlation between its “omic” value (e.g., expression) and the phenotype, and reports the top phenotype-related genes. Gene prioritization can be done in a Knowledge Network-guided mode, and with optional use of bootstrapping to achieve robust prioritization.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""4Gb""
suggested_disk: ""4Gb""
```

#### Workflow history

* **2017-08-23**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Michael Kotliar""
institution: ""CCHMC, Barski Lab""
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-12-19""
platform: ""CWL-Airflow""
workflow_type: ""CWL""
runner_version: ""0.0.1""
docker_version: ""1.12.6""
environment: ""local""
env_cpus: ""64""
env_memory: ""251Gb""
env_disk: ""230Gb""
```

### Steps

### Setting up environment
Install CWL-Airflow
```
  cd /home/michael_kotliar/workspaces/airflow/
  git clone https://github.com/Barski-lab/cwl-airflow.git
  cd cwl-airflow
  git fetch --tags
  git checkout v0.0.1
  pip install -e .
```
Update Airflow configuration file `/home/michael_kotliar/airflow/airflow.cfg`
```
  executor = SequentialExecutor
```
Install synapse client
```
  pip install synapseclient
```
Create empty folder for workflow running
```
  cd /home/michael_kotliar/temp/cwl_airflow/
  mkdir knoweng_gene_prioritization
```
Create Synapse credentials file `/home/michael_kotliar/temp/cwl_airflow/knoweng_gene_prioritization/.synapseConfig`, put there Synapse ID and password
```
[authentication]
username: user@usermail.org
password: <user-password>
```
### Downloading required files
Download the tool to submit workflow results
```
cd /home/michael_kotliar/temp/cwl_airflow/knoweng_gene_prioritization
synapse -c .synapseConfig get syn9732885   # dockstore-tool-synapse-submit.cwl
```
Download workflow input data
```
cd /home/michael_kotliar/temp/cwl_airflow/knoweng_gene_prioritization
synapse -c .synapseConfig get -r syn10235824
```
Wait until downloading is finished

### Running workflow
```
cwl-airflow-runner --debug gp_workflow.cwl gp_workflow_job.yml
```
### Validating results
Run checker tool
```
cd /home/michael_kotliar/temp/cwl_airflow/knoweng_gene_prioritization
cwltool --debug --non-strict check_results.cwl check_results_job.yml
```
Check results
```
cat results.json
``` 
```json
{
   ""overall"": true,
   ""steps"": {
      ""ranked_genes_download.tsv"": true,
      ""top_genes_download.tsv"": true,
      ""combo_results.txt"": true,
      ""9606.STRING_experimental.edge"": true
    }
}
```
### Submitting results
Update `submit_results.yml` with correct
`team_name` - the name of your team in plain text format (e.g., ""GA4GH-Sage Contenders"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
Run the tool
```
cwltool --debug --non-strict dockstore-tool-synapse-submit.cwl submit_results.yml
```
***Running time:*** 16 min  
***Disk usage:*** 807M",9657298
knoweng_gene_prioritization,9657792_report.md,"## KnowEnG Gene Prioritization Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Milt Epstein""
workflow_handle: ""knoweng_gene_prioritization""
input_handle: ""knoweng_gene_prioritization""
```

The following description is provided by the workflow author (see https://knoweng.org/pipelines/):
> You submit a spreadsheet of gene-level transcriptomic (or other omics) profiles of a collection of biological samples. Each sample is also annotated with a numeric  phenotype (e.g., drug response, patient survival, etc.) or categorical phenotype (e.g., cancer  subtype, metastatic status). This pipeline scores each gene by the correlation between its “omic” value (e.g., expression) and the phenotype, and reports the top phenotype-related genes. Gene prioritization can be done in a Knowledge Network-guided mode, and with optional use of bootstrapping to achieve robust prioritization.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""4Gb""
suggested_disk: ""4Gb""
```

#### Workflow history

* **2017-08-23**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Nihar Sheth"" # your name here
institution: ""DNAnexus Inc."" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

```YAML
date_accessed: ""2017-12-18"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""DNAnexus-CWL"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""alpha"" # indicate executor version used
docker_version: ""dx-docker"" # from `docker --version`
environment: ""DNAnexus"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""autoscale"" # indicate number of cores in environment
env_memory: ""autoscale"" # indicate available RAM in environment
env_disk: ""autoscale"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

On a Linux desktop with dx-toolkit and Docker installed, log into a DNAnexus project.
Also, set environment variables for your project and authentication token.
```
dx env
```
will give you your project ID.  We will assume it's accessible via `$PROJECT`.

You can generate a token via these instructions: https://wiki.dnanexus.com/Command-Line-Client/Login-and-Logout#Authentication-Tokens

Clone the dx-cwl repository:

```
https://github.com/dnanexus/dx-cwl.git
```

This was a commit hash used around the time of submission if you'd like to check it out: 2687fe8c671c113e8a780a790a85a18396aea23e

Ensure all pre-requisites are installed using the install-prerequisites.sh script or building a Docker image from the Dockerfile in the repository.


#### 2. Download required files

Use the `synapse get` command to recursively download all of the required files from the knoweng_gene_prioritization folder on synapse -- the CWL files for the workflow and to check the results, the associated parameters files (in YAML format), and the input data files:
```shell
synapse get -r syn10235824 # the knoweng_gene_prioritization folder
```

#### 3. Run main workflow

Upload downloaded files to the DNAnexus project

```
dx upload -r .
```

Compile the workflow to DNAnexus

```
dx-cwl/dx-cwl compile-workflow gp_workflow.cwl --project $PROJECT --token $TOKEN
```

Run the workflow on the platform

```
dx-cwl/dx-cwl run-workflow dx-cwl-run/gp_workflow/gp_workflow md5sum.cwl.json
```

Note that the file in the second argument is referring to the one you uploaded to the platform.


#### 4. Run workflow checker tool
sing the UI, or `dx describe` on the analysis ID from above, download relevant outputs using:

`dx download [filename or ID]`


To verify the workflow results before submission, use `cwltool` to run the checker as follows:
```shell
cwltool check_results.cwl check_results_job.yml
cat log.txt
cat results.json
```
Note: The default check_results parameters file `check_results_job.yml` expects the results files to be in the working directory (i.e., the current directory).  If you need to change that, you can edit the parameters file and modify the locations of the results files.

#### 5. Submit workflow outputs

Use the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools:
```shell
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
```

Modify the parameters in `submit_results.yml` appropriately; in particular, you will need to fill in the `team_name` (optional) and `parent_id` (required) fields; you may also need to modify the locations of the results files:
```YAML
config_file:
  class: File
  location: .synapseConfig
team_name: DNAnexus 
eval_id: ""9606345""
file:
  - class: File
    location: ./ranked_genes_download.tsv
  - class: File
    location: ./top_genes_download.tsv
  - class: File
    location: ./combo_results.txt
  - class: File
    location: ./9606.STRING_experimental.edge
parent_id: syn11634488
```

Finally, submit the outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl submit_results.yml
```

---",9657792
knoweng_gene_prioritization,9657906_report.md,"## KnowEnG Gene Prioritization Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Milt Epstein""
workflow_handle: ""knoweng_gene_prioritization""
input_handle: ""knoweng_gene_prioritization""
```

The following description is provided by the workflow author (see https://knoweng.org/pipelines/):
> You submit a spreadsheet of gene-level transcriptomic (or other omics) profiles of a collection of biological samples. Each sample is also annotated with a numeric  phenotype (e.g., drug response, patient survival, etc.) or categorical phenotype (e.g., cancer  subtype, metastatic status). This pipeline scores each gene by the correlation between its “omic” value (e.g., expression) and the phenotype, and reports the top phenotype-related genes. Gene prioritization can be done in a Knowledge Network-guided mode, and with optional use of bootstrapping to achieve robust prioritization.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""4Gb""
suggested_disk: ""4Gb""
```

#### Workflow history

* **2017-08-23**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Junjun Zhang"" # your name here
institution: ""Ontario Institute for Cancer Research"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-11-15"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""JTracker"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
cwltool_version: ""1.0.2017110733715""
runner_version: ""0.2.0a5"" # indicate executor version used
docker_version: ""1.12.6"" # from `docker --version`
environment: ""OpenStack VM"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""96GB"" # indicate available RAM in environment
env_disk: ""2TB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-08-31""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""1.12.6""
environment_ex: ""local"" 
env_cpus_ex: ""8""
env_memory_ex: ""96GB""
env_disk_ex: ""2TB""
```

### Write a JTracker Workflow
The JTracker workflow is written to automatically execute necessary steps to complete a Dream Challenge workflow. The JTracker workflow is named as `dream-challenge-wf-runner`, the source code is checked in Github at: https://github.com/jthub/demo-workflows/tree/master/dream-challenge-wf-runner/workflow.

Once tested out successfully, make a release of the source code. In this case, it is release version 0.0.7: https://github.com/jthub/demo-workflows/releases/tag/dream-challenge-wf-runner.0.0.7

### Register the JTracker Workflow in JTHub
#### Install JTracker command line tool

Follow the instructions here: https://github.com/icgc-dcc/jtracker

Once install successfully, you should be able to see the version number.
```
jt --version
```

#### Signup a JTHub account
Assume we choose `ga4gh_dream` as account name:
```
jt user signup -u ga4gh_dream
```
Login as `ga4gh_dream`
```
jt user login -u ga4gh_dream
```

#### Register the JTracker Dream Challenge Runner Workflow
Register a workflow is basically provide information to access the JTracker workflow source code in GitHub.
```
jt wf register --git-server https://github.com --git-account jthub --git-repo demo-workflows \
                       --git-path dream-challenge-wf-runner --git-tag dream-challenge-wf-runner.0.0.7 \
                       --wf-name dream-challenge-wf-runner --wf-version 0.0.7
```
To list all registered workflows in your account, do this:
```
jt wf ls
```

### Create a Job Queue
Once we have the workflow registered, you will be able to create a job queue for it.
```
jt queue add --wf-name dream-challenge-wf-runner --wf-version 0.0.7
```
Upon success, you will get a unique job queue ID. In my case, my queue ID is: `758b7668-0057-4ef6-a5b0-6f48acf38583`

To list all job queues you created, do this:
```
jt queue ls
```

### Add workflow job to the above queue
If we want to run `knoweng_gene_prioritization`, fill out the appropriate parameters in the job JSON as below:
```
jt job add -q 758b7668-0057-4ef6-a5b0-6f48acf38583 -j '
{
    ""workflow_name"": ""knoweng_gene_prioritization"",
    ""workflow_type"": ""CWL"",
    ""data_syn_id"": ""syn10235824"",
    ""wf_file_name"": ""gp_workflow.cwl"",
    ""job_file_name"": ""gp_workflow_job.yml"",
    ""checker_wf_file_name"": ""check_results.cwl"",
    ""checker_job_file_name"": ""check_results_job.yml"",
    ""submit_job_file_name"": ""submit.json"",
    ""team_name"": ""PCAWG-Tech"",
    ""syn_parent_id"": ""syn11639277"",
    ""eval_id"": ""9606345""
}
'
```
To list all jobs in the queue:
```
jt job ls -q 758b7668-0057-4ef6-a5b0-6f48acf38583
```
Note that the above steps can be done on any computer, it could be a normal workstation or a laptop.


### Run the above queued Sanger workflow job

To execute the workflow job you will need to set up necessary environment and tools, follow these steps:

#### Setting up environment
1. Install Docker

2. Install `cwltool` (version 1.0.20170217172322) and  `synapseclient`
```
pip install cwltool==1.0.20170217172322
pip install html5lib
pip install synapseclient
```

3. Create Synapse credentials file `.synapseConfig`
Put there Synapse ID and password
```
[authentication]
username: user@usermail.org
password: <user-password>
```
Put this file a particular place, for example under home directory, eg, `/home/ubuntu/.synapseConfig`, then export the follow environment variable:
```
export SYNCONF=/home/ubuntu/.synapseConfig
```
4. Install JTracker command line
This is the same step as the previous section. Follow installation instruction here: https://github.com/icgc-dcc/jtracker

#### Start JTracker Executor
Start the executor to run jobs in the queue as:
```
jt user login ga4gh_dream
SYNCONF=/home/ubuntu/.synapseConfig jt exec run -q 758b7668-0057-4ef6-a5b0-6f48acf38583
```
If everything goes well, in about 5 hours, the job should finish and you will see `pcawg-sanger-variant-caller` result uploaded to specified location on Synapse.

---",9657906
knoweng_gene_prioritization,9657919_report.md,"### Workflow description

```YAML
contributor: ""Milt Epstein""
workflow_handle: ""knoweng_gene_prioritization""
input_handle: ""knoweng_gene_prioritization""
```

### Participant information
```YAML
name: ""Ben Ernest""
institution: ""Digicon Corporation""
```

### Submission overview
```YAML
date_accessed: ""2017-12-05"" 
platform: ""cwltool"" 
workflow_type: ""CWL"" 
runner_version: ""1.0.20170217172322"" 
docker_version: ""17.09.0-ce"" 
environment: ""cluster"" 
env_cpus: ""12"" 
env_memory: ""62Gb"" 
env_disk: ""5Tb"" 
```

### Steps

#### 1. Set up environment, following instructions at https://dockstore.org/quick-start.  These only need to be done once for all workflows that use `cwltool`.
##### Instructions are for Linux CentOS

Download and install dockstore.  
```shell
mkdir -p ~/bin
curl -L -o ~/bin/dockstore https://github.com/ga4gh/dockstore/releases/download/1.3.0/dockstore
chmod +x ~/bin/dockstore
echo 'export PATH=~/bin:$PATH' >> ~/.bashrc
source ~/.bashrc
```

Create configuration file
```shell
mkdir -p ~/.dockstore
printf ""token: dummy-token\nserver-url: https://dockstore.org:8443\n"" > ~/.dockstore/config
```

Install `pip`
```shell
curl -L -o ~/get-pip.py https://bootstrap.pypa.io/get-pip.py
sudo python get-pip.py
```

Install `cwltool` (**note: version 1.0.20170217172322**)
```shell
sudo pip install setuptools==36.5.0
sudo pip install cwl-runner cwltool==1.0.20170217172322 schema-salad==2.6.20170806163416 avro==1.8.1 ruamel.yaml==0.14.12 requests==2.18.4
```

Install Docker
```shell
sudo yum install -y yum-utils device-mapper-persistent-data lvm2
sudo yum-config-manager --add-repo ""https://download.docker.com/linux/centos/docker-ce.repo""
sudo yum-config-manager --enable extras
sudo yum -y install docker-ce
sudo usermod -aG docker $USER
exec newgrp docker
```

Create aliases to start and stop Docker
```shell
echo 'alias start_docker=""sudo systemctl start docker""' >> ~/.bashrc
echo `alias stop_docker=""sudo systemctl stop docker""' >> ~/.bashrc
source ~/.bashrc
```
Install `synapseclient`
```
sudo pip install synapseclient
```

Create synapse credentials file with the content below, using your own Synapse credentials (no quotes or extra characters).  It can be named anything, but I'm using `.synapseConfig`.
```
[authentication]
username: email
password: password
```

Create a working directory and copy synapse credentials file into that folder.
```shell
mkdir -p knoweng
cd knoweng
cp ~/.synapseConfig .
```

#### 2. Download required files
Download the data and tools needed for running the workflow and the `dockstore-tool-synapse-submit.cwl` file for submitting the results.
```shell
synapse get -r syn10235824 # the knoweng_gene_prioritization folder
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
```

#### 3. Provision all workflow files
Start docker, using alias created previously.
```shell
start_docker
```

#### 4. Run main workflow
Use `cwltool` to run the workflow, as defined in `gp_workflow.cwl` and parameterized by `gp_workflow_job.yml`:
```shell
cwltool --non-strict gp_workflow.cwl gp_workflow_job.yml
```

#### 5. Run workflow checker tool
To verify workflow results before submission, use `cwltool` to run the checker as follows:
```shell
cwltool --non-strict check_results.cwl check_results_job.yml
```

#### 6. Submit workflow outputs
Modify `team_name` and `parent_id` in `submit_results.yml` as shown below, assuming Synapse credentials file is named `.synapseConfig` and located in `~/knoweng`.
```YAML
config_file:
  class: File
  location: .synapseConfig
team_name: ""BioGenLink""
eval_id: ""9606345""
file:
  - class: File
    location: ./ranked_genes_download.tsv
  - class: File
    location: ./top_genes_download.tsv
  - class: File
    location: ./combo_results.txt
  - class: File
    location: ./9606.STRING_experimental.edge
parent_id: ""syn11639782""

```

Submit outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl submit_results.yml
```

Stop Docker if desired.
```shell
stop_docker
```",9657919
knoweng_gene_prioritization,9657920_report.md,"### Workflow description

```YAML
contributor: ""Milt Epstein""
workflow_handle: ""knoweng_gene_prioritization""
input_handle: ""knoweng_gene_prioritization""
```

### Participant information
```YAML
name: ""Ben Ernest""
institution: ""Digicon Corporation""
```

### Submission overview
```YAML
date_accessed: ""2017-12-12"" 
platform: ""Dockstore"" 
workflow_type: ""CWL"" 
runner_version: ""1.0.20170217172322"" 
docker_version: ""17.09.0-ce"" 
environment: ""BioGenLink"" 
env_cpus: ""1"" 
env_memory: ""8Gb"" 
env_disk: ""5Tb"" 
```

### Steps
#####This workflow was run using the [BioGenLink](http://digicon.com/biogenlink.html) platform from [Digicon](http://digicon.com/).  Click [here](http://digicon.com/biogenlink.html) or [email us](mailto:biogenlink@digiconasp.com) for more information. 

#### **Setup**

##### Create synapse credentials file.  
This only needs to be done once, and the credentials file can be used for each workflow.
1. Log into BioGenLink.  [Click here](http://digicon.com/biogenlink.html) or [email us](mailto:biogenlink@digiconasp.com) for more information. 
${image?fileName=login%5Fscreen%5Fempty%2E2017%2D12%2D19%2Epng&align=None&scale=75&responsive=true}
2. In the **files** tab, right-click on any directory in the file system, select `Create File`, give the file a name (e.g., ""synapse_config.txt""), and click `Preview` to edit the file.  
${image?fileName=create%5Ffile%5Fpreview%2E2017%2D12%2D19%2Epng&align=None&scale=75&responsive=true}
Enter the following information in the file and save it by clicking **Save** (the disk button just above the text area).
```
[authentication]
username: email
password: password
[cache]
location: biodtfs/path/to/cache
```
**Note:** the cache directory is used by synapseClient for temporary files, and we must specify it in BioGenLink to avoid permissions errors. It can be be any directory the user chooses, even a non-existing one as long as the parent directory is valid.  It is suggested to create a working directory for each workflow and keep this file in a parent directory outside of the working directories.  

#### **Provision workflow files**

1. Create a working directory.  
    - Right-click on any directory in the file system, select `Create Folder`, and enter a name for the working directory (e.g., `knoweng_workflow`).

2. Run the `Synapse get` tool.
    - In the **tools** tab, find and select the `Synapse get` tool.  It can be found by keyword search or browsing to `Synapse/All/Synapse get`.  Double-clicking (shown below) the tool will open it in the workspace for editing and browsing documentation and will display the menu for providing inputs and running the tool.
${image?fileName=synapse%5Fget%5Fopen%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
    - In the `Synapse IDs` field, enter `syn9770802 ` and `syn9732885 ` to download `dockstore-tool-synapse-get.cwl` and `dockstore-tool-synapse-submit.cwl`.  
      Drag and drop the synapse credentials file (e.g., `synapse_config.txt`) from the file system into the field called `Synapse config file`.
      Set the switch labeled `Download tools and data` to `Off`.  
      Drag and drop the working directory into the field called `Output directory`.
      Run the tool by clicking `Quick Launch`.
    - In the `Synapse IDs` field, enter `syn10235824` to recursively download workflow files.
      Drag and drop the synapse credentials file (e.g., `synapse_config.txt`) from the file system into the field called `Synapse config file`.
      Set the switch labeled `Only tools and data` to `On`.
      Drag and drop the working directory into the field called `Output directory`.
      Run the tool by clicking `Quick Launch`.  
 ${image?fileName=synapse%5Fget%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}

#### **Run the workflow**
- Run the `Dockstore launch` tool.
    1. In the **Tools** tab, find and select the `Dockstore launch` tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore launch`.  
${image?fileName=dockstore%5Flaunch%2E2018%2D01%2D04%2Epng&align=None&scale=75&responsive=true}
    2. Drag and drop the `gp_workflow.cwl` and `gp_workflow_job.yml` files from the working directory into the fields labeled `CWL file` and `JSON file`, respectively.  `Parent directory` can be left blank, since the directory containing the two input files will be used as the parent directory by default.   
    3. Click `Quick Launch`.

#### **Validate the results**
- Run the `Dockstore checker` tool.
1. In the **tools** tab, find and select the `Dockstore checker` tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore checker`.  
${image?fileName=dockstore%5Fchecker%2E2017%2D12%2D25%2Epng&align=None&scale=75&responsive=true}
  2. Drag and drop the `check_results.cwl` and `check_results_job.yml` files from the working directory into the fields labeled `Checker CWL file` and `Checker JSON file`, respectively.  
  3. Click `Quick Launch`.
  4. Verify that the workflow ran successfully by opening the `results.json` file and confirming that the `Overall` field is equal to `true`.
${image?fileName=results%5Fjson%2E2017%2D12%2D25%2Epng&align=None&scale=75&responsive=true}

#### **Submit the results to Synapse**
- Run the `Dockstore submit` tool.
  1. In the **Tools** tab, find and select the `Dockstore submit` tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore submit`.  
${image?fileName=dockstore%5Fsubmit%2E2017%2D12%2D26%2Epng&align=None&scale=75&responsive=true}
  2. Drag and drop the `submit_results.yml` file into the field labeled `Submit JSON file`.  
  3. Enter a team name and the Synapse parent ID into the corresponding fields.  
  4. Drag and drop the synapse credentials file (e.g., `synapse_config.txt`) into the field labeled `Synapse config file`.
  5. Click `Quick Launch`.",9657920
md5sum,9621705_report.md,"## Dockstore md5sum Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""James Eddy"" # your name here
institution: ""Sage Bionetworks"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170217172322"" # indicate executor version used
docker_version: ""17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""4"" # indicate number of cores in environment
env_memory: ""16Gb"" # indicate available RAM in environment
env_disk: ""300Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

#### 1. Set up environment

On a personal laptop with Docker and Anaconda already installed, I created and configured a virtual environment  with `synapseclient` and `cwltool` as follows:
```shell
conda create -n syncwl
source activate syncwl
pip install synapseclient --no-cache-dir
pip install schema-salad==2.2.20170222151604 cwltool==1.0.20170217172322 --no-cache-dir
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir md5sum
cd md5sum
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **hello_world** workflow:
```shell
synapse get syn9771740 # md5sum_get_get.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 4. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `md5sum_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl md5sum_get.cwl.json
```

#### 5. Run main workflow

I again used `cwltool` to run the workflow, as defined in `md5sum.cwl` and parameterized by `md5sum.cwl.json`:
```shell
cwltool md5sum.cwl md5sum.cwl.json
```

#### 6. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool md5sum_checker.cwl md5sum_checker.cwl.json
cat results.json | grep -i overall
```

#### 7. Submit workflow outputs

I modified the parameters in `md5sum_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""SageWorkflowRunners"",
    ""eval_id"": ""9603664"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""md5sum.result""
        }
    ],
    ""parent_id"": ""syn9851737""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl md5sum_submit.cwl.json`
```

---",9621705
md5sum,9621853_report.md,"## Dockstore md5sum Workflow


### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Bogdan Gavrilovic"" # your name here
institution: ""Seven Bridges Genomics"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""rabix"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.0"" # indicate executor version used
docker_version: ""17.06.0-ce"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""4"" # indicate number of cores in environment
env_memory: ""16GB"" # indicate available RAM in environment
env_disk: ""200GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

#####1. [Install rabix](https://github.com/rabix/bunny#installing) on your machine and set environment variable $BUNNY. You need docker and java installed to run rabix:
```shell
wget https://github.com/rabix/bunny/releases/download/v1.0.0/rabix-1.0.0.tar.gz -O rabix-1.0.0.tar.gz && tar -xvf rabix-1.0.0.tar.gz
export BUNNY=$PWD/rabix-cli-1.0.0/rabix
```
#####2. If you've not already retrieved the CWL and data with synapse-get, you can use the [Synapse python client](https://github.com/Sage-Bionetworks/synapsePythonClient#installation):
```shell
pip install synapseclient
synapse get -r syn10167920 # md5sum workflow, tools and input files
synapse get syn9732885   # dockstore-tool-synapse-submit.cwl
```

#####3. Run the workflow using rabix executor on your machine by typing in the terminal: $BUNNY <app> <inputs>
For example:
```shell
$BUNNY ./md5sum.cwl ./md5sum.cwl.json
```
### Validating results
Modify the `md5sum_checker.cwl.json` to include the path to the requested output file and run checker tool
```shell
$BUNNY md5sum_checker.cwl md5sum_checker.cwl.json
```
Check results
```shell
cat ./path/to/results.json
``` 
```json
{ ""Overall"" : true, ""Steps"" : { ""md5sum_check"" : true } }
```
### Submitting results
- Copy the `synapseConfig` file to the current working directory.
- Update `md5sum_checker.cwl.json` with correct
`team_name` - the name of your team in plain text format (e.g., ""GA4GH-Sage Contenders"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
'file' - paths to output files
Run the tool
```shell
$BUNNY dockstore-tool-synapse-submit.cwl md5sum_submit.cwl.json
```

---",9621853
md5sum,9622068_report.md,"## Dockstore md5sum Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Lon Blauvelt""
institution: ""UCSC""
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL""
runner_version: ""1.0.20170217172322""
docker_version: ""17.06.0-ce, build 02c1d87""
environment: ""EC2""
env_cpus: ""2""
env_memory: ""4 Gb""
env_disk: ""50 Gb""
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

#### 1. Set up environment

I used the following to update the instance:

```shell
sudo apt-get update
sudo apt-get -y upgrade
sudo apt-get -y dist-upgrade
```

Install docker:

```shell
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
sudo add-apt-repository ""deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable""
sudo apt-get update
apt-cache policy docker-ce
sudo apt-get install -y docker-ce
sudo usermod -aG docker ${USER}
sudo su - ${USER}
```

Install pip, a virtualenv, and the requisite pip installs (cwltool, schema-salad, avro, synapse, and html5lib):

```shell
sudo apt install -y python-pip
sudo pip install --upgrade pip
sudo pip install virtualenv
virtualenv --python /usr/bin/python2 cwl
source /home/ubuntu/cwl/bin/activate
pip install cwl-runner cwltool==1.0.20170217172322 schema-salad==2.6.20170630075932 avro==1.8.1  ruamel.yaml==0.14.12 --no-cache-dir
pip install synapseclient --no-cache-dir
pip install html5lib
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:

```shell
mkdir syn
cd syn
nano syn-login.synapseConfig
[PASTE] username & password
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for workflows, and then modify the get file:

```shell
synapse get -r syn9689286
[PASTE] username & password
synapse get -r syn9689284
[PASTE] username & password

nano md5sum_get.cwl.json
[PASTE] /home/ubuntu/syn/syn-login.synapseConfig
```

#### 4. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `md5sum_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.

```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl md5sum_get.cwl.json
```

#### 5. Run main workflow

I again used `cwltool` to run the workflow, as defined in `md5sum.cwl` and parameterized by `md5sum.cwl.json`:
```
cwltool --non-strict md5sum.cwl md5sum.cwl.json
```

#### 6. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool --non-strict md5sum_checker.cwl md5sum_checker.cwl.json
```

#### 7. Submit workflow outputs

I modified the parameters in `md5sum_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": ""/home/ubuntu/syn/syn-login.synapseConfig""
    },
    ""team_name"": ""UCSC GA4GH-DREAM Challenge Team"",
    ""eval_id"": ""9603664"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""md5sum.result""
        }
    ],
    ""parent_id"": ""syn10182019""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:

```shell
cwltool dockstore-tool-synapse-submit.cwl md5sum_submit.cwl.json`
```

---",9622068
md5sum,9622069_report.md,"## Dockstore md5sum Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Lon Blauvelt""
institution: ""UCSC""
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL""
runner_version: ""1.0.20170217172322""
docker_version: ""17.06.0-ce, build 02c1d87""
environment: ""EC2""
env_cpus: ""2""
env_memory: ""4 Gb""
env_disk: ""50 Gb""
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

#### 1. Set up environment

I used the following to update the instance:

```shell
sudo apt-get update
sudo apt-get -y upgrade
sudo apt-get -y dist-upgrade
```

Install docker:

```shell
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
sudo add-apt-repository ""deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable""
sudo apt-get update
apt-cache policy docker-ce
sudo apt-get install -y docker-ce
sudo usermod -aG docker ${USER}
sudo su - ${USER}
```

Install pip, a virtualenv, and the requisite pip installs (cwltool, schema-salad, avro, synapse, and html5lib):

```shell
sudo apt install -y python-pip
sudo pip install --upgrade pip
sudo pip install virtualenv
virtualenv --python /usr/bin/python2 cwl
source /home/ubuntu/cwl/bin/activate
pip install cwl-runner cwltool==1.0.20170217172322 schema-salad==2.6.20170630075932 avro==1.8.1  ruamel.yaml==0.14.12 --no-cache-dir
pip install synapseclient --no-cache-dir
pip install html5lib
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:

```shell
mkdir syn
cd syn
nano syn-login.synapseConfig
[PASTE] username & password
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for workflows, and then modify the get file:

```shell
synapse get -r syn9689286
[PASTE] username & password
synapse get -r syn9689284
[PASTE] username & password

nano md5sum_get.cwl.json
[PASTE] /home/ubuntu/syn/syn-login.synapseConfig
```

#### 4. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `md5sum_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.

```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl md5sum_get.cwl.json
```

#### 5. Run main workflow

I again used `cwltool` to run the workflow, as defined in `md5sum.cwl` and parameterized by `md5sum.cwl.json`:
```
cwltool --non-strict md5sum.cwl md5sum.cwl.json
```

#### 6. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool --non-strict md5sum_checker.cwl md5sum_checker.cwl.json
```

#### 7. Submit workflow outputs

I modified the parameters in `md5sum_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": ""/home/ubuntu/syn/syn-login.synapseConfig""
    },
    ""team_name"": ""UCSC GA4GH-DREAM Challenge Team"",
    ""eval_id"": ""9603664"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""md5sum.result""
        }
    ],
    ""parent_id"": ""syn10182019""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:

```shell
cwltool dockstore-tool-synapse-submit.cwl md5sum_submit.cwl.json`
```

---",9622069
md5sum,9622070_report.md,"## Dockstore md5sum Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Jeltje van Baren""
institution: ""UCSC""
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""cwltool""
workflow_type: ""CWL""
runner_version: ""1.0.20170704143016""
docker_version: ""1.12.1, build 23cf638""
environment: ""UCSC podcloud VM Ubuntu 16:04""
env_cpus: ""31""
env_memory: ""252 G""
env_disk: ""1 Tb""
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

1. Used link on [3.3 - Access Data and Tools](https://www.synapse.org/#!Synapse:syn8507134/wiki/416015) to download [md5sum_get.cwl.json](https://www.synapse.org/Portal/filehandleassociation?associatedObjectId=9771740&associatedObjectType=FileEntity&fileHandleId=16639348&xsrfToken=5D9B3FA24C29121558A6DF4048E46A16)

2. From the same page, downloaded [dockstore-tool-synapse-get.cwl](https://www.synapse.org/Portal/filehandleassociation?associatedObjectId=9770802&associatedObjectType=FileEntity&fileHandleId=15691607&xsrfToken=F397E2A807CC92157AEC380011771547) and [dockstore-tool-synapse-submit.cwl](https://www.synapse.org/Portal/filehandleassociation?associatedObjectId=9732885&associatedObjectType=FileEntity&fileHandleId=16683837&xsrfToken=F397E2A807CC92157AEC380011771547):

      dockstore-tool-synapse-get.cwl pulls quay.io/ga4gh-dream/dockstore-tool-synapse-get:1.6.2.dev--2
      dockstore-tool-synapse-submit.cwl pulls  quay.io/ga4gh-dream/dockstore-tool-synapse-submit:1.7.1--1

3. Retrieved data:

    source ~/venv/cwl/bin/activate
    export TMPDIR=/mnt/tempdir
    tmpstuff=""--tmpdir-prefix=/mnt/tempdir --tmp-outdir-prefix=/mnt/tempdir""
    ln -s ~/.synapse.key .synapseConfig
    cwltool $tmpstuff --non-strict dockstore-tool-synapse-get.cwl md5sum_get.cwl.json

4. Ran workflow:

    cwltool $tmpstuff --non-strict md5sum.cwl  md5sum.cwl.json

5. Created a synapse project for this workflow [md5sum_GA4GH: syn10147112](https://www.synapse.org/#!Synapse:syn10147112), updated md5sum_submit.cwl.json with this information and submitted the output:

    cwltool $tmpstuff --non-strict dockstore-tool-synapse-submit.cwl md5sum_submit.cwl.json

Contents of md5sum_submit.cwl.json:
```
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": """",
    ""eval_id"": ""9603664"",
    ""file"": [
        {
            ""class"": ""File"",
            ""path"": ""md5sum.txt""
        }
    ],
    ""parent_id"": ""syn10147112""
}
```

---",9622070
md5sum,9622400_report.md,"## Dockstore md5sum Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Abraham Chavez"" # your name here
institution: ""UCSC"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""cwl"" # CWL or WDL
runner_version: ""1.0.20170217172322"" # indicate executor version used
docker_version: ""1.12.6"" # from `docker --version`
environment: ""local OS X"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""4"" # indicate number of cores in environment
env_memory: ""16Gb"" # indicate available RAM in environment
env_disk: ""250Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment 

If you have not set up your environment and install dependencies like **cwltool**, **dockstore**, **java** and so on
I recommend you follow [**this**](https://www.synapse.org/#!Synapse:syn10220609) instructions.

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir md5sum_cwltool
cd md5sum_cwltool
cp ~/.synapseConfig .
```
Information about `.synapseConfig` can be found [here](https://www.synapse.org/#!Synapse:syn8507133/wiki/451408)

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **hello_world** workflow:
```shell
synapse get syn9771740 # md5sum_get_get.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `md5sum_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl md5sum_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `md5sum.cwl` and parameterized by `md5sum.cwl.json`:
```
cwltool --non-strict md5sum.cwl md5sum.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool --non-strict md5sum_checker.cwl md5sum_checker.cwl.json
cat results.json | grep overall
```

#### 6. Submit workflow outputs

I modified the parameters in `md5sum_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""Your Team Name"",
    ""eval_id"": ""9603664"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""md5sum.result""
        }
    ],
    ""parent_id"": ""yourParentId""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl md5sum_submit.cwl.json`
```

---",9622400
md5sum,9622669_report.md,"## Dockstore md5sum Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Abraham Chavez"" 
institution: ""UCSC"" 
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""dockstore cli"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""cwl"" # CWL or WDL
runner_version: ""1.2.5"" # indicate executor version used
docker_version: ""1.12.6"" # from `docker --version`
environment: ""EC2"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""32Gb"" # indicate number of cores in environment
env_memory: ""244Gb"" # indicate available RAM in environment
env_disk: ""200Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

#### 1. Set up environment 

If you have not set up your environment and install dependencies like **cwltool**, **dockstore**, **java** and so on
I recommend you follow [**this**](https://www.synapse.org/#!Synapse:syn10220609) instructions.

Create a working directory for the current workflow and create a copy of your Synapse credentials in that folder:
```shell
mkdir md5sum_dockstore
cd md5sum_dockstore
cp ~/.synapseConfig .
```
Information about `.synapseConfig` can be found [**here**](https://www.synapse.org/#!Synapse:syn8507133/wiki/451408)

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **md5sum** workflow:
```shell
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn10167927 # md5sum.input
synapse get syn10167928 # md5sum_checker.cwl
synapse get syn10167929 # md5sum_checker.cwl.json
synapse get syn10167930 # md5sum_submit.cwl.json
```

#### 3. Provision your workflow
```shell
dockstore workflow convert entry2json --entry briandoconnor/dockstore-workflow-md5sum:1.2.0 > Dockstore.json
```
The previous step, generates a **Dockstore.json** file which is meant to be modified, but without examples as how to do it. You can try the following example:

```JSON
{ 
""input_file"":{
      ""class"": ""File"",
      ""path"": ""md5sum.input""
      },
      ""output_file"": {
      ""class"": ""File"",
      ""path"": ""md5sum.txt""
      }
 }
```

#### 4. Run main workflow

I again used `dockstore` to run the workflow, as defined in `dockstore-workflow-md5sum` and parameterized by `Dockstore.json`:
```
dockstore workflow launch --entry briandoconnor/dockstore-workflow-md5sum:1.2.0 --json Dockstore.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool --non-strict md5sum_checker.cwl md5sum_checker.cwl.json
cat results.json | grep overall
```

#### 6. Submit workflow outputs

I modified the parameters in `md5sum_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""yourTeamName"",
    ""eval_id"": ""9603664"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""md5sum.result""
        }
    ],
    ""parent_id"": ""yourParentID""
}
```

Finally, submit outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl md5sum_submit.cwl.json`
```
#### For more information visit:
 [**Dockstore**](https://dockstore.org/workflows/briandoconnor/dockstore-workflow-md5sum)
&
 [**Github**](https://github.com/briandoconnor/dockstore-workflow-md5sum)

---",9622669
md5sum,9623073_report.md,"## Dockstore md5sum Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Lon Blauvelt""
institution: ""UCSC""
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""Toil"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL""
runner_version: ""3.10.0a1""
docker_version: ""17.06.0-ce, build 02c1d87""
environment: ""EC2""
env_cpus: ""2""
env_memory: ""4 Gb""
env_disk: ""50 Gb""
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

#### 1. Set up environment

I used the following to update the instance:

```shell
sudo apt-get update
sudo apt-get -y upgrade
sudo apt-get -y dist-upgrade
```

Install docker:

```shell
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
sudo add-apt-repository ""deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable""
sudo apt-get update
apt-cache policy docker-ce
sudo apt-get install -y docker-ce
sudo usermod -aG docker ${USER}
sudo su - ${USER}
```

Install pip, a virtualenv, and the requisite pip installs (cwltool, schema-salad, avro, synapse, and html5lib):

```shell
sudo apt install -y python-pip
sudo pip install --upgrade pip
sudo pip install virtualenv
virtualenv --python /usr/bin/python2 cwl
source /home/ubuntu/cwl/bin/activate
pip install cwl-runner cwltool==1.0.20170217172322 schema-salad==2.6.20170630075932 avro==1.8.1  ruamel.yaml==0.14.12 --no-cache-dir
pip install toil
pip install synapseclient --no-cache-dir
pip install html5lib
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:

```shell
mkdir syn
cd syn
nano syn-login.synapseConfig
[PASTE] username & password
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for workflows, and then modify the get file:

```shell
synapse get -r syn9689286
[PASTE] username & password
synapse get -r syn9689284
[PASTE] username & password

nano md5sum_get.cwl.json
[PASTE] /home/ubuntu/syn/syn-login.synapseConfig
```

#### 4. Provision all workflow files

I used `cwltoil` to run `dockstore-tool-synapse-get.cwl` with parameters in `md5sum_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.

```shell
cwltoil dockstore-tool-synapse-get.cwl md5sum_get.cwl.json
```
There is a memory allocation adjustment needed to the files: dockstore-tool-md5sum.cwl & md5sum_checker.cwl, so modify the files:
```shell
nano dockstore-tool-md5sum.cwl
nano md5sum_checker.cwl
```
And change the following excerpt in each file:
```shell
hints:
- class: ResourceRequirement
  # The command really requires very little resources.
  coresMin: 1
  ramMin: 1024
  outdirMin: 512000
```
To this:
```shell
hints:
- class: ResourceRequirement
  # The command really requires very little resources.
  coresMin: 1
  ramMin: 1024
  outdirMin: 5
```

#### 5. Run main workflow

I again used `cwltoil` to run the workflow, as defined in `md5sum.cwl` and parameterized by `md5sum.cwl.json`:
```shell
cwltoil md5sum.cwl md5sum.cwl.json
```

#### 6. Run workflow checker tool

To verify workflow results before submission, I used `cwltoil` to run the checker as follows:
```shell
cwltoil md5sum_checker.cwl md5sum_checker.cwl.json
```

#### 7. Submit workflow outputs

I modified the parameters in `md5sum_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": ""/home/ubuntu/syn/syn-login.synapseConfig""
    },
    ""team_name"": ""UCSC GA4GH-DREAM Challenge Team"",
    ""eval_id"": ""9603664"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""md5sum.result""
        }
    ],
    ""parent_id"": ""syn10182019""
}
```

Finally, I submitted outputs using `cwltoil` and `dockstore-tool-synapse-submit.cwl`:

```shell
cwltoil dockstore-tool-synapse-submit.cwl md5sum_submit.cwl.json`
```

---",9623073
md5sum,9623289_report.md,"## Dockstore md5sum Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Zhicheng Ji""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Zhicheng Ji""
institution: ""Johns Hopkins University""
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""cwltool""
workflow_type: ""CWL""
runner_version: ""1.0.20170217172322""
docker_version: ""17.06.0-ce""
environment: ""EC2""
env_cpus: ""1""
env_memory: ""1GB""
env_disk: ""8GB""
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

On an EC2 Ubuntu environment with Docker installed, I created and configured a virtual environment as follows:
```shell
pip install --upgrade pip
pip install schema-salad==2.2.20170222151604 cwltool==1.0.20170217172322
pip install synapseclient
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir md5sum
cd md5sum
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **hello_world** workflow:
```shell
synapse get syn9771740 # md5sum_get.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `md5sum_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl md5sum_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `md5sum.cwl` and parameterized by `md5sum.cwl.json`:
```shell
cwltool md5sum.cwl md5sum.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool md5sum_checker.cwl md5sum_checker.cwl.json
cat results.json | grep -i overall
```

#### 6. Submit workflow outputs

I modified the parameters in `md5sum_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""zji90"",
    ""eval_id"": ""9603664"",
    ""file"": [
        {
            ""class"": ""File"",
            ""path"": ""md5sum.txt""
        }
    ],
    ""parent_id"": ""syn10221981""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool dockstore-tool-synapse-submit.cwl md5sum_submit.cwl.json
```

---",9623289
md5sum,9623786_report.md,"## Dockstore md5sum Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Han Hu"" # your name here
institution: ""Curacloud Corporation"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170721160741"" # indicate executor version used
docker_version: ""17.05.0-ce, build 89658be"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""40"" # indicate number of cores in environment
env_memory: ""128Gb"" # indicate available RAM in environment
env_disk: ""2.3Tb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

On a personal laptop with Docker and Anaconda installed, I created and configured a virtual environment as follows:
```shell
conda create -n md5sum
source activate md5sum
pip install --upgrade pip
pip install schema-salad==2.2.20170222151604 cwltool==1.0.20170217172322
pip install synapseclient
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir md5sum
cd md5sum
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **hello_world** workflow:
```shell
synapse get syn9771740 # md5sum_get.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `md5sum_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl md5sum_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `md5sum.cwl` and parameterized by `md5sum.cwl.json`:
```shell
cwltool md5sum.cwl md5sum.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool md5sum_checker.cwl md5sum_checker.cwl.json
cat results.json | grep -i overall
```

#### 6. Submit workflow outputs

I modified the parameters in `md5sum_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""BirdsEyeView"",
    ""eval_id"": ""9603664"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""md5sum.txt""
        }
    ],
    ""parent_id"": ""syn10227859""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl md5sum_submit.cwl.json
```

---",9623786
md5sum,9624613_report.md,"## Dockstore md5sum Workflow

### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Bogdan Gavrilovic"" # your name here
institution: ""Seven Bridges Genomics"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""SevenBridges"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.0"" # indicate executor version used
docker_version: ""1.12.6"" # from `docker --version`
environment: ""EC2"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""15Gb"" # indicate available RAM in environment
env_disk: ""700Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

#####1. [Install rabix](https://github.com/rabix/bunny#installing) on your machine and set environment variable $BUNNY. You need docker and java installed to run rabix:
```shell
wget https://github.com/rabix/bunny/releases/download/v1.0.0/rabix-1.0.0.tar.gz -O rabix-1.0.0.tar.gz && tar -xvf rabix-1.0.0.tar.gz
export BUNNY=$PWD/rabix-cli-1.0.0/rabix
```
#####2. If you've not already retrieved the CWL and data with synapse-get, you can use the [Synapse python client](https://github.com/Sage-Bionetworks/synapsePythonClient#installation):
```shell
pip install synapseclient
synapse get -r syn10167920 # md5sum workflow, tools and input files
synapse get syn9732885   # dockstore-tool-synapse-submit.cwl
```
#### Running on the [Cancer Genomics Cloud](https://cgc.sbgenomics.com/) 

#####3. Log in to the [Cancer Genomics Cloud](https://cgc.sbgenomics.com/) and [create a project](https://docs.cancergenomicscloud.org/docs/create-a-project) 
- Academic Users can create a free account on the Cancer Genomics Cloud (CGC). New users receive \$300 in cloud computing credits that you can apply to this challenge, and your own research. Additionally, users that leave feedback on their experience receive an additional \$1000 in cloud compute credits.
- Commercial users of the Seven Bridges Platform that wish to participate in the DREAM challenge can also create an account on the CGC to participate in this academic exercise and receive free credits to run the challenge workflows. Alternatively, commercial users are free to run DREAM challenge workflows in their commercial platform accounts, but should realize that they will incur cloud compute charges to do so. 
&nbsp;
#####4. Installing the workflow on the platform can be done using:  
**a)** [Rabix Composer app for CWL tool editing](http://rabix.io/) or   
**b)** a [CWL CommandLineTool](https://github.com/bogdang989/Import-CWL-to-SevenBridges) for importing CWL workflows to the Seven Bridges platform.  

#####4a. Rabix Composer
If you’re interested in trying out Seven Bridges’ new integrated development environment for creating CWL descriptions of tools and workflows, you can use the [Rabix Composer](http://rabix.io/) to upload the workflow to the platform. 
Use Rabix Composer to add the workflow to the platform:  
- [Install Rabix Composer](http://docs.rabix.io/rabix-composer-installation)
- [Configure Composer](http://docs.rabix.io/rabix-composer-configuration) to connect to the CGC or Seven Bridges platform
- [Add the project](http://docs.rabix.io/rabix-composer-configuration) you created for the DREAM challenge to the workspace
- [Add the local directory](http://docs.rabix.io/rabix-composer-configuration) containing the workflow to the workspace
- [Open](http://docs.rabix.io/rabix-composer-basics) the workflow with Composer
- [Save the workflow to the Platform project](http://docs.rabix.io/rabix-composer-basics) you added to the workspace
- Log into the Platform and [upload the input files](https://docs.cancergenomicscloud.org/docs/upload-to-the-cgc) to the project. 
- Run the task

> You can [upload the files manually to the platform](https://docs.cancergenomicscloud.org/docs/upload-to-the-cgc) by using either CGC Uploader app, command-line uploader, Python API or some other available upload method... All of the available methods are described in [the documentation](https://docs.cancergenomicscloud.org/docs/upload-to-the-cgc) 

#####4b. CWLtoSBG import tool
Download the CWL importing tool and **place it in the same directory with the CWL workflow** that should be installed on the platform. You can download the tool from [github](https://github.com/bogdang989/Import-CWL-to-SevenBridges) manually or from command-line by typing:
```shell
git clone https://github.com/bogdang989/Import-CWL-to-SevenBridges
```
Modify the `cwl_to_sbg-inputs.yaml` to include:

- Paths to `md5sum.cwl` and `md5sum.cwl.json`
- Id of your project on the platform (From project URL, in format *user-name/project-name* )
For example if project URL is https://cgc.sbgenomics.com/u/bogdang/demo-project; project_id is `bogdang/demo-project`
- Your [authentication token](http://docs.sevenbridges.com/docs/get-your-authentication-token)
- Adequate [EC2 instance type](http://www.ec2instances.info/)
&nbsp;
After modifying `cwl_to_sbg-inputs.yaml` with your information, import the workflow to the platform by running
```shell
$BUNNY cwl_to_sbg.cwl cwl_to_sbg-inputs.yaml
```
This will install the workflow and all required apps on the platform. All the files that are required for the task execution are uploaded if they are not uploaded previously. Template draft task is created. If `run_task` is set to `true` the task execution will start on the platform.
You can now open `task` page on the platform project to see task execution details.

### Validating results
[Download the output files](https://docs.cancergenomicscloud.org/docs/download-results) to your local machine.

Modify the `md5sum_checker.cwl.json` to include the path to the requested output file and run checker tool
```shell
$BUNNY md5sum_checker.cwl md5sum_checker.cwl.json
```
Check results
```shell
cat ./path/to/results.json
``` 
```json
{ ""Overall"" : true, ""Steps"" : { ""md5sum_check"" : true } }
```
### Submitting results
- Copy the `synapseConfig` file to the current working directory.
- Update `md5sum_checker.cwl.json` with correct
`team_name` - the name of your team in plain text format (e.g., ""GA4GH-Sage Contenders"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
'file' - paths to output files
Run the tool
```shell
$BUNNY dockstore-tool-synapse-submit.cwl md5sum_submit.cwl.json
```

---",9624613
md5sum,9627441_report.md,"## Dockstore md5sum Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Denis Yuen"" # your name here
institution: ""OICR"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""dockstore"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.2.5"" # indicate executor version used
docker_version: ""17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""64GB"" # indicate available RAM in environment
env_disk: ""400GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

On a personal desktop, I installed Docker, pip, cwltool, and the Dockstore command-line helper using a procedure similar to https://github.com/denis-yuen/2017-cloud-workflows-misc/blob/master/install-and-run-with-dockstore.md

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir md5sum_files
cd md5sum_files
cp ~/.synapseConfig .
```

#### 2. Download required files

I downloaded hello_world_get.json from the website. I then got the synapse-submit and synapse-get commands from Dockstore. 
```shell
dockstore tool cwl --entry quay.io/ga4gh-dream/dockstore-tool-synapse-submit > dockstore-tool-synapse-submit.cwl
dockstore tool cwl --entry quay.io/ga4gh-dream/dockstore-tool-synapse-get > dockstore-tool-synapse-get.cwl
```

#### 3. Modify path for download 

I changed md5sum_get.cwl.json to 
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""synapse_id"": ""syn9770748"",
    ""recursive"": true,
    ""output"": {
        ""class"": ""Directory"",
        ""path"": ""/home/dyuen/ga4gh-dream3/md5sum_files/""
    }
}
```

#### 4. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `md5sum_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
dockstore tool launch --local-entry dockstore-tool-synapse-get.cwl --json md5sum_get.cwl.json
```

#### 4. Run main workflow

I again used `dockstore` to run the workflow, as defined in `md5sum.cwl` and parameterized by `md5sum.cwl.json`:
```shell
dockstore workflow launch --local-entry md5sum.cwl --json md5sum.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
dockstore tool launch --local-entry md5sum_checker.cwl --json md5sum_checker.cwl.json
```

#### 6. Submit workflow outputs

I modified the parameters in `md5sum_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""Dockstore Team"",
    ""eval_id"": ""9603664"",
    ""file"": [
      {
        ""class"": ""File"",
        ""path"": ""md5sum.txt""
      }
    ],
    ""parent_id"": ""syn9961864""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
dockstore tool launch --local-entry dockstore-tool-synapse-submit.cwl --json md5sum_submit.cwl.json
```

---",9627441
md5sum,9631757_report.md,"## Dockstore md5sum Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Jacob Silterra"" # your name here
institution: ""No Institution"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-08-29"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170817131858"" # indicate executor version used
docker_version: ""Docker version 1.12.6, build 78d1802"" # from `docker --version`
environment: ""local Ubuntu 16.04"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""4"" # indicate number of cores in environment
env_memory: ""16 GB"" # indicate available RAM in environment
env_disk: ""10 GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-10""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

On a personal laptop with Docker installed, I created and configured a virtual environment as follows:
```shell
pip install virtualenv
virtualenv venv
source venv/bin/activate
pip install synapseclient
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir md5sum
cd md5sum
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **hello_world** workflow:
```shell
synapse get syn9771740 # md5sum_get.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `md5sum_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl md5sum_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `md5sum.cwl` and parameterized by `md5sum.cwl.json`:
```shell
cwltool md5sum.cwl md5sum.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool md5sum_checker.cwl md5sum_checker.cwl.json
cat results.json | grep -i overall
```

#### 6. Submit workflow outputs

I modified the parameters in `md5sum_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": """",
    ""eval_id"": ""9603664"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""md5sum.txt""
        }
    ],
    ""parent_id"": ""syn10519162""
}
```
Team name is blank because I'm not on a team. ""parent_id"" was set based on a new project created for this purpose.

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl md5sum_submit.cwl.json
```

---",9631757
md5sum,9631883_report.md,"## Dockstore md5sum Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Benjamin Story"" # your name here
institution: ""EMBL"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-08-31"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170413194156"" # indicate executor version used
docker_version: ""1.7.1, build 786b29d"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""12"" # indicate number of cores in environment
env_memory: ""72GB"" # indicate available RAM in environment
env_disk: ""1TB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment


I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir md5
cd md5
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **hello_world** workflow:
```shell
synapse get syn9771740 # md5sum_get.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `md5sum_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl md5sum_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `md5sum.cwl` and parameterized by `md5sum.cwl.json`:
```shell
cwltool md5sum.cwl md5sum.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool md5sum_checker.cwl md5sum_checker.cwl.json
cat results.json | grep -i overall
```

#### 6. Submit workflow outputs

I modified the parameters in `md5sum_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""EMBL GA4GH-DREAM Challenge Team"",
    ""eval_id"": ""9603664"",
    ""file"": [
        {
            ""class"": ""File"",
            ""path"": ""md5sum.txt""
        }
    ],
    ""parent_id"": ""syn10526535""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl md5sum_submit.cwl.json
```

---",9631883
md5sum,9632445_report.md,"## Dockstore md5sum Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Gary Luu"" # your name here
institution: ""Dockstore - OICR"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-05"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""dockstore"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.2.7"" # indicate executor version used
docker_version: ""17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""4"" # indicate number of cores in environment
env_memory: ""32 GB"" # indicate available RAM in environment
env_disk: ""470 GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-10""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

On a personal desktop, I installed Docker, pip, cwltool, and the Dockstore command-line helper using a procedure similar to https://github.com/denis-yuen/2017-cloud-workflows-misc/blob/master/install-and-run-with-dockstore.md .  
However, I used my own modified dockstore CLI (which will be 1.2.7)

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir md5sum
cd md5sum
cp ~/.synapseConfig .
```
#### 2. Download required files

I downloaded md5sum_get.cwl.json from the website. 


#### 3. Provision all workflow files

I used the synapse-get tool from Dockstore.
```shell
dockstore tool launch --entry quay.io/ga4gh-dream/dockstore-tool-synapse-get --json md5sum_get.cwl.json
```

#### 4. Run main workflow

I used dockstore to launch the recently downloaded md5sum.cwl
```shell
dockstore workflow launch --local-entry md5sum.cwl --json md5sum.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `dockstore` to run the checker as follows:
```shell
dockstore tool launch --local-entry md5sum_checker.cwl --json md5sum_checker.cwl.json
cat results.json | grep Overall
```

#### 6. Submit workflow outputs

I modified the parameters in `md5sum_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""Dockstore Team"",
    ""eval_id"": ""9603664"",
    ""file"": [
        {
            ""class"": ""File"",
            ""path"": ""md5sum.txt""
        }
    ],
    ""parent_id"": ""syn9877725""
}
```

Finally, I submitted outputs using dockstore-tool-synapse-submit`:
```shell
dockstore tool launch --entry quay.io/ga4gh-dream/dockstore-tool-synapse-submit --json md5sum_submit.cwl.json
```

---",9632445
md5sum,9632834_report.md,"## Dockstore md5sum Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Byunggil Yoo""
institution: ""Children's Mercy Kansas City""
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-08-11""
platform: ""cwltool""
workflow_type: ""CWL""
runner_version: ""1.0.20170817131858""
docker_version: ""17.06.0-ce, build 02c1d87""
environment: ""local""
env_cpus: ""48""
env_memory: ""512GB""
env_disk: ""368TB""
```

### Steps

#### 1. Set up environment

On a node (CentOS 7.2.1511) of a local cluster with Docker (17.06.0-ce) and Anaconda installed, I created and configured a virtual environment using the following YAML file:
```shell
channels:
  - bioconda
  - conda-forge
  - anaconda
  - r
dependencies:
  - cwltool=1.0.20170817131858
  - synapseclient
```

I created a working directory for the current workflow and created a copy of my Synapse credentials (~/.synapseConfig) in that folder:
```shell
mkdir md5sum
cd md5sum
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the workflow:
```shell
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
synapse get syn9771740 # md5sum_get.cwl.json
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `md5sum_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --outdir md5sum --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ \
        --non-strict dockstore-tool-synapse-get.cwl md5sum_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `md5sum.cwl` and parameterized by `md5sum.cwl.json`:
```shell
cwltool --basedir md5sum/ --outdir md5sum/ \
    --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
    md5sum/md5sum.cwl md5sum/md5sum.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool --basedir md5sum/ --outdir md5sum/ \
        --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
        md5sum/md5sum_checker.cwl md5sum/md5sum_checker.cwl.json
```

#### 6. Submit workflow outputs

I modified the parameters in `md5sum_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""Childrens Mercy GA4GH-DREAM Challenge Team"",
    ""eval_id"": ""9603664"",
    ""file"": [
        {
            ""class"": ""File"",
            ""path"": ""md5sum.txt""
        }
    ],
    ""parent_id"": ""syn10290419""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --basedir md5sum/ --outdir md5sum/ \
        --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
        dockstore-tool-synapse-submit.cwl md5sum/md5sum_submit.cwl.json
```

---",9632834
md5sum,9634723_report.md,"## Dockstore md5sum Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Denis Yuen"" # your name here
institution: ""OICR"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""dockstore 1.2.8"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.2.8"" # indicate executor version used
docker_version: ""17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""64GB"" # indicate available RAM in environment
env_disk: ""400GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

On a personal desktop, I installed Docker, pip, cwltool, and the Dockstore command-line helper using a procedure similar to https://github.com/denis-yuen/2017-cloud-workflows-misc/blob/master/install-and-run-with-dockstore.md

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir md5sum_files
cd md5sum_files
cp ~/.synapseConfig .
```

#### 2. Download required files

I downloaded hello_world_get.json from the website. I then got the synapse-submit and synapse-get commands from Dockstore. 
```shell
dockstore tool cwl --entry quay.io/ga4gh-dream/dockstore-tool-synapse-submit > dockstore-tool-synapse-submit.cwl
dockstore tool cwl --entry quay.io/ga4gh-dream/dockstore-tool-synapse-get > dockstore-tool-synapse-get.cwl
```

#### 3. Modify path for download 

I changed md5sum_get.cwl.json to 
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""synapse_id"": ""syn9770748"",
    ""recursive"": true,
    ""output"": {
        ""class"": ""Directory"",
        ""path"": ""/home/dyuen/ga4gh-dream3/md5sum_files/""
    }
}
```

#### 4. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `md5sum_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
dockstore tool launch --entry quay.io/ga4gh-dream/dockstore-tool-synapse-get --json md5sum_get.cwl.jso
```

#### 4. Run main workflow

I again used `dockstore` to run the workflow, as defined in `md5sum.cwl` and parameterized by `md5sum.cwl.json`:
```shell
dockstore workflow launch --local-entry md5sum.cwl --json md5sum.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
dockstore tool launch --local-entry md5sum_checker.cwl --json md5sum_checker.cwl.json
```

#### 6. Submit workflow outputs

I modified the parameters in `md5sum_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""Dockstore Team"",
    ""eval_id"": ""9603664"",
    ""file"": [
        {
            ""class"": ""File"",
            ""path"": ""md5sum.txt""
        }
    ],
    ""parent_id"": ""syn9961864""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
dockstore tool launch --local-entry dockstore-tool-synapse-submit.cwl --json md5sum_submit.cwl.json
```

---",9634723
md5sum,9635415_report.md,"## Dockstore md5sum Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Jeff Johnston"" # your name here
institution: ""Children's Mercy"" # your institution here
```

#### Submission overview

Provide high level summary information for workflow execution in the fields below.

```YAML
date_accessed: ""2017-09-15"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170817131858"" # indicate executor version used
docker_version: ""17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""48"" # indicate number of cores in environment
env_memory: ""512GB"" # indicate available RAM in environment
env_disk: ""368TB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

#### 1. Setup

This workflow was run on CentOS Linux release 7.2.1511. Docker and Conda 4.3.25 were installed. A conda environment was built using the following conda YAML file:

```yaml
channels:
  - bioconda
  - conda-forge
  - anaconda
  - r
dependencies:
  - cwltool=1.0.20170817131858
  - synapseclient
```

The Synapse client was configured by editing `~/.synapseConfig`.

##### 2. Download

The following commands were run within the conda environment:

```shell
conda
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
synapse get syn9771740 # md5sum_get.cwl.json
cwltool --outdir md5sum --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ \
        --non-strict dockstore-tool-synapse-get.cwl md5sum_get.cwl.json
cp ~/.synapseConfig md5sum
```

##### 3. Run

Next, the workflow was executed in the conda environment.

```shell
cwltool --basedir md5sum/ --outdir md5sum/ \
    --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
    md5sum/md5sum.cwl md5sum/md5sum.cwl.json
```

##### 4. Validate

After running, the workflow results were validated:

```shell
cwltool --basedir md5sum/ --outdir md5sum/ \
        --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
        md5sum/md5sum_checker.cwl md5sum/md5sum_checker.cwl.json
```

##### 5. Submit

`md5sum_submit.cwl.json` was modified for submission:

```yaml
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""Childrens Mercy GA4GH-DREAM Challenge Team"",
    ""eval_id"": ""9603664"",
    ""file"": [
        {
            ""class"": ""File"",
            ""path"": ""md5sum.txt""
        }
    ],
    ""parent_id"": ""syn10290419""
}
```

Finally, results were submitted:

```shell
cwltool --basedir md5sum/ --outdir md5sum/ \
        --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
        dockstore-tool-synapse-submit.cwl md5sum/md5sum_submit.cwl.json
```

---",9635415
md5sum,9635835_report.md,"## Dockstore md5sum Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Michael Kotliar""
institution: ""CCHMC, Barski Lab""
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-17""
platform: ""CWL-Airflow""
workflow_type: ""CWL""
runner_version: ""0.0.1""
docker_version: ""1.12.6""
environment: ""local""
env_cpus: ""64""
env_memory: ""251Gb""
env_disk: ""230Gb""
```

### Steps

### Setting up environment
Install CWL-Airflow
```
  cd /home/michael_kotliar/workspaces/airflow/
  git clone https://github.com/Barski-lab/cwl-airflow.git
  cd cwl-airflow
  git checkout v0.0.1
  pip install -e .
```
Run mysql-server:5.7 docker container
```
  cd /home/michael_kotliar/temp/cwl_airflow
  mkdir database
  docker pull mysql/mysql-server:5.7
  docker run -v /home/michael_kotliar/temp/cwl_airflow/database:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=airflow -e MYSQL_DATABASE=airflow -e MYSQL_USER=airflow -e MYSQL_PASSWORD=airflow -p 6603:3306 -d mysql/mysql-server:5.7
```
Update Airflow configuration file `/home/michael_kotliar/airflow/airflow.cfg`
```
  executor = LocalExecutor
  sql_alchemy_conn = mysql://airflow:airflow@127.0.0.1:6603/airflow
```
Install synapse client
```
  pip install synapseclient
```
Create empty folder for workflow running
```
  cd /home/michael_kotliar/temp/cwl_airflow/
  mkdir md5sum
```
Create Synapse credentials file `/home/michael_kotliar/temp/cwl_airflow/md5sum/.synapseConfig`, put there Synapse ID and password
```
[authentication]
username: user@usermail.org
password: <user-password>
```

### Downloading required files
Download tools to fetch workflow input data
```
cd /home/michael_kotliar/temp/cwl_airflow/md5sum
synapse -c .synapseConfig get syn9771740  # md5sum_get.json
synapse -c .synapseConfig get syn9732885   # dockstore-tool-synapse-submit.cwl
synapse -c .synapseConfig get syn9770802   # dockstore-tool-synapse-get.cwl
```
Download workflow input data
```
cd /home/michael_kotliar/temp/cwl_airflow/md5sum
cwltool --debug --non-strict dockstore-tool-synapse-get.cwl md5sum_get.cwl.json
```
Wait until downloading is finished

### Running workflow
Run the workflow
```
cwl-airflow-runner --debug md5sum.cwl md5sum.cwl.json
```

### Validating results
Run checker tool
```
cd /home/michael_kotliar/temp/cwl_airflow/md5sum
cwltool --debug --non-strict md5sum_checker.cwl md5sum_checker.cwl.json
```
Check results
```
cat results.json
``` 
```json
{ ""Overall"" : true, ""Steps"" : { ""md5sum_check"" : true } }
```
### Submitting results
Update `md5sum_submit.cwl.json` with correct
`team_name` - the name of your team in plain text format (e.g., ""GA4GH-Sage Contenders"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
Run the tool
```
cwltool --debug --non-strict dockstore-tool-synapse-submit.cwl md5sum_submit.cwl.json
```
***Running time:*** 25 sec  
***Disk usage:*** 68K
",9635835
md5sum,9635967_report.md,"## Dockstore md5sum Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Jeff Johnston"" # your name here
institution: ""Children's Mercy"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

```YAML
date_accessed: ""2017-09-15"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170817131858"" # indicate executor version used
docker_version: ""17.06.2-ce, build cec0b72"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""1"" # indicate number of cores in environment
env_memory: ""8GB"" # indicate available RAM in environment
env_disk: ""133GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps


#### 1. Setup

This workflow was run on a MacBook Pro running macOS 10.12.6. Docker and Miniconda2 were installed. Docker was configured to use 1 core and 8GB of RAM. A conda environment was built using the following conda YAML file:

```yaml
channels:
  - bioconda
  - conda-forge
  - anaconda
  - r
dependencies:
  - cwltool=1.0.20170817131858
  - synapseclient
```

The Synapse client was configured by editing `~/.synapseConfig`.

##### 2. Download

The following commands were run within the conda environment:

```shell
conda
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
synapse get syn9771740 # md5sum_get.cwl.json
cwltool --outdir md5sum --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ \
        --non-strict dockstore-tool-synapse-get.cwl md5sum_get.cwl.json
cp ~/.synapseConfig md5sum
```

##### 3. Run

Next, the workflow was executed in the conda environment.

```shell
cwltool --basedir md5sum/ --outdir md5sum/ \
    --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
    md5sum/md5sum.cwl md5sum/md5sum.cwl.json
```

##### 4. Validate

After running, the workflow results were validated:

```shell
cwltool --basedir md5sum/ --outdir md5sum/ \
        --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
        md5sum/md5sum_checker.cwl md5sum/md5sum_checker.cwl.json
```

##### 5. Submit

`md5sum_submit.cwl.json` was modified for submission:

```yaml
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""Childrens Mercy GA4GH-DREAM Challenge Team"",
    ""eval_id"": ""9603664"",
    ""file"": [
        {
            ""class"": ""File"",
            ""path"": ""md5sum.txt""
        }
    ],
    ""parent_id"": ""syn10290419""
}
```

Finally, results were submitted:

```shell
cwltool --basedir md5sum/ --outdir md5sum/ \
        --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
        dockstore-tool-synapse-submit.cwl md5sum/md5sum_submit.cwl.json
```

---
",9635967
md5sum,9635982_report.md,"## Dockstore md5sum Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Vipin T. Sreedharan""
institution: ""ETH Zürich, NEXUS Personalized Health Technologies""
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-14"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170828135420"" # indicate executor version used
docker_version: ""1.12.6"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""32Gb"" # indicate available RAM in environment
env_disk: ""140Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

At our institute, on a compute machine called `wfexec` with Red Hat Enterprise Linux Server release 7.4 (Maipo), installed Docker. Created a group named ""docker"" since it was preferred to use Docker as a non-root user on this machine. The instance has a non-root user called `wfrunner`. Next added the non-root user `wfrunner` to the ""docker"" group. Then started the docker engine and all the below commands were executed using root user privileges [sudo]:
```shell
yum install docker
groupadd docker 
usermod -aG docker wfrunner  
systemctl start docker 
```

As a non-root user on `wfexec` machine, installed Anaconda and cwltool to the home path of user `wfrunner`:
```shell
su - wfrunner
wget https://repo.continuum.io/archive/Anaconda2-4.4.0-Linux-x86_64.sh
bash Anaconda2-4.4.0-Linux-x86_64.sh 
conda install virtualenv
virtualenv -p python2 /home/wfrunner/venv
source /home/wfrunner/venv/bin/activate
pip install cwltools
deactivate
```

Created a utilities directory for storing the `synapse-get` and `synapse-submit` CWL tools. In the same folder, created a file with my Synapse credentials. 
```shell
mkdir -p /home/wfrunner/synapse_utils
cd /home/wfrunner/synapse_utils
wget -O dockstore-tool-synapse-get.cwl https://raw.githubusercontent.com/GA4GH-DREAM/dockstore-tool-synapse-get/master/Dockstore.cwl 
wget -O dockstore-tool-synapse-submit.cwl https://raw.githubusercontent.com/GA4GH-DREAM/dockstore-tool-synapse-submit/master/Dockstore.cwl
touch .synapse_config
vim .synapse_config
[WRITE] Synapse username & password
```

#### 2. Download required files

Downloaded data config file md5sum_get.cwl.json from the website `https://www.synapse.org/#!Synapse:syn8507133/wiki/451410` for the **md5sum** workflow. Created a directory for the storing the workflow associated data downloading JSON parameter file: 
```shell
mkdir -p /home/wfrunner/data_config_files
mv ~/md5sum_get.cwl.json ~/data_config_files
cd /home/wfrunner/data_config_files
vim md5sum_get.cwl.json
[PASTE] /home/wfrunner/synapse_utils/.synapse_config
```

#### 3. Provision all workflow files

Created a working directory for the current workflow. Used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `md5sum_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
mkdir -p /home/wfrunner/md5sum
cd /home/wfrunner/md5sum
cwltool --non-strict ~/synapse_utils/dockstore-tool-synapse-get.cwl ~/data_config_files/md5sum_get.cwl.json
```

#### 4. Run main workflow

Again `cwltool` was used to run the workflow, as defined in `md5sum.cwl` and parameterized by `md5sum.cwl.json`:
```shell
cd /home/wfrunner/md5sum
cwltool md5sum.cwl md5sum.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, used `cwltool` to run the checker as follows:
```shell
cd /home/wfrunner/md5sum
cwltool md5sum_checker.cwl md5sum_checker.cwl.json
cat results.json | grep -i overall
```

#### 6. Submit workflow outputs

Modified the parameters in `md5sum_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": ""/home/wfrunner/synapse_utils/.synapse_config""
    },
    ""team_name"": """",
    ""eval_id"": ""9603664"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""md5sum.txt""
        }
    ],
    ""parent_id"": ""syn10820429""
}
```

Finally, submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cd /home/wfrunner/md5sum
cwltool --non-strict ~/synapse_utils/dockstore-tool-synapse-submit.cwl md5sum_submit.cwl.json
```

---",9635982
md5sum,9636369_report.md,"## Dockstore md5sum Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Gary Luu"" # your name here
institution: ""Dockstore - OICR"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-20"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""dockstore 1.2.10"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.2.10"" # indicate executor version used
docker_version: ""17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""4"" # indicate number of cores in environment
env_memory: ""32 GB"" # indicate available RAM in environment
env_disk: ""470 GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-10""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

On a personal desktop, I installed Docker, pip, cwltool, and the Dockstore command-line helper using a procedure similar to https://github.com/denis-yuen/2017-cloud-workflows-misc/blob/master/install-and-run-with-dockstore.md .  

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir md5sum
cd md5sum
cp ~/.synapseConfig .
```
#### 2. Download required files

I downloaded md5sum_get.cwl.json from the website. 


#### 3. Provision all workflow files

I used the synapse-get tool from Dockstore.
```shell
dockstore tool launch --entry quay.io/ga4gh-dream/dockstore-tool-synapse-get --json md5sum_get.cwl.json
```

#### 4. Run main workflow

I used dockstore to launch the recently downloaded md5sum.cwl
```shell
dockstore workflow launch --local-entry md5sum.cwl --json md5sum.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `dockstore` to run the checker as follows:
```shell
dockstore tool launch --local-entry md5sum_checker.cwl --json md5sum_checker.cwl.json
cat results.json | grep Overall
```

#### 6. Submit workflow outputs

I modified the parameters in `md5sum_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""Dockstore Team"",
    ""eval_id"": ""9603664"",
    ""file"": [
        {
            ""class"": ""File"",
            ""path"": ""md5sum.txt""
        }
    ],
    ""parent_id"": ""syn9877725""
}
```

Finally, I submitted outputs using dockstore-tool-synapse-submit`:
```shell
dockstore tool launch --entry quay.io/ga4gh-dream/dockstore-tool-synapse-submit --json md5sum_submit.cwl.json
```

---",9636369
md5sum,9636720_report.md,"## Dockstore md5sum Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Jonathon Saunders""
institution: ""Children's Mercy Hospital""
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-07-19"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170817131858"" # indicate executor version used
docker_version: ""Docker version 17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""4"" # indicate number of cores in environment
env_memory: ""16"" # indicate available RAM in environment
env_disk: ""500gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-10""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

On a personal laptop with Docker and Anaconda installed, I created and configured a virtual environment as follows:
```shell
conda create -n md5sum
source activate md5sum
pip install --upgrade pip
pip install schema-salad==2.2.20170222151604 cwltool==1.0.20170217172322
pip install synapseclient
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir md5sum
cd md5sum
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **hello_world** workflow:
```shell
synapse get syn9771740 # md5sum_get.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `md5sum_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl md5sum_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `md5sum.cwl` and parameterized by `md5sum.cwl.json`:
```shell
cwltool md5sum.cwl md5sum.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool md5sum_checker.cwl md5sum_checker.cwl.json
cat results.json | grep -i overall
```

#### 6. Submit workflow outputs

I modified the parameters in `md5sum_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""UCSC GA4GH-DREAM Challenge Team"",
    ""eval_id"": ""9603664"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""md5sum.result""
        }
    ],
    ""parent_id"": ""syn9920362""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl md5sum_submit.cwl.json
```

---",9636720
md5sum,9637535_report.md,"## Dockstore md5sum Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Byunggil Yoo"" # your name here
institution: ""Children's Mercy Hospital"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-07"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cromwell"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""WDL"" # CWL or WDL
runner_version: ""29"" # indicate executor version used
docker_version: ""17.06.0-ce, build 02c1d87"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""48"" # indicate number of cores in environment
env_memory: ""512GB"" # indicate available RAM in environment
env_disk: ""367TB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

On a local machine (CentOS Linux release 7.2.1511) with Docker and Anaconda installed, conda environment is created using the following YAML file:
```shell
channels:
  - bioconda
  - conda-forge
  - anaconda
  - r
dependencies:
  - cwltool=1.0.20170817131858
  - synapseclient
```
The Synapse client was configured by editing `~/.synapseConfig`

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **md5sum** workflow:
```shell
synapse get syn9771740 # md5sum_get.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `md5sum_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --outdir md5sum --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ \
              --non-strict dockstore-tool-synapse-get.cwl md5sum_get.cwl.json
cp ~/.synapseConfig md5sum
```

#### 4. Run main workflow

I used `cromwell` to run the workflow, as defined in `md5sum.wdl` and parameterized by `md5sum.wdl.json`:
```shell
java -Duser.dir=md5sum -jar cromwell-29.jar run \
            md5sum.wdl -i md5sum.wdl.json \
            -m md5sum.wdl.run.metadata 
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I modified md5sum_checker.cwl.json as follows and named as md5sum_checker.wdl.json
``` JSON
{
  ""input_file"": {
        ""class"": ""File"",
        ""path"": ""cromwell-executions/ga4ghMd5/fe9e4836-58df-47fc-bd6a-c6914ba48f55/call-md5/execution/md5sum.txt""
    }
}
```

Then I used `cwltool` to run the checker as follows:
```shell
cwltool --basedir md5sum/ --outdir md5sum/ \
        --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
        md5sum_checker.cwl md5sum_checker.wdl.json
cat results.json | grep -i overall
```

#### 6. Submit workflow outputs

I modified the parameters in `md5sum_submit.cwl.json` as follows and named as md5sum_submit.wdl.json:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""Childrens Mercy GA4GH-DREAM Challenge Team"",
    ""eval_id"": ""9603664"",
    ""file"": [
        {
            ""class"": ""File"",
            ""path"": ""cromwell-executions/ga4ghMd5/fe9e4836-58df-47fc-bd6a-c6914ba48f55/call-md5/execution/md5sum.txt""
        }
    ],
    ""parent_id"": ""syn10814328""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --basedir md5sum/ --outdir md5sum/ \
        --tmpdir-prefix tmp/ --tmp-outdir-prefix tmp/ --non-strict \
        dockstore-tool-synapse-submit.cwl md5sum_submit.wdl.json
```

---",9637535
md5sum,9637566_report.md,"## Dockstore md5sum Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Abraham Chavez"" # your name here
institution: ""UCSC"" # your institution here
```

### Submission overview

```YAML
platform: ""cwltool"" 
workflow_type: ""CWL"" 
runner_version: ""1.0.20170217172322""
docker_version: ""17.06.0-ce-rc4""
environment: ""Google CC"" 
env_cpus: ""4""
env_memory: ""16Gb""
env_disk: ""200Gb""
```
> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps
-------------
#### 1. Set up environment 

If you have not set up your environment and install dependencies like **cwltool**, **dockstore**, **java** and so on
I recommend you follow [**this**](https://www.synapse.org/#!Synapse:syn10220609) instructions.
>**NOTE:**  When configuring docker to run as root. You might encounter problems setting the credentials as directed in digital ocean, try replacing `su - ${USER}` with `sudo su -` and running `usermod -aG docker ${USER}` and `su - ${USER}` inside root terminal.

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir md5sum_cwltool
cd md5sum_cwltool
cp ~/.synapseConfig .
```
Information about `.synapseConfig` can be found [here](https://www.synapse.org/#!Synapse:syn8507133/wiki/451408)

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **hello_world** workflow:
```shell
synapse get syn9771740 # md5sum_get_get.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `md5sum_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl md5sum_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `md5sum.cwl` and parameterized by `md5sum.cwl.json`:
```
cwltool --non-strict md5sum.cwl md5sum.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool --non-strict md5sum_checker.cwl md5sum_checker.cwl.json
cat results.json | grep overall
```

#### 6. Submit workflow outputs

I modified the parameters in `md5sum_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""Your Team Name"",
    ""eval_id"": ""9603664"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""md5sum.result""
        }
    ],
    ""parent_id"": ""yourParentId""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl md5sum_submit.cwl.json`
```

---",9637566
md5sum,9637646_report.md,"## Dockstore md5sum Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Thomas B. Mooney"" # your name here
institution: ""MGI WUSTL"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-26"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170828135420"" # indicate executor version used
docker_version: ""17.06.2-ce"" # from `docker --version`
environment: ""local openstack VM"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""2"" # indicate number of cores in environment
env_memory: ""64 GB"" # indicate available RAM in environment
env_disk: ""160 GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment
Spin up a new OpenStack VM with a Xenial cloud image, then install [docker](https://docs.docker.com/engine/installation/linux/docker-ce/ubuntu/) and  [pyenv](https://github.com/pyenv/pyenv-installer).
Then install the tools to obtain and run the workflows:
```shell
pyenv install 2.7.14
pyenv shell 2.7.14
pip install cwltool
pip install synapseclient
```

Create a directory to hold the results and link in the configuration for connecting to synapse:
```shell
mkdir -p ~/ga4gh/md5sum
cd ~/ga4gh/md5sum
ln -s ~/.synapseConfig .synapseConfig
```

#### 2. Download required files

Download the tools for getting/submitting workflows and the JSON to pull in the ""md5sum"" workflow data:
```shell
synapse get syn9771740 # md5sum_get.cwl.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

The dockstore tool CWL files contain extra information, so the ""get"" workflow must be run with the `--non-strict` option:
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl md5sum_get.cwl.json
```

#### 4. Run main workflow

Now run the workflow obtained in the previous step, again with `cwltool`:
```shell
cwltool md5sum.cwl md5sum.cwl.json
```

#### 5. Run workflow checker tool

This completes quickly, so then the checker workflow is run to verify the results:
```shell
cwltool md5sum_checker.cwl md5sum_checker.cwl.json
```

This produces a report, `results.json`:
```JSON
{ ""Overall"" : true, ""Steps"" : { ""md5sum_check"" : true } }
```

#### 6. Submit workflow outputs

Modify `md5sum_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""MGI WUSTL"",
    ""eval_id"": ""9603664"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""md5sum.result""
        }
    ],
    ""parent_id"": ""syn10907811""
}
```

Finally, run the workflow to submit the results:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl md5sum_submit.cwl.json
```

---",9637646
md5sum,9637736_report.md,"## Dockstore md5sum Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""John Chilton"" # your name here
institution: ""Galaxy Project"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-26"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""Galaxy via Planemo"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""Planemo 0.46.1"" # indicate executor version used
docker_version: ""Docker version 17.06.2-ce, build cec0b72"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""16Gb"" # indicate available RAM in environment
env_disk: ""200Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-10""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

I have documented the steps on this page - https://github.com/galaxyproject/planemo/tree/master/project_templates/ga4gh_execution_challenge_phase_2 including general information about setting up Synapse user information and installing Planemo at the top and specific information regarding this workflow further down at https://github.com/galaxyproject/planemo/tree/master/project_templates/ga4gh_execution_challenge_phase_2#md5sum.

---",9637736
md5sum,9643866_report.md,"## Dockstore md5sum Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Michael Krause"" # your name here
institution: ""UCSC Genomics Institute"" # your institution here
```

### Submission overview

```YAML
date_accessed: ""2017-10-10"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170217172322"" # indicate executor version used
docker_version: ""17.09.0-ce, build afdb6d4"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""2"" # indicate number of cores in environment
env_memory: ""4GB"" # indicate available RAM in environment
env_disk: ""120GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

On a personal laptop with the Java (v. 1.8, Oracle), Docker (CE), Python and ""pip"", schema-salad"", ""cwltool"", and ""synapseclient""  installed I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:

```shell
mkdir md5sum
cd md5sum
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **hello_world** workflow:
```shell
synapse get syn9771740 # md5sum_get.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `md5sum_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl md5sum_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `md5sum.cwl` and parameterized by `md5sum.cwl.json`:
```shell
cwltool md5sum.cwl md5sum.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool md5sum_checker.cwl md5sum_checker.cwl.json
cat results.json | grep -i overall
```

#### 6. Submit workflow outputs

I modified the parameters in `md5sum_submit.cwl.json` as follows:

```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""UCSC GA4GH-DREAM Challenge Team"",
    ""eval_id"": ""9603664"",
    ""file"": [
        {
            ""class"": ""File"",
            ""path"": ""md5sum.txt""
        }
    ],
    ""parent_id"": ""syn11189483""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl md5sum_submit.cwl.json
```

---",9643866
md5sum,9645925_report.md,"## Dockstore md5sum Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Azza E. Ahmed"" # your name here
institution: ""University of Khartoum, Sudan"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-10-19"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170217172322"" # indicate executor version used
docker_version: ""17.03.1-ce, build c6d412e"" # from `docker --version`
environment: "" EGI fedcloud"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""1"" # indicate number of cores in environment
env_memory: ""1G"" # indicate available RAM in environment
env_disk: ""elastic"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-10""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

On a personal laptop with Docker and Anaconda installed, I created and configured a virtual environment as follows:
```shell
#Needed to install anaconda first:
wget https://repo.continuum.io/archive/Anaconda2-5.0.0.1-Linux-x86_64.sh
bash Anaconda2-5.0.0.1-Linux-x86_64.sh

conda create -n md5sum
source activate md5sum
pip install --upgrade pip
pip install schema-salad==2.2.20170222151604 cwltool==1.0.20170217172322
pip install synapseclient
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir md5sum
cd md5sum
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **hello_world** workflow:
```shell
synapse get syn9771740 # md5sum_get.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `md5sum_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl md5sum_get.cwl.json
```

#### 4. Run main workflow

To run the workflow, I needed to make docker accessible to my user, so first:

```shell
sudo usermod -a -G docker $USER
```

Then, I used `cwltool` to run the workflow, as defined in `md5sum.cwl` and parameterized by `md5sum.cwl.json`:
```shell
cwltool md5sum.cwl md5sum.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool md5sum_checker.cwl md5sum_checker.cwl.json
cat results.json | grep -i overall
```

#### 6. Submit workflow outputs

I modified the parameters in `md5sum_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""UCSC GA4GH-DREAM Challenge Team"",
    ""eval_id"": ""9603664"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""md5sum.txt""
        }
    ],
    ""parent_id"": ""syn9920362""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl md5sum_submit.cwl.json
```

---",9645925
md5sum,9646111_report.md,"## Dockstore md5sum Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Joe Slagel"" # your name here
institution: ""Institute for Systems Biology"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""10/29/2017"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170822192924"" # indicate executor version used
docker_version: ""1.12.6, build 78d1802"" # from `docker --version`
environment: ""Google Compute"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""30 GB"" # indicate available RAM in environment
env_disk: ""250 GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-10""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

Using the Google Console I launched an Ubuntu 16.04 LTS ubuntu based virtual machine and logged in using google compute ssh.  I then ran the following commands:

```shell
sudo apt-get update
sudo apt-get install docker.io
sudo apt-get install python-pip
sudo apt-get pip install cwltool
sudo pip install --upgrade synapseclient 
```

Next I created Synapse credentials file in my home directory:

```shell
vi ~/.synapseConfig
```


#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the md5sum JSON parameters:
```shell
synapse get syn9771740 # md5sum_get.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `md5sum_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
sudo cwltool dockstore-tool-synapse-get.cwl md5sum_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `md5sum.cwl` and parameterized by `md5sum.cwl.json`:
```shell
sudo cwltool md5sum.cwl md5sum.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
sudo cwltool md5sum_checker.cwl md5sum_checker.cwl.json
```

#### 6. Submit workflow outputs

I modified the parameters in submission json file to include the parent_id of a folder I created under our project.

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
sudo cwltool -dockstore-tool-synapse-submit.cwl md5sum_submit.cwl.json > submit.log 2>&1
```
---",9646111
md5sum,9646114_report.md,"## Dockstore md5sum Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Madelyn Reyes""
institution: ""ISB-CGC/CSRA"" 
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""09/28/2017"" 
platform: ""cwltool"" 
workflow_type: ""CWL"" 
runner_version: ""1.0.20170217172322""
docker_version: ""17.09.0-ce, build afdb6d4"" 
environment: ""Google Compute"" 
env_cpus: ""8""
env_memory: ""35GB""
env_disk: ""250 GB"" 
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-10""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

On a personal laptop with Docker and Anaconda installed, I created and configured a virtual environment as follows:
```shell
conda create -n md5sum
source activate md5sum
pip install --upgrade pip
pip install schema-salad==2.2.20170222151604 cwltool==1.0.20170217172322
pip install synapseclient
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir md5sum
cd md5sum
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **hello_world** workflow:
```shell
synapse get syn9771740 # md5sum_get.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `md5sum_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl md5sum_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `md5sum.cwl` and parameterized by `md5sum.cwl.json`:
```shell
cwltool md5sum.cwl md5sum.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool md5sum_checker.cwl md5sum_checker.cwl.json
cat results.json | grep -i overall
```

#### 6. Submit workflow outputs

I modified the parameters in `md5sum_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""UCSC GA4GH-DREAM Challenge Team"",
    ""eval_id"": ""9603664"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""md5sum.txt""
        }
    ],
    ""parent_id"": ""syn9920362""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl md5sum_submit.cwl.json
```

---",9646114
md5sum,9646177_report.md,"## Dockstore md5sum Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Abraham Chavex"" # your name here
institution: ""UCSC GA4GH-DREM Challenge Team"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-10-09"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""dockstore cli "" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.2.10"" # indicate executor version used
docker_version: ""17.06.2-ce"" # from `docker --version`
environment: ""Google CC"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""4"" # indicate number of cores in environment
env_memory: ""16Gb"" # indicate available RAM in environment
env_disk: ""200Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-10""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

On a personal laptop with Docker and Anaconda installed, I created and configured a virtual environment as follows:
```shell
conda create -n md5sum
source activate md5sum
pip install --upgrade pip
pip install schema-salad==2.2.20170222151604 cwltool==1.0.20170217172322
pip install synapseclient
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir md5sum
cd md5sum
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **hello_world** workflow:
```shell
synapse get syn9771740 # md5sum_get.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `md5sum_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl md5sum_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `md5sum.cwl` and parameterized by `md5sum.cwl.json`:
```shell
cwltool md5sum.cwl md5sum.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool md5sum_checker.cwl md5sum_checker.cwl.json
cat results.json | grep -i overall
```

#### 6. Submit workflow outputs

I modified the parameters in `md5sum_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""UCSC GA4GH-DREAM Challenge Team"",
    ""eval_id"": ""9603664"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""md5sum.txt""
        }
    ],
    ""parent_id"": ""syn9920362""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl md5sum_submit.cwl.json
```

---",9646177
md5sum,9655149_report.md,"## Dockstore md5sum Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Jim Vlasblom"" # your name here
institution: ""DNAstack"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-11-23"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""DNAstack/Cromwell"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""WDL"" # CWL or WDL
runner_version: ""28"" # indicate executor version used
docker_version: ""v1alpha2 Google Pipelines API"" # from `docker --version`
environment: ""Google Compute"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""1"" # indicate number of cores is environment
env_memory: ""512MB"" # indicate available RAM in environment
env_disk: ""10GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-10""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up (submission client) environment

On an instance (e.g. could be a local laptop, but I used a Google compute engine instance) based on Debian 9.2 with synapse, python, pip, and docker installed:
```shell
pip install --upgrade pip
pip install schema-salad==2.2.20170222151604 cwltool==1.0.20170217172322
pip install synapseclient
mkdir md5sum
cd md5sum
synapse get syn9771740 # md5sum_get.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir md5sum
cd md5sum
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **hello_world** workflow:
```shell
synapse get syn9771740 # md5sum_get.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `md5sum_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl md5sum_get.cwl.json
```

#### 4. Run main workflow
##### DNAstack Project Configuration:
- Visit https://dnastack.com
- Click 'Sign in'
- Click 'Sign up' and register a new account
- Click 'Create a new organization'.  Entered 'DNAstack DREAM Challenges'.
- Click 'Create' beside projects to create a new project.  Entered 'Phase 2'.  Under Billing, selected 'Free Trial'.

##### Create and run md5sum workflow from Dockstore:
- Click 'Workflows', then 'Create Workflow', then 'Import from Dockstore'.
- Type 'md5sum'.  Choose 'briandoconnor/dockstore-workflow-md5sum/dockstore-wdl-workflow-md5sum', and select Version 1.4.0 from the dropdown.
- Click 'Import'.
- In the workflow run section that appears, fill out the input for ga4ghMd5.inputFile by clicking 'choose a file', then click '+ Choose Files' and locate the input file /path/to/md5sum/md5sum.input
- After selecting the input, click 'run', and then select the 'workflow job' link.
- When job is done, click 'outputs' tab and download the outputs to a local directory on the submission client instance (e.g. laptop, GCE instance, etc.): /path/to/md5sum/outputs

#### 5. Run workflow checker tool
On submission client instance:
```shell
cd /path/to/md5sum
cwltool md5sum_checker.cwl --input_file outputs/md5sum.txt
```

#### 6. Submit workflow outputs

I modified the parameters in `md5sum_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""DNAstack"",
    ""eval_id"": ""9603664"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""outputs/md5sum.txt""
        }
    ],
    ""parent_id"": ""syn11503455""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl md5sum_submit.cwl.json
```

---",9655149
md5sum,9655241_report.md,"## Dockstore md5sum Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Azza E Ahmed"" # your name here
institution: ""University of Khartoum"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-11-29"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""Rabix"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.0"" # indicate executor version used
docker_version: ""17.03.1-ce, build c6d412e"" # from `docker --version`
environment: ""EGI FedCloud"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""32Gb"" # indicate available RAM in environment
env_disk: ""50GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-10""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

I launched an EGI FedCloud instance of type `EGI Docker (Ubuntu 16.04)` as provided by `CESNET MetaCloud (IaaS Cloud)` with one node, mounted a 50GB volume, and Docker pre-installed.

```shell
# Adding my user to the docker group
sudo usermod -a -G docker $USER

# Installing java:
sudo apt-get update
sudo apt-get install default-jre
sudo apt-get install default-jdk

# Installing Rabix:
wget https://github.com/rabix/bunny/releases/download/v1.0.0/rabix-1.0.0.tar.gz
tar -xvzf rabix-1.0.0.tar.gz
export PATH=$PATH://home/azza/software/rabix-cli-1.0.0

# Installing synapse environment
sudo pip install synapseclient
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir md5sum
cd md5sum
vi .synapseConfig # [Adding in my Synapse credentials]
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **hello_world** workflow:
```shell
synapse  -c  .synapseConfig  get syn9771740 # md5sum_get.json
synapse  -c  .synapseConfig get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse  -c  .synapseConfig get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `rabix` to run `dockstore-tool-synapse-get.cwl` with parameters in `md5sum_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
rabix ./dockstore-tool-synapse-get.cwl ./md5sum_get.cwl.json
```

#### 4. Run main workflow
Rabix creates its own directory structure that contains the downloaded files. In this case, it is named after the called script + a date-time stamp. So, I go to that directory to run the workflow:

```shell
cd dockstore-tool-synapse-get-2017-11-28-173356.368/root/synapse_files

rabix  ./md5sum.cwl ./md5sum.cwl.json
```

#### 5. Run workflow checker tool
Again, Rabix have created its own directory of processed files, so I change the output `path` within  the `md5sum_checker.cwl.json` to point to the correct location before running the checker:

```shell
$ vi md5sum_checker.cwl.json
 # Change path to: /home/azza/md5sum/dockstore-tool-synapse-get-2017-11-28-173356.368/root/synapse_files/md5sum-2017-11-28-173523.191/root/md5sum/md5sum.txt

$ rabix ./md5sum_checker.cwl ./md5sum_checker.cwl.json

$ cat md5sum_checker-2017-11-28-173718.246/root/results.json | grep -i overall
```

#### 6. Submit workflow outputs

Now, I'm ready to submit after modifying  `md5sum_submit.cwl.json` to point to the correct output `path` as in step 5 above, and then also changing the `team_name` and `parent_id`. I just copy the docker submission script and synapse credentials beforehand.

```shell
vi md5sum_submit.cwl.json
cp ../../../dockstore-tool-synapse-submit.cwl .
cp ../../../.synapseConfig .

rabix ./dockstore-tool-synapse-submit.cwl ./md5sum_submit.cwl.json
```

---",9655241
md5sum,9655242_report.md,"## Dockstore md5sum Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Azza E Ahmed"" # your name here
institution: ""University of Khartoum"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
ate_accessed: ""2017-11-29"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""Toil"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""3.12.0"" # indicate executor version used
docker_version: ""17.03.1-ce, build c6d412e"" # from `docker --version`
environment: ""EGI FedCloud"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""32Gb"" # indicate available RAM in environment
env_disk: ""50GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-10""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

I launched an EGI FedCloud instance of type `EGI Docker (Ubuntu 16.04)` as provided by `CESNET MetaCloud (IaaS Cloud)` with one node, mounted a 50GB volume, and Docker pre-installed.

```shell
# Adding my user to the docker group
sudo usermod -a -G docker $USER

# Installing Toil:
sudo pip install toil
sudo pip install toil[cwl]

# And synapse
sudo pip install synapseclient
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir md5sum
cd md5sum
vi .synapseConfig #Adding my credintials
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **hello_world** workflow:
```shell
synapse -c .synapseConfig get syn9771740 # md5sum_get.json
synapse -c .synapseConfig get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse -c .synapseConfig get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files
I `toil-cwl-runner` to run `dockstore-tool-synapse-get.cwl` with parameters in `md5sum_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.

But, for this step to work, I needed to first reduce the resource requirements of the workflow, `outdirMin`, in the `dockstore-tool-md5sum.cwl`, from the default `512000` to `512` so it may run on my environment. 
```shell
$ vi dockstore-tool-md5sum.cwl
# Change line 33: to   outdirMin: 512

$ toil-cwl-runner --not-strict dockstore-tool-synapse-get.cwl md5sum_get.cwl.json
```

#### 4. Run main workflow

I again used `toil-cwl-runner` to run the workflow, as defined in `md5sum.cwl` and parameterized by `md5sum.cwl.json`:
```shell
toil-cwl-runner --not-strict md5sum.cwl md5sum.cwl.json
```

#### 5. Run workflow checker tool

As in step 2, I needed to first reduce the resource requirements of the workflow, `outdirMin`, in the `md5sum_checker.cwl`, from the default `512000` to `512` so it may run on my environment.  Then, I could  verify workflow results before submission, using `toil-cwl-runner`:
```shell
$ vi md5sum_checker.cwl
 # Change   outdirMin: 512

$ toil-cwl-runner  md5sum_checker.cwl md5sum_checker.cwl.json

$ cat results.json
{ ""Overall"" : true, ""Steps"" : { ""md5sum_check"" : true } } 

```

#### 6. Submit workflow outputs

I modified the parameters in `md5sum_submit.cwl.json`  to point to my `team_name` and `parent_id`, and now I'm able to submit:

```shell
toil-cwl-runner dockstore-tool-synapse-submit.cwl md5sum_submit.cwl.json
```

---",9655242
md5sum,9655243_report.md,"## Dockstore md5sum Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Azza E Ahmed"" # your name here
institution: ""University of Khartoum"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-11-29"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cromwell"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""WDL"" # CWL or WDL
runner_version: ""29"" # indicate executor version used
docker_version: ""17.03.1-ce, build c6d412e"" # from `docker --version`
environment: ""EGI FedCloud"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""32Gb"" # indicate available RAM in environment
env_disk: ""50GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-10""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

I launched an EGI FedCloud instance of type `EGI Docker (Ubuntu 16.04)` as provided by `CESNET MetaCloud (IaaS Cloud)` with one node, mounted a 50GB volume, and Docker pre-installed.

I created and configured a virtual environment as follows:
```shell
# Adding my user to the docker group
sudo usermod -a -G docker $USER

# Installing java:
sudo apt-get update
sudo apt-get install default-jre
sudo apt-get install default-jdk

# Installing pre-requisits: sbt:
echo ""deb https://dl.bintray.com/sbt/debian /"" | sudo tee -a /etc/apt/sources.list.d/sbt.list
sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 2EE0EA64E40A89B84B2DF73499E82A75642AC823
sudo apt-get update
sudo apt-get install sbt 

# Downloading cromwell:
wget https://github.com/broadinstitute/cromwell/releases/download/29/cromwell-29.jar

# I still needed cwltool for some steps, so it was installed as usual.
```


I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir md5sum
cd md5sum
vi .synapseConfig .# Adding my synapse credentials
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **hello_world** workflow:
```shell
synapse get syn9771740 # md5sum_get.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `md5sum_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl md5sum_get.cwl.json
```

#### 4. Run main workflow

Now, I'm using `cromwell` to run the workflow:

```shell
java -jar $cromwell run md5sum.wdl --inputs md5sum.wdl.json

```

#### 5. Run workflow checker tool

`cromwell` creates its own directroy tree containing the results of processing. Therefore, I point the `md5sum_checker.cwl.json` to the correct path within that tree of the output file:

```shell
$ vi md5sum_checker.cwl
# The path is changed as in:
                     cromwell-executions/ga4ghMd5/c2097ae2-a22e-4cc3-95cb-b41cb2add082/call-md5/execution/md5sum.txt 

$ cwltool md5sum_checker.cwl md5sum_checker.cwl.json
$ cat results.json
{ ""Overall"" : true, ""Steps"" : { ""md5sum_check"" : true } }
```

#### 6. Submit workflow outputs

Similarly, I modified the parameters in `md5sum_submit.cwl.json` to point to the correct path of the output file as in the previous step, and also added my `team_name`,  `parent_id`. Now, I'm ready to submit:

```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl md5sum_submit.cwl.json
```

---",9655243
md5sum,9655735_report.md,"## Dockstore md5sum Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Joe Slagel"" # your name here
institution: ""Institute for Systems Biology"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-11-28"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""ISB-CGC dsub/cwltool/cwl_runner.sh"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""cwltool-1.0.20171107133715"" # indicate executor version used
docker_version: ""17.11.0"" # from `docker --version`
environment: ""Google Compute"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""2"" # indicate number of cores in environment
env_memory: ""7.5"" # indicate available RAM in environment
env_disk: ""200"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

I was curious as to how much of the challenge I could do using only dsub and cwl_runner.sh.

#### 1. Set up environment

On a personal Google Cloud VM with gcloud, gsutil, dsub and cwl_runner.sh installed:

```shell
gsutil cp ~/.synapseConfig gs://isb-ga4gh-dream/md5sum/data/.synapseConfig
dsub \
   --name dream-setup-md5sum \
   --project cgc-05-0026 \
   --zones 'us-*' \
   --image quay.io/ga4gh-dream/dockstore-tool-synapse-get \
   --input  'CFG=gs://isb-ga4gh-dream/md5sum/data/.synapseConfig' \
   --output-recursive 'OUT=gs://isb-ga4gh-dream/md5sum/data/' \
   --logging 'gs://isb-ga4gh-dream/md5sum/log' \
   --wait \
   --command 'cd ${OUT}; \
              synapse -c ${CFG} get syn9732885; \
              synapse -c ${CFG} get syn9771740; \
              synapse -c ${CFG} get syn9770802; \
              '
```

#### 2. Download required files

```shell
./cwl_runner.sh \
   -m n1-standard-2 \
   -i gs://isb-ga4gh-dream/md5sum/data/.synapseConfig \
   -w gs://isb-ga4gh-dream/md5sum/data/dockstore-tool-synapse-get.cwl \
   -s gs://isb-ga4gh-dream/md5sum/data/md5sum_get.cwl.json \
   -o gs://isb-ga4gh-dream/md5sum/data
```

#### 3. Run main workflow

```shell
./cwl_runner.sh \
   -m n1-standard-2 \
   -r gs://isb-ga4gh-dream/md5sum/data/ \
   -w gs://isb-ga4gh-dream/md5sum/data/md5sum.cwl \
   -s gs://isb-ga4gh-dream/md5sum/data/md5sum.cwl.json \
   -o gs://isb-ga4gh-dream/md5sum/data
```

#### 4. Run workflow checker tool

```shell
./cwl_runner.sh \
   -m n1-standard-2 \
   -r gs://isb-ga4gh-dream/md5sum/data/ \
   -w gs://isb-ga4gh-dream/md5sum/data/md5sum_checker.cwl \
   -s gs://isb-ga4gh-dream/md5sum/data/md5sum_checker.cwl.json \
   -o gs://isb-ga4gh-dream/md5sum/data
```

#### 5. Submit workflow outputs

```shell
gsutil cat gs://isb-ga4gh-dream/md5sum/data/md5sum_submit.cwl.json \
   | jq '.team_name=""ISB-CGC"" | .parent_id=""syn11413175""' \
   | gsutil cp - gs://isb-ga4gh-dream/md5sum/data/md5sum_submit.cwl.json
./cwl_runner.sh \
   -m n1-standard-2 \
   -r gs://isb-ga4gh-dream/md5sum/data/ \
   -w gs://isb-ga4gh-dream/md5sum/data/dockstore-tool-synapse-submit.cwl \
   -s gs://isb-ga4gh-dream/md5sum/data/md5sum_submit.cwl.json \
   -o gs://isb-ga4gh-dream/md5sum/data
```

---",9655735
md5sum,9655813_report.md,"### Workflow description
```YAML
contributor: ""James Eddy""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

### Participant information
```YAML
name: ""Ben Ernest""
institution: ""Digicon Corporation""
```

### Submission overview
```YAML
date_accessed: ""2017-12-05"" 
platform: ""cwltool"" 
workflow_type: ""CWL"" 
runner_version: ""1.0.20170217172322"" 
docker_version: ""17.09.0-ce"" 
environment: ""cluster"" 
env_cpus: ""12"" 
env_memory: ""62Gb"" 
env_disk: ""5Tb"" 
```

### Steps

#### 1. Set up environment, following instructions at https://dockstore.org/quick-start
##### Instructions are for Linux CentOS

Download and install dockstore.  
```shell
mkdir -p ~/bin
curl -L -o ~/bin/dockstore https://github.com/ga4gh/dockstore/releases/download/1.3.0/dockstore
chmod +x ~/bin/dockstore
echo 'export PATH=~/bin:$PATH' >> ~/.bashrc
source ~/.bashrc
```

Create configuration file
```shell
mkdir -p ~/.dockstore
printf ""token: dummy-token\nserver-url: https://dockstore.org:8443\n"" > ~/.dockstore/config
```

Install `pip`
```shell
curl -L -o ~/get-pip.py https://bootstrap.pypa.io/get-pip.py
sudo python get-pip.py
```

Install `cwltool` (**note: version 1.0.20170217172322**)
```shell
sudo pip install setuptools==36.5.0
sudo pip install cwl-runner cwltool==1.0.20170217172322 schema-salad==2.6.20170806163416 avro==1.8.1 ruamel.yaml==0.14.12 requests==2.18.4
```

Install Docker
```shell
sudo yum install -y yum-utils device-mapper-persistent-data lvm2
sudo yum-config-manager --add-repo ""https://download.docker.com/linux/centos/docker-ce.repo""
sudo yum-config-manager --enable extras
sudo yum -y install docker-ce
sudo usermod -aG docker $USER
exec newgrp docker
```

Create aliases to start and stop Docker
```shell
echo 'alias start_docker=""sudo systemctl start docker""' >> ~/.bashrc
echo `alias stop_docker=""sudo systemctl stop docker""' >> ~/.bashrc
source ~/.bashrc
```
Install `synapseclient`
```
sudo pip install synapseclient
```

Create synapse credentials file with the content below, using your own Synapse credentials (no quotes or extra characters).  It can be named anything, but I'm using `.synapseConfig`.
```
[authentication]
username: email
password: password
```

Create a working directory and copy synapse credentials file into that folder.
```shell
mkdir -p md5sum_run
cd md5sum_run
cp ~/.synapseConfig .
```

#### 2. Download required files
Download tools to fetch workflow input data.
```shell
synapse get syn9771740 # md5sum_get.cwl.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files
Start docker, using alias created previously.
```shell
start_docker
```

Use `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `md5sum_get.cwl.json` to download tools and data needed to run the workflow and submit results.
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl md5sum_get.cwl.json
```

#### 4. Run main workflow
Use `cwltool` to run the workflow, as defined in `md5sum.cwl` and parameterized by `md5sum.cwl.json`:
```shell
cwltool --non-strict md5sum.cwl md5sum.cwl.json
```

#### 5. Run workflow checker tool
To verify workflow results before submission, use `cwltool` to run the checker as follows:
```shell
cwltool --non-strict md5sum_checker.cwl md5sum_checker.cwl.json
```

#### 6. Submit workflow outputs
Modify `team_name` and `parent_id` in `md5sum_submit.cwl.json` as shown below, assuming Synapse credentials file is named `.synapseConfig` and located in `~/md5sum_run`.
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""BioGenLink"",
    ""eval_id"": ""9603664"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""md5sum.txt""
        }
    ],
    ""parent_id"": ""syn11565348""
}
```

Submit outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl md5sum_submit.cwl.json
```

Stop Docker if desired.
```shell
stop_docker
```
",9655813
md5sum,9655835_report.md,"## Dockstore md5sum Workflow with arvados-cwl-runner

Arvados container record: https://cloud.curoverse.com/container_requests/qr1hi-xvhdp-9vch6kqxifwbv45

### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Peter Amstutz"" # your name here
institution: ""Veritas Genetics"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-13"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""Arvados"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""arvados-cwl-runner 0d06a2984420d9d48e16ccb6d85982b3dce05644 1.0.20171127193714, arvados-python-client 0.1.20171010180436, cwltool 1.0.20171205195520"" # indicate executor version used
docker_version: ""Docker version 17.05.0-ce, build 89658be"" # from `docker --version`
environment: ""Azure"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""1"" # indicate number of cores in environment
env_memory: ""3.5 GB"" # indicate available RAM in environment
env_disk: ""50 GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-10""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

On a personal laptop with Docker and Anaconda installed, I created and configured a virtual environment as follows:
```shell
virtualenv venv
. venv/bin/activate
pip install synapseclient arvados-cwl-runner
```

I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir md5sum
cd md5sum
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **hello_world** workflow:
```shell
synapse get syn9771740 # md5sum_get.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `md5sum_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool dockstore-tool-synapse-get.cwl md5sum_get.cwl.json
```

#### 4. Run main workflow

I again used `arvados-cwl-runner` to run the workflow, as defined in `md5sum.cwl` and parameterized by `md5sum.cwl.json`:
```shell
arvados-cwl-runner --api=containers --project-uuid= md5sum.cwl md5sum.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool md5sum_checker.cwl md5sum_checker.cwl.json
cat results.json | grep -i overall
```

#### 6. Submit workflow outputs

I modified the parameters in `md5sum_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""Arvados Project"",
    ""eval_id"": ""9603664"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""keep/by_id/47be7c05e23ff5ce8a92cd7498bc0ee5+115/md5sum.txt""
        }
    ],
    ""parent_id"": ""syn9920362""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl md5sum_submit.cwl.json
```

---",9655835
md5sum,9657474_report.md,"## Dockstore md5sum Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Nihar Sheth"" # your name here
institution: ""DNAnexus Inc."" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.


```YAML
date_accessed: ""2017-12-18"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20171107133715"" # indicate executor version used
docker_version: ""17.09.0-ce"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""2"" # indicate number of cores in environment
env_memory: ""16Gb"" # indicate available RAM in environment
env_disk: ""512Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

On a personal laptop with Docker installed, I created and configured a virtual environment as follows:
```shell
virtualenv -p python dream
source dream/bin/activate
pip install --upgrade pip
pip install cwltool
```

I created a working directory for dream workflows  and created a  my Synapse credentials file in that folder:
```shell
mkdir  dreamworkflows
cd dreamworkflows
emacs ~/.synapseConfig .
```

#### 2. Download required files
I downloaded synapse get/submit cwl files using curl  in my working directory for dream workflows 
```shell
curl https://raw.githubusercontent.com/GA4GH-DREAM/dockstore-tool-synapse-get/master/Dockstore.cwl > dockstore-tool-synapse-get.cwl
curl https://raw.githubusercontent.com/GA4GH-DREAM/dockstore-tool-synapse-submit/master/Dockstore.cwl > dockstore-tool-synapse-submit.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `md5sum_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl md5sum_get.cwl.json
```

#### 4. Run main workflow

I again used `cwltool` to run the workflow, as defined in `md5sum.cwl` and parameterized by `md5sum.cwl.json`:
```shell
cwltool md5sum.cwl md5sum.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool md5sum_checker.cwl md5sum_checker.cwl.json
cat results.json | grep -i overall
```

#### 6. Submit workflow outputs

I modified the parameters in `md5sum_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""DNAnexus"",
    ""eval_id"": ""9603664"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""md5sum.txt""
        }
    ],
    ""parent_id"": ""syn11617443""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl md5sum_submit.cwl.json
```

---",9657474
md5sum,9657789_report.md,"## Dockstore md5sum Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Nihar Sheth"" # your name here
institution: ""DNAnexus Inc."" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.


```YAML
date_accessed: ""2017-12-18"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""DNAnexus-WDL"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""WDL"" # CWL or WDL
runner_version: ""0.56"" # indicate executor version used
docker_version: ""dx-docker"" # from `docker --version`
environment: ""DNAnexus"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""autoscale"" # indicate number of cores in environment
env_memory: ""autoscale"" # indicate available RAM in environment
env_disk: ""autoscale"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

On a Linux desktop with dx-toolkit and Docker installed, log into a DNAnexus project.
Also, set environment variables for your project and authentication token.
```
dx env
```
will give you your project ID.  We will assume it's accessible via `$PROJECT`.

You can generate a token via these instructions: https://wiki.dnanexus.com/Command-Line-Client/Login-and-Logout#Authentication-Tokens

Obtain the jar file for the 0.56 release of DNAnexus-WDL: https://github.com/dnanexus/dxWDL/releases/download/0.56/dxWDL-0.56.jar

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **md5sum** workflow:
```shell
synapse get syn9771740 # md5sum_get.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `md5sum_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl md5sum_get.cwl.json
```

#### 4. Run main workflow

Upload downloaded files to the DNAnexus project

```
dx upload -r .
```

Let `$INPUTS` be the JSON file corresponding to the inputs for the WDL workflow (e.g. md5sum.wdl.json)

Edit file names in `$INPUTS` such that they are prefixed with `dx://`, e.g:

```json
{
 ""ga4ghMd5.inputFile"": ""dx://md5sum.input""
}
```

Compile the workflow to your project.

```
java -jar dxWDL-0.56.jar compile md5sum.wdl -input $INPUTS.json
```
The command above outputs workflow ID.  Let's call it `$WORKFLOW`.  You can also call it by name.  Use `dx ls -l` to look for the name of the workflow with that ID.

Run the workflow:

```
dx run $WORKFLOW -f $INPUTS.dx.json
```

You can also use the UI to run it and provide the inputs manually.

#### 5. Run workflow checker tool

Using the UI, or `dx describe` on the analysis ID from above, download relevant outputs using:

`dx download [filename or ID]`

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool md5sum_checker.cwl md5sum_checker.cwl.json
cat results.json | grep -i overall
```

#### 6. Submit workflow outputs

I modified the parameters in `md5sum_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""DNAnexus"",
    ""eval_id"": ""9603664"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""md5sum.txt""
        }
    ],
    ""parent_id"": ""syn11633473""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl md5sum_submit.cwl.json
```

---",9657789
md5sum,9657790_report.md,"## Dockstore md5sum Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Nihar Sheth"" # your name here
institution: ""DNAnexus Inc."" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

```YAML
date_accessed: ""2017-12-18"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""DNAnexus-CWL"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""alpha"" # indicate executor version used
docker_version: ""dx-docker"" # from `docker --version`
environment: ""DNAnexus"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""autoscale"" # indicate number of cores in environment
env_memory: ""autoscale"" # indicate available RAM in environment
env_disk: ""autoscale"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

On a Linux desktop with dx-toolkit and Docker installed, log into a DNAnexus project.
Also, set environment variables for your project and authentication token.
```
dx env
```
will give you your project ID.  We will assume it's accessible via `$PROJECT`.

You can generate a token via these instructions: https://wiki.dnanexus.com/Command-Line-Client/Login-and-Logout#Authentication-Tokens

Clone the dx-cwl repository:

```
https://github.com/dnanexus/dx-cwl.git
```

This was a commit hash used around the time of submission if you'd like to check it out: 2687fe8c671c113e8a780a790a85a18396aea23e

Ensure all pre-requisites are installed using the install-prerequisites.sh script or building a Docker image from the Dockerfile in the repository.

#### 2. Download required files

I used the `synapse get` command to download the `synapse-get` and `synapse-submit` CWL tools as well as the JSON parameters to download data for the **hello_world** workflow:
```shell
synapse get syn9771740 # md5sum_get.json
synapse get syn9732885 # dockstore-tool-synapse-submit.cwl
synapse get syn9770802 # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files

I used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `md5sum_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl md5sum_get.cwl.json
```

#### 4. Run main workflow

Upload downloaded files to the DNAnexus project

```
dx upload -r .
```

Compile the workflow to DNAnexus

```
dx-cwl/dx-cwl compile-workflow md5sum.cwl --project $PROJECT --token $TOKEN
```

Run the workflow on the platform

```
dx-cwl/dx-cwl run-workflow dx-cwl-run/md5sum/md5sum md5sum.cwl.json
```

Note that the file in the second argument is referring to the one you uploaded to the platform.

#### 5. Run workflow checker tool

Using the UI, or `dx describe` on the analysis ID from above, download relevant outputs using:

`dx download [filename or ID]`

To verify workflow results before submission, I used `cwltool` to run the checker as follows:
```shell
cwltool md5sum_checker.cwl md5sum_checker.cwl.json
cat results.json | grep -i overall
```

#### 6. Submit workflow outputs

I modified the parameters in `md5sum_submit.cwl.json` as follows:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""DNAnexus"",
    ""eval_id"": ""9603664"",
    ""file"": [
        {
          ""class"": ""File"",
          ""path"": ""md5sum.txt""
        }
    ],
    ""parent_id"": ""syn11633474""
}
```

Finally, I submitted outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl md5sum_submit.cwl.json
```

---",9657790
md5sum,9657794_report.md,"## Dockstore md5sum Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Joe Slagel"" # your name here
institution: ""ISB"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-12-19"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""ISB-CGC dsub/rabix/cwl_runner.sh"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.3"" # indicate executor version used
docker_version: ""17.11.0"" # from `docker --version`
environment: ""Google Compute"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""2"" # indicate number of cores in environment
env_memory: ""7.5"" # indicate available RAM in environment
env_disk: ""200"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Trying the challenge using dsub and cwl_runner.sh with rabix.

#### 1. Set up environment

On a personal Google Cloud VM with gcloud, gsutil, dsub and cwl_runner.sh installed:

```shell
gsutil cp ~/.synapseConfig gs://isb-ga4gh-dream/rabix/md5sum/data/.synapseConfig
dsub \
   --name dream-setup-md5sum \
   --project cgc-05-0026 \
   --zones 'us-*' \
   --image quay.io/ga4gh-dream/dockstore-tool-synapse-get \
   --input  'CFG=gs://isb-ga4gh-dream/rabix/md5sum/data/.synapseConfig' \
   --output-recursive 'OUT=gs://isb-ga4gh-dream/rabix/md5sum/data/' \
   --logging 'gs://isb-ga4gh-dream/rabix/md5sum/log' \
   --wait \
   --command 'cd ${OUT}; \
              synapse -c ${CFG} get syn9732885; \
              synapse -c ${CFG} get syn9771740; \
              synapse -c ${CFG} get syn9770802; \
              '
```
NOTE: I did have to update cwl_runner.sh to download the latest release of rabix.

### 2. Download required files

```shell
./cwl_runner.sh -r rabix \
   -m n1-standard-2 \
   -i gs://isb-ga4gh-dream/rabix/md5sum/data/.synapseConfig \
   -w gs://isb-ga4gh-dream/rabix/md5sum/data/dockstore-tool-synapse-get.cwl \
   -s gs://isb-ga4gh-dream/rabix/md5sum/data/md5sum_get.cwl.json \
   -o gs://isb-ga4gh-dream/rabix/md5sum/data
```

#### 3. Run main workflow

```shell
gsutil cp -r gs://isb-ga4gh-dream/rabix/md5sum/data/dockstore-tool-synapse-get-*/root/synapse_files/* gs://isb-ga4gh-dream/rabix/md5sum/data/
./cwl_runner.sh -r rabix \
   -m n1-standard-2 \
   -I gs://isb-ga4gh-dream/rabix/md5sum/data/ \
   -w gs://isb-ga4gh-dream/rabix/md5sum/data/md5sum.cwl \
   -s gs://isb-ga4gh-dream/rabix/md5sum/data/md5sum.cwl.json \
   -o gs://isb-ga4gh-dream/rabix/md5sum/data
```

#### 4. Run workflow checker tool

```shell
gsutil cp -r gs://isb-ga4gh-dream/rabix/md5sum/data/md5sum-*/root/md5sum/* gs://isb-ga4gh-dream/rabix/md5sum/data/
./cwl_runner.sh -r rabix \
   -m n1-standard-2 \
   -I gs://isb-ga4gh-dream/rabix/md5sum/data/ \
   -w gs://isb-ga4gh-dream/rabix/md5sum/data/md5sum_checker.cwl \
   -s gs://isb-ga4gh-dream/rabix/md5sum/data/md5sum_checker.cwl.json \
   -o gs://isb-ga4gh-dream/rabix/md5sum/data
```

#### 5. Submit workflow outputs

```shell
gsutil cp -r gs://isb-ga4gh-dream/rabix/md5sum/data/md5sum_checker-*/root/* gs://isb-ga4gh-dream/rabix/md5sum/data/
gsutil cat gs://isb-ga4gh-dream/rabix/md5sum/data/md5sum_submit.cwl.json \
   | jq '.team_name=""ISB-CGC"" | .parent_id=""syn11634306""' \
   | gsutil cp - gs://isb-ga4gh-dream/rabix/md5sum/data/md5sum_submit.cwl.json
./cwl_runner.sh -r rabix \
   -m n1-standard-2 \
   -I gs://isb-ga4gh-dream/rabix/md5sum/data/ \
   -w gs://isb-ga4gh-dream/rabix/md5sum/data/dockstore-tool-synapse-submit.cwl \
   -s gs://isb-ga4gh-dream/rabix/md5sum/data/md5sum_submit.cwl.json \
   -o gs://isb-ga4gh-dream/rabix/md5sum/data
```

--",9657794
md5sum,9657807_report.md,"## Dockstore md5sum Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Junjun Zhang"" # your name here
institution: ""Ontario Institute for Cancer Research"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-11-15"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""JTracker"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
cwltool_version: ""1.0.2017110733715""
runner_version: ""0.2.0a4"" # indicate executor version used
docker_version: ""1.12.6"" # from `docker --version`
environment: ""OpenStack VM"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""96GB"" # indicate available RAM in environment
env_disk: ""2TB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-08-31""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""1.12.6""
environment_ex: ""local"" 
env_cpus_ex: ""8""
env_memory_ex: ""96GB""
env_disk_ex: ""2TB""
```

### Write a JTracker Workflow
The JTracker workflow is written to automatically execute necessary steps to complete a Dream Challenge workflow. The JTracker workflow is named as `dream-challenge-wf-runner`, the source code is checked in Github at: https://github.com/jthub/demo-workflows/tree/master/dream-challenge-wf-runner/workflow.

Once tested out successfully, make a release of the source code. In this case, it is release version 0.0.6: https://github.com/jthub/demo-workflows/releases/tag/dream-challenge-wf-runner.0.0.6

### Register the JTracker Workflow in JTHub
#### Install JTracker command line tool

Follow the instructions here: https://github.com/icgc-dcc/jtracker

Once install successfully, you should be able to see the version number.
```
jt --version
```

#### Signup a JTHub account
Assume we choose `ga4gh_dream` as account name:
```
jt user signup -u ga4gh_dream
```
Login as `ga4gh_dream`
```
jt user login -u ga4gh_dream
```

#### Register the JTracker Dream Challenge Runner Workflow
Register a workflow is basically provide information to access the JTracker workflow source code in GitHub.
```
jt wf register --git-server https://github.com --git-account jthub --git-repo demo-workflows \
                       --git-path dream-challenge-wf-runner --git-tag dream-challenge-wf-runner.0.0.6 \
                       --wf-name dream-challenge-wf-runner --wf-version 0.0.6
```
To list all registered workflows in your account, do this:
```
jt wf ls
```

### Create a Job Queue
Once we have the workflow registered, you will be able to create a job queue for it.
```
jt queue add --wf-name dream-challenge-wf-runner --wf-version 0.0.6
```
Upon success, you will get a unique job queue ID. In my case, my queue ID is: `758b7668-0057-4ef6-a5b0-6f48acf38583`

To list all job queues you created, do this:
```
jt queue ls
```

### Add workflow job to the above queue
If we want to run `pcawg-sanger-variant-caller`, fill out the appropriate parameters in the job JSON as below:
```
jt job add -q 758b7668-0057-4ef6-a5b0-6f48acf38583 -j '
{
    ""workflow_name"": ""md5sum"",
    ""workflow_type"": ""CWL"",
    ""data_syn_id"": ""syn10167920"",
    ""wf_file_name"": ""md5sum.cwl"",
    ""job_file_name"": ""md5sum.cwl.json"",
    ""checker_wf_file_name"": ""md5sum_checker.cwl"",
    ""checker_job_file_name"": ""md5sum_checker.cwl.json"",
    ""submit_job_file_name"": ""md5sum_submit.submit.json"",
    ""team_name"": ""PCAWG-Tech"",
    ""syn_parent_id"": ""syn11638600"",
    ""eval_id"": ""9603664""
}
'
```
To list all jobs in the queue:
```
jt job ls -q 758b7668-0057-4ef6-a5b0-6f48acf38583
```
Note that the above steps can be done on any computer, it could be a normal workstation or a laptop.


### Run the above queued Sanger workflow job

To execute the workflow job you will need to set up necessary environment and tools, follow these steps:

#### Setting up environment
1. Install Docker

2. Install `cwltool` (version 1.0.20170217172322) and  `synapseclient`
```
pip install cwltool==1.0.20170217172322
pip install synapseclient
```

3. Create Synapse credentials file `.synapseConfig`
Put there Synapse ID and password
```
[authentication]
username: user@usermail.org
password: <user-password>
```
Put this file a particular place, for example under home directory, eg, `/home/ubuntu/.synapseConfig`, then export the follow environment variable:
```
export SYNCONF=/home/ubuntu/.synapseConfig
```
4. Install JTracker command line
This is the same step as the previous section. Follow installation instruction here: https://github.com/icgc-dcc/jtracker

#### Start JTracker Executor
Start the executor to run jobs in the queue as:
```
jt user login ga4gh_dream
SYNCONF=/home/ubuntu/.synapseConfig jt exec run -q 758b7668-0057-4ef6-a5b0-6f48acf38583
```
If everything goes well, in about 5 hours, the job should finish and you will see `pcawg-sanger-variant-caller` result uploaded to specified location on Synapse.


---",9657807
md5sum,9657810_report.md,"### Workflow description
```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

### Participant information
```YAML
name: ""Ben Ernest""
institution: ""Digicon Corporation""
```

### Submission overview
```YAML
date_accessed: ""2017-12-12"" 
platform: ""Dockstore"" 
workflow_type: ""CWL"" 
runner_version: ""1.0.20170217172322"" 
docker_version: ""17.09.0-ce"" 
environment: ""BioGenLink"" 
env_cpus: ""1"" 
env_memory: ""62Gb"" 
env_disk: ""5Tb"" 
```

### Steps
#####This workflow was run using the [BioGenLink](http://digicon.com/biogenlink.html) platform from [Digicon](http://digicon.com/).  Click [here](http://digicon.com/biogenlink.html) or [email us](mailto:biogenlink@digiconasp.com) for more information. 

#### **Setup**

##### Create synapse credentials file.  
This only needs to be done once, and the credentials file can be used for each workflow.
1. Log into BioGenLink.  Click [here](http://digicon.com/biogenlink.html) for more information. 
${image?fileName=login%5Fscreen%5Fempty%2E2017%2D12%2D19%2Epng&align=None&scale=75&responsive=true}
2. In the **Files** tab, right-click on a directory, select `Create File`, give the file a name (e.g., ""synapse_config.txt""), and click `Preview` to edit the file.  
${image?fileName=create%5Ffile%5Fpreview%2E2017%2D12%2D19%2Epng&align=None&scale=75&responsive=true}

Enter the following information in the file and save it by clicking **Save** (the disk button just above the text area).
```
[authentication]
username: email
password: password
[cache]
location: biodtfs/path/to/cache
```
**Note:** the cache directory is used by synapseClient for temporary files, and we must specify it in BioGenLink to avoid permissions errors. It can be be any directory the user chooses, even a non-existing one as long as the parent directory is valid.  It is suggested to create a working directory for each workflow and keep this file in a parent directory outside of the working directories.  

#### **Provision workflow files**
1. Create a working directory.  
    - Right-click on any directory in the file system, select `Create Folder`, and enter a name for the working directory (e.g., `md5sum_workflow`).

2. Run the `Synapse get` tool.
    - In the **Tools** tab, find and select the `Synapse get` tool.  It can be found by keyword search or browsing to `Synapse/All/Synapse get`.  Double-clicking (shown below) the tool will open it in the workspace for editing and browsing documentation and will display the menu for providing inputs and running the tool.
${image?fileName=synapse%5Fget%5Fopen%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
    - In the `Synapse IDs` field, enter the Synapse IDs for files to be downloaded.  In this case, the synapse IDs include the following, which correspond to `md5sum_get.cwl.json`, `dockstore-tool-synapse-submit.cwl`, and `dockstore-tool-synapse-get.cwl`:
```shell
syn9771740 
syn9732885 
syn9770802 
```   
${image?fileName=synapse%5Fget%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
- Drag and drop the synapse credentials file (e.g., `synapse_config.txt`) from the file system into the field labeled `Synapse config file`.
- Drag and drop the working directory  (e.g., `md5sum_workflow`) into the field called `Output directory`.
- Run the tool by clicking `Quick Launch`.

#### **Run the workflow**
- Run the `Dockstore launch` tool.
    1. In the **Tools** tab, find and select the `Dockstore launch` tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore launch`.  
${image?fileName=dockstore%5Flaunch%2E2018%2D01%2D04%2Epng&align=None&scale=75&responsive=true}
    2. Drag and drop the `md5sum.cwl` and `md5sum.cwl.json` files from the working directory into the fields labeled `CWL file` and `JSON file`, respectively.  `Parent directory` can be left blank, since the directory containing the two input files will be used as the parent directory by default.   
    3. Click `Quick Launch`.

#### **Validate the results**
- Run the `Dockstore checker` tool.
  1. In the **Tools** tab, find and select the `Dockstore checker` tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore checker`.  
${image?fileName=dockstore%5Fchecker%2E2017%2D12%2D25%2Epng&align=None&scale=75&responsive=true}
  2. Drag and drop the `md5sum_checker.cwl` and `md5sum_checker.cwl.json` files from the working directory into the fields labeled `Checker CWL file` and `Checker JSON file`, respectively.  
  3. Click `Quick Launch`.
  4. Verify that the workflow ran successfully by opening the `results.json` file and confirming that the `Overall` field is equal to `true`.
${image?fileName=results%5Fjson%2E2017%2D12%2D25%2Epng&align=None&scale=75&responsive=true}

#### **Submit the results to Synapse**
- Run the `Dockstore submit` tool.
  1. In the **Tools** tab, find and select the `Dockstore submit` tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore submit`.  
${image?fileName=dockstore%5Fsubmit%2E2017%2D12%2D26%2Epng&align=None&scale=75&responsive=true}
  2. Drag and drop the `md5sum_submit.cwl.json` file into the field labeled `Submit JSON file`.  
  3. Enter a team name and the Synapse parent ID into the corresponding fields.  
  4. Drag and drop the synapse credentials file (e.g., `synapse_config.txt`) into the field labeled `Synapse config file`.
  5. Click `Quick Launch`.",9657810
md5sum,9657908_report.md,"## Dockstore md5sum Workflow

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

The following description is provided by the workflow author:
> This is an extremely simple workflow used to show how to call a workflow via Dockstore. It includes one step, running the extremely simple tool `dockstore-tool-md5sum`, which uses a Docker image/container for the md5sum command.

#### Suggested resources

```YAML
suggested_cpus: ""1""
suggested_ram: ""1Gb""
suggested_disk: ""512Kb""
```

#### Workflow history

+ **2017-07-05**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Azza E Ahmed"" # your name here
institution: ""University of Khartoum"" # your institution here
```


### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-12-29"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""Dockstore"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170828135420"" # indicate executor version used
docker_version: ""17.03.1-ce, build c6d412e"" # from `docker --version`
environment: ""EGI FedCloud"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""32GB"" # indicate available RAM in environment
env_disk: ""100GB"" # indicate available disk space, or note ""elastic"" for EFS et al.

```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-07-10""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce-rc4""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""300Gb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

#### 1. Set up environment

0. I launched a VM instance from EGI FedCloud resources (EGI Docker (Ubuntu 14.04) from CESNET MetaCloud (IaaS Cloud)) with extra large memory (32GB ram, 100GB disk, 8 cores). Docker is pre-installed, so I only needed to add the $USER to the `docker` group

1. [Install dockstore](https://dockstore.org) on my machine. This also needs cwltool and java installed beforehand:

```shell
sudo pip install setuptools==36.5.0
sudo pip install cwl-runner cwltool==1.0.20170828135420 schema-salad==2.6.20170806163416 avro==1.8.1 ruamel.yaml==0.14.12 requests==2.18.4

sudo add-apt-repository ppa:webupd8team/java
sudo apt-get update && sudo apt-get install -y oracle-java8-set-default

mkdir -p ~/bin
curl -L -o ~/bin/dockstore https://github.com/ga4gh/dockstore/releases/download/1.3.1/dockstore
chmod +x ~/bin/dockstore
echo 'export PATH=~/bin:$PATH' >> ~/.bashrc
source ~/.bashrc
 mkdir -p ~/.dockstore
printf ""token: eaed4f494bb41e6b78c19786a7ab5feb06c1e02f6f75315d9347f6d066be3719\nserver-url: https://dockstore.org:8443\n"" > ~/.dockstore/config
```

2. I created a working directory for the current workflow and created a copy of my Synapse credentials in that folder:
```shell
mkdir md5sum
cd md5sum
cp ~/.synapseConfig .
```

#### 2. Download required files

I used the quay.io image of the `synapse get` and `synapse submit` commands, so I only need to download the ` the JSON parameters file of the workflow:
```shell
synapse get syn9771740 # md5sum_get.json

```

#### 3. Provision all workflow files

I used `dockstore` to run `dockstore-tool-synapse-get.cwl` with parameters in `md5sum_get.cwl.json` to download input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
dockstore tool launch --entry quay.io/ga4gh-dream/dockstore-tool-synapse-get --json 
```

#### 4. Run main workflow

I again used `dockstore` to run the workflow, as defined in `md5sum.cwl` and parameterized by `md5sum.cwl.json`:
```shell
dockstore workflow launch --local-entry md5sum.cwl --json  md5sum.cwl.json
```

#### 5. Run workflow checker tool

To verify workflow results before submission, I used `dockstore` to run the checker as follows:
```shell
dockstore tool launch --local-entry md5sum_checker.cwl --json md5sum_checker.cwl.json
cat results.json | grep -i overall
```

#### 6. Submit workflow outputs

I modified the parameters in `md5sum_submit.cwl.json` to reflect the `team_name` and `parent_id`, then submit:

```shell
dockstore tool launch --entry quay.io/ga4gh-dream/dockstore-tool-synapse-submit --json
```

---",9657908
md5sum,9657913_report.md,"### Workflow description

```YAML
contributor: ""Brian O'Connor""
workflow_handle: ""md5sum""
input_handle: ""hello input""
```

### Participant information
```YAML
name: ""Ben Ernest""
institution: ""Digicon Corporation""
```

### Submission overview
```YAML
date_accessed: ""2017-12-12"" 
platform: ""BioGenLink"" 
workflow_type: ""CWL"" 
runner_version: ""1.0.20170217172322"" 
docker_version: ""17.09.0-ce"" 
environment: ""BioGenLink"" 
env_cpus: ""1"" 
env_memory: ""8Gb"" 
env_disk: ""5Tb"" 
```

### Steps
#####This workflow was run using the [BioGenLink](http://digicon.com/biogenlink.html) platform from [Digicon](http://digicon.com/).  Click [here](http://digicon.com/biogenlink.html) or [email us](mailto:biogenlink@digiconasp.com) for more information. 

#### **Setup**

##### Create synapse credentials file.  
This only needs to be done once, and the credentials file can be used for each workflow.
1. Log into BioGenLink.  [Click here](http://digicon.com/biogenlink.html) or [email us](mailto:biogenlink@digiconasp.com) for more information.
${image?fileName=login%5Fscreen%5Fempty%2E2017%2D12%2D19%2Epng&align=None&scale=75&responsive=true}

2. In the **files** tab, right-click on any directory in the file system, select `Create File`, give the file a name (e.g., ""synapse_config.txt""), and click `Preview` to edit the file.  
${image?fileName=create%5Ffile%5Fpreview%2E2017%2D12%2D19%2Epng&align=None&scale=75&responsive=true}

Enter the following information in the file and save it by clicking **Save** (the disk button just above the text area).
```
[authentication]
username: email
password: password
[cache]
location: biodtfs/path/to/cache
```
**Note:** the cache directory is used by `synapseClient` for temporary files, and we must specify it in BioGenLink to avoid permissions errors. It can be any directory the user chooses, even a non-existing one as long as the parent directory is valid.  It is suggested to create a working directory for each workflow and keep this file in a parent directory outside of the working directories.  

#### **Provision workflow files**

1. Create a working directory.  
    - Right-click on any directory in the file system, select `Create Folder`, and enter a name for the working directory (e.g., `md5sum_workflow`).

2. Run the `Synapse get` tool.
    - In the **tools** tab, find and select the `Synapse get` tool.  It can be found by keyword search or browsing to `Synapse/All/Synapse get`.  Double-clicking (shown below) the tool will open it in the workspace for editing and browsing documentation and will display the menu for providing inputs and running the tool.
${image?fileName=synapse%5Fget%5Fopen%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
    - In the `Synapse IDs` field, enter the Synapse IDs for files to be downloaded.  In this case, the synapse IDs include the following, which correspond to `md5sum_get.cwl.json`, `dockstore-tool-synapse-submit.cwl`, and `dockstore-tool-synapse-get.cwl`:
```shell
syn9771740
syn9732885
syn9770802
```
${image?fileName=synapse%5Fget%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
    - Drag and drop the synapse credentials file (e.g., `synapse_config.txt`) from the file system into the field called `Synapse config file`.
    - Drag and drop the working directory into the field called `Output directory`.
    - Run the tool by clicking `Quick Launch`.

#### **Import the workflow**
- If the workflow has not been imported yet, go to the **files** tab and find the `CWL` file corresponding to the workflow you want to build (e.g., `md5sum.cwl`).  Right-click on the file, and select `Import CWL File`.  This will automatically build a workflow which can be edited and run within the BioGenLink platform. 
${image?fileName=import%5Fcwl%5Ffile%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
The `md5sum` workflow is automatically created and placed in the **workflows** tab, under `CWL/Autogenerated`. 

#### **Run the workflow**
1. In the **workflows** tab, find and select the `md5sum` workflow.  The previous step automatically places it in the `CWL/Autogenerated` folder.  Double-clicking (shown below) opens the workflow in the workspace for editing and will display the menu for providing inputs and running the workflow.
${image?fileName=hello%5Fworld%5Fworkflow%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
If the run parameters aren't visible, right-click the orange ""play button"" at top right of the workspace to open them.
${image?fileName=hello%5Fworld%5Fworkflow%5Frun%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
The default inputs should already be set, but if they aren't then drag and drop the `md5sum.input` into the `input_file` field.
2. Drag and drop a directory from the file system into the `Output Directory` field.
3. Run the workflow by clicking the `RUN WITH SKIPPING` button.


#### **Validate the results**
- Run the `Dockstore checker` tool.
1. In the **tools** tab, find and select the `Dockstore checker` tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore checker`.  
${image?fileName=dockstore%5Fchecker%2E2017%2D12%2D25%2Epng&align=None&scale=75&responsive=true}
2. Drag and drop the `md5sum_checker.cwl` and `md5sum_checker.cwl.json` files from the working directory into the fields labeled `Checker CWL file` and `Checker JSON file`, respectively.  
3. Click `Quick Launch`.
4. Verify that the workflow ran successfully by opening the `results.json` file and confirming that the `Overall` field is equal to `true`.
${image?fileName=results%5Fjson%2E2017%2D12%2D25%2Epng&align=None&scale=75&responsive=true}

#### **Submit the results to Synapse**
- Run the `Dockstore submit` tool.
1. In the **tools** tab, find and select the `Dockstore submit` tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore submit`.  
${image?fileName=dockstore%5Fsubmit%2E2017%2D12%2D26%2Epng&align=None&scale=75&responsive=true}
2. Drag and drop the `md5sum_submit.cwl.json` file into the field labeled `Submit JSON file`.  
3. Enter a team name and the Synapse parent ID into the corresponding fields.  
4. Drag and drop the synapse credentials file (e.g., `synapse_config.txt`) into the field labeled `Synapse config file`.
5. Click `Quick Launch`.",9657913
pcawg-bwa-mem-aligner,9654933_report.md,"## PCAWG bwa mem Aligner

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brice Aminou""
workflow_handle: ""pcawg-bwa-mem-aligner""
input_handle: """"
```

The following description is provided by the workflow authors:


#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-08-31**: In progress

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Brice Aminou"" # your name here
institution: ""Ontario Institute for Cancer Research"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: """" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170217172322"" # indicate executor version used
docker_version: ""1.13.1"" # from `docker --version`
environment: ""Openstack VM"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""93.8GB"" # indicate available RAM in environment
env_disk: ""2.5TB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-08-31""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""1.13.1""
environment_ex: ""Openstack VM"" 
env_cpus_ex: ""8""
env_memory_ex: ""93.8GB""
env_disk_ex: ""2.5TB""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

_____________________
#### Example
### Setting up environment
Install `cwltool` (version 1.0.20170217172322) and  `synapseclient`
```
pip install cwltool==1.0.20170217172322
pip install synapseclient
```
Create empty folder for workflow running
```
mkdir pcawg-bwa-mem
cd pcawg-bwa-mem
```
Create Synapse credentials file `.synapseConfig`, put there Synapse ID and password
```
[authentication]
username: user@usermail.org
password: <user-password>
```
### Downloading required files
Download tools to fetch workflow input data
```
synapse -c .synapseConfig get syn10611673  # pcawg-bwa-mem-aligner.stage-files.json
synapse -c .synapseConfig get syn9770802   # dockstore-tool-synapse-get.cwl
synapse -c .synapseConfig get syn9732885   # dockstore-tool-synapse-submit.cwl
```
Download workflow input data
```
cwltool --debug --non-strict dockstore-tool-synapse-get.cwl pcawg-bwa-mem-aligner.stage-files.json
```
Wait until downloading is finished

### Running workflow
Run the workflow
```
cwltool --debug --non-strict pcawg-bwa-mem-aligner.cwl pcawg-bwa-mem-aligner.json
```
### Validating results
#### Run Checker Tool
Before running the Checker Tool, please edit `pcawg-bwa-mem-aligner.checker.job.json` to ensure output files from your workflow run are corrected included.

```
cwltool --debug --non-strict pcawg-bwa-mem-aligner.checker.cwl pcawg-bwa-mem-aligner-caller.checker.job.json
```
This should take just a few minutes.

#### Check results
```
cat results.json
```
You should see `""overall"": true`. If result does not match, you will see `""overall"": false`, please take a look at `log.txt` for more details.

### Submitting results
Update `pcawg-bwa-mem-aligner.submit.json` with correct
`team_name` - the name of your team in plain text format (e.g., ""Your team name"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
`eval_id` - 9606715
`file` - result files from the workflow run, please ensure to replace it with your file name. The timestamp part will be different in your result compare to the example below.

The JSON should look similar to below, make sure you fill out team name, parentID and file names correctly:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""PCAWG-Tech"",
    ""eval_id"": ""9606715"",
    ""file"": [
    {""class"": ""File"", ""path"": ""hg19.chr22.5x.normal.bam""},
    {""class"": ""File"", ""path"": ""hg19.chr22.5x.normal.bam.bai""},
    {""class"": ""File"", ""path"": ""hg19.chr22.5x.normal.bam.metrics""},
    {""class"": ""File"", ""path"": ""hg19.chr22.5x.normal.unmapped.bam""},
    {""class"": ""File"", ""path"": ""hg19.chr22.5x.normal.unmapped.bam.bai""},
    {""class"": ""File"", ""path"": ""hg19.chr22.5x.normal.unmapped.bam.metrics""}
    ],
    ""parent_id"": ""syn11496973""
}
```

Run the synapse submit tool
```
cwltool --debug --non-strict dockstore-tool-synapse-submit.cwl pcawg-bwa-mem-aligner.submit.json
```
***Running time:*** ~5 hours  
***Disk usage:*** ~15G",9654933
pcawg-bwa-mem-aligner,9655619_report.md,"## PCAWG bwa mem Aligner

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brice Aminou""
workflow_handle: ""pcawg-bwa-mem-aligner""
input_handle: """"
```

The following description is provided by the workflow authors:


#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-08-31**: In progress

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Brice Aminou"" # your name here
institution: ""Ontario Institute for Cancer Research"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: """" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170217172322"" # indicate executor version used
docker_version: ""1.13.1"" # from `docker --version`
environment: ""Openstack VM"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""93.8GB"" # indicate available RAM in environment
env_disk: ""2.5TB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-08-31""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""1.13.1""
environment_ex: ""Openstack VM"" 
env_cpus_ex: ""8""
env_memory_ex: ""93.8GB""
env_disk_ex: ""2.5TB""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

_____________________
#### Example
### Setting up environment
Install `cwltool` (version 1.0.20170217172322) and  `synapseclient`
```
pip install cwltool==1.0.20170217172322
pip install synapseclient
```
Create empty folder for workflow running
```
mkdir pcawg-bwa-mem
cd pcawg-bwa-mem
```
Create Synapse credentials file `.synapseConfig`, put there Synapse ID and password
```
[authentication]
username: user@usermail.org
password: <user-password>
```
### Downloading required files
Download tools to fetch workflow input data
```
synapse -c .synapseConfig get syn10611673  # pcawg-bwa-mem-aligner.stage-files.json
synapse -c .synapseConfig get syn9770802   # dockstore-tool-synapse-get.cwl
synapse -c .synapseConfig get syn9732885   # dockstore-tool-synapse-submit.cwl
```
Download workflow input data
```
cwltool --debug --non-strict dockstore-tool-synapse-get.cwl pcawg-bwa-mem-aligner.stage-files.json
```
Wait until downloading is finished

### Running workflow
Run the workflow
```
cwltool --debug --non-strict pcawg-bwa-mem-aligner.cwl pcawg-bwa-mem-aligner.json
```
### Validating results
#### Run Checker Tool
Before running the Checker Tool, please edit `pcawg-bwa-mem-aligner.checker.job.json` to ensure output files from your workflow run are corrected included.

```
cwltool --debug --non-strict pcawg-bwa-mem-aligner.checker.cwl pcawg-bwa-mem-aligner.checker.job.json
```
This should take just a few minutes.

#### Check results
```
cat results.json
```
You should see `""overall"": true`. If result does not match, you will see `""overall"": false`, please take a look at `log.txt` for more details.

### Submitting results
Update `pcawg-bwa-mem-aligner.submit.json` with correct
`team_name` - the name of your team in plain text format (e.g., ""Your team name"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
`eval_id` - 9606715
`file` - result files from the workflow run, please ensure to replace it with your file name. The timestamp part will be different in your result compare to the example below.

The JSON should look similar to below, make sure you fill out team name, parentID and file names correctly:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""PCAWG-Tech"",
    ""eval_id"": ""9606715"",
    ""file"": [
    {""class"": ""File"", ""path"": ""hg19.chr22.5x.normal.bam""},
    {""class"": ""File"", ""path"": ""hg19.chr22.5x.normal.bam.bai""},
    {""class"": ""File"", ""path"": ""hg19.chr22.5x.normal.bam.metrics""},
    {""class"": ""File"", ""path"": ""hg19.chr22.5x.normal.unmapped.bam""},
    {""class"": ""File"", ""path"": ""hg19.chr22.5x.normal.unmapped.bam.bai""},
    {""class"": ""File"", ""path"": ""hg19.chr22.5x.normal.unmapped.bam.metrics""}
    ],
    ""parent_id"": ""syn11496973""
}
```

Run the synapse submit tool
```
cwltool --debug --non-strict dockstore-tool-synapse-submit.cwl pcawg-bwa-mem-aligner.submit.json
```
***Running time:*** ~5 hours  
***Disk usage:*** ~15G",9655619
pcawg-bwa-mem-aligner,9656279_report.md,"## PCAWG bwa mem Aligner

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brice Aminou""
workflow_handle: ""pcawg-bwa-mem-aligner""
input_handle: ""hg19.chr22.5x.normal""
```

The following description is provided by the workflow authors (from [GitHub](https://github.com/ICGC-TCGA-PanCancer/Seqware-BWA-Workflow/tree/2.6.8_1.3)):

> This is the SeqWare workflow for the TCGA/ICGC PanCancer project that aligns whole genome sequences with BWA-Mem. It also reads/writes to GNOS (optionally), the metadata/data repository system used in the project. It can now be used in a standalone mode using the [Dockstore](http://dockstore.org/) CLI. For more information about the workflow see the [CHANGELOG](https://github.com/ICGC-TCGA-PanCancer/Seqware-BWA-Workflow/blob/2.6.8_1.3/CHANGELOG.md).


#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-09-20**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Benjamin Story"" # your name here
institution: ""EMBL"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-09-08"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""cwltool 1.0.20170413194156"" # indicate executor version used
docker_version: ""1.7.1, build 786b29d"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""12"" # indicate number of cores in environment
env_memory: ""72GB"" # indicate available RAM in environment
env_disk: ""1TB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-08-31""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""1.12.6""
environment_ex: ""local"" 
env_cpus_ex: ""8""
env_memory_ex: ""96Gb""
env_disk_ex: ""2Tb""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

_____________________
#### Example
### Setting up environment
Create empty folder for workflow running
```
mkdir pcawg-bwa-mem
cd pcawg-bwa-mem
```
Create Synapse credentials file `.synapseConfig`, put there Synapse ID and password
```
[authentication]
username: user@usermail.org
password: <user-password>
```
### Downloading required files
Download tools to fetch workflow input data
```
synapse -c .synapseConfig get syn10903609  # pcawg-bwa-mem-aligner_get.cwl.json
synapse -c .synapseConfig get syn9770802   # dockstore-tool-synapse-get.cwl
synapse -c .synapseConfig get syn9732885   # dockstore-tool-synapse-submit.cwl
```
Download workflow input data
```
cwltool --debug --non-strict dockstore-tool-synapse-get.cwl pcawg-bwa-mem-aligner_get.cwl.json
```
Wait until downloading is finished

### Running workflow
Run the workflow
```
cwltool --tmpdir-prefix tmp/ --cachedir cache/ --debug --non-strict pcawg-bwa-mem-aligner.cwl pcawg-bwa-mem-aligner.json
```
### Validating results
#### Run Checker Tool
Before running the Checker Tool, please edit `pcawg-bwa-mem-aligner.checker.job.json` to ensure output files from your workflow run are corrected included.

```
cwltool --tmpdir-prefix tmp/ --cachedir cache/ --debug --non-strict pcawg-bwa-mem-aligner.checker.cwl pcawg-bwa-mem-aligner.checker.job.json
```
This should take just a few minutes.

#### Check results
```
cat results.json
```
You should see `""overall"": true`. If result does not match, you will see `""overall"": false`, please take a look at `log.txt` for more details.

### Submitting results
Update `pcawg-bwa-mem-aligner.submit.json` with correct
`team_name` - the name of your team in plain text format (e.g., ""Your team name"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
`eval_id` - 9606715
`file` - result files from the workflow run, please ensure to replace it with your file name. The timestamp part will be different in your result compare to the example below.

The JSON should look similar to below, make sure you fill out team name, parentID and file names correctly:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""EMBL GA4GH-DREAM Challenge Team"",
    ""eval_id"": ""9606715"",
    ""file"": [
    {""class"": ""File"", ""path"": ""hg19.chr22.5x.normal.bam""},
    {""class"": ""File"", ""path"": ""hg19.chr22.5x.normal.bam.bai""},
    {""class"": ""File"", ""path"": ""hg19.chr22.5x.normal.bam.metrics""},
    {""class"": ""File"", ""path"": ""hg19.chr22.5x.normal.unmapped.bam""},
    {""class"": ""File"", ""path"": ""hg19.chr22.5x.normal.unmapped.bam.bai""},
    {""class"": ""File"", ""path"": ""hg19.chr22.5x.normal.unmapped.bam.metrics""}
    ],
    ""parent_id"": ""syn11587003""
}
```

Run the synapse submit tool
```
cwltool --debug --non-strict dockstore-tool-synapse-submit.cwl pcawg-bwa-mem-aligner.submit.json
```
***Running time:*** ~5 hours  
***Disk usage:*** ~15G",9656279
pcawg-bwa-mem-aligner,9657027_report.md,"## PCAWG bwa mem Aligner

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brice Aminou""
workflow_handle: ""pcawg-bwa-mem-aligner""
input_handle: ""hg19.chr22.5x.normal""
```

The following description is provided by the workflow authors (from [GitHub](https://github.com/ICGC-TCGA-PanCancer/Seqware-BWA-Workflow/tree/2.6.8_1.3)):

> This is the SeqWare workflow for the TCGA/ICGC PanCancer project that aligns whole genome sequences with BWA-Mem. It also reads/writes to GNOS (optionally), the metadata/data repository system used in the project. It can now be used in a standalone mode using the [Dockstore](http://dockstore.org/) CLI. For more information about the workflow see the [CHANGELOG](https://github.com/ICGC-TCGA-PanCancer/Seqware-BWA-Workflow/blob/2.6.8_1.3/CHANGELOG.md).


#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-09-20**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Vipin T. Sreedharan"" # your name here
institution: ""ETH Zürich, NEXUS Personalized Health Technologies"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-12-13"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""cwltool 1.0.20170828135420"" # indicate executor version used
docker_version: ""1.12.6, build c4618fb"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""32Gb"" # indicate available RAM in environment
env_disk: ""100Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

#### 1. Setting up environment

At our institute, on a compute machine called `wfexec` with Red Hat Enterprise Linux Server release 7.4 (Maipo), installed Docker. Created a group named ""docker"" since it was preferred to use Docker as a non-root user on this machine. The instance has a non-root user called `wfrunner`. Next added the non-root user `wfrunner` to the ""docker"" group. Then started the docker engine and all the below commands were executed using root user privileges [sudo]:
```shell
yum install docker
groupadd docker 
usermod -aG docker wfrunner  
systemctl start docker 
```
&nbsp;




Install `cwltool` (version 1.0.20170217172322) and  `synapseclient`
```
pip install cwltool==1.0.20170217172322
pip install synapseclient
```
Create empty folder for workflow running
```
mkdir pcawg-bwa-mem
cd pcawg-bwa-mem
```
Create Synapse credentials file `.synapseConfig`, put there Synapse ID and password
```
[authentication]
username: user@usermail.org
password: <user-password>
```
### Downloading required files
Download tools to fetch workflow input data
```
synapse -c .synapseConfig get syn10903609  # pcawg-bwa-mem-aligner_get.cwl.json
synapse -c .synapseConfig get syn9770802   # dockstore-tool-synapse-get.cwl
synapse -c .synapseConfig get syn9732885   # dockstore-tool-synapse-submit.cwl
```
Download workflow input data
```
cwltool --debug --non-strict dockstore-tool-synapse-get.cwl pcawg-bwa-mem-aligner_get.cwl.json
```
Wait until downloading is finished

### Running workflow
Run the workflow
```
cwltool --debug --non-strict pcawg-bwa-mem-aligner.cwl pcawg-bwa-mem-aligner.json
```
### Validating results
#### Run Checker Tool
Before running the Checker Tool, please edit `pcawg-bwa-mem-aligner.checker.job.json` to ensure output files from your workflow run are corrected included.

```
cwltool --debug --non-strict pcawg-bwa-mem-aligner.checker.cwl pcawg-bwa-mem-aligner.checker.job.json
```
This should take just a few minutes.

#### Check results
```
cat results.json
```
You should see `""overall"": true`. If result does not match, you will see `""overall"": false`, please take a look at `log.txt` for more details.

### Submitting results
Update `pcawg-bwa-mem-aligner.submit.json` with correct
`team_name` - the name of your team in plain text format (e.g., ""Your team name"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
`eval_id` - 9606715
`file` - result files from the workflow run, please ensure to replace it with your file name. The timestamp part will be different in your result compare to the example below.

The JSON should look similar to below, make sure you fill out team name, parentID and file names correctly:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""PCAWG-Tech"",
    ""eval_id"": ""9606715"",
    ""file"": [
    {""class"": ""File"", ""path"": ""hg19.chr22.5x.normal.bam""},
    {""class"": ""File"", ""path"": ""hg19.chr22.5x.normal.bam.bai""},
    {""class"": ""File"", ""path"": ""hg19.chr22.5x.normal.bam.metrics""},
    {""class"": ""File"", ""path"": ""hg19.chr22.5x.normal.unmapped.bam""},
    {""class"": ""File"", ""path"": ""hg19.chr22.5x.normal.unmapped.bam.bai""},
    {""class"": ""File"", ""path"": ""hg19.chr22.5x.normal.unmapped.bam.metrics""}
    ],
    ""parent_id"": ""syn11496973""
}
```

Run the synapse submit tool
```
cwltool --debug --non-strict dockstore-tool-synapse-submit.cwl pcawg-bwa-mem-aligner.submit.json
```
***Running time:*** ~5 hours  
***Disk usage:*** ~15G",9657027
pcawg-bwa-mem-aligner,9657034_report.md,"## PCAWG bwa mem Aligner

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brice Aminou""
workflow_handle: ""pcawg-bwa-mem-aligner""
input_handle: ""hg19.chr22.5x.normal""
```

The following description is provided by the workflow authors (from [GitHub](https://github.com/ICGC-TCGA-PanCancer/Seqware-BWA-Workflow/tree/2.6.8_1.3)):

> This is the SeqWare workflow for the TCGA/ICGC PanCancer project that aligns whole genome sequences with BWA-Mem. It also reads/writes to GNOS (optionally), the metadata/data repository system used in the project. It can now be used in a standalone mode using the [Dockstore](http://dockstore.org/) CLI. For more information about the workflow see the [CHANGELOG](https://github.com/ICGC-TCGA-PanCancer/Seqware-BWA-Workflow/blob/2.6.8_1.3/CHANGELOG.md).


#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-09-20**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Joe Slagel"" # your name here
institution: ""ISB"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-12-13"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170822192924"" # indicate executor version used
docker_version: ""Docker version 1.12.6, build 78d1802"" # from `docker --version`
environment: ""Google Compute"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""30 GB"" # indicate available RAM in environment
env_disk: ""200 GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

_____________________

### Setting up environment
```shell
mkdir pcawg-bwa-mem-aligner
cd pcawg-bwa-mem-aligner
cp ~/.synapseConfig .
synapse -c .synapseConfig get syn9770802;
synapse -c .synapseConfig get syn9732885;
synapse -c .synapseConfig get syn10903609;
```


### Downloading required files
```shell
sudo cwltool --debug --non-strict dockstore-tool-synapse-get.cwl pcawg-bwa-mem-aligner_get.cwl.json > get.log 2>&1
```

### Running workflow
```shell
sudo cwltool --debug --non-strict pcawg-bwa-mem-aligner.cwl pcawg-bwa-mem-aligner.json > run.log 2>&1
```

#### Check results

```shell
sudo cwltool --debug --non-strict pcawg-bwa-mem-aligner.checker.cwl  pcawg-bwa-mem-aligner.checker.job.json > check.log 2>&1
cat result.json
```
You should see `""overall"": true`. If result does not match, you will see `""overall"": false`, please take a look at `log.txt` for more details.

### Submitting results

```shell
jq '.team_name=""ISB-CGC"" | .parent_id=""syn11583662""' pcawg-bwa-mem-aligner.submit.json \
   > /tmp/pcawg-bwa-mem-aligner.submit.json
mv /tmp/pcawg-bwa-mem-aligner.submit.json .

sudo cwltool --debug --non-strict dockstore-tool-synapse-submit.cwl pcawg-bwa-mem-aligner.submit.json > submit.log 2>&1
```
",9657034
pcawg-bwa-mem-aligner,9657036_report.md,"## PCAWG bwa mem Aligner

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brice Aminou""
workflow_handle: ""pcawg-bwa-mem-aligner""
input_handle: ""hg19.chr22.5x.normal""
```

The following description is provided by the workflow authors (from [GitHub](https://github.com/ICGC-TCGA-PanCancer/Seqware-BWA-Workflow/tree/2.6.8_1.3)):

> This is the SeqWare workflow for the TCGA/ICGC PanCancer project that aligns whole genome sequences with BWA-Mem. It also reads/writes to GNOS (optionally), the metadata/data repository system used in the project. It can now be used in a standalone mode using the [Dockstore](http://dockstore.org/) CLI. For more information about the workflow see the [CHANGELOG](https://github.com/ICGC-TCGA-PanCancer/Seqware-BWA-Workflow/blob/2.6.8_1.3/CHANGELOG.md).


#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-09-20**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Vipin T. Sreedharan"" # your name here
institution: ""ETH Zürich, NEXUS Personalized Health Technologies"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-12-13"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""Toil"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""cwltoil 3.11.0"" # indicate executor version used
docker_version: ""1.12.6, build c4618fb"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""32Gb"" # indicate available RAM in environment
env_disk: ""100Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```


### Steps
_____________________
#### 1. Setting up environment

At our institute, on a compute machine called `wfexec` with Red Hat Enterprise Linux Server release 7.4 (Maipo), installed Docker. Created a group named ""docker"" since it was preferred to use Docker as a non-root user on this machine. The instance has a non-root user called `wfrunner`. Next added the non-root user `wfrunner` to the ""docker"" group. Then started the docker engine and all the below commands were executed using root user privileges [sudo]:
```shell
yum install docker
groupadd docker 
usermod -aG docker wfrunner  
systemctl start docker 
```

As a non-root user `wfrunner` on `wfexec` machine, installed Anaconda and Toil to the home path:
```shell
su - wfrunner
wget https://repo.continuum.io/archive/Anaconda2-4.4.0-Linux-x86_64.sh
bash Anaconda2-4.4.0-Linux-x86_64.sh 
conda install virtualenv
virtualenv -p python2 /home/wfrunner/venv
source /home/wfrunner/venv/bin/activate
pip install toil synapseclient
deactivate
export PATH=$PATH:/home/wfrunner/venv/bin/
```
By installing the `synapseclient` we can provision some basic files that can help us provision the rest of our workflow, and the submit file that will put the workflow results back on synapse.

Created a utilities directory for storing the `synapse-get` and `synapse-submit` CWL tools. In the same folder, created Synapse credential file `.synapse_config` and put there Synapse ID and password. 
```shell
mkdir -p /home/wfrunner/synapse_utils
cd /home/wfrunner/synapse_utils
touch .synapse_config
vim .synapse_config
[WRITE]
[authentication]
username: user@usermail.org
password: <user-password>

synapse -c .synapse_config get syn9770802   # dockstore-tool-synapse-get.cwl
synapse -c .synapse_config get syn9732885   # dockstore-tool-synapse-submit.cwl
```

#### 2. Downloading required files

Downloaded data config file `pcawg-bwa-mem-aligner_get.cwl.json` for the **pcawg-bwa-mem-aligner** workflow. Created a directory for storing the workflow associated data downloading JSON parameter file:

```shell
mkdir -p /home/wfrunner/data_config_files
synapse -c ~/synapse_utils/.synapse_config get syn10903609  # pcawg-bwa-mem-aligner_get.cwl.json
vim pcawg-bwa-mem-aligner_get.cwl.json
[PASTE] /home/wfrunner/synapse_utils/.synapse_config
```

#### 3. Download workflow input data

Since we already have the file with the information about the files to run our workflow, by running the following command, we can provisioned in our machine. Created a working directory for the current workflow.
```shell
mkdir -p /home/wfrunner/pcawg-bwa-mem-aligner
cd /home/wfrunner/pcawg-bwa-mem-aligner
```

Used `cwltoil` to run `dockstore-tool-synapse-get.cwl` with parameters in `pcawg-bwa-mem-aligner_get.cwl.json` to download workflow input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltoil --workDir ~/tmp/ ~/synapse_utils/dockstore-tool-synapse-get.cwl ~/data_config_files/pcawg-bwa-mem-aligner_get.cwl.json
```
Wait until downloading is finished

#### 4. Run the workflow

Running workflow with `cwltoil`:
```shell 
cd /home/wfrunner/pcawg-bwa-mem-aligner
cwltoil --workDir ~/tmp/ pcawg-bwa-mem-aligner.cwl pcawg-bwa-mem-aligner.json 
```
Wait for the run to finish.

#### 5. Run workflow checker tool

Before running the Checker Tool, please edit `pcawg-bwa-mem-aligner.checker.job.json` to ensure output files from your workflow run are corrected included.

```shell
cd /home/wfrunner/pcawg-bwa-mem-aligner
cwltoil --workDir  ~/tmp pcawg-bwa-mem-aligner.checker.cwl pcawg-bwa-mem-aligner.checker.job.json
```
This should take just a few minutes.

Check results:
```
cd /home/wfrunner/pcawg-bwa-mem-aligner
cat results.json
[STDOUT] {""overall"": true}
```
If result does not match, you will see `""overall"": false`, please take a look at `log.txt` for more details.

#### 6. Submitting results

Update `pcawg-bwa-mem-aligner.submit.json` with correct
`path` - synapse credential stored file
`team_name` - the name of your team in plain text format (e.g., ""Your team name"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
`eval_id` - 9606715
`file` - result files from the workflow run, please ensure to replace it with your file name. The timestamp part will be different in your result compare to the example below.

The JSON should look similar to below, make sure you fill out team name, parentID and file names correctly:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": ""/home/wfrunner/synapse_utils/.synapse_config""
    },
    ""team_name"": ""ETH Zurich NEXUS Workflow Handler"",
    ""eval_id"": ""9606715"",
    ""file"": [
    {""class"": ""File"", ""path"": ""hg19.chr22.5x.normal.bam""},
    {""class"": ""File"", ""path"": ""hg19.chr22.5x.normal.bam.bai""},
    {""class"": ""File"", ""path"": ""hg19.chr22.5x.normal.bam.metrics""},
    {""class"": ""File"", ""path"": ""hg19.chr22.5x.normal.unmapped.bam""},
    {""class"": ""File"", ""path"": ""hg19.chr22.5x.normal.unmapped.bam.bai""},
    {""class"": ""File"", ""path"": ""hg19.chr22.5x.normal.unmapped.bam.metrics""}
    ],
    ""parent_id"": ""syn11612171""
}
```
Finally, submitted outputs using the submission tool `dockstore-tool-synapse-submit.cwl`:
```shell
cd /home/wfrunner/pcawg-bwa-mem-aligner
cwltoil --workDir ~/tmp/ ~/synapse_utils/dockstore-tool-synapse-submit.cwl pcawg-bwa-mem-aligner.submit.json
```
",9657036
pcawg-bwa-mem-aligner,9657799_report.md,"## PCAWG bwa mem Aligner

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brice Aminou""
workflow_handle: ""pcawg-bwa-mem-aligner""
input_handle: ""hg19.chr22.5x.normal""
```

The following description is provided by the workflow authors (from [GitHub](https://github.com/ICGC-TCGA-PanCancer/Seqware-BWA-Workflow/tree/2.6.8_1.3)):

> This is the SeqWare workflow for the TCGA/ICGC PanCancer project that aligns whole genome sequences with BWA-Mem. It also reads/writes to GNOS (optionally), the metadata/data repository system used in the project. It can now be used in a standalone mode using the [Dockstore](http://dockstore.org/) CLI. For more information about the workflow see the [CHANGELOG](https://github.com/ICGC-TCGA-PanCancer/Seqware-BWA-Workflow/blob/2.6.8_1.3/CHANGELOG.md).


#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-09-20**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Michael Kotliar""
institution: ""CCHMC, Barski Lab""
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-12-23""
platform: ""CWL-Airflow""
workflow_type: ""CWL""
runner_version: ""0.0.1""
docker_version: ""1.12.6""
environment: ""local""
env_cpus: ""64""
env_memory: ""251Gb""
env_disk: ""230Gb""
```
### Steps

### Setting up environment
Install CWL-Airflow
```
  cd /home/michael_kotliar/workspaces/airflow/
  git clone https://github.com/Barski-lab/cwl-airflow.git
  cd cwl-airflow
  git fetch --tags
  git checkout v0.0.1
  pip install -e .
```
Update Airflow configuration file `/home/michael_kotliar/airflow/airflow.cfg`
```
  executor = LocalExecutor
  sql_alchemy_conn = mysql://airflow:airflow@127.0.0.1:6603/airflow
```
Install synapse client
```
  pip install synapseclient
```
Create empty folder for workflow running
```
  cd /home/michael_kotliar/temp/cwl_airflow/
  mkdir pcawg-bwa-mem-aligner
```
Create Synapse credentials file `/home/michael_kotliar/temp/cwl_airflow/pcawg-bwa-mem-aligner/.synapseConfig`, put there Synapse ID and password
```
[authentication]
username: user@usermail.org
password: <user-password>
```
### Downloading required files
Download the tool to submit workflow results
```
cd /home/michael_kotliar/temp/cwl_airflow/pcawg-bwa-mem-aligner
synapse -c .synapseConfig get syn9732885   # dockstore-tool-synapse-submit.cwl
```
Download workflow input data
```
cd /home/michael_kotliar/temp/cwl_airflow/pcawg-bwa-mem-aligner
synapse -c .synapseConfig get -r syn10517407
```
Wait until downloading is finished

### Running workflow
```
cwl-airflow-runner --debug Dockstore.cwl pcawg-bwa-mem-aligner.job.json
```
### Validating results
Run checker tool
```
cd /home/michael_kotliar/temp/cwl_airflow/pcawg-bwa-mem-aligner
cwltool --debug --non-strict pcawg-bwa-mem-aligner.checker.cwl pcawg-bwa-mem-aligner.checker.job.json
```
Check results
```
cat results.json
``` 
```json
{""overall"": true}
```
### Submitting results
Update `pcawg-bwa-mem-aligner.submit.json` with correct
`team_name` - the name of your team in plain text format (e.g., ""GA4GH-Sage Contenders"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
Run the tool
```
cwltool --debug --non-strict dockstore-tool-synapse-submit.cwl pcawg-bwa-mem-aligner.submit.json
```
***Running time:*** 205 min  
***Disk usage:*** 6.7G",9657799
pcawg-bwa-mem-aligner,9657804_report.md,"## PCAWG bwa mem Aligner

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brice Aminou""
workflow_handle: ""pcawg-bwa-mem-aligner""
input_handle: ""hg19.chr22.5x.normal""
```

The following description is provided by the workflow authors (from [GitHub](https://github.com/ICGC-TCGA-PanCancer/Seqware-BWA-Workflow/tree/2.6.8_1.3)):

> This is the SeqWare workflow for the TCGA/ICGC PanCancer project that aligns whole genome sequences with BWA-Mem. It also reads/writes to GNOS (optionally), the metadata/data repository system used in the project. It can now be used in a standalone mode using the [Dockstore](http://dockstore.org/) CLI. For more information about the workflow see the [CHANGELOG](https://github.com/ICGC-TCGA-PanCancer/Seqware-BWA-Workflow/blob/2.6.8_1.3/CHANGELOG.md).


#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-09-20**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Bogdan Gavrilovic"" # your name here
institution: ""Seven Bridges Genomics"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""rabix"" 
workflow_type: ""CWL"" 
runner_version: ""1.0.1""
docker_version: ""17.05.0-ce""
environment: ""local"" 
env_cpus: ""8""
env_memory: ""32b""
env_disk: ""900Gb""
```

### Steps
#####1. [Install rabix](https://github.com/rabix/bunny#installing) on your machine and set environment variable $BUNNY. You need docker and java installed to run rabix:
```shell
wget https://github.com/rabix/bunny/releases/download/v1.0.1/rabix-1.0.1.tar.gz -O rabix-1.0.1.tar.gz && tar -xvf rabix-1.0.1.tar.gz
export BUNNY=$PWD/rabix-cli-1.0.1/rabix
```
#####2. If you've not already retrieved the CWL and data with synapse-get, you can use the [Synapse python client](https://github.com/Sage-Bionetworks/synapsePythonClient#installation):
```shell
pip install synapseclient
synapse get -r syn10517407 # workflow and inputs
synapse get syn9732885   # dockstore-tool-synapse-submit.cwl
```
Modify the docker image request line in the `pcawg-bwa-mem-aligner.cwl` with images.sbgenomics.com/bogdang/pcawg-bwa:2.0  

```CWL
    - dockerPull: quay.io/pancancer/pcawg-bwa-mem-workflow:2.6.8_1.2
    + dockerPull: images.sbgenomics.com/bogdang/pcawg-bwa:2.0
```

#####3. Run the workflow using rabix executor on your machine by typing in the terminal: $BUNNY <app> <inputs>
For example:
```shell
 $BUNNY pcawg-bwa-mem-aligner.cwl pcawg-bwa-mem-aligner.json
```
### Validating results

Modify `pcawg-bwa-mem-aligner.checker.job.json` to include the paths to the requested output files. 
> NOTE: The docker image was to be modified to overcome some environment specifics of cwltool runs, which changes the paths written in BAM header. This change causes the md5 sum of `.BAI` files to change. Since one of the steps in checker tool is comparing MD5 sum of original and produced `.BAI`, the checker will fail. For this reason, replace paths to produced `.BAI` files with paths to the reference `.BAI` files in `pcawg-bwa-mem-aligner.checker.job.json` and `pcawg-bwa-mem-aligner.submit.json`

After these changes, run:
```shell
cwltool --non-strict pcawg-bwa-mem-aligner.checker.cwl pcawg-bwa-mem-aligner.checker.job.json
```
Check results
```shell
cat results.json
```
You should see `""overall"": true`. If result does not match, you will see `""overall"": false`, please take a look at `log.txt` for more details.

### Submit results
Modify entries in `pcawg-bwa-mem-aligner.submit.json`
- Copy the .synapseConfig file to the current working directory.
- Update `pcawg-bwa-mem-aligner.submit.json` with correct
`team_name` - the name of your team in plain text format (e.g., ""GA4GH-Sage Contenders"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
`file` - paths to output files  

Submit your results to synapse, using the `rabix` 
```shell
$BUNNY dockstore-tool-synapse-submit.cwl pcawg-bwa-mem-aligner.submit.json
```",9657804
pcawg-bwa-mem-aligner,9657805_report.md,"## PCAWG bwa mem Aligner

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brice Aminou""
workflow_handle: ""pcawg-bwa-mem-aligner""
input_handle: ""hg19.chr22.5x.normal""
```

The following description is provided by the workflow authors (from [GitHub](https://github.com/ICGC-TCGA-PanCancer/Seqware-BWA-Workflow/tree/2.6.8_1.3)):

> This is the SeqWare workflow for the TCGA/ICGC PanCancer project that aligns whole genome sequences with BWA-Mem. It also reads/writes to GNOS (optionally), the metadata/data repository system used in the project. It can now be used in a standalone mode using the [Dockstore](http://dockstore.org/) CLI. For more information about the workflow see the [CHANGELOG](https://github.com/ICGC-TCGA-PanCancer/Seqware-BWA-Workflow/blob/2.6.8_1.3/CHANGELOG.md).


#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-09-20**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Bogdan Gavrilovic"" # your name here
institution: ""Seven Bridges Genomics"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""SevenBridges"" 
workflow_type: ""CWL"" 
runner_version: ""latest""
docker_version: ""1.12.6""
environment: ""EC2""  # c4.2xlarge instance
env_cpus: ""8""
env_memory: ""15Gb""
env_disk: ""700Gb""
```

### Steps
#####1. [Install rabix](https://github.com/rabix/bunny#installing) on your machine and set environment variable $BUNNY. You need docker and java installed to run rabix:
```shell
wget https://github.com/rabix/bunny/releases/download/v1.0.1/rabix-1.0.1.tar.gz -O rabix-1.0.1.tar.gz && tar -xvf rabix-1.0.1.tar.gz
export BUNNY=$PWD/rabix-cli-1.0.1/rabix
```
#####2. If you've not already retrieved the CWL and data with synapse-get, you can use the [Synapse python client](https://github.com/Sage-Bionetworks/synapsePythonClient#installation):
```shell
pip install synapseclient
synapse get -r syn10517407 # workflow and inputs
synapse get syn9732885   # dockstore-tool-synapse-submit.cwl
```
Modify the docker image request line in the `pcawg-bwa-mem-aligner.cwl` with images.sbgenomics.com/bogdang/pcawg-bwa:2.0  

```CWL
    - dockerPull: quay.io/pancancer/pcawg-bwa-mem-workflow:2.6.8_1.2
    + dockerPull: images.sbgenomics.com/bogdang/pcawg-bwa:2.0
```

#### Running on the [Cancer Genomics Cloud](https://cgc.sbgenomics.com/) 

#####3. Log in to the [Cancer Genomics Cloud](https://cgc.sbgenomics.com/) and [create a project](https://docs.cancergenomicscloud.org/docs/create-a-project) 
- Academic Users can create a free account on the Cancer Genomics Cloud (CGC). New users receive \$300 in cloud computing credits that you can apply to this challenge, and your own research. Additionally, users that leave feedback on their experience receive an additional \$1000 in cloud compute credits.
- Commercial users of the Seven Bridges Platform that wish to participate in the DREAM challenge can also create an account on the CGC to participate in this academic exercise and receive free credits to run the challenge workflows. Alternatively, commercial users are free to run DREAM challenge workflows in their commercial platform accounts, but should realize that they will incur cloud compute charges to do so. 
&nbsp;
#####4. Installing the workflow on the platform can be done using:  
**a)** [Rabix Composer app for CWL tool editing](http://rabix.io/) or   
**b)** a [CWL CommandLineTool](https://github.com/bogdang989/Import-CWL-to-SevenBridges) for importing CWL workflows to the Seven Bridges platform.  

#####4a. Rabix Composer
If you’re interested in trying out Seven Bridges’ new integrated development environment for creating CWL descriptions of tools and workflows, you can use the [Rabix Composer](http://rabix.io/) to upload the workflow to the platform. 
Use Rabix Composer to add the workflow to the platform:  
- [Install Rabix Composer](http://docs.rabix.io/rabix-composer-installation)
- [Configure Composer](http://docs.rabix.io/rabix-composer-configuration) to connect to the CGC or Seven Bridges platform
- [Add the project](http://docs.rabix.io/rabix-composer-configuration) you created for the DREAM challenge to the workspace
- [Add the local directory](http://docs.rabix.io/rabix-composer-configuration) containing the workflow to the workspace
- [Open](http://docs.rabix.io/rabix-composer-basics) the workflow with Composer
- [Save the workflow to the Platform project](http://docs.rabix.io/rabix-composer-basics) you added to the workspace
- Log into the Platform and [upload the input files](https://docs.cancergenomicscloud.org/docs/upload-to-the-cgc) to the project. 
- Run the task

> You can [upload the files manually to the platform](https://docs.cancergenomicscloud.org/docs/upload-to-the-cgc) by using either CGC Uploader app, command-line uploader, Python API or some other available upload method... All of the available methods are described in [the documentation](https://docs.cancergenomicscloud.org/docs/upload-to-the-cgc) 

#####4b. CWLtoSBG import tool
Download the CWL importing tool and **place it in the same directory with the CWL workflow** that should be installed on the platform. You can download the tool from [github](https://github.com/bogdang989/Import-CWL-to-SevenBridges) manually or from command-line by typing:
```shell
git clone https://github.com/bogdang989/Import-CWL-to-SevenBridges
```
Modify the `cwl_to_sbg-inputs.yaml` to include:  
- Paths to `pcawg-bwa-mem-aligner.cwl` and ` pcawg-bwa-mem-aligner.json`
- Id of your project on the platform (From project URL, in format *user-name/project-name* )
For example if project URL is https://cgc.sbgenomics.com/u/bogdang/demo-project; project_id is `bogdang/demo-project`
- Your [authentication token](http://docs.sevenbridges.com/docs/get-your-authentication-token)
- Adequate [EC2 instance type](http://www.ec2instances.info/)
&nbsp;
After modifying `cwl_to_sbg-inputs.yaml` with your information, import the workflow to the platform by running
```shell
$BUNNY cwl_to_sbg.cwl cwl_to_sbg-inputs.yaml
```
This will install the workflow and all required apps on the platform. All the files that are required for the task execution are uploaded if they are not uploaded previously. Template draft task is created. If `run_task` is set to `true` the task execution will start on the platform.
You can now open `task` page on the platform project to see task execution details.

### Validating results
[Download the output files](https://docs.cancergenomicscloud.org/docs/download-results) to your local machine.

Modify `pcawg-bwa-mem-aligner.checker.job.json` to include the paths to the requested output files. 
> NOTE: The docker image was to be modified to overcome some environment specifics of cwltool runs, which changes the paths written in BAM header. This change causes the md5 sum of `.BAI` files to change. Since one of the steps in checker tool is comparing MD5 sum of original and produced `.BAI`, the checker will fail. For this reason, replace paths to produced `.BAI` files with paths to the reference `.BAI` files in `pcawg-bwa-mem-aligner.checker.job.json` and `pcawg-bwa-mem-aligner.submit.json`

After these changes, run:
```shell
cwltool --non-strict pcawg-bwa-mem-aligner.checker.cwl pcawg-bwa-mem-aligner.checker.job.json
```
Check results
```shell
cat results.json
```
You should see `""overall"": true`. If result does not match, you will see `""overall"": false`, please take a look at `log.txt` for more details.

### Submit results
Modify entries in `pcawg-bwa-mem-aligner.submit.json`
- Copy the .synapseConfig file to the current working directory.
- Update `pcawg-bwa-mem-aligner.submit.json` with correct
`team_name` - the name of your team in plain text format (e.g., ""GA4GH-Sage Contenders"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
`file` - paths to output files  

Submit your results to synapse, using the `rabix` 
```shell
$BUNNY dockstore-tool-synapse-submit.cwl pcawg-bwa-mem-aligner.submit.json
```",9657805
pcawg-bwa-mem-aligner,9657907_report.md,"## PCAWG bwa mem Aligner

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brice Aminou""
workflow_handle: ""pcawg-bwa-mem-aligner""
input_handle: ""hg19.chr22.5x.normal""
```

The following description is provided by the workflow authors (from [GitHub](https://github.com/ICGC-TCGA-PanCancer/Seqware-BWA-Workflow/tree/2.6.8_1.3)):

> This is the SeqWare workflow for the TCGA/ICGC PanCancer project that aligns whole genome sequences with BWA-Mem. It also reads/writes to GNOS (optionally), the metadata/data repository system used in the project. It can now be used in a standalone mode using the [Dockstore](http://dockstore.org/) CLI. For more information about the workflow see the [CHANGELOG](https://github.com/ICGC-TCGA-PanCancer/Seqware-BWA-Workflow/blob/2.6.8_1.3/CHANGELOG.md).


#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-09-20**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Faisal M. Fadlelmola"" # your name here
institution: ""University of Khartoum"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-12-29"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""Dockstore"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170828135420"" # indicate executor version used
docker_version: ""17.03.1-ce, build c6d412e"" # from `docker --version`
environment: ""EGI FedCloud"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""32GB"" # indicate available RAM in environment
env_disk: ""100GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-08-31""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""1.12.6""
environment_ex: ""local"" 
env_cpus_ex: ""8""
env_memory_ex: ""96Gb""
env_disk_ex: ""2Tb""
```

### Steps

I launched a VM instance from EGI FedCloud resources (EGI Docker (Ubuntu 14.04) from CESNET MetaCloud (IaaS Cloud)) with extra large memory (32GB ram, 100GB disk, 8 cores). Docker is pre-installed, so I only needed to add the $USER to the `docker` group

_____________________


#####1. Setting up environment. 

This involves installing cwltool, java and dockstore:

```shell
sudo pip install setuptools==36.5.0
sudo pip install cwl-runner cwltool==1.0.20170828135420 schema-salad==2.6.20170806163416 avro==1.8.1 ruamel.yaml==0.14.12 requests==2.18.4

sudo add-apt-repository ppa:webupd8team/java
sudo apt-get update && sudo apt-get install -y oracle-java8-set-default

mkdir -p ~/bin
curl -L -o ~/bin/dockstore https://github.com/ga4gh/dockstore/releases/download/1.3.1/dockstore
chmod +x ~/bin/dockstore
echo 'export PATH=~/bin:$PATH' >> ~/.bashrc
source ~/.bashrc
 mkdir -p ~/.dockstore
printf ""token: eaed4f494bb41e6b78c19786a7ab5feb06c1e02f6f75315d9347f6d066be3719\nserver-url: https://dockstore.org:8443\n"" > ~/.dockstore/config
```

Create empty folder for workflow running

```
mkdir pcawg-bwa-mem
cd pcawg-bwa-mem
```

Create Synapse credentials file .synapseConfig, put there Synapse ID and password

```
$ cat .synapseConfig
[authentication]
username: my_registered_synapse_email
password: my_corresponding_password
```

#####2. Download required files:

```shell
pip install synapseclient
synapse -c .synapseConfig get syn10903609  # pcawg-bwa-mem-aligner_get.cwl.json
```

Using the `dockstore-tool-synapse-get.cwl` image from quay.io, I'm downloading the workflow data by running the script below in the background:

```
$ cat download_files.sh
#!/bin/bash
set -x
dockstore tool launch --entry quay.io/ga4gh-dream/dockstore-tool-synapse-get  --json  pcawg-bwa-mem-aligner_get.cwl.json
echo ""Done :)""

$ nohup ./download_files.sh &> nohup.download_files.sh.log &
```

#####3. Running the worklfow
Again:

```
$ cat runworkflow.sh
#!/bin/bash
set -x
dockstore tool launch --local-entry pcawg-bwa-mem-aligner.cwl --json pcawg-bwa-mem-aligner.json
echo ""Done :)""

$ nohup ./runworkflow.sh &> nohup.runworkflow.sh.log &
```

#####4. Validating results
Out of the 6 expected output files (as per `pcawg-bwa-mem-aligner.checker.job.json`), only 2 are directly provisioned in the current working directory, and can be checked. The remaining 4 files need their path adjusted (they are within the `datastore/launcher-f9cdf0f4-3d76-40ac-bab3-b7a5ebdb1f29/outputs/` folder, so I prefixed this path to each file) 

After these changes, run:

```shell
dockstore tool launch --local-entry pcawg-bwa-mem-aligner.checker.cwl --json pcawg-bwa-mem-aligner.checker.job.json

$ cat results.json    # Check results
{""overall"": true}
```

So, all is good :)

#####5. Submit results
Now, simply modify the file `pcawg-bwa-mem-aligner.submit.json`, to include the right `team_name`, path to each output file as in the previous step, and the corresponding `parent_id`

Submit your results to synapse, using the `dockstore`  command below:

```shell
dockstore tool launch --entry quay.io/ga4gh-dream/dockstore-tool-synapse-submit --json pcawg-bwa-mem-aligner.submit.json
```
",9657907
pcawg-bwa-mem-aligner,9657912_report.md,"## PCAWG bwa mem Aligner

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Brice Aminou""
workflow_handle: ""pcawg-bwa-mem-aligner""
input_handle: ""hg19.chr22.5x.normal""
```

The following description is provided by the workflow authors (from [GitHub](https://github.com/ICGC-TCGA-PanCancer/Seqware-BWA-Workflow/tree/2.6.8_1.3)):

> This is the SeqWare workflow for the TCGA/ICGC PanCancer project that aligns whole genome sequences with BWA-Mem. It also reads/writes to GNOS (optionally), the metadata/data repository system used in the project. It can now be used in a standalone mode using the [Dockstore](http://dockstore.org/) CLI. For more information about the workflow see the [CHANGELOG](https://github.com/ICGC-TCGA-PanCancer/Seqware-BWA-Workflow/blob/2.6.8_1.3/CHANGELOG.md).


#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-09-20**: Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Junjun Zhang"" # your name here
institution: ""Ontario Institute for Cancer Research"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-11-15"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""JTracker"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
cwltool_version: ""1.0.2017110733715""
runner_version: ""0.2.0a5"" # indicate executor version used
docker_version: ""1.12.6"" # from `docker --version`
environment: ""OpenStack VM"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""96GB"" # indicate available RAM in environment
env_disk: ""2TB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-08-31""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""1.12.6""
environment_ex: ""local"" 
env_cpus_ex: ""8""
env_memory_ex: ""96GB""
env_disk_ex: ""2TB""
```

### Write a JTracker Workflow
The JTracker workflow is written to automatically execute necessary steps to complete a Dream Challenge workflow. The JTracker workflow is named as `dream-challenge-wf-runner`, the source code is checked in Github at: https://github.com/jthub/demo-workflows/tree/master/dream-challenge-wf-runner/workflow.

Once tested out successfully, make a release of the source code. In this case, it is release version 0.0.7: https://github.com/jthub/demo-workflows/releases/tag/dream-challenge-wf-runner.0.0.7

### Register the JTracker Workflow in JTHub
#### Install JTracker command line tool

Follow the instructions here: https://github.com/icgc-dcc/jtracker

Once install successfully, you should be able to see the version number.
```
jt --version
```

#### Signup a JTHub account
Assume we choose `ga4gh_dream` as account name:
```
jt user signup -u ga4gh_dream
```
Login as `ga4gh_dream`
```
jt user login -u ga4gh_dream
```

#### Register the JTracker Dream Challenge Runner Workflow
Register a workflow is basically provide information to access the JTracker workflow source code in GitHub.
```
jt wf register --git-server https://github.com --git-account jthub --git-repo demo-workflows \
                       --git-path dream-challenge-wf-runner --git-tag dream-challenge-wf-runner.0.0.7 \
                       --wf-name dream-challenge-wf-runner --wf-version 0.0.7
```
To list all registered workflows in your account, do this:
```
jt wf ls
```

### Create a Job Queue
Once we have the workflow registered, you will be able to create a job queue for it.
```
jt queue add --wf-name dream-challenge-wf-runner --wf-version 0.0.7
```
Upon success, you will get a unique job queue ID. In my case, my queue ID is: `758b7668-0057-4ef6-a5b0-6f48acf38583`

To list all job queues you created, do this:
```
jt queue ls
```

### Add workflow job to the above queue
If we want to run ` pcawg-bwa-mem-aligner`, fill out the appropriate parameters in the job JSON as below:
```
jt job add -q 758b7668-0057-4ef6-a5b0-6f48acf38583 -j '
{
    ""workflow_name"": ""pcawg-bwa-mem-aligner"",
    ""workflow_type"": ""CWL"",
    ""data_syn_id"": ""syn10517407"",
    ""wf_file_name"": ""pcawg-bwa-mem-aligner.cwl"",
    ""job_file_name"": ""pcawg-bwa-mem-aligner.json"",
    ""checker_wf_file_name"": ""pcawg-bwa-mem-aligner.checker.cwl"",
    ""checker_job_file_name"": ""pcawg-bwa-mem-aligner.checker.job.json"",
    ""submit_job_file_name"": ""pcawg-bwa-mem-aligner.submit.json"",
    ""team_name"": ""PCAWG-Tech"",
    ""syn_parent_id"": ""syn11496968"",
    ""eval_id"": ""9606715""
}
'
```
To list all jobs in the queue:
```
jt job ls -q 758b7668-0057-4ef6-a5b0-6f48acf38583
```
Note that the above steps can be done on any computer, it could be a normal workstation or a laptop.


### Run the above queued Sanger workflow job

To execute the workflow job you will need to set up necessary environment and tools, follow these steps:

#### Setting up environment
1. Install Docker

2. Install `cwltool` (version 1.0.20170217172322) and  `synapseclient`
```
pip install cwltool==1.0.20170217172322
pip install synapseclient
```

3. Create Synapse credentials file `.synapseConfig`
Put there Synapse ID and password
```
[authentication]
username: user@usermail.org
password: <user-password>
```
Put this file a particular place, for example under home directory, eg, `/home/ubuntu/.synapseConfig`, then export the follow environment variable:
```
export SYNCONF=/home/ubuntu/.synapseConfig
```
4. Install JTracker command line
This is the same step as the previous section. Follow installation instruction here: https://github.com/icgc-dcc/jtracker

#### Start JTracker Executor
Start the executor to run jobs in the queue as:
```
jt user login ga4gh_dream
SYNCONF=/home/ubuntu/.synapseConfig jt exec run -q 758b7668-0057-4ef6-a5b0-6f48acf38583
```
If everything goes well, in about 5 hours, the job should finish and you will see `pcawg-bwa-mem-aligner` result uploaded to specified location on Synapse.

",9657912
pcawg-bwa-mem-aligner,9657921_report.md,"### Workflow description

```YAML
contributor: ""Brice Aminou""
workflow_handle: ""pcawg-bwa-mem-aligner""
input_handle: ""hg19.chr22.5x.normal""
```

### Participant information
```YAML
name: ""Ben Ernest""
institution: ""Digicon Corporation""
```

### Submission overview
```YAML
date_accessed: ""2017-12-05"" 
platform: ""cwltool"" 
workflow_type: ""CWL"" 
runner_version: ""1.0.20170217172322"" 
docker_version: ""17.09.0-ce"" 
environment: ""cluster"" 
env_cpus: ""12"" 
env_memory: ""62Gb"" 
env_disk: ""5Tb"" 
```

### Steps

#### 1. Set up environment, following instructions at https://dockstore.org/quick-start
##### Instructions are for Linux CentOS

Download and install dockstore.  
```shell
mkdir -p ~/bin
curl -L -o ~/bin/dockstore https://github.com/ga4gh/dockstore/releases/download/1.3.0/dockstore
chmod +x ~/bin/dockstore
echo 'export PATH=~/bin:$PATH' >> ~/.bashrc
source ~/.bashrc
```

Create configuration file
```shell
mkdir -p ~/.dockstore
printf ""token: dummy-token\nserver-url: https://dockstore.org:8443\n"" > ~/.dockstore/config
```

Install `pip`
```shell
curl -L -o ~/get-pip.py https://bootstrap.pypa.io/get-pip.py
sudo python get-pip.py
```

Install `cwltool` (**note: version 1.0.20170217172322**)
```shell
sudo pip install setuptools==36.5.0
sudo pip install cwl-runner cwltool==1.0.20170217172322 schema-salad==2.6.20170806163416 avro==1.8.1 ruamel.yaml==0.14.12 requests==2.18.4
```

Install Docker
```shell
sudo yum install -y yum-utils device-mapper-persistent-data lvm2
sudo yum-config-manager --add-repo ""https://download.docker.com/linux/centos/docker-ce.repo""
sudo yum-config-manager --enable extras
sudo yum -y install docker-ce
sudo usermod -aG docker $USER
exec newgrp docker
```

Create aliases to start and stop Docker
```shell
echo 'alias start_docker=""sudo systemctl start docker""' >> ~/.bashrc
echo `alias stop_docker=""sudo systemctl stop docker""' >> ~/.bashrc
source ~/.bashrc
```
Install `synapseclient`
```
sudo pip install synapseclient
```

Create synapse credentials file with the content below, using your own Synapse credentials (no quotes or extra characters).  It can be named anything, but I'm using `.synapseConfig`.
```
[authentication]
username: email
password: password
```

Create a working directory and copy synapse credentials file into that folder.
```shell
mkdir -p pcawg_bwa
cd pcawg_bwa
cp ~/.synapseConfig .
```

#### 2. Download required files
Download tools to fetch workflow input data.
```shell
synapse get syn10903609  # pcawg-bwa-mem-aligner_get.cwl.json
synapse get syn9770802   # dockstore-tool-synapse-get.cwl
synapse get syn9732885   # dockstore-tool-synapse-submit.cwl
```

#### 3. Provision all workflow files
Start docker, using alias created previously.
```shell
start_docker
```

Use `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `pcawg-bwa-mem-aligner_get.cwl.json` to download tools and data needed to run the workflow and submit results.
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl pcawg-bwa-mem-aligner_get.cwl.json
```

#### 4. Run main workflow
Use `cwltool` to run the workflow, as defined in `pcawg-bwa-mem-aligner.cwl` and parameterized by `pcawg-bwa-mem-aligner.json`:
```shell
cwltool --debug --non-strict pcawg-bwa-mem-aligner.cwl pcawg-bwa-mem-aligner.json
```

#### 5. Run workflow checker tool
To verify workflow results before submission, use `cwltool` to run the checker as follows:
```shell
cwltool --debug --non-strict pcawg-bwa-mem-aligner.checker.cwl pcawg-bwa-mem-aligner.checker.job.json
```

#### 6. Submit workflow outputs
Modify `team_name` and `parent_id` in `pcawg-bwa-mem-aligner.submit.json` as shown below, assuming Synapse credentials file is named `.synapseConfig` and located in `~/pcawg_bwa`.
```JSON
{
  ""config_file"": {
    ""class"": ""File"",
    ""path"": "".synapseConfig""
  },
  ""team_name"": ""BioGenLink"",
  ""eval_id"": ""9606715"",
  ""file"": [
    {""class"": ""File"", ""path"": ""hg19.chr22.5x.normal.bam""},
    {""class"": ""File"", ""path"": ""hg19.chr22.5x.normal.bam.bai""},
    {""class"": ""File"", ""path"": ""hg19.chr22.5x.normal.bam.metrics""},
    {""class"": ""File"", ""path"": ""hg19.chr22.5x.normal.unmapped.bam""},
    {""class"": ""File"", ""path"": ""hg19.chr22.5x.normal.unmapped.bam.bai""},
    {""class"": ""File"", ""path"": ""hg19.chr22.5x.normal.unmapped.bam.metrics""}
  ],
  ""parent_id"": ""syn11638642""
}
```

Submit outputs using `cwltool` and `dockstore-tool-synapse-submit.cwl`:
```shell
cwltool --debug --non-strict dockstore-tool-synapse-submit.cwl pcawg-bwa-mem-aligner.submit.json
```

Stop Docker if desired.
```shell
stop_docker
```",9657921
pcawg-bwa-mem-aligner,9657922_report.md,"### Workflow description

```YAML
contributor: ""Brice Aminou""
workflow_handle: ""pcawg-bwa-mem-aligner""
input_handle: ""hg19.chr22.5x.normal""
```

### Participant information
```YAML
name: ""Ben Ernest""
institution: ""Digicon Corporation""
```

### Submission overview
```YAML
date_accessed: ""2017-12-12"" 
platform: ""Dockstore"" 
workflow_type: ""CWL"" 
runner_version: ""1.0.20170217172322"" 
docker_version: ""17.09.0-ce"" 
environment: ""BioGenLink"" 
env_cpus: ""1"" 
env_memory: ""8Gb"" 
env_disk: ""5Tb"" 
```

### Steps
#####This workflow was run using the [BioGenLink](http://digicon.com/biogenlink.html) platform from [Digicon](http://digicon.com/).  Click [here](http://digicon.com/biogenlink.html) or [email us](mailto:biogenlink@digiconasp.com) for more information. 

#### **Setup**

##### Create synapse credentials file.  
This only needs to be done once, and the credentials file can be used for each workflow.
1. Log into BioGenLink.  [Click here](http://digicon.com/biogenlink.html) or [email us](mailto:biogenlink@digiconasp.com) for more information. 
${image?fileName=login%5Fscreen%5Fempty%2E2017%2D12%2D19%2Epng&align=None&scale=75&responsive=true}

2. In the **files** tab, right-click on any directory in the file system, select `Create File`, give the file a name (e.g., ""synapse_config.txt""), and click `Preview` to edit the file.  
${image?fileName=create%5Ffile%5Fpreview%2E2017%2D12%2D19%2Epng&align=None&scale=75&responsive=true}

Enter the following information in the file and save it by clicking **Save** (the disk button just above the text area).
```
[authentication]
username: email
password: password
[cache]
location: biodtfs/path/to/cache
```
**Note:** the cache directory is used by `synapseClient` for temporary files, and we must specify it in BioGenLink to avoid permissions errors. It can be any directory the user chooses, even a non-existing one as long as the parent directory is valid.  It is suggested to create a working directory for each workflow and keep this file in a parent directory outside of the working directories.  

#### **Provision workflow files**

1. Create a working directory.  
    - Right-click on any directory in the file system, select `Create Folder`, and enter a name for the working directory (e.g., `pcawg_bwa`).

2. Run the `Synapse get` tool.
    - In the **tools** tab, find and select the `Synapse get` tool.  It can be found by keyword search or browsing to `Synapse/All/Synapse get`.  Double-clicking (shown below) the tool will open it in the workspace for editing and browsing documentation and will display the menu for providing inputs and running the tool.
${image?fileName=synapse%5Fget%5Fopen%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
    - In the `Synapse IDs` field, enter the Synapse IDs for files to be downloaded.  In this case, the synapse IDs include the following, which correspond to `pcawg-bwa-mem-aligner_get.cwl.json`, `dockstore-tool-synapse-submit.cwl`, and `dockstore-tool-synapse-get.cwl`:
```shell
syn10903609  
syn9770802   
syn9732885   
```   
${image?fileName=synapse%5Fget%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
    - Drag and drop the synapse credentials file (e.g., `synapse_config.txt`) from the file system into the field called `Synapse config file`.
    - Drag and drop the working directory into the field called `Output directory`.
    - Run the tool by clicking `Quick Launch`.

#### **Run the workflow**
- Run the `Dockstore launch` tool.
    1. In the **Tools** tab, find and select the `Dockstore launch` tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore launch`.  
${image?fileName=dockstore%5Flaunch%2E2018%2D01%2D04%2Epng&align=None&scale=75&responsive=true}
    2. Drag and drop the `pcawg-bwa-mem-aligner.cwl` and `pcawg-bwa-mem-aligner.json` files from the working directory into the fields labeled `CWL file` and `JSON file`, respectively.  `Parent directory` can be left blank, since the directory containing the two input files will be used as the parent directory by default.   
    3. Click `Quick Launch`.

#### **Validate the results**
- Run the `Dockstore checker` tool.
1. In the **tools** tab, find and select the `Dockstore checker` tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore checker`.  
${image?fileName=dockstore%5Fchecker%2E2017%2D12%2D25%2Epng&align=None&scale=75&responsive=true}
  2. Drag and drop the `pcawg-bwa-mem-aligner.checker.cwl` and `pcawg-bwa-mem-aligner.checker.job.json` files from the working directory into the fields labeled `Checker CWL file` and `Checker JSON file`, respectively.  
  3. Click `Quick Launch`.
  4. Verify that the workflow ran successfully by opening the `results.json` file and confirming that the `Overall` field is equal to `true`.
${image?fileName=results%5Fjson%2E2017%2D12%2D25%2Epng&align=None&scale=75&responsive=true}

#### **Submit the results to Synapse**
- Run the `Dockstore submit` tool.
  1. In the **Tools** tab, find and select the `Dockstore submit` tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore submit`.  
${image?fileName=dockstore%5Fsubmit%2E2017%2D12%2D26%2Epng&align=None&scale=75&responsive=true}
  2. Drag and drop the `pcawg-bwa-mem-aligner.submit.json` file into the field labeled `Submit JSON file`.  
  3. Enter a team name and the Synapse parent ID into the corresponding fields.  
  4. Drag and drop the synapse credentials file (e.g., `synapse_config.txt`) into the field labeled `Synapse config file`.
  5. Click `Quick Launch`.",9657922
pcawg-bwa-mem-aligner,9657929_report.md,"### Workflow description

```YAML
contributor: ""Brice Aminou""
workflow_handle: ""pcawg-bwa-mem-aligner""
input_handle: ""hg19.chr22.5x.normal""
```

### Participant information
```YAML
name: ""Ben Ernest""
institution: ""Digicon Corporation""
```

### Submission overview
```YAML
date_accessed: ""2017-12-12"" 
platform: ""BioGenLink"" 
workflow_type: ""CWL"" 
runner_version: ""1.0.20170217172322"" 
docker_version: ""17.09.0-ce"" 
environment: ""BioGenLink"" 
env_cpus: ""1"" 
env_memory: ""8Gb"" 
env_disk: ""5Tb"" 
```

### Steps
#####This workflow was run using the [BioGenLink](http://digicon.com/biogenlink.html) platform from [Digicon](http://digicon.com/).  Click [here](http://digicon.com/biogenlink.html) or [email us](mailto:biogenlink@digiconasp.com) for more information. 

#### **Setup**

##### Create synapse credentials file.  
This only needs to be done once, and the credentials file can be used for each workflow.
1. Log into BioGenLink.  [Click here](http://digicon.com/biogenlink.html) or [email us](mailto:biogenlink@digiconasp.com) for more information.
${image?fileName=login%5Fscreen%5Fempty%2E2017%2D12%2D19%2Epng&align=None&scale=75&responsive=true}

2. In the **files** tab, right-click on any directory in the file system, select `Create File`, give the file a name (e.g., ""synapse_config.txt""), and click `Preview` to edit the file.  
${image?fileName=create%5Ffile%5Fpreview%2E2017%2D12%2D19%2Epng&align=None&scale=75&responsive=true}

Enter the following information in the file and save it by clicking **Save** (the disk button just above the text area).
```
[authentication]
username: email
password: password
[cache]
location: biodtfs/path/to/cache
```
**Note:** the cache directory is used by `synapseClient` for temporary files, and we must specify it in BioGenLink to avoid permissions errors. It can be any directory the user chooses, even a non-existing one as long as the parent directory is valid.  It is suggested to create a working directory for each workflow and keep this file in a parent directory outside of the working directories.  

#### **Provision workflow files**

1. Create a working directory.  
    - Right-click on any directory in the file system, select `Create Folder`, and enter a name for the working directory (e.g., `pcawg_bwa`).

2. Run the `Synapse get` tool.
    - In the **tools** tab, find and select the `Synapse get` tool.  It can be found by keyword search or browsing to `Synapse/All/Synapse get`.  Double-clicking (shown below) the tool will open it in the workspace for editing and browsing documentation and will display the menu for providing inputs and running the tool.
${image?fileName=synapse%5Fget%5Fopen%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
    - In the `Synapse IDs` field, enter the Synapse IDs for files to be downloaded.  In this case, the synapse IDs include the following, which correspond to `pcawg-bwa-mem-aligner_get.cwl.json`, `dockstore-tool-synapse-submit.cwl`, and `dockstore-tool-synapse-get.cwl`:
```shell
syn10903609
syn9732885
syn9770802
```
${image?fileName=synapse%5Fget%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
    - Drag and drop the synapse credentials file (e.g., `synapse_config.txt`) from the file system into the field called `Synapse config file`.
    - Drag and drop the working directory into the field called `Output directory`.
    - Run the tool by clicking `Quick Launch`.

#### **Import the workflow**
- If the workflow has not been imported yet, go to the **files** tab and find the `CWL` file corresponding to the workflow you want to build (e.g., `pcawg-bwa-mem-aligner.cwl`).  Right-click on the file, and select `Import CWL File`.  This will automatically build a workflow which can be edited and run within the BioGenLink platform. 
${image?fileName=import%5Fcwl%5Ffile%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
The `pcawg-bwa-mem-aligner` workflow is automatically created and placed in the **workflows** tab, under `CWL/Autogenerated`. 

#### **Run the workflow**
1. In the **workflows** tab, find and select the `pcawg-bwa-mem-aligner` workflow.  The previous step automatically places it in the `CWL/Autogenerated` folder.  Double-clicking (shown below) opens the workflow in the workspace for editing and will display the menu for providing inputs and running the workflow.
${image?fileName=hello%5Fworld%5Fworkflow%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
If the run parameters aren't visible, right-click the orange ""play button"" at top right of the workspace to open them.
${image?fileName=hello%5Fworld%5Fworkflow%5Frun%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
The default inputs should already be set, but if they aren't then drag and drop the appropriate files from the working directory into the input fields.
2. Drag and drop a directory from the file system into the `Output Directory` field.
3. Run the workflow by clicking the `RUN WITH SKIPPING` button.


#### **Validate the results**
- Run the `Dockstore checker` tool.
1. In the **tools** tab, find and select the `Dockstore checker` tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore checker`.  
${image?fileName=dockstore%5Fchecker%2E2017%2D12%2D25%2Epng&align=None&scale=75&responsive=true}
2. Drag and drop the `pcawg-bwa-mem-aligner.checker.cwl` and `pcawg-bwa-mem-aligner.checker.job.json` files from the working directory into the fields labeled `Checker CWL file` and `Checker JSON file`, respectively.  
3. Click `Quick Launch`.
4. Verify that the workflow ran successfully by opening the `results.json` file and confirming that the `Overall` field is equal to `true`.
${image?fileName=results%5Fjson%2E2017%2D12%2D25%2Epng&align=None&scale=75&responsive=true}

#### **Submit the results to Synapse**
- Run the `Dockstore submit` tool.
1. In the **tools** tab, find and select the `Dockstore submit` tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore submit`.  
${image?fileName=dockstore%5Fsubmit%2E2017%2D12%2D26%2Epng&align=None&scale=75&responsive=true}
2. Drag and drop the `pcawg-bwa-mem-aligner.submit.cwl.json` file into the field labeled `Submit JSON file`.  
3. Enter a team name and the Synapse parent ID into the corresponding fields.  
4. Drag and drop the synapse credentials file (e.g., `synapse_config.txt`) into the field labeled `Synapse config file`.
5. Click `Quick Launch`.",9657929
pcawg-delly-sv-caller,9646147_report.md,"## PCAWG-delly-sv-caller

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Abraham Chavez""
workflow_handle: ""pcawg-delly-sv-caller""
input_handle:  ""HCC1143""
```


> **Description:** DELLY is an integrated structural variant prediction method that can detect deletions, tandem duplications, inversions and translocations at single-nucleotide resolution in short-read massively parallel sequencing data. It uses paired-ends and split-reads to sensitively and accurately delineate genomic rearrangements throughout the genome.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""16Gb""
suggested_disk: ""50Gb""
```

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Abraham Chavez"" # your name here
institution: ""UCSC Genomics Institute"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170217172322"" # indicate executor version used
docker_version: ""17.06.0-ce"" # from `docker --version`
environment: ""EC2"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""4"" # indicate number of cores in environment
env_memory: ""16GB"" # indicate available RAM in environment
env_disk: ""200GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""500Gb""
```

### Steps

_____________________

### Setting up environment

If you have not set up your environment and install dependencies like **cwltool**, **dockstore**, **java** and so on
I recommend you follow [**this**](https://www.synapse.org/#!Synapse:syn10220609) instructions.

Create empty folder for workflow running
```SHELL
mkdir pcawg-delly
cd pcawg-delly
cp ../.synapseConfig .
```
Information about `.synapseConfig` can be found [**here**](https://www.synapse.org/#!Synapse:syn8507133/wiki/451408)
#####
#### 2. Download required files
By installing the `synapse` client we can provision some basic files that can help us provision the rest of our workflow, and the submit file that will put the workflow results back on synapse. 
```shell
synapse -c .synapseConfig get syn10903611 # pcawg-delly-sv-caller_get.cwl.json
synapse -c .synapseConfig get syn9732885   # dockstore-tool-synapse-submit.cwl
synapse -c .synapseConfig get syn9770802   # dockstore-tool-synapse-get.cwl
```

#### 3. Provision input files and workflow commands.
Since we already have the file with the information about the files to run our workflow, by running the following command, we can provisioned in our machine using the `cwltool`.
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl pcawg-delly-sv-caller_get.cwl.json
```
#### 4. Run the workflow
Again using `cwltool` we then run the main workflow, which should take about 15-20 minutes to run if the resources specified are satisfied, I would guess that it would take less if more RAM is used. 
```shell
 cwltool --debug --non-strict pcawg-delly-sv-caller.cwl pcawg-delly-sv-caller.cwl.json 
```
#### 5. Check the outputs
We can confirm the outputs obtained are correct by running the following tool. If you ran the workflow using `dockstore cli` you can use `cwltool` to check your results it should be the same.
```shell
 cwltool --debug --non-strict pcawg-delly-sv-caller_checker.cwl pcawg-delly-sv-caller_checker.cwl.json
```
Observe that the checker produced the right results.
> **NOTE:** The checker tool does not check the produced `plots` and `cov` folders. It only checks the `text_logs` for `germline.sv.bedpe` and `somatic.sv.bedpe` as well as the `sv.log` since those files and folders contain the information regarding the run, and all the variations predicted can be found there. The specifics of all the comparisons including non-variation data can be excluded. 
```shell
cat result.json | grep overall
```
Should yield `overall : True` to confirm all the outputs were correct.

#### 6. Submit results
Modify entries in `pcawg-delly-sv-caller_submit.cwl.json` (if required) to ensure the output files are in the correct path, as described in the json file.
```JSON
{
  ""config_file"": {
    ""class"": ""File"",
    ""path"": "".synapseConfig""
  },
  ""team_name"": """",
  ""eval_id"": ""9606704"",
  ""file"": [
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.germline.sv.bedpe.txt""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.germline.sv.vcf.gz""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.somatic.sv.bedpe.txt""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.somatic.sv.vcf.gz""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.sv.cov.plots.tar.gz""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.sv.cov.tar.gz""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.sv.timing.json""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.sv.qc.json""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.sv.log.tar.gz""}
  ],
  ""parent_id"": ""syn012345678""
}
```

Submit your results to synapse, using the `cwltool` 
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl pcawg-delly-sv-caller_submit.cwl.json
```
",9646147
pcawg-delly-sv-caller,9655152_report.md,"## PCAWG-delly-sv-caller

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Abraham Chavez""
workflow_handle: ""pcawg-delly-sv-caller""
input_handle:  ""HCC1143""
```


> **Description:** DELLY is an integrated structural variant prediction method that can detect deletions, tandem duplications, inversions and translocations at single-nucleotide resolution in short-read massively parallel sequencing data. It uses paired-ends and split-reads to sensitively and accurately delineate genomic rearrangements throughout the genome.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""16Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-09-21:** Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Azza E Ahmed"" # your name here
institution: ""University of Khartoum"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
pdate_accessed: ""2017-11-25"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170217172322"" # indicate executor version used
docker_version: ""17.03.1-ce, build c6d412e"" # from `docker --version`
environment: ""EGI FedCloud"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""32GB"" # indicate available RAM in environment
env_disk: ""100GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""500Gb""
```

### Steps

_____________________

### Setting up environment


0.  I launched a VM instance from EGI FedCloud resources (EGI Docker (Ubuntu 14.04) from CESNET MetaCloud (IaaS Cloud)) with extra large memory (32GB ram, 100GB disk, 8 cores). 

1.   Next, I created the challenge directory:


```SHELL
mkdir pcawg-delly
cd pcawg-delly
vi .synapseConfig #edit to include Synapse username and password
```

#### 2. Download required files
By installing the `synapse` client we can provision some basic files that can help us provision the rest of our workflow, and the submit file that will put the workflow results back on synapse. 

```shell
synapse -c .synapseConfig get syn10903611 # pcawg-delly-sv-caller_get.cwl.json
synapse -c .synapseConfig get syn9732885   # dockstore-tool-synapse-submit.cwl
synapse -c .synapseConfig get syn9770802   # dockstore-tool-synapse-get.cwl
```

#### 3. Provision input files and workflow commands.
Since we already have the file with the information about the files to run our workflow, by running the following command, we can provisioned in our machine using the `cwltool`.

```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl pcawg-delly-sv-caller_get.cwl.json
```
#### 4. Run the workflow
Again using `cwltool` we then run the main workflow:

```shell
 cwltool --debug --non-strict pcawg-delly-sv-caller.cwl pcawg-delly-sv-caller.cwl.json 
```
#### 5. Check the outputs
We can confirm the outputs obtained are correct by running the following tool. If you ran the workflow using `dockstore cli` you can use `cwltool` to check your results it should be the same.
```shell
 cwltool --debug --non-strict pcawg-delly-sv-caller_checker.cwl pcawg-delly-sv-caller_checker.cwl.json
```
Observe that the checker produced the right results.
> **NOTE:** The checker tool does not check the produced `plots` and `cov` folders. It only checks the `text_logs` for `germline.sv.bedpe` and `somatic.sv.bedpe` as well as the `sv.log` since those files and folders contain the information regarding the run, and all the variations predicted can be found there. The specifics of all the comparisons including non-variation data can be excluded. 
```shell
cat result.json | grep overall
```
Should yield `overall : True` to confirm all the outputs were correct.

#### 6. Submit results
Modify entries in `pcawg-delly-sv-caller_submit.cwl.json` (if required) to ensure the output files are in the correct path, as described in the json file.
```JSON
{
  ""config_file"": {
    ""class"": ""File"",
    ""path"": "".synapseConfig""
  },
  ""team_name"": """", #Your team name
  ""eval_id"": ""9606704"",
  ""file"": [
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.germline.sv.bedpe.txt""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.germline.sv.vcf.gz""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.somatic.sv.bedpe.txt""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.somatic.sv.vcf.gz""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.sv.cov.plots.tar.gz""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.sv.cov.tar.gz""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.sv.timing.json""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.sv.qc.json""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.sv.log.tar.gz""}
  ],
  ""parent_id"": """" #parent directory to submit to
}
```

Submit your results to synapse, using the `cwltool` 
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl pcawg-delly-sv-caller_submit.cwl.json
```
",9655152
pcawg-delly-sv-caller,9656278_report.md,"## PCAWG-delly-sv-caller

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Abraham Chavez""
workflow_handle: ""pcawg-delly-sv-caller""
input_handle:  ""HCC1143""
```


> **Description:** DELLY is an integrated structural variant prediction method that can detect deletions, tandem duplications, inversions and translocations at single-nucleotide resolution in short-read massively parallel sequencing data. It uses paired-ends and split-reads to sensitively and accurately delineate genomic rearrangements throughout the genome.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""16Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-09-21:** Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Joe Slagel"" # your name here
institution: ""ISB"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-12-7"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170822192924"" # indicate executor version used
docker_version: ""Docker version 1.12.6, build 78d1802"" # from `docker --version`
environment: ""Google Compute"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""2"" # indicate number of cores in environment
env_memory: ""7.5 GB"" # indicate available RAM in environment
env_disk: ""250 GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

_____________________

### Setting up environment

I created an empty folder for workflow on a Google VM were I had already installed docker, synapse client,  and cwtool using the following instructions:

```SHELL
mkdir pcawg-delly
cd pcawg-delly
cp ~/.synapseConfig .
```

#####
#### 2. Download required files

Provisioned some basic files that can help us provision the rest of our workflow, and the submit file that will put the workflow results back on synapse:

```shell
synapse -c .synapseConfig get syn10903611 # pcawg-delly-sv-caller_get.cwl.json
synapse -c .synapseConfig get syn9732885   # dockstore-tool-synapse-submit.cwl
synapse -c .synapseConfig get syn9770802   # dockstore-tool-synapse-get.cwl
```

#### 3. Provision input files and workflow commands.

```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl pcawg-delly-sv-caller_get.cwl.json > get.log 2>&1
```

#### 4. Run the workflow

```shell
 cwltool --debug --non-strict pcawg-delly-sv-caller.cwl pcawg-delly-sv-caller.cwl.json > run.log 2>&1
```

#### 5. Check the outputs

```shell
 cwltool --debug --non-strict pcawg-delly-sv-caller_checker.cwl pcawg-delly-sv-caller_checker.cwl.json > check.log 2>&1
```
Observe that the checker produced the right results.

```shell
cat result.json | grep overall
```
Should yield `overall : True` to confirm all the outputs were correct.

#### 6. Submit results

Modified the entries in `pcawg-delly-sv-caller_submit.cwl.json` (if required) to ensure the output files are in the correct path, as described in the json file.

Submit results to synapse, using the `cwltool` 
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl pcawg-delly-sv-caller_submit.cwl.json > submit.log 2>&1
```
",9656278
pcawg-delly-sv-caller,9656280_report.md,"## PCAWG-delly-sv-caller

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Abraham Chavez""
workflow_handle: ""pcawg-delly-sv-caller""
input_handle:  ""HCC1143""
```


> **Description:** DELLY is an integrated structural variant prediction method that can detect deletions, tandem duplications, inversions and translocations at single-nucleotide resolution in short-read massively parallel sequencing data. It uses paired-ends and split-reads to sensitively and accurately delineate genomic rearrangements throughout the genome.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""16Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-09-21:** Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Benjamin Story"" # your name here
institution: ""EMBL"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""12/09/2017"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""cwltool 1.0.20170413194156"" # indicate executor version used
docker_version: ""1.7.1, build 786b29d"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""12"" # indicate number of cores in environment
env_memory: ""72GB"" # indicate available RAM in environment
env_disk: ""1TB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""17.06.0-ce""
environment_ex: ""local"" 
env_cpus_ex: ""4""
env_memory_ex: ""16Gb""
env_disk_ex: ""500Gb""
```

### Steps

_____________________

### Setting up environment

If you have not set up your environment and install dependencies like **cwltool**, **dockstore**, **java** and so on
I recommend you follow [**this**](https://www.synapse.org/#!Synapse:syn10220609) instructions.

Create empty folder for workflow running
```SHELL
mkdir pcawg-delly
cd pcawg-delly
cp ../.synapseConfig .
```
Information about `.synapseConfig` can be found [**here**](https://www.synapse.org/#!Synapse:syn8507133/wiki/451408)
#####
#### 2. Download required files
By installing the `synapse` client we can provision some basic files that can help us provision the rest of our workflow, and the submit file that will put the workflow results back on synapse. 
```shell
synapse -c .synapseConfig get syn10903611 # pcawg-delly-sv-caller_get.cwl.json
synapse -c .synapseConfig get syn9732885   # dockstore-tool-synapse-submit.cwl
synapse -c .synapseConfig get syn9770802   # dockstore-tool-synapse-get.cwl
```

#### 3. Provision input files and workflow commands.
Since we already have the file with the information about the files to run our workflow, by running the following command, we can provisioned in our machine using the `cwltool`.
```shell
cwltool  --tmpdir-prefix tmp/ --cachedir cache/ --non-strict dockstore-tool-synapse-get.cwl pcawg-delly-sv-caller_get.cwl.json
```
#### 4. Run the workflow
Move into the location with the data (cache redirected files):
```shell
cd /tmpdata/story/pcawg-delly/cache/e819a28dd178887028236d434ea85324/
```
Copy and symbolically link missing files
``` shell
ln -s ../../../*.cwl ./
ln -s ../../../*.json ./
cp ../../../.synapseConfig ./
```
Again using `cwltool` we then run the main workflow, which should take about 15-20 minutes to run if the resources specified are satisfied, I would guess that it would take less if more RAM is used. 
```shell
 cwltool --tmpdir-prefix tmp/ --cachedir cache/ --debug --non-strict pcawg-delly-sv-caller.cwl pcawg-delly-sv-caller.cwl.json 
```
#### 5. Check the outputs
We can confirm the outputs obtained are correct by running the following tool. If you ran the workflow using `dockstore cli` you can use `cwltool` to check your results it should be the same.
```shell
 cwltool --debug --non-strict pcawg-delly-sv-caller_checker.cwl pcawg-delly-sv-caller_checker.cwl.json
```
Observe that the checker produced the right results.
> **NOTE:** The checker tool does not check the produced `plots` and `cov` folders. It only checks the `text_logs` for `germline.sv.bedpe` and `somatic.sv.bedpe` as well as the `sv.log` since those files and folders contain the information regarding the run, and all the variations predicted can be found there. The specifics of all the comparisons including non-variation data can be excluded. 
```shell
cat result.json | grep overall
```
Should yield `overall : True` to confirm all the outputs were correct.

#### 6. Submit results
Modify entries in `pcawg-delly-sv-caller_submit.cwl.json` (if required) to ensure the output files are in the correct path, as described in the json file.
```JSON
{
  ""config_file"": {
    ""class"": ""File"",
    ""path"": "".synapseConfig""
  },
  ""team_name"": ""EMBL GA4GH-DREAM Challenge Team"",
  ""eval_id"": ""9606704"",
  ""file"": [
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.germline.sv.bedpe.txt""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.germline.sv.vcf.gz""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.somatic.sv.bedpe.txt""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.somatic.sv.vcf.gz""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.sv.cov.plots.tar.gz""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.sv.cov.tar.gz""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.sv.timing.json""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.sv.qc.json""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.sv.log.tar.gz""}
  ],
  ""parent_id"": ""syn11587005""
}
```

Submit your results to synapse, using the `cwltool` 
```shell
cwltool --non-strict dockstore-tool-synapse-submit.cwl pcawg-delly-sv-caller_submit.cwl.json
```
",9656280
pcawg-delly-sv-caller,9656798_report.md,"## PCAWG-delly-sv-caller

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Abraham Chavez""
workflow_handle: ""pcawg-delly-sv-caller""
input_handle:  ""HCC1143""
```


> **Description:** DELLY is an integrated structural variant prediction method that can detect deletions, tandem duplications, inversions and translocations at single-nucleotide resolution in short-read massively parallel sequencing data. It uses paired-ends and split-reads to sensitively and accurately delineate genomic rearrangements throughout the genome.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""16Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-09-21:** Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Vipin T. Sreedharan"" # your name here
institution: ""ETH Zürich, NEXUS Personalized Health Technologies"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-12-11""
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""cwltool  1.0.20170828135420"" # indicate executor version used
docker_version: ""1.12.6, build c4618fb"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""32Gb"" # indicate available RAM in environment
env_disk: ""100Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```


### Steps

_____________________

#### 1. Setting up environment

At our institute, on a compute machine called `wfexec` with Red Hat Enterprise Linux Server release 7.4 (Maipo), installed Docker. Created a group named ""docker"" since it was preferred to use Docker as a non-root user on this machine. The instance has a non-root user called `wfrunner`. Next added the non-root user `wfrunner` to the ""docker"" group. Then started the docker engine and all the below commands were executed using root user privileges [sudo]:

```shell
yum install docker
groupadd docker 
usermod -aG docker wfrunner  
systemctl start docker 
```
&nbsp;

As a non-root user `wfrunner` on `wfexec` machine, installed Anaconda and cwltool to the home path:
```shell
su - wfrunner
wget https://repo.continuum.io/archive/Anaconda2-4.4.0-Linux-x86_64.sh
bash Anaconda2-4.4.0-Linux-x86_64.sh 
conda install virtualenv
virtualenv -p python2 /home/wfrunner/venv
source /home/wfrunner/venv/bin/activate
pip install cwltools synapseclient
deactivate
```
&nbsp;

By installing the `synapseclient` we can provision some basic files that can help us provision the rest of our workflow, and the submit file that will put the workflow results back on synapse. 
Created a utilities directory for storing the `synapse-get` and `synapse-submit` CWL tools. In the same folder, created Synapse credential file `.synapse_config` and put there Synapse ID and password. 
```shell
mkdir -p /home/wfrunner/synapse_utils
cd /home/wfrunner/synapse_utils
touch .synapse_config
vim .synapse_config
[WRITE] Synapse username & password

synapse -c .synapse_config get syn9770802   # dockstore-tool-synapse-get.cwl
synapse -c .synapse_config get syn9732885   # dockstore-tool-synapse-submit.cwl
```

#### 2. Download required files
Downloaded data config file `pcawg-delly-sv-caller_get.cwl.json` for the **pcawg-delly-sv-caller** workflow. Created a directory for storing the workflow associated data downloading JSON parameter file: 

```shell
mkdir -p /home/wfrunner/data_config_files
synapse -c ~/synapse_utils/.synapse_config get syn10903611 # pcawg-delly-sv-caller_get.cwl.json
vim pcawg-delly-sv-caller_get.cwl.json
[PASTE] /home/wfrunner/synapse_utils/.synapse_config
```

#### 3. Provision input files and workflow commands.
Since we already have the file with the information about the files to run our workflow, by running the following command, we can provisioned in our machine. Created a working directory for the current workflow.
```shell
mkdir -p /home/wfrunner/pcawg-delly-sv-caller
cd /home/wfrunner/pcawg-delly-sv-caller
```
Used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `pcawg-delly-sv-caller_get.cwl.json` to download workflow input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltool --tmpdir-prefix ~/tmp/ --tmp-outdir-prefix ~/tmp/ --debug --non-strict ~/synapse_utils/dockstore-tool-synapse-get.cwl ~/config_files/pcawg-delly-sv-caller_get.cwl.json
```
Wait until downloading is finished. 

#### 4. Run the main workflow
Run the workflow. 
```shell
cd /home/wfrunner/pcawg-delly-sv-caller
cwltool --tmpdir-prefix ~/tmp/ --tmp-outdir-prefix ~/tmp/ --debug --non-strict pcawg-delly-sv-caller.cwl pcawg-delly-sv-caller.cwl.json
```
Wait for the run to finish. 

#### 5. Run workflow checker tool 

Run checker tool to validate workflow results before submission:
```shell
cd /home/wfrunner/pcawg-delly-sv-caller
cwltool --tmpdir-prefix ~/tmp/ --tmp-outdir-prefix ~/tmp/ --debug --non-strict pcawg-delly-sv-caller_checker.cwl pcawg-delly-sv-caller_checker.cwl.json
```

Check results:
```shell
cd /home/wfrunner/pcawg-delly-sv-caller
cat results.json | grep -i overall
[OUTPUT] ""overall"": true
``` 
Confirming that all the outputs were correct. 

> **NOTE:** The checker tool does not check the produced `plots` and `cov` folders. It only checks the `text_logs` for `germline.sv.bedpe` and `somatic.sv.bedpe` as well as the `sv.log` since those files and folders contain the information regarding the run, and all the variations predicted can be found there. The specifics of all the comparisons including non-variation data can be excluded. 

#### 6. Submit results
Modified the entries in `pcawg-delly-sv-caller_submit.cwl.json` with correct: 
`path` - the synapse credentials file 
`team_name` - the name of your team in plain text format
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse

```JSON
{
  ""config_file"": {
    ""class"": ""File"",
    ""path"": ""/home/wfrunner/synapse_utils/.synapse_config""
  },
  ""team_name"": ""ETH Zurich NEXUS Workflow Handler"",
  ""eval_id"": ""9606704"",
  ""file"": [
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.germline.sv.bedpe.txt""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.germline.sv.vcf.gz""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.somatic.sv.bedpe.txt""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.somatic.sv.vcf.gz""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.sv.cov.plots.tar.gz""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.sv.cov.tar.gz""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.sv.timing.json""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.sv.qc.json""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.sv.log.tar.gz""}
  ],
  ""parent_id"": ""syn11599665""
}
```

Finally, submitted outputs using the submission tool `dockstore-tool-synapse-submit.cwl`:
```shell
cd /home/wfrunner/pcawg-delly-sv-caller
cwltool --debug --non-strict ~/synapse_utils/dockstore-tool-synapse-submit.cwl pcawg-delly-sv-caller_submit.cwl.json
```
",9656798
pcawg-delly-sv-caller,9657025_report.md,"## PCAWG-delly-sv-caller

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Abraham Chavez""
workflow_handle: ""pcawg-delly-sv-caller""
input_handle:  ""HCC1143""
```


> **Description:** DELLY is an integrated structural variant prediction method that can detect deletions, tandem duplications, inversions and translocations at single-nucleotide resolution in short-read massively parallel sequencing data. It uses paired-ends and split-reads to sensitively and accurately delineate genomic rearrangements throughout the genome.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""16Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-09-21:** Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Vipin T. Sreedharan"" # your name here
institution: ""ETH Zürich, NEXUS Personalized Health Technologies"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-12-11"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""Rabix"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""rabix 1.0.1"" # indicate executor version used
docker_version: ""1.12.6, build c4618fb"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""32Gb"" # indicate available RAM in environment
env_disk: ""100Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps
_____________________

#### 1. Setting up environment

At our institute, on a compute machine called `wfexec` with Red Hat Enterprise Linux Server release 7.4 (Maipo), installed Docker. Created a group named ""docker"" since it was preferred to use Docker as a non-root user on this machine. The instance has a non-root user called `wfrunner`. Next added the non-root user `wfrunner` to the ""docker"" group. Then started the docker engine and all the below commands were executed using root user privileges [sudo]:
```shell
yum install docker
groupadd docker 
usermod -aG docker wfrunner  
systemctl start docker 
# required for Rabix
yum install java-1.8.0-openjdk-devel.x86_64 
```

As a non-root user `wfrunner` on `wfexec` machine, installed Anaconda and Rabix to the home path:
```shell
su - wfrunner
wget https://repo.continuum.io/archive/Anaconda2-4.4.0-Linux-x86_64.sh
bash Anaconda2-4.4.0-Linux-x86_64.sh 
conda install virtualenv
virtualenv -p python2 /home/wfrunner/venv
source /home/wfrunner/venv/bin/activate
pip install cwltools
deactivate
conda install -c bioconda synapseclient
wget https://github.com/rabix/bunny/releases/download/v1.0.1/rabix-1.0.1.tar.gz -O rabix-1.0.1.tar.gz
tar -xzf rabix-1.0.1.tar.gz
export PATH=$PATH:/home/wfrunner/rabix-cli-1.0.1/
```

By installing the `synapseclient` we can provision some basic files that can help us provision the rest of our workflow, and the submit file that will put the workflow results back on synapse.
Created a utilities directory for storing the `synapse-get` and `synapse-submit` CWL tools. In the same folder, created Synapse credential file `.synapse_config` and put there Synapse ID and password. 

```shell
mkdir -p /home/wfrunner/synapse_utils
cd /home/wfrunner/synapse_utils
touch .synapse_config
vim .synapse_config
[WRITE]
[authentication]
username: user@usermail.org
password: <user-password>

synapse -c .synapse_config get syn9770802   # dockstore-tool-synapse-get.cwl
synapse -c .synapse_config get syn9732885   # dockstore-tool-synapse-submit.cwl
```
#### 2. Download required files

Downloaded data config file `pcawg-delly-sv-caller_get.cwl.json` for the **pcawg-delly-sv-caller** workflow. Created a directory for storing the workflow associated data downloading JSON parameter file:

```shell
mkdir -p /home/wfrunner/data_config_files
cd /home/wfrunner/data_config_files
synapse -c ~/synapse_utils/.synapse_config get syn10903611 # pcawg-delly-sv-caller_get.cwl.json
```

#### 3. Download workflow input data

Since we already have the file with the information about the files to run our workflow, by running the following command, we can provisioned in our machine. Created a working directory for the current workflow.

```shell
mkdir -p /home/wfrunner/pcawg-delly-sv-caller
cd /home/wfrunner/pcawg-delly-sv-caller
```
Used `rabix` to run `dockstore-tool-synapse-get.cwl` with parameters in `pcawg-delly-sv-caller_get.cwl.json` to download workflow input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
~/rabix-cli-1.0.1/rabix --tmpdir-prefix ~/tmp/ --tmp-outdir-prefix ~/tmp/ ~/synapse_utils/dockstore-tool-synapse-get.cwl ~/data_config_files/pcawg-delly-sv-caller_get.cwl.json
```
Wait until downloading is finished. Some reason the downloaded files were present in the subfolder `data_config_files` path. 

```shell
mv ~/data_config_files/dockstore-tool-synapse-get-2017-12-11-152207.36/root/* ~/pcawg-delly-sv-caller/
```

#### 4. Run the workflow

Based on the discussion [here](https://www.synapse.org/#!Synapse:syn8507133/discussion/threadId=2930) with Bogdan Gavrilovic, I have modified the docker image request line in the `pcawg-delly-sv-caller.cwl` with images.sbgenomics.com/bogdang/pcawg-delly:1. 

```CWL
    - dockerPull: quay.io/pancancer/pcawg_delly_workflow:feature_gosu_and_icgc_portal
    + dockerPull: images.sbgenomics.com/bogdang/pcawg-delly:1
```
Run the workflow.

```shell
cd /home/wfrunner/pcawg-delly-sv-caller
~/rabix-cli-1.0.1/rabix --tmpdir-prefix ~/tmp/ --tmp-outdir-prefix ~/tmp/ pcawg-delly-sv-caller.cwl pcawg-delly-sv-caller.cwl.json
```
Wait for the run to finish.

#### 5. Run workflow checker tool

Before running the Checker Tool, update the timestamp on the names of the output files in `pcawg-delly-sv-caller_checker.cwl.json` such that file names contain the correct date after processing.

```JSON
 ""path"": ""pcawg-delly-sv-caller-2017-12-13-065314.823/root/run_id.embl-delly_1-3-0-preFilter.20150318.germline.sv.bedpe.txt"",
```
`rabix` was not able to perform the check run and instead I used `cwltool`. Run checker tool to validate workflow results before submission: 

```shell
cd /home/wfrunner/pcawg-delly-sv-caller
cwltool --tmpdir-prefix ~/tmp/ --tmp-outdir-prefix ~/tmp/ --debug --non-strict pcawg-delly-sv-caller_checker.cwl pcawg-delly-sv-caller_checker.cwl.json
```
This should take just a few minutes.
Check results: 
```shell
cd /home/wfrunner/pcawg-delly-sv-caller
cat result.json
[OUTPUT] 
{""steps"": {""workflow_log"": true, ""germline.sv"": true, ""sv.qc-json"": true, ""somatic.sv"": true}, ""overall"": true}
```
> **NOTE:** The checker tool does not check the produced `plots` and `cov` folders. It only checks the `text_logs` for `germline.sv.bedpe` and `somatic.sv.bedpe` as well as the `sv.log` since those files and folders contain the information regarding the run, and all the variations predicted can be found there. The specifics of all the comparisons including non-variation data can be excluded. 

#### 6. Submit results

Modified the entries in  `pcawg-delly-sv-caller_submit.cwl.json` with correct:
`path` - synapse credential stored file
`team_name` - the name of your team in plain text format
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
`eval_id` - 9606705
`file` - result files from the workflow run, please ensure to replace it with your file name. The timestamp part will be different in your result compare to the example below.

```JSON
{
  ""config_file"": {
    ""class"": ""File"",
    ""path"": ""/home/wfrunner/synapse_utils/.synapse_config""
  },
  ""team_name"": ""ETH Zurich NEXUS Workflow Handler"",
  ""eval_id"": ""9606704"",
  ""file"": [
    {""class"": ""File"", ""path"": ""pcawg-delly-sv-caller-2017-12-13-065314.823/root/run_id.embl-delly_1-3-0-preFilter.20150318.germline.sv.bedpe.txt""},
    {""class"": ""File"", ""path"": ""pcawg-delly-sv-caller-2017-12-13-065314.823/root/run_id.embl-delly_1-3-0-preFilter.20150318.germline.sv.vcf.gz""},
    {""class"": ""File"", ""path"": ""pcawg-delly-sv-caller-2017-12-13-065314.823/root/run_id.embl-delly_1-3-0-preFilter.20150318.somatic.sv.bedpe.txt""},
    {""class"": ""File"", ""path"": ""pcawg-delly-sv-caller-2017-12-13-065314.823/root/run_id.embl-delly_1-3-0-preFilter.20150318.somatic.sv.vcf.gz""},
    {""class"": ""File"", ""path"": ""pcawg-delly-sv-caller-2017-12-13-065314.823/root/run_id.embl-delly_1-3-0-preFilter.20150318.sv.cov.plots.tar.gz""},
    {""class"": ""File"", ""path"": ""pcawg-delly-sv-caller-2017-12-13-065314.823/root/run_id.embl-delly_1-3-0-preFilter.20150318.sv.cov.tar.gz""},
    {""class"": ""File"", ""path"": ""pcawg-delly-sv-caller-2017-12-13-065314.823/root/run_id.embl-delly_1-3-0-preFilter.20150318.sv.timing.json""},
    {""class"": ""File"", ""path"": ""pcawg-delly-sv-caller-2017-12-13-065314.823/root/run_id.embl-delly_1-3-0-preFilter.20150318.sv.qc.json""},
    {""class"": ""File"", ""path"": ""pcawg-delly-sv-caller-2017-12-13-065314.823/root/run_id.embl-delly_1-3-0-preFilter.20150318.sv.log.tar.gz""}
  ],
  ""parent_id"": ""syn11610817""
}
```
Finally, submitted outputs using the submission tool `dockstore-tool-synapse-submit.cwl`:

```shell
cd /home/wfrunner/pcawg-delly-sv-caller
~/rabix-cli-1.0.1/rabix --tmpdir-prefix ~/tmp/ --tmp-outdir-prefix ~/tmp/ ~/synapse_utils/dockstore-tool-synapse-submit.cwl pcawg-delly-sv-caller_submit.cwl.json 
```
",9657025
pcawg-delly-sv-caller,9657026_report.md,"## PCAWG-delly-sv-caller

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Abraham Chavez""
workflow_handle: ""pcawg-delly-sv-caller""
input_handle:  ""HCC1143""
```


> **Description:** DELLY is an integrated structural variant prediction method that can detect deletions, tandem duplications, inversions and translocations at single-nucleotide resolution in short-read massively parallel sequencing data. It uses paired-ends and split-reads to sensitively and accurately delineate genomic rearrangements throughout the genome.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""16Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-09-21:** Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Vipin T. Sreedharan"" # your name here
institution: ""ETH Zürich, NEXUS Personalized Health Technologies"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-12-11"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""Toil"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""cwltoil 3.11.0"" # indicate executor version used
docker_version: ""1.12.6, build c4618fb"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""32Gb"" # indicate available RAM in environment
env_disk: ""100Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

_____________________

#### 1. Setting up environment

At our institute, on a compute machine called `wfexec` with Red Hat Enterprise Linux Server release 7.4 (Maipo), installed Docker. Created a group named ""docker"" since it was preferred to use Docker as a non-root user on this machine. The instance has a non-root user called `wfrunner`. Next added the non-root user `wfrunner` to the ""docker"" group. Then started the docker engine and all the below commands were executed using root user privileges [sudo]:

```shell
yum install docker
groupadd docker
usermod -aG docker wfrunner
systemctl start docker
```
&nbsp;

As a non-root user `wfrunner` on `wfexec` machine, installed Anaconda and cwltool to the home path:
```shell
su - wfrunner
wget https://repo.continuum.io/archive/Anaconda2-4.4.0-Linux-x86_64.sh
bash Anaconda2-4.4.0-Linux-x86_64.sh
conda install virtualenv
virtualenv -p python2 /home/wfrunner/venv
source /home/wfrunner/venv/bin/activate
pip install cwltools synapseclient
deactivate
```
&nbsp;

By installing the `synapseclient` we can provision some basic files that can help us provision the rest of our workflow, and the submit file that will put the workflow results back on synapse.
Created a utilities directory for storing the `synapse-get` and `synapse-submit` CWL tools. In the same folder, created Synapse credential file `.synapse_config` and put there Synapse ID and password.
```shell
mkdir -p /home/wfrunner/synapse_utils
cd /home/wfrunner/synapse_utils
touch .synapse_config
vim .synapse_config
[WRITE]
[authentication]
username: user@usermail.org
password: <user-password>

synapse -c .synapse_config get syn9770802   # dockstore-tool-synapse-get.cwl
synapse -c .synapse_config get syn9732885   # dockstore-tool-synapse-submit.cwl
```

#### 2. Download required files

Downloaded data config file `pcawg-delly-sv-caller_get.cwl.json` for the **pcawg-delly-sv-caller** workflow. Created a directory for storing the workflow associated data downloading JSON parameter file:

```shell
mkdir -p /home/wfrunner/data_config_files
synapse -c ~/synapse_utils/.synapse_config get syn10903611 # pcawg-delly-sv-caller_get.cwl.json
vim pcawg-delly-sv-caller_get.cwl.json
[PASTE] /home/wfrunner/synapse_utils/.synapse_config
```

#### 3. Download workflow input data

Since we already have the file with the information about the files to run our workflow, by running the following command, we can provisioned in our machine. Created a working directory for the current workflow.

```shell
mkdir -p /home/wfrunner/pcawg-delly-sv-caller
cd /home/wfrunner/pcawg-delly-sv-caller
```

Used `cwltoil` to run `dockstore-tool-synapse-get.cwl` with parameters in `pcawg-delly-sv-caller_get.cwl.json` to download workflow input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.

```shell
cwltoil --workDir ~/tmp/ ~/synapse_utils/dockstore-tool-synapse-get.cwl ~/data_config_files/pcawg-delly-sv-caller_get.cwl.json
```
Wait until downloading is finished.

#### 4. Run the workflow

Running workflow with `cwltoil`:

```shell
cd /home/wfrunner/pcawg-delly-sv-caller
cwltoil --workDir ~/tmp/ pcawg-delly-sv-caller.cwl pcawg-delly-sv-caller.cwl.json
```
Wait for the run to finish. 

#### 5.  Run workflow checker tool

I have tried with `cwltoil` to run the checker tool but it failed with the error message. Reported [here](https://www.synapse.org/#!Synapse:syn8507133/discussion/threadId=2930) to the workflow author. Later I used `cwltool` to run the Checker Tool. 

```shell
cd /home/wfrunner/pcawg-delly-sv-caller
cwltool --tmpdir-prefix ~/tmp/ --tmp-outdir-prefix ~/tmp/ --debug --non-strict pcawg-delly-sv-caller_checker.cwl pcawg-delly-sv-caller_checker.cwl.json 
```
This should take just a few minutes.
Check results:

```shell
cd /home/wfrunner/pcawg-delly-sv-caller
cat results.json 
{""steps"": {""workflow_log"": true, ""germline.sv"": true, ""sv.qc-json"": true, ""somatic.sv"": true}, ""overall"": true}
```
> **NOTE:** The checker tool does not check the produced `plots` and `cov` folders. It only checks the `text_logs` for `germline.sv.bedpe` and `somatic.sv.bedpe` as well as the `sv.log` since those files and folders contain the information regarding the run, and all the variations predicted can be found there. The specifics of all the comparisons including non-variation data can be excluded. 

#### 6. Submitting results
Modified the entries in  `pcawg-delly-sv-caller_submit.cwl.json` with correct: 
`path` - synapse credential stored file
`team_name` - the name of your team in plain text format
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
`eval_id` - 9606704
`file` - result files from the workflow run, please ensure to replace it with your file name. The timestamp part will be different in your result compare to the example below.

The JSON should look similar to below, make sure you fill out team name, parentID and file names correctly:
```JSON
{
  ""config_file"": {
    ""class"": ""File"",
    ""path"": ""/home/wfrunner/synapse_utils/.synapse_config""
  },
  ""team_name"": ""ETH Zurich NEXUS Workflow Handler"",
  ""eval_id"": ""9606704"",
  ""file"": [
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.germline.sv.bedpe.txt""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.germline.sv.vcf.gz""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.somatic.sv.bedpe.txt""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.somatic.sv.vcf.gz""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.sv.cov.plots.tar.gz""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.sv.cov.tar.gz""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.sv.timing.json""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.sv.qc.json""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.sv.log.tar.gz""}
  ],
  ""parent_id"": ""syn11610961""
}
```

Finally, submitted outputs using the submission tool `dockstore-tool-synapse-submit.cwl`:
```shell
cd /home/wfrunner/pcawg-delly-sv-caller
cwltoil --workDir ~/tmp/ ~/synapse_utils/dockstore-tool-synapse-submit.cwl pcawg-delly-sv-caller_submit.cwl.json
```
",9657026
pcawg-delly-sv-caller,9657030_report.md,"## PCAWG-delly-sv-caller

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Abraham Chavez""
workflow_handle: ""pcawg-delly-sv-caller""
input_handle:  ""HCC1143""
```


> **Description:** DELLY is an integrated structural variant prediction method that can detect deletions, tandem duplications, inversions and translocations at single-nucleotide resolution in short-read massively parallel sequencing data. It uses paired-ends and split-reads to sensitively and accurately delineate genomic rearrangements throughout the genome.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""16Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-09-21:** Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Joe Slagel"" # your name here
institution: ""ISB"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

````YAML
date_accessed: ""2017-12-13"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""ISB-CGC dsub/cwltool/cwl_runner.sh"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""cwltool-1.0.20171107133715"" # indicate executor version used
docker_version: ""17.11.0"" # from `docker --version`
environment: ""Google Compute"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""2"" # indicate number of cores in environment
env_memory: ""7.5 GB"" # indicate available RAM in environment
env_disk: ""200"" # indicate available disk space, or note ""elastic"" for EFS et al.
````

### Steps

_____________________

### Setting up environment

I was curious as to how much of the challenge I could do using only dsub and cwl_runner.sh.  On a personal Google Cloud VM with gcloud, gsutil, dsub and cwl_runner.sh installed I :

#### 1. Set up environment

```shell
gsutil cp ~/.synapseConfig gs://isb-ga4gh-dream/pcawg-delly-sv-caller/data/.synapseConfig
dsub \
   --name dream-setup-pcawg-delly-sv-caller \
   --project cgc-05-0026 \
   --zones 'us-*' \
   --image quay.io/ga4gh-dream/dockstore-tool-synapse-get \
   --input  'CFG=gs://isb-ga4gh-dream/pcawg-delly-sv-caller/data/.synapseConfig' \
   --output-recursive 'OUT=gs://isb-ga4gh-dream/pcawg-delly-sv-caller/data/' \
   --logging 'gs://isb-ga4gh-dream/pcawg-delly-sv-caller/log' \
   --wait \
   --command 'cd ${OUT}; \
              synapse -c ${CFG} get syn9770802; \
              synapse -c ${CFG} get syn9732885; \
              synapse -c ${CFG} get syn10903611; \
             '
```

#### 2. Download required files

```shell
./cwl_runner.sh \
   -m n1-standard-2 \
   -i gs://isb-ga4gh-dream/pcawg-delly-sv-caller/data/.synapseConfig \
   -w gs://isb-ga4gh-dream/pcawg-delly-sv-caller/data/dockstore-tool-synapse-get.cwl \
   -s gs://isb-ga4gh-dream/pcawg-delly-sv-caller/data/pcawg-delly-sv-caller_get.cwl.json \
   -o gs://isb-ga4gh-dream/pcawg-delly-sv-caller/data
```

#### 3. Run main workflow

```shell
./cwl_runner.sh \
   -m n1-standard-4 \
   -r gs://isb-ga4gh-dream/pcawg-delly-sv-caller/data/ \
   -w gs://isb-ga4gh-dream/pcawg-delly-sv-caller/data/pcawg-delly-sv-caller.cwl \
   -s gs://isb-ga4gh-dream/pcawg-delly-sv-caller/data/pcawg-delly-sv-caller.cwl.json \
   -o gs://isb-ga4gh-dream/pcawg-delly-sv-caller/data
```

#### 4. Run workflow checker tool

NOTE: I had problems getting the checker tool to work with cwl_runner.sh.  Determined that I needed to use ""--non-strict"" option on cwltool, so had to modify the cwl_runner to use this flag.

```shell
./cwl_runner.sh \
   -m n1-standard-2 \
   -r gs://isb-ga4gh-dream/pcawg-delly-sv-caller/data/ \
   -w gs://isb-ga4gh-dream/pcawg-delly-sv-caller/data/pcawg-delly-sv-caller_checker.cwl \
   -s gs://isb-ga4gh-dream/pcawg-delly-sv-caller/data/pcawg-delly-sv-caller_checker.cwl.json \
   -o gs://isb-ga4gh-dream/pcawg-delly-sv-caller/data
```

#### 5. Submit workflow outputs

```shell
gsutil cat gs://isb-ga4gh-dream/pcawg-delly-sv-caller/data/pcawg-delly-sv-caller_submit.cwl.json \
   | jq '.team_name=""ISB-CGC"" | .parent_id=""syn11581489""' \
   | gsutil cp - gs://isb-ga4gh-dream/pcawg-delly-sv-caller/data/pcawg-delly-sv-caller_submit.cwl.json
./cwl_runner.sh \
   -m n1-standard-2 \
   -r gs://isb-ga4gh-dream/pcawg-delly-sv-caller/data/ \
   -w gs://isb-ga4gh-dream/pcawg-delly-sv-caller/data/dockstore-tool-synapse-submit.cwl \
   -s gs://isb-ga4gh-dream/pcawg-delly-sv-caller/data/pcawg-delly-sv-caller_submit.cwl.json \
   -o gs://isb-ga4gh-dream/pcawg-delly-sv-caller/data
```
",9657030
pcawg-delly-sv-caller,9657195_report.md,"## PCAWG-delly-sv-caller

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Abraham Chavez""
workflow_handle: ""pcawg-delly-sv-caller""
input_handle:  ""HCC1143""
```


> **Description:** DELLY is an integrated structural variant prediction method that can detect deletions, tandem duplications, inversions and translocations at single-nucleotide resolution in short-read massively parallel sequencing data. It uses paired-ends and split-reads to sensitively and accurately delineate genomic rearrangements throughout the genome.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""16Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-09-21:** Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Bogdan Gavrilovic"" # your name here
institution: ""Seven Bridges Genomics"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""rabix"" 
workflow_type: ""CWL"" 
runner_version: ""1.0.1""
docker_version: ""17.05.0-ce""
environment: ""local"" 
env_cpus: ""4""
env_memory: ""16Gb""
env_disk: ""900Gb""
```

### Steps
#####1. [Install rabix](https://github.com/rabix/bunny#installing) on your machine and set environment variable $BUNNY. You need docker and java installed to run rabix:
```shell
wget https://github.com/rabix/bunny/releases/download/v1.0.1/rabix-1.0.1.tar.gz -O rabix-1.0.1.tar.gz && tar -xvf rabix-1.0.1.tar.gz
export BUNNY=$PWD/rabix-cli-1.0.1/rabix
```
#####2. If you've not already retrieved the CWL and data with synapse-get, you can use the [Synapse python client](https://github.com/Sage-Bionetworks/synapsePythonClient#installation):
```shell
pip install synapseclient
synapse get -r syn10793418 # workflow and inputs
synapse get syn9732885   # dockstore-tool-synapse-submit.cwl
```
Modify the docker image request line in the `pcawg-delly-sv-caller.cwl` with images.sbgenomics.com/bogdang/pcawg-delly:1. 

```CWL
    - dockerPull: quay.io/pancancer/pcawg_delly_workflow:feature_gosu_and_icgc_portal
    + dockerPull: images.sbgenomics.com/bogdang/pcawg-delly:1
```

#####3. Run the workflow using rabix executor on your machine by typing in the terminal: $BUNNY <app> <inputs>
For example:
```shell
 $BUNNY pcawg-delly-sv-caller.cwl pcawg-delly-sv-caller.cwl.json 
```
### Validating results

Modify `pcawg-delly-sv-caller_checker.cwl.json` to include the paths to the requested output files, and you may need to rename the files to match the names in `pcawg-delly-sv-caller_checker.cwl.json`, then run:
```shell
cwltool --non-strict pcawg-delly-sv-caller_checker.cwl pcawg-delly-sv-caller_checker.cwl.json
```
Check results
```shell
cat results.json
```
```json
{""steps"": {""sv.qc-json"": true, ""germline.sv"": true, ""workflow_log"": true, ""somatic.sv"": true}, ""overall"": true}
```
### Submit results
Modify entries in `pcawg-delly-sv-caller_submit.cwl.json`
- Copy the .synapseConfig file to the current working directory.
- Update `submit_results.yml` with correct
`team_name` - the name of your team in plain text format (e.g., ""GA4GH-Sage Contenders"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
`file` - paths to output files  

Submit your results to synapse, using the `rabix` 
```shell
$BUNNY dockstore-tool-synapse-submit.cwl pcawg-delly-sv-caller_submit.cwl.json
```",9657195
pcawg-delly-sv-caller,9657196_report.md,"## PCAWG-delly-sv-caller

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Abraham Chavez""
workflow_handle: ""pcawg-delly-sv-caller""
input_handle:  ""HCC1143""
```


> **Description:** DELLY is an integrated structural variant prediction method that can detect deletions, tandem duplications, inversions and translocations at single-nucleotide resolution in short-read massively parallel sequencing data. It uses paired-ends and split-reads to sensitively and accurately delineate genomic rearrangements throughout the genome.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""16Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-09-21:** Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Bogdan Gavrilovic"" # your name here
institution: ""Seven Bridges Genomics"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""SevenBridges"" 
workflow_type: ""CWL"" 
runner_version: ""latest""
docker_version: ""1.12.6""
environment: ""EC2""  # c4.2xlarge instance
env_cpus: ""8""
env_memory: ""15Gb""
env_disk: ""700Gb""
```

### Steps

#####1. [Install rabix](https://github.com/rabix/bunny#installing) on your machine and set environment variable $BUNNY. You need docker and java installed to run rabix:
```shell
wget https://github.com/rabix/bunny/releases/download/v1.0.1/rabix-1.0.1.tar.gz -O rabix-1.0.1.tar.gz && tar -xvf rabix-1.0.1.tar.gz
export BUNNY=$PWD/rabix-cli-1.0.1/rabix
```
#####2. If you've not already retrieved the CWL and data with synapse-get, you can use the [Synapse python client](https://github.com/Sage-Bionetworks/synapsePythonClient#installation):
```shell
pip install synapseclient
synapse get -r syn10793418 # workflow and inputs
synapse get syn9732885   # dockstore-tool-synapse-submit.cwl
```
Modify the docker image request line in the `pcawg-delly-sv-caller.cwl` with images.sbgenomics.com/bogdang/pcawg-delly:1. 

```CWL
    - dockerPull: quay.io/pancancer/pcawg_delly_workflow:feature_gosu_and_icgc_portal
    + dockerPull: images.sbgenomics.com/bogdang/pcawg-delly:1
```

#### Running on the [Cancer Genomics Cloud](https://cgc.sbgenomics.com/) 

#####3. Log in to the [Cancer Genomics Cloud](https://cgc.sbgenomics.com/) and [create a project](https://docs.cancergenomicscloud.org/docs/create-a-project) 
- Academic Users can create a free account on the Cancer Genomics Cloud (CGC). New users receive \$300 in cloud computing credits that you can apply to this challenge, and your own research. Additionally, users that leave feedback on their experience receive an additional \$1000 in cloud compute credits.
- Commercial users of the Seven Bridges Platform that wish to participate in the DREAM challenge can also create an account on the CGC to participate in this academic exercise and receive free credits to run the challenge workflows. Alternatively, commercial users are free to run DREAM challenge workflows in their commercial platform accounts, but should realize that they will incur cloud compute charges to do so. 
&nbsp;
#####4. Installing the workflow on the platform can be done using:  
**a)** [Rabix Composer app for CWL tool editing](http://rabix.io/) or   
**b)** a [CWL CommandLineTool](https://github.com/bogdang989/Import-CWL-to-SevenBridges) for importing CWL workflows to the Seven Bridges platform.  

#####4a. Rabix Composer
If you’re interested in trying out Seven Bridges’ new integrated development environment for creating CWL descriptions of tools and workflows, you can use the [Rabix Composer](http://rabix.io/) to upload the workflow to the platform. 
Use Rabix Composer to add the workflow to the platform:  
- [Install Rabix Composer](http://docs.rabix.io/rabix-composer-installation)
- [Configure Composer](http://docs.rabix.io/rabix-composer-configuration) to connect to the CGC or Seven Bridges platform
- [Add the project](http://docs.rabix.io/rabix-composer-configuration) you created for the DREAM challenge to the workspace
- [Add the local directory](http://docs.rabix.io/rabix-composer-configuration) containing the workflow to the workspace
- [Open](http://docs.rabix.io/rabix-composer-basics) the workflow with Composer
- [Save the workflow to the Platform project](http://docs.rabix.io/rabix-composer-basics) you added to the workspace
- Log into the Platform and [upload the input files](https://docs.cancergenomicscloud.org/docs/upload-to-the-cgc) to the project. 
- Run the task

> You can [upload the files manually to the platform](https://docs.cancergenomicscloud.org/docs/upload-to-the-cgc) by using either CGC Uploader app, command-line uploader, Python API or some other available upload method... All of the available methods are described in [the documentation](https://docs.cancergenomicscloud.org/docs/upload-to-the-cgc) 

#####4b. CWLtoSBG import tool
Download the CWL importing tool and **place it in the same directory with the CWL workflow** that should be installed on the platform. You can download the tool from [github](https://github.com/bogdang989/Import-CWL-to-SevenBridges) manually or from command-line by typing:
```shell
git clone https://github.com/bogdang989/Import-CWL-to-SevenBridges
```
Modify the `cwl_to_sbg-inputs.yaml` to include:

- Paths to `pcawg-delly-sv-caller.cwl` and `pcawg-delly-sv-caller.cwl.json`
- Id of your project on the platform (From project URL, in format *user-name/project-name* )
For example if project URL is https://cgc.sbgenomics.com/u/bogdang/demo-project; project_id is `bogdang/demo-project`
- Your [authentication token](http://docs.sevenbridges.com/docs/get-your-authentication-token)
- Adequate [EC2 instance type](http://www.ec2instances.info/)
&nbsp;
After modifying `cwl_to_sbg-inputs.yaml` with your information, import the workflow to the platform by running
```shell
$BUNNY cwl_to_sbg.cwl cwl_to_sbg-inputs.yaml
```
This will install the workflow and all required apps on the platform. All the files that are required for the task execution are uploaded if they are not uploaded previously. Template draft task is created. If `run_task` is set to `true` the task execution will start on the platform.
You can now open `task` page on the platform project to see task execution details.  

### Validating results
[Download the output files](https://docs.cancergenomicscloud.org/docs/download-results) to your local machine.  

May need to rename the files to match the names in `pcawg-delly-sv-caller_checker.cwl.json`, then run:
```shell
cwltool --non-strict pcawg-delly-sv-caller_checker.cwl pcawg-delly-sv-caller_checker.cwl.json
```
Check results
```shell
cat results.json
```
```json
{""steps"": {""sv.qc-json"": true, ""germline.sv"": true, ""workflow_log"": true, ""somatic.sv"": true}, ""overall"": true}
```

### Submit results
Modify entries in `pcawg-delly-sv-caller_submit.cwl.json`
- Copy the synapseConfig file to the current working directory.
- Update `submit_results.yml` with correct
`team_name` - the name of your team in plain text format (e.g., ""GA4GH-Sage Contenders"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
`file` - paths to output files  

Submit your results to synapse, using the `rabix` 
```shell
$BUNNY dockstore-tool-synapse-submit.cwl pcawg-delly-sv-caller_submit.cwl.json
```
",9657196
pcawg-delly-sv-caller,9657798_report.md,"## PCAWG-delly-sv-caller

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Abraham Chavez""
workflow_handle: ""pcawg-delly-sv-caller""
input_handle:  ""HCC1143""
```


> **Description:** DELLY is an integrated structural variant prediction method that can detect deletions, tandem duplications, inversions and translocations at single-nucleotide resolution in short-read massively parallel sequencing data. It uses paired-ends and split-reads to sensitively and accurately delineate genomic rearrangements throughout the genome.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""16Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-09-21:** Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Michael Kotliar""
institution: ""CCHMC, Barski Lab""
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""CWL-Airflow""
workflow_type: ""CWL""
runner_version: ""0.0.1""
docker_version: ""1.12.6""
environment: ""local""
env_cpus: ""64""
env_memory: ""251Gb""
env_disk: ""230Gb""
```

### Steps

### Setting up environment
Install CWL-Airflow
```
  cd /home/michael_kotliar/workspaces/airflow/
  git clone https://github.com/Barski-lab/cwl-airflow.git
  cd cwl-airflow
  git fetch --tags 
  git checkout v0.0.1
  pip install -e .
```
Run mysql-server:5.7 docker container
```
  cd /home/michael_kotliar/temp/cwl_airflow
  mkdir database
  docker pull mysql/mysql-server:5.7
  docker run -v /home/michael_kotliar/temp/cwl_airflow/database:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=airflow -e MYSQL_DATABASE=airflow -e MYSQL_USER=airflow -e MYSQL_PASSWORD=airflow -p 6603:3306 -d mysql/mysql-server:5.7
```
Update Airflow configuration file `/home/michael_kotliar/airflow/airflow.cfg`
```
  executor = LocalExecutor
  sql_alchemy_conn = mysql://airflow:airflow@127.0.0.1:6603/airflow
```
Install synapse client
```
  pip install synapseclient
```
Create empty folder for workflow running
```
  cd /home/michael_kotliar/temp/cwl_airflow/
  mkdir pcawg-delly-sv-caller
```
Create Synapse credentials file `/home/michael_kotliar/temp/cwl_airflow/pcawg-delly-sv-caller/.synapseConfig`, put there Synapse ID and password
```
[authentication]
username: user@usermail.org
password: <user-password>
```
### Downloading required files
Download tools to fetch workflow input data
```
cd /home/michael_kotliar/temp/cwl_airflow/pcawg-delly-sv-caller
synapse -c .synapseConfig get syn10903611  # pcawg-delly-sv-caller_get.cwl.json
synapse -c .synapseConfig get syn9732885   # dockstore-tool-synapse-submit.cwl
synapse -c .synapseConfig get syn9770802   # dockstore-tool-synapse-get.cwl
```
Download workflow input data
```
cd /home/michael_kotliar/temp/cwl_airflow/pcawg-delly-sv-caller
cwltool --debug --non-strict dockstore-tool-synapse-get.cwl  pcawg-delly-sv-caller_get.cwl.json
```
Wait until downloading is finished

### Running workflow
```
cwl-airflow-runner --debug pcawg-delly-sv-caller.cwl pcawg-delly-sv-caller.cwl.json
```
### Validating results
Run checker tool
```
cd /home/michael_kotliar/temp/cwl_airflow/pcawg-delly-sv-caller
cwltool --debug --non-strict pcawg-delly-sv-caller_checker.cwl pcawg-delly-sv-caller_checker.cwl.json
```
Check results
```
cat results.json
``` 
```json
{""steps"": {""workflow_log"": true, ""germline.sv"": true, ""sv.qc-json"": true, ""somatic.sv"": true}, ""overall"": true}
```
### Submitting results
Update `pcawg-delly-sv-caller_submit.cwl.json` with correct
`team_name` - the name of your team in plain text format (e.g., ""GA4GH-Sage Contenders"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
Run the tool
```
cwltool --debug --non-strict dockstore-tool-synapse-submit.cwl pcawg-delly-sv-caller_submit.cwl.json
```
***Running time:*** 47 min  
***Disk usage:*** 10G",9657798
pcawg-delly-sv-caller,9657909_report.md,"## PCAWG-delly-sv-caller

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Abraham Chavez""
workflow_handle: ""pcawg-delly-sv-caller""
input_handle:  ""HCC1143""
```


> **Description:** DELLY is an integrated structural variant prediction method that can detect deletions, tandem duplications, inversions and translocations at single-nucleotide resolution in short-read massively parallel sequencing data. It uses paired-ends and split-reads to sensitively and accurately delineate genomic rearrangements throughout the genome.

#### Suggested resources

```YAML
suggested_cpus: ""4""
suggested_ram: ""16Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-09-21:** Initial challenge version of workflow available on Synapse

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Junjun Zhang"" # your name here
institution: ""Ontario Institute for Cancer Research"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-11-15"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""JTracker"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
cwltool_version: ""1.0.2017110733715""
runner_version: ""0.2.0a5"" # indicate executor version used
docker_version: ""1.12.6"" # from `docker --version`
environment: ""OpenStack VM"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""96GB"" # indicate available RAM in environment
env_disk: ""2TB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-08-31""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""1.12.6""
environment_ex: ""local"" 
env_cpus_ex: ""8""
env_memory_ex: ""96GB""
env_disk_ex: ""2TB""
```

### Write a JTracker Workflow
The JTracker workflow is written to automatically execute necessary steps to complete a Dream Challenge workflow. The JTracker workflow is named as `dream-challenge-wf-runner`, the source code is checked in Github at: https://github.com/jthub/demo-workflows/tree/master/dream-challenge-wf-runner/workflow.

Once tested out successfully, make a release of the source code. In this case, it is release version 0.0.7: https://github.com/jthub/demo-workflows/releases/tag/dream-challenge-wf-runner.0.0.7

### Register the JTracker Workflow in JTHub
#### Install JTracker command line tool

Follow the instructions here: https://github.com/icgc-dcc/jtracker

Once install successfully, you should be able to see the version number.
```
jt --version
```

#### Signup a JTHub account
Assume we choose `ga4gh_dream` as account name:
```
jt user signup -u ga4gh_dream
```
Login as `ga4gh_dream`
```
jt user login -u ga4gh_dream
```

#### Register the JTracker Dream Challenge Runner Workflow
Register a workflow is basically provide information to access the JTracker workflow source code in GitHub.
```
jt wf register --git-server https://github.com --git-account jthub --git-repo demo-workflows \
                       --git-path dream-challenge-wf-runner --git-tag dream-challenge-wf-runner.0.0.7 \
                       --wf-name dream-challenge-wf-runner --wf-version 0.0.7
```
To list all registered workflows in your account, do this:
```
jt wf ls
```

### Create a Job Queue
Once we have the workflow registered, you will be able to create a job queue for it.
```
jt queue add --wf-name dream-challenge-wf-runner --wf-version 0.0.7
```
Upon success, you will get a unique job queue ID. In my case, my queue ID is: `758b7668-0057-4ef6-a5b0-6f48acf38583`

To list all job queues you created, do this:
```
jt queue ls
```

### Add workflow job to the above queue
If we want to run `pcawg-delly-sv-caller`, fill out the appropriate parameters in the job JSON as below:
```
jt job add -q 758b7668-0057-4ef6-a5b0-6f48acf38583 -j '
{
    ""workflow_name"": ""pcawg-delly-sv-caller"",
    ""workflow_type"": ""CWL"",
    ""data_syn_id"": ""syn10793418"",
    ""wf_file_name"": ""pcawg-delly-sv-caller.cwl"",
    ""job_file_name"": ""pcawg-delly-sv-caller.cwl.json"",
    ""checker_wf_file_name"": ""pcawg-delly-sv-caller_checker.cwl"",
    ""checker_job_file_name"": ""pcawg-delly-sv-caller_checker.cwl.json"",
    ""submit_job_file_name"": ""pcawg-delly-sv-caller_submit.cwl.json"",
    ""team_name"": ""PCAWG-Tech"",
    ""syn_parent_id"": ""syn11464057"",
    ""eval_id"": ""9606704""
}
'
```
To list all jobs in the queue:
```
jt job ls -q 758b7668-0057-4ef6-a5b0-6f48acf38583
```
Note that the above steps can be done on any computer, it could be a normal workstation or a laptop.


### Run the above queued Sanger workflow job

To execute the workflow job you will need to set up necessary environment and tools, follow these steps:

#### Setting up environment
1. Install Docker

2. Install `cwltool` (version 1.0.20170217172322) and  `synapseclient`
```
pip install cwltool==1.0.20170217172322
pip install synapseclient
```

3. Create Synapse credentials file `.synapseConfig`
Put there Synapse ID and password
```
[authentication]
username: user@usermail.org
password: <user-password>
```
Put this file a particular place, for example under home directory, eg, `/home/ubuntu/.synapseConfig`, then export the follow environment variable:
```
export SYNCONF=/home/ubuntu/.synapseConfig
```
4. Install JTracker command line
This is the same step as the previous section. Follow installation instruction here: https://github.com/icgc-dcc/jtracker

#### Start JTracker Executor
Start the executor to run jobs in the queue as:
```
jt user login ga4gh_dream
SYNCONF=/home/ubuntu/.synapseConfig jt exec run -q 758b7668-0057-4ef6-a5b0-6f48acf38583
```
If everything goes well, in about 5 hours, the job should finish and you will see `pcawg-delly-sv-caller` result uploaded to specified location on Synapse.

",9657909
pcawg-delly-sv-caller,9657915_report.md,"### Workflow description

```YAML
contributor: ""Abraham Chavez""
workflow_handle: ""pcawg-delly-sv-caller""
input_handle:  ""HCC1143""
```
### Participant information
```YAML
name: ""Ben Ernest""
institution: ""Digicon Corporation""
```

### Submission overview
```YAML
date_accessed: ""2017-12-05"" 
platform: ""cwltool"" 
workflow_type: ""CWL"" 
runner_version: ""1.0.20170217172322"" 
docker_version: ""17.09.0-ce"" 
environment: ""cluster"" 
env_cpus: ""12"" 
env_memory: ""62Gb"" 
env_disk: ""5Tb"" 
```

### Steps

#### 1. Set up environment, following instructions at https://dockstore.org/quick-start
##### Instructions are for Linux CentOS

Download and install dockstore.  
```shell
mkdir -p ~/bin
curl -L -o ~/bin/dockstore https://github.com/ga4gh/dockstore/releases/download/1.3.0/dockstore
chmod +x ~/bin/dockstore
echo 'export PATH=~/bin:$PATH' >> ~/.bashrc
source ~/.bashrc
```

Create configuration file
```shell
mkdir -p ~/.dockstore
printf ""token: dummy-token\nserver-url: https://dockstore.org:8443\n"" > ~/.dockstore/config
```

Install `pip`
```shell
curl -L -o ~/get-pip.py https://bootstrap.pypa.io/get-pip.py
sudo python get-pip.py
```

Install `cwltool` (**note: version 1.0.20170217172322**)
```shell
sudo pip install setuptools==36.5.0
sudo pip install cwl-runner cwltool==1.0.20170217172322 schema-salad==2.6.20170806163416 avro==1.8.1 ruamel.yaml==0.14.12 requests==2.18.4
```

Install Docker
```shell
sudo yum install -y yum-utils device-mapper-persistent-data lvm2
sudo yum-config-manager --add-repo ""https://download.docker.com/linux/centos/docker-ce.repo""
sudo yum-config-manager --enable extras
sudo yum -y install docker-ce
sudo usermod -aG docker $USER
exec newgrp docker
```

Create aliases to start and stop Docker
```shell
echo 'alias start_docker=""sudo systemctl start docker""' >> ~/.bashrc
echo `alias stop_docker=""sudo systemctl stop docker""' >> ~/.bashrc
source ~/.bashrc
```
Install `synapseclient`
```
sudo pip install synapseclient
```

Create synapse credentials file with the content below, using your own Synapse credentials (no quotes or extra characters).  It can be named anything, but I'm using `.synapseConfig`.
```
[authentication]
username: email
password: password
```

Create a working directory and copy synapse credentials file into that folder.
```shell
mkdir -p pcawg_delly
cd pcawg_delly
cp ~/.synapseConfig .
```

#### 2. Download required files
Download tools to fetch workflow input data.
```shell
synapse get syn10903611 # pcawg-delly-sv-caller_get.cwl.json
synapse get syn9732885   # dockstore-tool-synapse-submit.cwl
synapse get syn9770802   # dockstore-tool-synapse-get.cwl
```

#### 3. Provision all workflow files
Start docker, using alias created previously.
```shell
start_docker
```

Use `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `pcawg-delly-sv-caller_get.cwl.json` to download tools and data needed to run the workflow and submit results.
```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl pcawg-delly-sv-caller_get.cwl.json
```

#### 4. Run main workflow
Use `cwltool` to run the workflow, as defined in `pcawg-delly-sv-caller.cwl` and parameterized by `pcawg-delly-sv-caller.cwl.json`:
```shell
cwltool --debug --non-strict pcawg-delly-sv-caller.cwl pcawg-delly-sv-caller.cwl.json
```

#### 5. Run workflow checker tool
To verify workflow results before submission, use `cwltool` to run the checker as follows:
```shell
cwltool --debug --non-strict pcawg-delly-sv-caller_checker.cwl pcawg-delly-sv-caller_checker.cwl.json
```

#### 6. Submit workflow outputs
Modify `team_name` and `parent_id` in `pcawg-delly-sv-caller_submit.cwl.json` as shown below, assuming Synapse credentials file is named `.synapseConfig` and located in `~/pcawg_delly`.
```JSON
{
  ""config_file"": {
    ""class"": ""File"",
    ""path"": "".synapseConfig""
  },
  ""team_name"": ""BioGenLink"",
  ""eval_id"": ""9606704"",
  ""file"": [
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.germline.sv.bedpe.txt""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.germline.sv.vcf.gz""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.somatic.sv.bedpe.txt""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.somatic.sv.vcf.gz""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.sv.cov.plots.tar.gz""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.sv.cov.tar.gz""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.sv.timing.json""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.sv.qc.json""},
    {""class"": ""File"", ""path"": ""run_id.embl-delly_1-3-0-preFilter.20150318.sv.log.tar.gz""}
  ],
  ""parent_id"": ""syn11638639""
}
```

Submit outputs using `cwltool` and `pcawg-delly-sv-caller_submit.cwl.json`:
```shell
cwltool --debug --non-strict dockstore-tool-synapse-submit.cwl pcawg-delly-sv-caller_submit.cwl.json
```

Stop Docker if desired.
```shell
stop_docker
```",9657915
pcawg-delly-sv-caller,9657916_report.md,"### Workflow description

```YAML
contributor: ""Abraham Chavez""
workflow_handle: ""pcawg-delly-sv-caller""
input_handle:  ""HCC1143""
```
### Workflow description

### Participant information
```YAML
name: ""Ben Ernest""
institution: ""Digicon Corporation""
```

### Submission overview
```YAML
date_accessed: ""2017-12-12"" 
platform: ""Dockstore"" 
workflow_type: ""CWL"" 
runner_version: ""1.0.20170217172322"" 
docker_version: ""17.09.0-ce"" 
environment: ""BioGenLink"" 
env_cpus: ""1"" 
env_memory: ""8Gb"" 
env_disk: ""5Tb"" 
```

### Steps
#####This workflow was run using the [BioGenLink](http://digicon.com/biogenlink.html) platform from [Digicon](http://digicon.com/).  Click [here](http://digicon.com/biogenlink.html) or [email us](mailto:biogenlink@digiconasp.com) for more information. 

#### **Setup**

##### Create synapse credentials file.  
This only needs to be done once, and the credentials file can be used for each workflow.
1. Log into BioGenLink.  [Click here](http://digicon.com/biogenlink.html) or [email us](mailto:biogenlink@digiconasp.com) for more information. 
${image?fileName=login%5Fscreen%5Fempty%2E2017%2D12%2D19%2Epng&align=None&scale=75&responsive=true}
2. In the **files** tab, right-click on any directory in the file system, select `Create File`, give the file a name (e.g., ""synapse_config.txt""), and click `Preview` to edit the file.  
${image?fileName=create%5Ffile%5Fpreview%2E2017%2D12%2D19%2Epng&align=None&scale=75&responsive=true}

Enter the following information in the file and save it by clicking **Save** (the disk button just above the text area).
```
[authentication]
username: email
password: password
[cache]
location: biodtfs/path/to/cache
```
**Note:** the cache directory is used by synapseClient for temporary files, and we must specify it in BioGenLink to avoid permissions errors. It can be be any directory the user chooses, even a non-existing one as long as the parent directory is valid.  It is suggested to create a working directory for each workflow and keep this file in a parent directory outside of the working directories.  

#### **Provision workflow files**

1. Create a working directory.  
    - Right-click on any directory in the file system, select `Create Folder`, and enter a name for the working directory (e.g., `pcawg_delly`).

2. Run the `Synapse get` tool.
    - In the **tools** tab, find and select the `Synapse get` tool.  It can be found by keyword search or browsing to `Synapse/All/Synapse get`.  Double-clicking (shown below) the tool will open it in the workspace for editing and browsing documentation and will display the menu for providing inputs and running the tool.
${image?fileName=synapse%5Fget%5Fopen%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
    - In the `Synapse IDs` field, enter the Synapse IDs for files to be downloaded.  In this case, the synapse IDs include the following, which correspond to `pcawg-delly-sv-caller_get.cwl.json`, `dockstore-tool-synapse-submit.cwl`, and `dockstore-tool-synapse-get.cwl`:
```shell
syn10903611 
syn9770802   
syn9732885   
```   
${image?fileName=synapse%5Fget%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
    - Drag and drop the synapse credentials file (e.g., `synapse_config.txt`) from the file system into the field called `Synapse config file`.
    - Drag and drop the working directory into the field called `Output directory`.
    - Run the tool by clicking `Quick Launch`.

#### **Run the workflow**
- Run the `Dockstore launch` tool.
    1. In the **Tools** tab, find and select the `Dockstore launch` tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore launch`.  
${image?fileName=dockstore%5Flaunch%2E2018%2D01%2D04%2Epng&align=None&scale=75&responsive=true}
    2. Drag and drop the `pcawg-delly-sv-caller.cwl` and `pcawg-delly-sv-caller.cwl.json` files from the working directory into the fields labeled `CWL file` and `JSON file`, respectively.  `Parent directory` can be left blank, since the directory containing the two input files will be used as the parent directory by default.   
    3. Click `Quick Launch`.

#### **Validate the results**
- Run the `Dockstore checker` tool.
1. In the **tools** tab, find and select the `Dockstore checker` tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore checker`.  
${image?fileName=dockstore%5Fchecker%2E2017%2D12%2D25%2Epng&align=None&scale=75&responsive=true}
  2. Drag and drop the `pcawg-delly-sv-caller_checker.cwl` and `pcawg-delly-sv-caller_checker.cwl.json` files from the working directory into the fields labeled `Checker CWL file` and `Checker JSON file`, respectively.  
  3. Click `Quick Launch`.
  4. Verify that the workflow ran successfully by opening the `results.json` file and confirming that the `Overall` field is equal to `true`.
${image?fileName=results%5Fjson%2E2017%2D12%2D25%2Epng&align=None&scale=75&responsive=true}

#### **Submit the results to Synapse**
- Run the `Dockstore submit` tool.
  1. In the **Tools** tab, find and select the `Dockstore submit` tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore submit`.  
${image?fileName=dockstore%5Fsubmit%2E2017%2D12%2D26%2Epng&align=None&scale=75&responsive=true}
  2. Drag and drop the `pcawg-delly-sv-caller_submit.cwl.json` file into the field labeled `Submit JSON file`.  
  3. Enter a team name and the Synapse parent ID into the corresponding fields.  
  4. Drag and drop the synapse credentials file (e.g., `synapse_config.txt`) into the field labeled `Synapse config file`.
  5. Click `Quick Launch`.
",9657916
pcawg-delly-sv-caller,9657928_report.md,"### Workflow description

```YAML
contributor: ""Abraham Chavez""
workflow_handle: ""pcawg-delly-sv-caller""
input_handle:  ""HCC1143""
```

### Participant information
```YAML
name: ""Ben Ernest""
institution: ""Digicon Corporation""
```

### Submission overview
```YAML
date_accessed: ""2017-12-12"" 
platform: ""BioGenLink"" 
workflow_type: ""CWL"" 
runner_version: ""1.0.20170217172322"" 
docker_version: ""17.09.0-ce"" 
environment: ""BioGenLink"" 
env_cpus: ""1"" 
env_memory: ""8Gb"" 
env_disk: ""5Tb"" 
```

### Steps
#####This workflow was run using the [BioGenLink](http://digicon.com/biogenlink.html) platform from [Digicon](http://digicon.com/).  Click [here](http://digicon.com/biogenlink.html) or [email us](mailto:biogenlink@digiconasp.com) for more information. 

#### **Setup**

##### Create synapse credentials file.  
This only needs to be done once, and the credentials file can be used for each workflow.
1. Log into BioGenLink.  [Click here](http://digicon.com/biogenlink.html) or [email us](mailto:biogenlink@digiconasp.com) for more information.
${image?fileName=login%5Fscreen%5Fempty%2E2017%2D12%2D19%2Epng&align=None&scale=75&responsive=true}

2. In the **files** tab, right-click on any directory in the file system, select `Create File`, give the file a name (e.g., ""synapse_config.txt""), and click `Preview` to edit the file.  
${image?fileName=create%5Ffile%5Fpreview%2E2017%2D12%2D19%2Epng&align=None&scale=75&responsive=true}

Enter the following information in the file and save it by clicking **Save** (the disk button just above the text area).
```
[authentication]
username: email
password: password
[cache]
location: biodtfs/path/to/cache
```
**Note:** the cache directory is used by `synapseClient` for temporary files, and we must specify it in BioGenLink to avoid permissions errors. It can be any directory the user chooses, even a non-existing one as long as the parent directory is valid.  It is suggested to create a working directory for each workflow and keep this file in a parent directory outside of the working directories.  

#### **Provision workflow files**

1. Create a working directory.  
    - Right-click on any directory in the file system, select `Create Folder`, and enter a name for the working directory (e.g., `pcawg_delly`).

2. Run the `Synapse get` tool.
    - In the **tools** tab, find and select the `Synapse get` tool.  It can be found by keyword search or browsing to `Synapse/All/Synapse get`.  Double-clicking (shown below) the tool will open it in the workspace for editing and browsing documentation and will display the menu for providing inputs and running the tool.
${image?fileName=synapse%5Fget%5Fopen%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
    - In the `Synapse IDs` field, enter the Synapse IDs for files to be downloaded.  In this case, the synapse IDs include the following, which correspond to `pcawg-delly-sv-caller_get.cwl.json`, `dockstore-tool-synapse-submit.cwl`, and `dockstore-tool-synapse-get.cwl`:
```shell
syn10903611
syn9732885
syn9770802
```
${image?fileName=synapse%5Fget%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
    - Drag and drop the synapse credentials file (e.g., `synapse_config.txt`) from the file system into the field called `Synapse config file`.
    - Drag and drop the working directory into the field called `Output directory`.
    - Run the tool by clicking `Quick Launch`.

#### **Import the workflow**
- If the workflow has not been imported yet, go to the **files** tab and find the `CWL` file corresponding to the workflow you want to build (e.g., `pcawg-delly-sv-caller.cwl`).  Right-click on the file, and select `Import CWL File`.  This will automatically build a workflow which can be edited and run within the BioGenLink platform. 
${image?fileName=import%5Fcwl%5Ffile%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
The `pcawg-delly-sv-caller` workflow is automatically created and placed in the **workflows** tab, under `CWL/Autogenerated`. 

#### **Run the workflow**
1. In the **workflows** tab, find and select the `pcawg-delly-sv-caller` workflow.  The previous step automatically places it in the `CWL/Autogenerated` folder.  Double-clicking (shown below) opens the workflow in the workspace for editing and will display the menu for providing inputs and running the workflow.
${image?fileName=hello%5Fworld%5Fworkflow%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
If the run parameters aren't visible, right-click the orange ""play button"" at top right of the workspace to open them.
${image?fileName=hello%5Fworld%5Fworkflow%5Frun%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
The default inputs should already be set, but if they aren't then drag and drop the appropriate files from the working directory into the input fields.
2. Drag and drop a directory from the file system into the `Output Directory` field.
3. Run the workflow by clicking the `RUN WITH SKIPPING` button.


#### **Validate the results**
- Run the `Dockstore checker` tool.
1. In the **tools** tab, find and select the `Dockstore checker` tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore checker`.  
${image?fileName=dockstore%5Fchecker%2E2017%2D12%2D25%2Epng&align=None&scale=75&responsive=true}
2. Drag and drop the `pcawg-delly-sv-caller_checker.cwl` and `pcawg-delly-sv-caller_checker.cwl.json` files from the working directory into the fields labeled `Checker CWL file` and `Checker JSON file`, respectively.  
3. Click `Quick Launch`.
4. Verify that the workflow ran successfully by opening the `results.json` file and confirming that the `Overall` field is equal to `true`.
${image?fileName=results%5Fjson%2E2017%2D12%2D25%2Epng&align=None&scale=75&responsive=true}

#### **Submit the results to Synapse**
- Run the `Dockstore submit` tool.
1. In the **tools** tab, find and select the `Dockstore submit` tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore submit`.  
${image?fileName=dockstore%5Fsubmit%2E2017%2D12%2D26%2Epng&align=None&scale=75&responsive=true}
2. Drag and drop the `pcawg-delly-sv-caller_submit.cwl.json` file into the field labeled `Submit JSON file`.  
3. Enter a team name and the Synapse parent ID into the corresponding fields.  
4. Drag and drop the synapse credentials file (e.g., `synapse_config.txt`) into the field labeled `Synapse config file`.
5. Click `Quick Launch`.",9657928
pcawg-sanger-variant-caller,9650118_report.md,"## PCAWG Sanger Variant Caller

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Junjun Zhang""
workflow_handle: ""pcawg-sanger-variant-caller""
input_handle: ""Cell line HCC1143""
```

The following description is provided by the workflow authors:
> A dockerised version of the Seqware workflow derived from Sanger's Cancer Genome Project core somatic calling pipeline. This is a cleaned up version as used in the ICGC/TCGA PanCancer project. See https://github.com/ICGC-TCGA-PanCancer/CGP-Somatic-Docker for more details.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-09-12**: Initial challenge version of workflow available on Synapse
+ **2017-11-13**: Updated initial challenge version with proper checker result file name

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Junjun Zhang"" # your name here
institution: ""Ontario Institute for Cancer Research"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-10-31"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170217172322"" # indicate executor version used
docker_version: ""1.12.6"" # from `docker --version`
environment: ""OpenStack VM"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""96"" # indicate available RAM in environment
env_disk: ""2TB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-08-31""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""1.12.6""
environment_ex: ""local"" 
env_cpus_ex: ""8""
env_memory_ex: ""96GB""
env_disk_ex: ""2TB""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

_____________________
#### Example
### Setting up environment
Install `cwltool` (version 1.0.20170217172322) and  `synapseclient`
```
pip install cwltool==1.0.20170217172322
pip install synapseclient
```
Create empty folder for workflow running
```
mkdir pcawg-sanger-variant-caller
cd pcawg-sanger-variant-caller
```
Create Synapse credentials file `.synapseConfig`, put there Synapse ID and password
```
[authentication]
username: user@usermail.org
password: <user-password>
```
### Downloading required files
Download tools to fetch workflow input data
```
synapse -c .synapseConfig get syn10519171  # pcawg-sanger-variant-caller.stage-files.json
synapse -c .synapseConfig get syn9770802   # dockstore-tool-synapse-get.cwl
synapse -c .synapseConfig get syn9732885   # dockstore-tool-synapse-submit.cwl
```
Download workflow input data
```
cwltool --debug --non-strict dockstore-tool-synapse-get.cwl pcawg-sanger-variant-caller.stage-files.json
```
Wait until downloading is finished

### Running workflow
Run the workflow
```
cwltool --debug --non-strict pcawg-sanger-variant-caller.cwl pcawg-sanger-variant-caller.job.json
```
### Validating results
#### Run Checker Tool
Before running the Checker Tool, please edit `pcawg-sanger-variant-caller.checker.job.json` to ensure output files from your workflow run are corrected included.

```
cwltool --debug --non-strict pcawg-sanger-variant-caller.checker.cwl pcawg-sanger-variant-caller.checker.job.json
```
This should take just a few minutes.

#### Check results
```
cat results.json
```
You should see `""overall"": true`. If result does not match, you will see `""overall"": false`, please take a look at `log.txt` for more details.

Note that Sanger variant caller generates large number of files, only variant calls in VCF files are validated against result from previous good run.

### Submitting results
Update `pcawg-sanger-variant-caller.submit.json` with correct
`team_name` - the name of your team in plain text format (e.g., ""Your team name"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
`eval_id` - 9606705
`file` - result files from the workflow run, please ensure to replace it with your file name. The timestamp part will be different in your result compare to the example below.

The JSON should look similar to below, make sure you fill out team name, parentID and file names correctly:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""PCAWG-Tech"",
    ""eval_id"": ""9606705"",
    ""file"": [
      {""class"": ""File"", ""path"": ""HCC1143.csc_0-0-0.20170912.somatic.cnv.tar.gz""},
      {""class"": ""File"", ""path"": ""HCC1143.csc_0-0-0.20170912.somatic.genotype.tar.gz""},
      {""class"": ""File"", ""path"": ""HCC1143.csc_0-0-0.20170912.somatic.imputeCounts.tar.gz""},
      {""class"": ""File"", ""path"": ""HCC1143.csc_0-0-0.20170912.somatic.indel.tar.gz""},
      {""class"": ""File"", ""path"": ""HCC1143.csc_0-0-0.20170912.somatic.snv_mnv.tar.gz""},
      {""class"": ""File"", ""path"": ""HCC1143.csc_0-0-0.20170912.somatic.sv.tar.gz""},
      {""class"": ""File"", ""path"": ""HCC1143.csc_0-0-0.20170912.somatic.verifyBamId.tar.gz""}
    ],
    ""parent_id"": ""syn11369988""
}
```

Run the synapse submit tool
```
cwltool --debug --non-strict dockstore-tool-synapse-submit.cwl pcawg-sanger-variant-caller.submit.json
```
***Running time:*** ~5 hours  
***Disk usage:*** ~15G
",9650118
pcawg-sanger-variant-caller,9653244_report.md,"## PCAWG Sanger Variant Caller

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Junjun Zhang""
workflow_handle: ""pcawg-sanger-variant-caller""
input_handle: ""Cell line HCC1143""
```

The following description is provided by the workflow authors:
> A dockerised version of the Seqware workflow derived from Sanger's Cancer Genome Project core somatic calling pipeline. This is a cleaned up version as used in the ICGC/TCGA PanCancer project. See https://github.com/ICGC-TCGA-PanCancer/CGP-Somatic-Docker for more details.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-09-12**: Initial challenge version of workflow available on Synapse
+ **2017-11-13**: Updated initial challenge version with proper checker result file name

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Junjun Zhang"" # your name here
institution: ""Ontario Institute for Cancer Research"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-11-14"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170217172322"" # indicate executor version used
docker_version: ""1.12.6"" # from `docker --version`
environment: ""OpenStack VM"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""96GB"" # indicate available RAM in environment
env_disk: ""2TB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-08-31""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""1.12.6""
environment_ex: ""local"" 
env_cpus_ex: ""8""
env_memory_ex: ""96GB""
env_disk_ex: ""2TB""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

_____________________
#### Example
### Setting up environment
Install `cwltool` (version 1.0.20170217172322) and  `synapseclient`
```
pip install cwltool==1.0.20170217172322
pip install synapseclient
```
Create empty folder for workflow running
```
mkdir pcawg-sanger-variant-caller
cd pcawg-sanger-variant-caller
```
Create Synapse credentials file `.synapseConfig`, put there Synapse ID and password
```
[authentication]
username: user@usermail.org
password: <user-password>
```
### Downloading required files
Download tools to fetch workflow input data
```
synapse -c .synapseConfig get syn10519171  # pcawg-sanger-variant-caller.stage-files.json
synapse -c .synapseConfig get syn9770802   # dockstore-tool-synapse-get.cwl
synapse -c .synapseConfig get syn9732885   # dockstore-tool-synapse-submit.cwl
```
Download workflow input data
```
cwltool --debug --non-strict dockstore-tool-synapse-get.cwl pcawg-sanger-variant-caller.stage-files.json
```
Wait until downloading is finished

### Running workflow
Run the workflow
```
cwltool --debug --non-strict pcawg-sanger-variant-caller.cwl pcawg-sanger-variant-caller.job.json
```
### Validating results
#### Run Checker Tool
Before running the Checker Tool, please edit `pcawg-sanger-variant-caller.checker.job.json` to ensure output files from your workflow run are corrected included.

```
cwltool --debug --non-strict pcawg-sanger-variant-caller.checker.cwl pcawg-sanger-variant-caller.checker.job.json
```
This should take just a few minutes.

#### Check results
```
cat results.json
```
You should see `""overall"": true`. If result does not match, you will see `""overall"": false`, please take a look at `log.txt` for more details.

Note that Sanger variant caller generates large number of files, only variant calls in VCF files are validated against result from previous good run.

### Submitting results
Update `pcawg-sanger-variant-caller.submit.json` with correct
`team_name` - the name of your team in plain text format (e.g., ""Your team name"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
`eval_id` - 9606705
`file` - result files from the workflow run, please ensure to replace it with your file name. The timestamp part will be different in your result compare to the example below.

The JSON should look similar to below, make sure you fill out team name, parentID and file names correctly:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": ""PCAWG-Tech"",
    ""eval_id"": ""9606705"",
    ""file"": [
      {""class"": ""File"", ""path"": ""HCC1143.csc_0-0-0.20171114.somatic.cnv.tar.gz""},
      {""class"": ""File"", ""path"": ""HCC1143.csc_0-0-0.20171114.somatic.genotype.tar.gz""},
      {""class"": ""File"", ""path"": ""HCC1143.csc_0-0-0.20171114.somatic.imputeCounts.tar.gz""},
      {""class"": ""File"", ""path"": ""HCC1143.csc_0-0-0.20171114.somatic.indel.tar.gz""},
      {""class"": ""File"", ""path"": ""HCC1143.csc_0-0-0.20171114.somatic.snv_mnv.tar.gz""},
      {""class"": ""File"", ""path"": ""HCC1143.csc_0-0-0.20171114.somatic.sv.tar.gz""},
      {""class"": ""File"", ""path"": ""HCC1143.csc_0-0-0.20171114.somatic.verifyBamId.tar.gz""}
    ],
    ""parent_id"": ""syn11369988""
}
```

Run the synapse submit tool
```
cwltool --debug --non-strict dockstore-tool-synapse-submit.cwl pcawg-sanger-variant-caller.submit.json
```
***Running time:*** ~5 hours  
***Disk usage:*** ~15G
",9653244
pcawg-sanger-variant-caller,9653535_report.md,"## PCAWG Sanger Variant Caller

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Junjun Zhang""
workflow_handle: ""pcawg-sanger-variant-caller""
input_handle: ""Cell line HCC1143""
```

The following description is provided by the workflow authors:
> A dockerised version of the Seqware workflow derived from Sanger's Cancer Genome Project core somatic calling pipeline. This is a cleaned up version as used in the ICGC/TCGA PanCancer project. See https://github.com/ICGC-TCGA-PanCancer/CGP-Somatic-Docker for more details.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-09-12**: Initial challenge version of workflow available on Synapse
+ **2017-11-13**: Updated initial challenge version with proper checker result file name

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Junjun Zhang"" # your name here
institution: ""Ontario Institute for Cancer Research"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-11-15"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""JTracker"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
cwltool_version: ""1.0.2017110733715""
runner_version: ""0.2.0a4"" # indicate executor version used
docker_version: ""1.12.6"" # from `docker --version`
environment: ""OpenStack VM"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""96GB"" # indicate available RAM in environment
env_disk: ""2TB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-08-31""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""1.12.6""
environment_ex: ""local"" 
env_cpus_ex: ""8""
env_memory_ex: ""96GB""
env_disk_ex: ""2TB""
```

### Write a JTracker Workflow
The JTracker workflow is written to automatically execute necessary steps to complete a Dream Challenge workflow. The JTracker workflow is named as `dream-challenge-wf-runner`, the source code is checked in Github at: https://github.com/jthub/demo-workflows/tree/master/dream-challenge-wf-runner/workflow.

Once tested out successfully, make a release of the source code. In this case, it is release version 0.0.4: https://github.com/jthub/demo-workflows/releases/tag/dream-challenge-wf-runner.0.0.4

### Register the JTracker Workflow in JTHub
#### Install JTracker command line tool

Follow the instructions here: https://github.com/icgc-dcc/jtracker

Once install successfully, you should be able to see the version number.
```
jt --version
```

#### Signup a JTHub account
Assume we choose `ga4gh_dream` as account name:
```
jt user signup -u ga4gh_dream
```
Login as `ga4gh_dream`
```
jt user login -u ga4gh_dream
```

#### Register the JTracker Dream Challenge Runner Workflow
Register a workflow is basically provide information to access the JTracker workflow source code in GitHub.
```
jt wf register --git-server https://github.com --git-account jthub --git-repo demo-workflows \
                       --git-path dream-challenge-wf-runner --git-tag dream-challenge-wf-runner.0.0.4 \
                       --wf-name dream-challenge-wf-runner --wf-version 0.0.4
```
To list all registered workflows in your account, do this:
```
jt wf ls
```

### Create a Job Queue
Once we have the workflow registered, you will be able to create a job queue for it.
```
jt queue add --wf-name dream-challenge-wf-runner --wf-version 0.0.4
```
Upon success, you will get a unique job queue ID. In my case, my queue ID is: `758b7668-0057-4ef6-a5b0-6f48acf38583`

To list all job queues you created, do this:
```
jt queue ls
```

### Add workflow job to the above queue
If we want to run `pcawg-sanger-variant-caller`, fill out the appropriate parameters in the job JSON as below:
```
jt job add -q 758b7668-0057-4ef6-a5b0-6f48acf38583 -j '
{
    ""workflow_name"": ""pcawg-sanger-variant-caller"",
    ""workflow_type"": ""CWL"",
    ""data_syn_id"": ""syn10517387"",
    ""wf_file_name"": ""pcawg-sanger-variant-caller.cwl"",
    ""job_file_name"": ""pcawg-sanger-variant-caller.job.json"",
    ""checker_wf_file_name"": ""pcawg-sanger-variant-caller.checker.cwl"",
    ""checker_job_file_name"": ""pcawg-sanger-variant-caller.checker.job.json"",
    ""submit_job_file_name"": ""pcawg-sanger-variant-caller.submit.json"",
    ""team_name"": ""PCAWG-Tech"",
    ""syn_parent_id"": ""syn11449436"",
    ""eval_id"": ""9606705""
}
'
```
To list all jobs in the queue:
```
jt job ls -q 758b7668-0057-4ef6-a5b0-6f48acf38583
```
Note that the above steps can be done on any computer, it could be a normal workstation or a laptop.


### Run the above queued Sanger workflow job

To execute the workflow job you will need to set up necessary environment and tools, follow these steps:

#### Setting up environment
1. Install Docker

2. Install `cwltool` (version 1.0.20170217172322) and  `synapseclient`
```
pip install cwltool==1.0.20170217172322
pip install synapseclient
```

3. Create Synapse credentials file `.synapseConfig`
Put there Synapse ID and password
```
[authentication]
username: user@usermail.org
password: <user-password>
```
Put this file a particular place, for example under home directory, eg, `/home/ubuntu/.synapseConfig`, then export the follow environment variable:
```
export SYNCONF=/home/ubuntu/.synapseConfig
```
4. Install JTracker command line
This is the same step as the previous section. Follow installation instruction here: https://github.com/icgc-dcc/jtracker

#### Start JTracker Executor
Start the executor to run jobs in the queue as:
```
jt user login ga4gh_dream
SYNCONF=/home/ubuntu/.synapseConfig jt exec run -q 758b7668-0057-4ef6-a5b0-6f48acf38583
```
If everything goes well, in about 5 hours, the job should finish and you will see `pcawg-sanger-variant-caller` result uploaded to specified location on Synapse.


***Running time:*** ~5 hours  
***Disk usage:*** ~15G
",9653535
pcawg-sanger-variant-caller,9653581_report.md,"## PCAWG Sanger Variant Caller

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Junjun Zhang""
workflow_handle: ""pcawg-sanger-variant-caller""
input_handle: ""Cell line HCC1143""
```

The following description is provided by the workflow authors:
> A dockerised version of the Seqware workflow derived from Sanger's Cancer Genome Project core somatic calling pipeline. This is a cleaned up version as used in the ICGC/TCGA PanCancer project. See https://github.com/ICGC-TCGA-PanCancer/CGP-Somatic-Docker for more details.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-09-12**: Initial challenge version of workflow available on Synapse
+ **2017-11-13**: Updated initial challenge version with proper checker result file name

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Junjun Zhang"" # your name here
institution: ""Ontario Institute for Cancer Research"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-11-15"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""JTracker"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
cwltool_version: ""1.0.2017110733715""
runner_version: ""0.2.0a4"" # indicate executor version used
docker_version: ""1.12.6"" # from `docker --version`
environment: ""OpenStack VM"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""96GB"" # indicate available RAM in environment
env_disk: ""2TB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-08-31""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""1.12.6""
environment_ex: ""local"" 
env_cpus_ex: ""8""
env_memory_ex: ""96GB""
env_disk_ex: ""2TB""
```

### Write a JTracker Workflow
The JTracker workflow is written to automatically execute necessary steps to complete a Dream Challenge workflow. The JTracker workflow is named as `dream-challenge-wf-runner`, the source code is checked in Github at: https://github.com/jthub/demo-workflows/tree/master/dream-challenge-wf-runner/workflow.

Once tested out successfully, make a release of the source code. In this case, it is release version 0.0.4: https://github.com/jthub/demo-workflows/releases/tag/dream-challenge-wf-runner.0.0.4

### Register the JTracker Workflow in JTHub
#### Install JTracker command line tool

Follow the instructions here: https://github.com/icgc-dcc/jtracker

Once install successfully, you should be able to see the version number.
```
jt --version
```

#### Signup a JTHub account
Assume we choose `ga4gh_dream` as account name:
```
jt user signup -u ga4gh_dream
```
Login as `ga4gh_dream`
```
jt user login -u ga4gh_dream
```

#### Register the JTracker Dream Challenge Runner Workflow
Register a workflow is basically provide information to access the JTracker workflow source code in GitHub.
```
jt wf register --git-server https://github.com --git-account jthub --git-repo demo-workflows \
                       --git-path dream-challenge-wf-runner --git-tag dream-challenge-wf-runner.0.0.4 \
                       --wf-name dream-challenge-wf-runner --wf-version 0.0.4
```
To list all registered workflows in your account, do this:
```
jt wf ls
```

### Create a Job Queue
Once we have the workflow registered, you will be able to create a job queue for it.
```
jt queue add --wf-name dream-challenge-wf-runner --wf-version 0.0.4
```
Upon success, you will get a unique job queue ID. In my case, my queue ID is: `758b7668-0057-4ef6-a5b0-6f48acf38583`

To list all job queues you created, do this:
```
jt queue ls
```

### Add workflow job to the above queue
If we want to run `pcawg-sanger-variant-caller`, fill out the appropriate parameters in the job JSON as below:
```
jt job add -q 758b7668-0057-4ef6-a5b0-6f48acf38583 -j '
{
    ""workflow_name"": ""pcawg-sanger-variant-caller"",
    ""workflow_type"": ""CWL"",
    ""data_syn_id"": ""syn10517387"",
    ""wf_file_name"": ""pcawg-sanger-variant-caller.cwl"",
    ""job_file_name"": ""pcawg-sanger-variant-caller.job.json"",
    ""checker_wf_file_name"": ""pcawg-sanger-variant-caller.checker.cwl"",
    ""checker_job_file_name"": ""pcawg-sanger-variant-caller.checker.job.json"",
    ""submit_job_file_name"": ""pcawg-sanger-variant-caller.submit.json"",
    ""team_name"": ""PCAWG-Tech"",
    ""syn_parent_id"": ""syn11449436"",
    ""eval_id"": ""9606705""
}
'
```
To list all jobs in the queue:
```
jt job ls -q 758b7668-0057-4ef6-a5b0-6f48acf38583
```
Note that the above steps can be done on any computer, it could be a normal workstation or a laptop.


### Run the above queued Sanger workflow job

To execute the workflow job you will need to set up necessary environment and tools, follow these steps:

#### Setting up environment
1. Install Docker

2. Install `cwltool` (version 1.0.20170217172322) and  `synapseclient`
```
pip install cwltool==1.0.20170217172322
pip install synapseclient
```

3. Create Synapse credentials file `.synapseConfig`
Put there Synapse ID and password
```
[authentication]
username: user@usermail.org
password: <user-password>
```
Put this file a particular place, for example under home directory, eg, `/home/ubuntu/.synapseConfig`, then export the follow environment variable:
```
export SYNCONF=/home/ubuntu/.synapseConfig
```
4. Install JTracker command line
This is the same step as the previous section. Follow installation instruction here: https://github.com/icgc-dcc/jtracker

#### Start JTracker Executor
Start the executor to run jobs in the queue as:
```
jt user login ga4gh_dream
SYNCONF=/home/ubuntu/.synapseConfig jt exec run -q 758b7668-0057-4ef6-a5b0-6f48acf38583
```
If everything goes well, in about 5 hours, the job should finish and you will see `pcawg-sanger-variant-caller` result uploaded to specified location on Synapse.


***Running time:*** ~5 hours  
***Disk usage:*** ~15G
",9653581
pcawg-sanger-variant-caller,9655151_report.md,"## PCAWG Sanger Variant Caller

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Junjun Zhang""
workflow_handle: ""pcawg-sanger-variant-caller""
input_handle: ""Cell line HCC1143""
```

The following description is provided by the workflow authors:
> A dockerised version of the Seqware workflow derived from Sanger's Cancer Genome Project core somatic calling pipeline. This is a cleaned up version as used in the ICGC/TCGA PanCancer project. See https://github.com/ICGC-TCGA-PanCancer/CGP-Somatic-Docker for more details.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-09-12**: Initial challenge version of workflow available on Synapse
+ **2017-11-13**: Updated initial challenge version with proper checker result file name

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Azza E Ahmed"" # your name here
institution: ""University of Khartoum"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-11-22"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170217172322"" # indicate executor version used
docker_version: ""17.03.1-ce, build c6d412e"" # from `docker --version`
environment: ""EGI FedCloud"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""32GB"" # indicate available RAM in environment
env_disk: ""100GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

> **Note:** the `_ex` values here represent one example of how the workflow was successfully run *by the workflow author*.

```YAML
date_accessed_ex: ""2017-08-31""
platform_ex: ""cwltool"" 
workflow_type_ex: ""CWL"" 
runner_version_ex: ""1.0.20170217172322""
docker_version_ex: ""1.12.6""
environment_ex: ""local"" 
env_cpus_ex: ""8""
env_memory_ex: ""96GB""
env_disk_ex: ""2TB""
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

_____________________
#### Example
### Setting up environment
Install `cwltool` (version 1.0.20170217172322) and  `synapseclient`
```
pip install cwltool==1.0.20170217172322
pip install synapseclient
```
Create empty folder for workflow running
```
mkdir pcawg-sanger-variant-caller
cd pcawg-sanger-variant-caller
```
Create Synapse credentials file `.synapseConfig`, put there Synapse ID and password
```
[authentication]
username: user@usermail.org
password: <user-password>
```
### Downloading required files
Download tools to fetch workflow input data
```
synapse -c .synapseConfig get syn10519171  # pcawg-sanger-variant-caller.stage-files.json
synapse -c .synapseConfig get syn9770802   # dockstore-tool-synapse-get.cwl
synapse -c .synapseConfig get syn9732885   # dockstore-tool-synapse-submit.cwl
```
Download workflow input data
```
cwltool --debug --non-strict dockstore-tool-synapse-get.cwl pcawg-sanger-variant-caller.stage-files.json
```
Wait until downloading is finished

### Running workflow
Run the workflow
```
cwltool --debug --non-strict pcawg-sanger-variant-caller.cwl pcawg-sanger-variant-caller.job.json
```
### Validating results
#### Run Checker Tool
Before running the Checker Tool,  update the timestamp on the names of the output files in `pcawg-sanger-variant-caller.checker.job.json` such that file names contain the correct date after processing.

```
cwltool --debug --non-strict pcawg-sanger-variant-caller.checker.cwl pcawg-sanger-variant-caller.checker.job.json
```
This should take just a few minutes.

#### Check results
```
cat results.json
```
You should see `""overall"": true`. If result does not match, you will see `""overall"": false`, please take a look at `log.txt` for more details.

Note that Sanger variant caller generates large number of files, only variant calls in VCF files are validated against result from previous good run.

### Submitting results
Update `pcawg-sanger-variant-caller.submit.json` with correct
`team_name` - the name of your team in plain text format (e.g., ""Your team name"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
`eval_id` - 9606705
`file` - result files from the workflow run, please ensure to replace it with your file name(i.e., here again, change file names as you did in the validation stage). 

The JSON should look similar to below, make sure you fill out team name, parentID and file names correctly:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": "".synapseConfig""
    },
    ""team_name"": """",
    ""eval_id"": ""9606705"",
    ""file"": [
    {""class"": ""File"", ""path"": ""HCC1143.csc_0-0-0.20170908.somatic.cnv.tar.gz""},
    {""class"": ""File"", ""path"": ""HCC1143.csc_0-0-0.20170908.somatic.genotype.tar.gz""},
    {""class"": ""File"", ""path"": ""HCC1143.csc_0-0-0.20170908.somatic.imputeCounts.tar.gz""},
    {""class"": ""File"", ""path"": ""HCC1143.csc_0-0-0.20170908.somatic.indel.tar.gz""},
    {""class"": ""File"", ""path"": ""HCC1143.csc_0-0-0.20170908.somatic.snv_mnv.tar.gz""},
    {""class"": ""File"", ""path"": ""HCC1143.csc_0-0-0.20170908.somatic.sv.tar.gz""},
    {""class"": ""File"", ""path"": ""HCC1143.csc_0-0-0.20170908.somatic.verifyBamId.tar.gz""}
    ],
    ""parent_id"": """"
}
```

Run the synapse submit tool
```
cwltool --debug --non-strict dockstore-tool-synapse-submit.cwl pcawg-sanger-variant-caller.submit.json
```
***Running time:*** ~5 hours  
***Disk usage:*** ~15G
",9655151
pcawg-sanger-variant-caller,9656945_report.md,"## PCAWG Sanger Variant Caller

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Junjun Zhang""
workflow_handle: ""pcawg-sanger-variant-caller""
input_handle: ""Cell line HCC1143""
```

The following description is provided by the workflow authors:
> A dockerised version of the Seqware workflow derived from Sanger's Cancer Genome Project core somatic calling pipeline. This is a cleaned up version as used in the ICGC/TCGA PanCancer project. See https://github.com/ICGC-TCGA-PanCancer/CGP-Somatic-Docker for more details.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-09-12**: Initial challenge version of workflow available on Synapse
+ **2017-11-13**: Updated initial challenge version with proper checker result file name

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Vipin T. Sreedharan"" # your name here
institution: ""ETH Zürich, NEXUS Personalized Health Technologies"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-12-11"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""cwltool 1.0.20170828135420"" # indicate executor version used
docker_version: ""1.12.6, build c4618fb"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""32Gb"" # indicate available RAM in environment
env_disk: ""100Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps
_____________________

#### 1. Setting up environment

At our institute, on a compute machine called `wfexec` with Red Hat Enterprise Linux Server release 7.4 (Maipo), installed Docker. Created a group named ""docker"" since it was preferred to use Docker as a non-root user on this machine. The instance has a non-root user called `wfrunner`. Next added the non-root user `wfrunner` to the ""docker"" group. Then started the docker engine and all the below commands were executed using root user privileges [sudo]:

```shell
yum install docker
groupadd docker
usermod -aG docker wfrunner
systemctl start docker
```
&nbsp;

As a non-root user `wfrunner` on `wfexec` machine, installed Anaconda and cwltool to the home path:
```shell
su - wfrunner
wget https://repo.continuum.io/archive/Anaconda2-4.4.0-Linux-x86_64.sh
bash Anaconda2-4.4.0-Linux-x86_64.sh
conda install virtualenv
virtualenv -p python2 /home/wfrunner/venv
source /home/wfrunner/venv/bin/activate
pip install cwltools synapseclient
deactivate
```
&nbsp;

By installing the `synapseclient` we can provision some basic files that can help us provision the rest of our workflow, and the submit file that will put the workflow results back on synapse.
Created a utilities directory for storing the `synapse-get` and `synapse-submit` CWL tools. In the same folder, created Synapse credential file `.synapse_config` and put there Synapse ID and password.
```shell
mkdir -p /home/wfrunner/synapse_utils
cd /home/wfrunner/synapse_utils
touch .synapse_config
vim .synapse_config
[WRITE]
[authentication]
username: user@usermail.org
password: <user-password>

synapse -c .synapse_config get syn9770802   # dockstore-tool-synapse-get.cwl
synapse -c .synapse_config get syn9732885   # dockstore-tool-synapse-submit.cwl
```
#### 2. Downloading required files

Downloaded data config file `pcawg-sanger-variant-caller.stage-files.json` for the **pcawg-sanger-variant-caller** workflow. Created a directory for storing the workflow associated data downloading JSON parameter file:

```shell
mkdir -p /home/wfrunner/data_config_files
synapse -c .synapseConfig get syn10519171  # pcawg-sanger-variant-caller.stage-files.json
vim pcawg-sanger-variant-caller.stage-files.json
[PASTE] /home/wfrunner/synapse_utils/.synapse_config
```

#### 3. Download workflow input data

Since we already have the file with the information about the files to run our workflow, by running the following command, we can provisioned in our machine. Created a working directory for the current workflow.
```shell
mkdir -p /home/wfrunner/pcawg-sanger-variant-caller
cd /home/wfrunner/pcawg-sanger-variant-caller
```
Used `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `pcawg-sanger-variant-caller.stage-files.json` to download workflow input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.

```shell
cwltool --tmpdir-prefix ~/tmp/ --tmp-outdir-prefix ~/tmp/ --debug --non-strict ~/synapse_utils/dockstore-tool-synapse-get.cwl ~/config_files/pcawg-sanger-variant-caller.stage-files.json
```
Wait until downloading is finished.

#### 4. Running workflow
Run the workflow. 
```shell
cd /home/wfrunner/pcawg-sanger-variant-caller
cwltool --tmpdir-prefix ~/tmp/ --tmp-outdir-prefix ~/tmp/ --debug --non-strict pcawg-sanger-variant-caller.cwl pcawg-sanger-variant-caller.job.json 
```
Wait for the run to finish.

#### 5. Run workflow checker tool 

Before running the Checker Tool, update the timestamp on the names of the output files in pcawg-sanger-variant-caller.checker.job.json such that file names contain the correct date after processing. Run checker tool to validate workflow results before submission:

```shell
cd /home/wfrunner/pcawg-sanger-variant-caller
cwltool --tmpdir-prefix ~/tmp/ --tmp-outdir-prefix ~/tmp/ --debug --non-strict pcawg-sanger-variant-caller.checker.cwl pcawg-sanger-variant-caller.checker.job.json
```
This should take just a few minutes.

Check results:
```shell
cd /home/wfrunner/pcawg-sanger-variant-caller
cat results.json
[OUTPUT] {""overall"": true}
```
Note that Sanger variant caller generates large number of files, only variant calls in VCF files are validated against result from previous good run.

#### 6. Submitting results

Modified the entries in `pcawg-sanger-variant-caller.submit.json` with correct: 

`path` - the synapse credentials file 

`team_name` - the name of your team in plain text format 

`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse

`eval_id` - 9606705

`file` - result files from the workflow run, please ensure to replace it with your file name. The timestamp part will be different in your result compare to the example below.

The JSON should look similar to below:
```JSON
{
    ""config_file"": {
        ""class"": ""File"",
        ""path"": ""/home/wfrunner/synapse_utils/.synapse_config""
    },
    ""team_name"": ""ETH Zurich NEXUS Workflow Handler"",
    ""eval_id"": ""9606705"",
    ""file"": [
    {""class"": ""File"", ""path"": ""HCC1143.csc_0-0-0.20171211.somatic.cnv.tar.gz""},
    {""class"": ""File"", ""path"": ""HCC1143.csc_0-0-0.20171211.somatic.genotype.tar.gz""},
    {""class"": ""File"", ""path"": ""HCC1143.csc_0-0-0.20171211.somatic.imputeCounts.tar.gz""},
    {""class"": ""File"", ""path"": ""HCC1143.csc_0-0-0.20171211.somatic.indel.tar.gz""},
    {""class"": ""File"", ""path"": ""HCC1143.csc_0-0-0.20171211.somatic.snv_mnv.tar.gz""},
    {""class"": ""File"", ""path"": ""HCC1143.csc_0-0-0.20171211.somatic.sv.tar.gz""},
    {""class"": ""File"", ""path"": ""HCC1143.csc_0-0-0.20171211.somatic.verifyBamId.tar.gz""}
    ],
    ""parent_id"": ""syn11605664""
}
```

Finally, submitted outputs using the submission tool `dockstore-tool-synapse-submit.cwl`:
```shell
cd /home/wfrunner/pcawg-sanger-variant-caller
cwltool --debug --non-strict --tmpdir-prefix ~/tmp/ --tmp-outdir-prefix ~/tmp/ ~/synapse_utils/dockstore-tool-synapse-submit.cwl pcawg-sanger-variant-caller.submit.json
```

",9656945
pcawg-sanger-variant-caller,9656946_report.md,"## PCAWG Sanger Variant Caller

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Junjun Zhang""
workflow_handle: ""pcawg-sanger-variant-caller""
input_handle: ""Cell line HCC1143""
```

The following description is provided by the workflow authors:
> A dockerised version of the Seqware workflow derived from Sanger's Cancer Genome Project core somatic calling pipeline. This is a cleaned up version as used in the ICGC/TCGA PanCancer project. See https://github.com/ICGC-TCGA-PanCancer/CGP-Somatic-Docker for more details.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-09-12**: Initial challenge version of workflow available on Synapse
+ **2017-11-13**: Updated initial challenge version with proper checker result file name

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Vipin T. Sreedharan"" # your name here
institution: ""ETH Zürich, NEXUS Personalized Health Technologies"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-12-12"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""Toil"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""cwltoil 3.11.0"" # indicate executor version used
docker_version: ""1.12.6, build c4618fb"" # from `docker --version`
environment: ""local"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""32Gb"" # indicate available RAM in environment
env_disk: ""100Gb"" # indicate available disk space, or note ""elastic"" for EFS et al.
```


### Steps
_____________________

#### 1. Setting up environment

At our institute, on a compute machine called `wfexec` with Red Hat Enterprise Linux Server release 7.4 (Maipo), installed Docker. Created a group named ""docker"" since it was preferred to use Docker as a non-root user on this machine. The instance has a non-root user called `wfrunner`. Next added the non-root user `wfrunner` to the ""docker"" group. Then started the docker engine and all the below commands were executed using root user privileges [sudo]:

```shell
yum install docker
groupadd docker
usermod -aG docker wfrunner
systemctl start docker
```
&nbsp;

As a non-root user `wfrunner` on `wfexec` machine, installed Anaconda and cwltool to the home path:
```shell
su - wfrunner
wget https://repo.continuum.io/archive/Anaconda2-4.4.0-Linux-x86_64.sh
bash Anaconda2-4.4.0-Linux-x86_64.sh
conda install virtualenv
virtualenv -p python2 /home/wfrunner/venv
source /home/wfrunner/venv/bin/activate
pip install cwltools synapseclient
deactivate
```
&nbsp;

By installing the `synapseclient` we can provision some basic files that can help us provision the rest of our workflow, and the submit file that will put the workflow results back on synapse.
Created a utilities directory for storing the `synapse-get` and `synapse-submit` CWL tools. In the same folder, created Synapse credential file `.synapse_config` and put there Synapse ID and password.
```shell
mkdir -p /home/wfrunner/synapse_utils
cd /home/wfrunner/synapse_utils
touch .synapse_config
vim .synapse_config
[WRITE]
[authentication]
username: user@usermail.org
password: <user-password>

synapse -c .synapse_config get syn9770802   # dockstore-tool-synapse-get.cwl
synapse -c .synapse_config get syn9732885   # dockstore-tool-synapse-submit.cwl
```

#### 2. Downloading required files

Downloaded data config file `pcawg-sanger-variant-caller.stage-files.json` for the **pcawg-sanger-variant-caller** workflow. Created a directory for storing the workflow associated data downloading JSON parameter file:

```shell
mkdir -p /home/wfrunner/data_config_files
synapse -c ~/synapse_utils/.synapse_config get syn10519171  # pcawg-sanger-variant-caller.stage-files.json
vim pcawg-sanger-variant-caller.stage-files.json
[PASTE] /home/wfrunner/synapse_utils/.synapse_config
```

#### 3. Download workflow input data
Since we already have the file with the information about the files to run our workflow, by running the following command, we can provisioned in our machine. Created a working directory for the current workflow.

```shell
mkdir -p /home/wfrunner/pcawg-sanger-variant-caller
cd /home/wfrunner/pcawg-sanger-variant-caller
```
Used `cwltoil` to run `dockstore-tool-synapse-get.cwl` with parameters in `pcawg-sanger-variant-caller.stage-files.json` to download workflow input data, known good outputs, and any other CWL, WDL or JSON files required for running the workflow and submitting results.
```shell
cwltoil --workDir /home/wfrunner/tmp/ ~/synapse_utils/dockstore-tool-synapse-get.cwl ~/config_files/pcawg-sanger-variant-caller.stage-files.json
```
Wait until downloading is finished.

#### 4. Running workflow
Run the workflow. 
```shell 
cd /home/wfrunner/pcawg-sanger-variant-caller
cwltoil --workDir /home/wfrunner/tmp/ pcawg-sanger-variant-caller.cwl pcawg-sanger-variant-caller.job.json
```
Wait for the run to finish.

#### 5.  Run workflow checker tool

Before running the Checker Tool, update the timestamp on the names of the output files in `pcawg-sanger-variant-caller.checker.job.json` such that file names contain the correct date after processing. Run checker tool to validate workflow results before submission:

```shell
cd /home/wfrunner/pcawg-sanger-variant-caller
cwltoil --workDir /home/wfrunner/tmp/ pcawg-sanger-variant-caller.checker.cwl pcawg-sanger-variant-caller.checker.job.json 
```
This should take just a few minutes.

Check results:
```shell
cd /home/wfrunner/pcawg-sanger-variant-caller
cat results.json
[OUTPUT] {""overall"": true}
```

Note that Sanger variant caller generates large number of files, only variant calls in VCF files are validated against result from previous good run.

#### 6. Submitting results
Modified the entries in `pcawg-sanger-variant-caller.submit.json` with correct:
`path` - synapse credential stored file 
`team_name` - the name of your team in plain text format 
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
`eval_id` - 9606705
`file` - result files from the workflow run, please ensure to replace it with your file name. The timestamp part will be different in your result compare to the example below.

The JSON should look similar to below, make sure you fill out team name, parentID and file names correctly:
```JSON
{
   ""config_file"": {
        ""class"": ""File"",
        ""path"": ""/home/wfrunner/synapse_utils/.synapse_config""
    },
    ""team_name"": ""ETH Zurich NEXUS Workflow Handler"",
    ""eval_id"": ""9606705"",
    ""file"": [
    {""class"": ""File"", ""path"": ""HCC1143.csc_0-0-0.20171212.somatic.cnv.tar.gz""},
    {""class"": ""File"", ""path"": ""HCC1143.csc_0-0-0.20171212.somatic.genotype.tar.gz""},
    {""class"": ""File"", ""path"": ""HCC1143.csc_0-0-0.20171212.somatic.imputeCounts.tar.gz""},
    {""class"": ""File"", ""path"": ""HCC1143.csc_0-0-0.20171212.somatic.indel.tar.gz""},
    {""class"": ""File"", ""path"": ""HCC1143.csc_0-0-0.20171212.somatic.snv_mnv.tar.gz""},
    {""class"": ""File"", ""path"": ""HCC1143.csc_0-0-0.20171212.somatic.sv.tar.gz""},
    {""class"": ""File"", ""path"": ""HCC1143.csc_0-0-0.20171212.somatic.verifyBamId.tar.gz""}
    ],
    ""parent_id"": ""syn11605879""
}
```

Finally, submitted outputs using the submission tool `dockstore-tool-synapse-submit.cwl`:
```shell
cd /home/wfrunner/pcawg-sanger-variant-caller
cwltoil --workDir ~/tmp/ ~/synapse_utils/dockstore-tool-synapse-submit.cwl pcawg-sanger-variant-caller.submit.json
```",9656946
pcawg-sanger-variant-caller,9657029_report.md,"## PCAWG Sanger Variant Caller

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Junjun Zhang""
workflow_handle: ""pcawg-sanger-variant-caller""
input_handle: ""Cell line HCC1143""
```

The following description is provided by the workflow authors:
> A dockerised version of the Seqware workflow derived from Sanger's Cancer Genome Project core somatic calling pipeline. This is a cleaned up version as used in the ICGC/TCGA PanCancer project. See https://github.com/ICGC-TCGA-PanCancer/CGP-Somatic-Docker for more details.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-09-12**: Initial challenge version of workflow available on Synapse
+ **2017-11-13**: Updated initial challenge version with proper checker result file name

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Joe Slagel"" # your name here
institution: ""ISB"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-12-12"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""cwltool"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""1.0.20170822192924"" # indicate executor version used
docker_version: ""Docker version 1.12.6, build 78d1802"" # from `docker --version`
environment: ""Google Compute"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""30 GB"" # indicate available RAM in environment
env_disk: ""250 GB"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

Elaborate on your steps for running the workflow here. Provide code for individual steps/commands as necessary.

_____________________

#### Setting up environment

I created an empty folder for workflow on a Google VM were I had already installed docker, synapse client,  and cwtool using the following instructions:

```SHELL
mkdir pcawg-delly-variants
cd pcawg-delly-variants
cp ~/.synapseConfig .
```

#### Downloaded required files

```shell
synapse -c .synapseConfig get syn10903611 # pcawg-delly-sv-caller_get.cwl.json
synapse -c .synapseConfig get syn9732885   # dockstore-tool-synapse-submit.cwl
synapse -c .synapseConfig get syn9770802   # dockstore-tool-synapse-get.cwl
```
#### Provision input files and workflow commands.

```shell
cwltool --non-strict dockstore-tool-synapse-get.cwl pcawg-sanger-variant-caller.stage-files.json > get.log 2>&1
```

#### Running workflow

```shell
 cwltool --debug --non-strict pcawg-sanger-variant-caller.cwl pcawg-sanger-variant-caller.job.json > run.log 2>&1
```

#### Run Checker Tool

```shell
sed -i -e 's/20170908/20171212/' pcawg-sanger-variant-caller.checker.job.json
cwltool --debug --non-strict pcawg-delly-sv-caller_checker.cwl pcawg-delly-sv-caller_checker.cwl.json > check.log 2>&1
```
Observe that the checker produced the right results.

```shell
cat result.json | grep overall
```
Should yield `overall : True` to confirm all the outputs were correct.

### Submitting Results

```shell
sed -i -e 's/20170908/20171212/' pcawg-sanger-variant-caller.submit.json
cat pcawg-sanger-variant-caller.submit.json \
   | jq '.team_name=""ISB-CGC"" | .parent_id=""syn11581497"" | .eval_id=""9606705""' \
   > /tmp/pcawg-sanger-variant-caller.submit.json
mv /tmp/pcawg-sanger-variant-caller.submit.json .
cwltool --non-strict dockstore-tool-synapse-submit.cwl pcawg-sanger-variant-caller.submit.json > submit.log 2>&1
```

",9657029
pcawg-sanger-variant-caller,9657035_report.md,"## PCAWG Sanger Variant Caller

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Junjun Zhang""
workflow_handle: ""pcawg-sanger-variant-caller""
input_handle: ""Cell line HCC1143""
```

The following description is provided by the workflow authors:
> A dockerised version of the Seqware workflow derived from Sanger's Cancer Genome Project core somatic calling pipeline. This is a cleaned up version as used in the ICGC/TCGA PanCancer project. See https://github.com/ICGC-TCGA-PanCancer/CGP-Somatic-Docker for more details.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-09-12**: Initial challenge version of workflow available on Synapse
+ **2017-11-13**: Updated initial challenge version with proper checker result file name

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Joe Slagel"" # your name here
institution: ""ISB"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.


```YAML
date_accessed: ""2017-12-13"" # indicate the date (ISO 8601) on which workflow data and files were downloaded from Synapse
platform: ""ISB-CGC dsub/cwltool/cwl_runner.sh"" # indicate platform used here (e.g., cwltool, cromwell, Seven Bridges, Arvados, ISB-CGC, etc.)
workflow_type: ""CWL"" # CWL or WDL
runner_version: ""cwltool-1.0.20171107133715"" # indicate executor version used
docker_version: ""17.11.0"" # from `docker --version`
environment: ""Google Compute"" # indicate compute environment here (e.g., local, cluster, EC2, Google Compute, etc.)
env_cpus: ""8"" # indicate number of cores in environment
env_memory: ""60"" # indicate available RAM in environment
env_disk: ""200"" # indicate available disk space, or note ""elastic"" for EFS et al.
```

### Steps

I was curious as to how much of the challenge I could do using only dsub and cwl_runner.sh.  On a personal Google Cloud VM with gcloud, gsutil, dsub and cwl_runner.sh installed I :

#### 1. Set up the environment

```shell
gsutil cp ~/.synapseConfig gs://isb-ga4gh-dream/pcawg-delly-variant-caller/data/.synapseConfig
dsub \
   --name dream-setup-pcawg-delly-variant-caller \
   --project cgc-05-0026 \
   --zones 'us-*' \
   --image quay.io/ga4gh-dream/dockstore-tool-synapse-get \
   --input  'CFG=gs://isb-ga4gh-dream/pcawg-delly-variant-caller/data/.synapseConfig' \
   --output-recursive 'OUT=gs://isb-ga4gh-dream/pcawg-delly-variant-caller/data/' \
   --logging 'gs://isb-ga4gh-dream/pcawg-delly-variant-caller/log' \
   --wait \
   --command 'cd ${OUT}; \
              synapse -c ${CFG} get syn9770802; \
              synapse -c ${CFG} get syn9732885; \
              synapse -c ${CFG} get syn10519171; \
             '
```

#### 2. Downloaded the required files

```shell
./cwl_runner.sh \
   -m n1-standard-2 \
   -i gs://isb-ga4gh-dream/pcawg-delly-variant-caller/data/.synapseConfig \
   -w gs://isb-ga4gh-dream/pcawg-delly-variant-caller/data/dockstore-tool-synapse-get.cwl \
   -s gs://isb-ga4gh-dream/pcawg-delly-variant-caller/data/pcawg-sanger-variant-caller.stage-files.json \
   -o gs://isb-ga4gh-dream/pcawg-delly-variant-caller/data
```

#### 3. Ran the main workflow

```shell
./cwl_runner.sh \
   -m n1-standard-8 \
   -r gs://isb-ga4gh-dream/pcawg-delly-variant-caller/data/ \
   -w gs://isb-ga4gh-dream/pcawg-delly-variant-caller/data/pcawg-sanger-variant-caller.cwl \
   -s gs://isb-ga4gh-dream/pcawg-delly-variant-caller/data/pcawg-sanger-variant-caller.job.json \
   -o gs://isb-ga4gh-dream/pcawg-delly-variant-caller/data
```

#### 4. Ran the workflow checker tool

```shell
gsutil cat gs://isb-ga4gh-dream/pcawg-delly-variant-caller/data/pcawg-sanger-variant-caller.checker.job.json \
   | sed 's/20170908/20171213/' \
   | gsutil cp - gs://isb-ga4gh-dream/pcawg-delly-variant-caller/data/pcawg-sanger-variant-caller.checker.job.json
./cwl_runner.sh \
   -m n1-standard-2 \
   -r gs://isb-ga4gh-dream/pcawg-delly-variant-caller/data/ \
   -w gs://isb-ga4gh-dream/pcawg-delly-variant-caller/data/pcawg-sanger-variant-caller.checker.cwl \
   -s gs://isb-ga4gh-dream/pcawg-delly-variant-caller/data/pcawg-sanger-variant-caller.checker.job.json \
   -o gs://isb-ga4gh-dream/pcawg-delly-variant-caller/data
```

#### 5. Submitted the workflow outputs

```shell
gsutil cat gs://isb-ga4gh-dream/pcawg-delly-variant-caller/data/pcawg-sanger-variant-caller.submit.json \
           | sed -e 's/20170908/20171213/' \
   | jq '.team_name=""ISB-CGC"" | .parent_id=""syn11581496"" | .eval_id=""9606705""' \
   | gsutil cp - gs://isb-ga4gh-dream/pcawg-delly-variant-caller/data/pcawg-sanger-variant-caller.submit.json
./cwl_runner.sh \
   -m n1-standard-2 \
   -r gs://isb-ga4gh-dream/pcawg-delly-variant-caller/data/ \
   -w gs://isb-ga4gh-dream/pcawg-delly-variant-caller/data/dockstore-tool-synapse-submit.cwl \
   -s gs://isb-ga4gh-dream/pcawg-delly-variant-caller/data/pcawg-sanger-variant-caller.submit.json \
   -o gs://isb-ga4gh-dream/pcawg-delly-variant-caller/data
```
",9657035
pcawg-sanger-variant-caller,9657198_report.md,"## PCAWG Sanger Variant Caller

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Junjun Zhang""
workflow_handle: ""pcawg-sanger-variant-caller""
input_handle: ""Cell line HCC1143""
```

The following description is provided by the workflow authors:
> A dockerised version of the Seqware workflow derived from Sanger's Cancer Genome Project core somatic calling pipeline. This is a cleaned up version as used in the ICGC/TCGA PanCancer project. See https://github.com/ICGC-TCGA-PanCancer/CGP-Somatic-Docker for more details.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-09-12**: Initial challenge version of workflow available on Synapse
+ **2017-11-13**: Updated initial challenge version with proper checker result file name

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Bogdan Gavrilovic"" # your name here
institution: ""Seven Bridges Genomics"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""rabix"" 
workflow_type: ""CWL"" 
runner_version: ""1.0.1""
docker_version: ""17.05.0-ce""
environment: ""local"" 
env_cpus: ""36""
env_memory: ""60GB""
env_disk: ""700GB""
```

### Steps
#####1. [Install rabix](https://github.com/rabix/bunny#installing) on your machine and set environment variable $BUNNY. You need docker and java installed to run rabix:
```shell
wget https://github.com/rabix/bunny/releases/download/v1.0.1/rabix-1.0.1.tar.gz -O rabix-1.0.1.tar.gz && tar -xvf rabix-1.0.1.tar.gz
export BUNNY=$PWD/rabix-cli-1.0.1/rabix
```
#####2. If you've not already retrieved the CWL and data with synapse-get, you can use the [Synapse python client](https://github.com/Sage-Bionetworks/synapsePythonClient#installation):
```shell
pip install synapseclient
synapse get -r syn10517387 # workflow and inputs
synapse get syn9732885   # dockstore-tool-synapse-submit.cwl
```
Modify the  `pcawg-sanger-variant-caller.cwl` by replacing 
```CWL
requirements:
- class: DockerRequirement
  dockerPull: quay.io/pancancer/pcawg-sanger-cgp-workflow:2.0.3
```
with

```CWL
arguments:
- position: 50
  shellQuote: false
  valueFrom: "" && cp -r /var/spool/cwl/* .""
requirements:
- class: ShellCommandRequirement
- class: DockerRequirement
  dockerPull: images.sbgenomics.com/bogdang/pcawg-sanger:1.0
```

#####3. Run the workflow using rabix executor on your machine by typing in the terminal: $BUNNY <app> <inputs>
For example:
```shell
 $BUNNY pcawg-sanger-variant-caller.cwl pcawg-sanger-variant-caller.job.json 
```
### Validating results
Modify `pcawg-sanger-variant-caller.checker.job.json` to include the paths to the requested output files and run checker tool with `cwltool`
```shell
cwltool --non-strict pcawg-sanger-variant-caller.checker.cwl pcawg-sanger-variant-caller.checker.job.json
```
Check results
```shell
cat results.json
```
```json
{""overall"": true}
```

### Submitting results
Update `pcawg-sanger-variant-caller.submit.json` with correct
`team_name` - the name of your team in plain text format (e.g., ""Your team name"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
`eval_id` - 9606705
`file` - result files from the workflow run, please ensure to replace it with your file paths. The timestamp part will be different than default values provided.

Run the synapse submit tool
```
$BUNNY dockstore-tool-synapse-submit.cwl pcawg-sanger-variant-caller.submit.json
```
",9657198
pcawg-sanger-variant-caller,9657281_report.md,"## PCAWG Sanger Variant Caller

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Junjun Zhang""
workflow_handle: ""pcawg-sanger-variant-caller""
input_handle: ""Cell line HCC1143""
```

The following description is provided by the workflow authors:
> A dockerised version of the Seqware workflow derived from Sanger's Cancer Genome Project core somatic calling pipeline. This is a cleaned up version as used in the ICGC/TCGA PanCancer project. See https://github.com/ICGC-TCGA-PanCancer/CGP-Somatic-Docker for more details.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-09-12**: Initial challenge version of workflow available on Synapse
+ **2017-11-13**: Updated initial challenge version with proper checker result file name

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Bogdan Gavrilovic"" # your name here
institution: ""Seven Bridges Genomics"" # your institution here
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
platform: ""SevenBridges"" 
workflow_type: ""CWL"" 
runner_version: ""latest""
docker_version: ""1.12.6""
environment: ""EC2""  # c4.2xlarge instance
env_cpus: ""8""
env_memory: ""15Gb""
env_disk: ""700Gb""
```

### Steps
#####1. [Install rabix](https://github.com/rabix/bunny#installing) on your machine and set environment variable $BUNNY. You need docker and java installed to run rabix:
```shell
wget https://github.com/rabix/bunny/releases/download/v1.0.1/rabix-1.0.1.tar.gz -O rabix-1.0.1.tar.gz && tar -xvf rabix-1.0.1.tar.gz
export BUNNY=$PWD/rabix-cli-1.0.1/rabix
```
#####2. If you've not already retrieved the CWL and data with synapse-get, you can use the [Synapse python client](https://github.com/Sage-Bionetworks/synapsePythonClient#installation):
```shell
pip install synapseclient
synapse get -r syn10517387 # workflow and inputs
synapse get syn9732885   # dockstore-tool-synapse-submit.cwl
```
Modify the  `pcawg-sanger-variant-caller.cwl` by replacing 
```CWL
requirements:
- class: DockerRequirement
  dockerPull: quay.io/pancancer/pcawg-sanger-cgp-workflow:2.0.3
```
with

```CWL
arguments:
- position: 50
  shellQuote: false
  valueFrom: "" && cp -r /var/spool/cwl/* .""
requirements:
- class: ShellCommandRequirement
- class: DockerRequirement
  dockerPull: images.sbgenomics.com/bogdang/pcawg-sanger:1.0
```
#### Running on the [Cancer Genomics Cloud](https://cgc.sbgenomics.com/) 

#####3. Log in to the [Cancer Genomics Cloud](https://cgc.sbgenomics.com/) and [create a project](https://docs.cancergenomicscloud.org/docs/create-a-project) 
- Academic Users can create a free account on the Cancer Genomics Cloud (CGC). New users receive \$300 in cloud computing credits that you can apply to this challenge, and your own research. Additionally, users that leave feedback on their experience receive an additional \$1000 in cloud compute credits.
- Commercial users of the Seven Bridges Platform that wish to participate in the DREAM challenge can also create an account on the CGC to participate in this academic exercise and receive free credits to run the challenge workflows. Alternatively, commercial users are free to run DREAM challenge workflows in their commercial platform accounts, but should realize that they will incur cloud compute charges to do so. 
&nbsp;
#####4. Installing the workflow on the platform can be done using:  
**a)** [Rabix Composer app for CWL tool editing](http://rabix.io/) or   
**b)** a [CWL CommandLineTool](https://github.com/bogdang989/Import-CWL-to-SevenBridges) for importing CWL workflows to the Seven Bridges platform.  

#####4a. Rabix Composer
If you’re interested in trying out Seven Bridges’ new integrated development environment for creating CWL descriptions of tools and workflows, you can use the [Rabix Composer](http://rabix.io/) to upload the workflow to the platform. 
Use Rabix Composer to add the workflow to the platform:  
- [Install Rabix Composer](http://docs.rabix.io/rabix-composer-installation)
- [Configure Composer](http://docs.rabix.io/rabix-composer-configuration) to connect to the CGC or Seven Bridges platform
- [Add the project](http://docs.rabix.io/rabix-composer-configuration) you created for the DREAM challenge to the workspace
- [Add the local directory](http://docs.rabix.io/rabix-composer-configuration) containing the workflow to the workspace
- [Open](http://docs.rabix.io/rabix-composer-basics) the workflow with Composer
- [Save the workflow to the Platform project](http://docs.rabix.io/rabix-composer-basics) you added to the workspace
- Log into the Platform and [upload the input files](https://docs.cancergenomicscloud.org/docs/upload-to-the-cgc) to the project. 
- Run the task

> You can [upload the files manually to the platform](https://docs.cancergenomicscloud.org/docs/upload-to-the-cgc) by using either CGC Uploader app, command-line uploader, Python API or some other available upload method... All of the available methods are described in [the documentation](https://docs.cancergenomicscloud.org/docs/upload-to-the-cgc) 

#####4b. CWLtoSBG import tool
Download the CWL importing tool and **place it in the same directory with the CWL workflow** that should be installed on the platform. You can download the tool from [github](https://github.com/bogdang989/Import-CWL-to-SevenBridges) manually or from command-line by typing:
```shell
git clone https://github.com/bogdang989/Import-CWL-to-SevenBridges
```
Modify the `cwl_to_sbg-inputs.yaml` to include:

- Paths to `pcawg-sanger-variant-caller.cwl` and `pcawg-sanger-variant-caller.job.json`
- Id of your project on the platform (From project URL, in format *user-name/project-name* )
For example if project URL is https://cgc.sbgenomics.com/u/bogdang/demo-project; project_id is `bogdang/demo-project`
- Your [authentication token](http://docs.sevenbridges.com/docs/get-your-authentication-token)
- Adequate [EC2 instance type](http://www.ec2instances.info/)
&nbsp;
After modifying `cwl_to_sbg-inputs.yaml` with your information, import the workflow to the platform by running
```shell
$BUNNY cwl_to_sbg.cwl cwl_to_sbg-inputs.yaml
```
This will install the workflow and all required apps on the platform. All the files that are required for the task execution are uploaded if they are not uploaded previously. Template draft task is created. If `run_task` is set to `true` the task execution will start on the platform.
You can now open `task` page on the platform project to see task execution details.

### Validating results
[Download the output files](https://docs.cancergenomicscloud.org/docs/download-results) to your local machine.

Modify `pcawg-sanger-variant-caller.checker.job.json` to include the paths to the requested output files and run checker tool with `cwltool`
```shell
cwltool --non-strict pcawg-sanger-variant-caller.checker.cwl pcawg-sanger-variant-caller.checker.job.json
```
Check results
```shell
cat results.json
```
```json
{""overall"": true}
```

### Submitting results
Update `pcawg-sanger-variant-caller.submit.json` with correct
`team_name` - the name of your team in plain text format (e.g., ""Your team name"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse
`eval_id` - 9606705
`file` - result files from the workflow run, please ensure to replace it with your file paths. The timestamp part will be different than default values provided.

Run the synapse submit tool
```
$BUNNY dockstore-tool-synapse-submit.cwl pcawg-sanger-variant-caller.submit.json
```
",9657281
pcawg-sanger-variant-caller,9657800_report.md,"## PCAWG Sanger Variant Caller

This wiki template will automatically be copied to any files submitted to the **GA4GH-DREAM Workflow Execution Challenge** generated by this workflow. Participants will be responsible for updating fields below and filling in documentation to describe how they ran the workflow. They will also need to update the sharing settings on the submitted file so that it's viewable by other challenge participants.

### Workflow description

```YAML
contributor: ""Junjun Zhang""
workflow_handle: ""pcawg-sanger-variant-caller""
input_handle: ""Cell line HCC1143""
```

The following description is provided by the workflow authors:
> A dockerised version of the Seqware workflow derived from Sanger's Cancer Genome Project core somatic calling pipeline. This is a cleaned up version as used in the ICGC/TCGA PanCancer project. See https://github.com/ICGC-TCGA-PanCancer/CGP-Somatic-Docker for more details.

#### Suggested resources

```YAML
suggested_cpus: ""8""
suggested_ram: ""32Gb""
suggested_disk: ""50Gb""
```

#### Workflow history

+ **2017-09-12**: Initial challenge version of workflow available on Synapse
+ **2017-11-13**: Updated initial challenge version with proper checker result file name

### Participant information

Fill in information about the person submitting workflow outputs here (if you submitted as part of a team for the challenge, this information will already be recorded in the leaderboards).

```YAML
name: ""Michael Kotliar""
institution: ""CCHMC, Barski Lab""
```

### Submission overview

Provide high level summary information for workflow execution in the fields below.

> Participants should update these fields to reflect the approach they used.

```YAML
date_accessed: ""2017-12-24""
platform: ""CWL-Airflow""
workflow_type: ""CWL""
runner_version: ""0.0.1""
docker_version: ""1.12.6""
environment: ""local""
env_cpus: ""64""
env_memory: ""251Gb""
env_disk: ""230Gb""
```

### Steps

### Setting up environment
Install CWL-Airflow
```
  cd /home/michael_kotliar/workspaces/airflow/
  git clone https://github.com/Barski-lab/cwl-airflow.git
  cd cwl-airflow
  git fetch --tags
  git checkout v0.0.1
  pip install -e .
```
Run mysql-server:5.7 docker container
```
  cd /home/michael_kotliar/temp/cwl_airflow
  mkdir database
  docker pull mysql/mysql-server:5.7
  docker run -v /home/michael_kotliar/temp/cwl_airflow/database:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=airflow -e MYSQL_DATABASE=airflow -e MYSQL_USER=airflow -e MYSQL_PASSWORD=airflow -p 6603:3306 -d mysql/mysql-server:5.7
```
Update Airflow configuration file `/home/michael_kotliar/airflow/airflow.cfg`
```
  executor = LocalExecutor
  sql_alchemy_conn = mysql://airflow:airflow@127.0.0.1:6603/airflow
```
Install synapse client
```
  pip install synapseclient
```
Create empty folder for workflow running
```
  cd /home/michael_kotliar/temp/cwl_airflow/
  mkdir pcawg-sanger-variant-caller
```
Create Synapse credentials file `/home/michael_kotliar/temp/cwl_airflow/pcawg-sanger-variant-caller/.synapseConfig`, put there Synapse ID and password
```
[authentication]
username: user@usermail.org
password: <user-password>
```
### Downloading required files
Download the tool to submit workflow results
```
cd /home/michael_kotliar/temp/cwl_airflow/pcawg-sanger-variant-caller
synapse -c .synapseConfig get syn9732885   # dockstore-tool-synapse-submit.cwl
```
Download workflow input data
```
cd /home/michael_kotliar/temp/cwl_airflow/pcawg-sanger-variant-caller
synapse -c .synapseConfig get -r syn10517387
```
Wait until downloading is finished

### Running workflow
```
cwl-airflow-runner --debug pcawg-sanger-variant-caller.cwl pcawg-sanger-variant-caller.job.json
```
### Validating results
Run checker tool
```
cd /home/michael_kotliar/temp/cwl_airflow/encode_mapping
cwltool --debug --non-strict pcawg-sanger-variant-caller.checker.cwl pcawg-sanger-variant-caller.checker.job.json
```
Check results
```
cat results.json
``` 
```json
{""overall"": true}
```
### Submitting results
Update `pcawg-sanger-variant-caller.submit.json` with correct
`team_name` - the name of your team in plain text format (e.g., ""GA4GH-Sage Contenders"")
`parent_id` - the Synapse ID of a project or folder where the submission data will be stored in Synapse.
Update filenames to include a correct timestamp.
Run the tool
```
cwltool --debug --non-strict dockstore-tool-synapse-submit.cwl pcawg-sanger-variant-caller.submit.json
```
***Running time:*** 147 min  
***Disk usage:*** 15G",9657800
pcawg-sanger-variant-caller,9657925_report.md,"### Workflow description

```YAML
contributor: ""Junjun Zhang""
workflow_handle: ""pcawg-sanger-variant-caller""
input_handle: ""Cell line HCC1143""
```

### Participant information
```YAML
name: ""Ben Ernest""
institution: ""Digicon Corporation""
```

### Submission overview
```YAML
date_accessed: ""2017-12-05"" 
platform: ""cwltool"" 
workflow_type: ""CWL"" 
runner_version: ""1.0.20170217172322"" 
docker_version: ""17.09.0-ce"" 
environment: ""cluster"" 
env_cpus: ""12"" 
env_memory: ""62Gb"" 
env_disk: ""5Tb"" 
```

### Steps

#### 1. Set up environment, following instructions at https://dockstore.org/quick-start
##### Instructions are for Linux CentOS

Download and install dockstore.  
```shell
mkdir -p ~/bin
curl -L -o ~/bin/dockstore https://github.com/ga4gh/dockstore/releases/download/1.3.0/dockstore
chmod +x ~/bin/dockstore
echo 'export PATH=~/bin:$PATH' >> ~/.bashrc
source ~/.bashrc
```

Create configuration file
```shell
mkdir -p ~/.dockstore
printf ""token: dummy-token\nserver-url: https://dockstore.org:8443\n"" > ~/.dockstore/config
```

Install `pip`
```shell
curl -L -o ~/get-pip.py https://bootstrap.pypa.io/get-pip.py
sudo python get-pip.py
```

Install `cwltool` (**note: version 1.0.20170217172322**)
```shell
sudo pip install setuptools==36.5.0
sudo pip install cwl-runner cwltool==1.0.20170217172322 schema-salad==2.6.20170806163416 avro==1.8.1 ruamel.yaml==0.14.12 requests==2.18.4
```

Install Docker
```shell
sudo yum install -y yum-utils device-mapper-persistent-data lvm2
sudo yum-config-manager --add-repo ""https://download.docker.com/linux/centos/docker-ce.repo""
sudo yum-config-manager --enable extras
sudo yum -y install docker-ce
sudo usermod -aG docker $USER
exec newgrp docker
```

Create aliases to start and stop Docker
```shell
echo 'alias start_docker=""sudo systemctl start docker""' >> ~/.bashrc
echo `alias stop_docker=""sudo systemctl stop docker""' >> ~/.bashrc
source ~/.bashrc
```
Install `synapseclient`
```
sudo pip install synapseclient
```

Create synapse credentials file with the content below, using your own Synapse credentials (no quotes or extra characters).  It can be named anything, but I'm using `.synapseConfig`.
```
[authentication]
username: email
password: password
```

Create a working directory and copy synapse credentials file into that folder.
```shell
mkdir -p pcawg_sanger
cd pcawg_sanger
cp ~/.synapseConfig .
```

#### 2. Download required files
Download tools to fetch workflow input data.
```shell
synapse get syn10519171  # pcawg-sanger-variant-caller.stage-files.json
synapse get syn9770802   # dockstore-tool-synapse-get.cwl
synapse get syn9732885   # dockstore-tool-synapse-submit.cwl
```

#### 3. Provision all workflow files
Start docker, using alias created previously.
```shell
start_docker
```

Use `cwltool` to run `dockstore-tool-synapse-get.cwl` with parameters in `pcawg-sanger-variant-caller.stage-files.json` to download tools and data needed to run the workflow and submit results.
```shell
cwltool --debug --non-strict dockstore-tool-synapse-get.cwl pcawg-sanger-variant-caller.stage-files.json
```

#### 4. Run main workflow
Use `cwltool` to run the workflow, as defined in `pcawg-sanger-variant-caller.cwl` and parameterized by `pcawg-sanger-variant-caller.job.json`:
```shell
cwltool --debug --non-strict pcawg-sanger-variant-caller.cwl pcawg-sanger-variant-caller.job.json
```

#### 5. Run workflow checker tool
Edit the dates in the file names in `pcawg-sanger-variant-caller.checker.job.json` to match the dates in the actual output file names.
Use `cwltool` to run the checker as follows:
```shell
cwltool --debug --non-strict pcawg-sanger-variant-caller.checker.cwl pcawg-sanger-variant-caller.checker.job.json
```

#### 6. Submit workflow outputs
Modify `team_name` and `parent_id` in `pcawg-sanger-variant-caller.submit.json` as shown below, assuming Synapse credentials file is named `.synapseConfig` and located in `~/pcawg_sanger`.
```JSON
{
  ""config_file"": {
    ""class"": ""File"",
    ""path"": "".synapseConfig""
  },
  ""team_name"": ""BioGenLink"",
  ""eval_id"": ""9606705"",
  ""file"": [
    {""class"": ""File"", ""path"": ""HCC1143.csc_0-0-0.20171230.somatic.cnv.tar.gz""},
    {""class"": ""File"", ""path"": ""HCC1143.csc_0-0-0.20171230.somatic.genotype.tar.gz""},
    {""class"": ""File"", ""path"": ""HCC1143.csc_0-0-0.20171230.somatic.imputeCounts.tar.gz""},
    {""class"": ""File"", ""path"": ""HCC1143.csc_0-0-0.20171230.somatic.indel.tar.gz""},
    {""class"": ""File"", ""path"": ""HCC1143.csc_0-0-0.20171230.somatic.snv_mnv.tar.gz""},
    {""class"": ""File"", ""path"": ""HCC1143.csc_0-0-0.20171230.somatic.sv.tar.gz""},
    {""class"": ""File"", ""path"": ""HCC1143.csc_0-0-0.20171230.somatic.verifyBamId.tar.gz""}
  ],
  ""parent_id"": ""syn11638638""
}
```

Submit outputs using `cwltool` and `pcawg-sanger-variant-caller.submit.json`:
```shell
cwltool --debug --non-strict dockstore-tool-synapse-submit.cwl pcawg-sanger-variant-caller.submit.json
```

Stop Docker if desired.
```shell
stop_docker
```",9657925
pcawg-sanger-variant-caller,9657926_report.md,"### Workflow description

```YAML
contributor: ""Junjun Zhang""
workflow_handle: ""pcawg-sanger-variant-caller""
input_handle: ""Cell line HCC1143""
```

### Participant information
```YAML
name: ""Ben Ernest""
institution: ""Digicon Corporation""
```

### Submission overview
```YAML
date_accessed: ""2017-12-12"" 
platform: ""Dockstore"" 
workflow_type: ""CWL"" 
runner_version: ""1.0.20170217172322"" 
docker_version: ""17.09.0-ce"" 
environment: ""BioGenLink"" 
env_cpus: ""1"" 
env_memory: ""8Gb"" 
env_disk: ""5Tb"" 
```

### Steps
#####This workflow was run using the [BioGenLink](http://digicon.com/biogenlink.html) platform from [Digicon](http://digicon.com/).  Click [here](http://digicon.com/biogenlink.html) or [email us](mailto:biogenlink@digiconasp.com) for more information. 

#### **Setup**

##### Create synapse credentials file.  
This only needs to be done once, and the credentials file can be used for each workflow.
1. Log into BioGenLink.  [Click here](http://digicon.com/biogenlink.html) or [email us](mailto:biogenlink@digiconasp.com) for more information. 
${image?fileName=login%5Fscreen%5Fempty%2E2017%2D12%2D19%2Epng&align=None&scale=75&responsive=true}

2. In the **files** tab, right-click on any directory in the file system, select `Create File`, give the file a name (e.g., ""synapse_config.txt""), and click `Preview` to edit the file.  
${image?fileName=create%5Ffile%5Fpreview%2E2017%2D12%2D19%2Epng&align=None&scale=75&responsive=true}

Enter the following information in the file and save it by clicking **Save** (the disk button just above the text area).
```
[authentication]
username: email
password: password
[cache]
location: biodtfs/path/to/cache
```
**Note:** the cache directory is used by synapseClient for temporary files, and we must specify it in BioGenLink to avoid permissions errors. It can be be any directory the user chooses, even a non-existing one as long as the parent directory is valid.  It is suggested to create a working directory for each workflow and keep this file in a parent directory outside of the working directories.  

#### **Provision workflow files**

1. Create a working directory.  
    - Right-click on any directory in the file system, select `Create Folder`, and enter a name for the working directory (e.g., `pcawg_sanger`).

2. Run the `Synapse get` tool.
    - In the **tools** tab, find and select the `Synapse get` tool.  It can be found by keyword search or browsing to `Synapse/All/Synapse get`.  Double-clicking (shown below) the tool will open it in the workspace for editing and browsing documentation and will display the menu for providing inputs and running the tool.
${image?fileName=synapse%5Fget%5Fopen%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
    - In the `Synapse IDs` field, enter the Synapse IDs for files to be downloaded.  In this case, the synapse IDs include the following, which correspond to `pcawg-sanger-variant-caller.stage-files.json`, `dockstore-tool-synapse-submit.cwl`, and `dockstore-tool-synapse-get.cwl`:
```shell
syn10519171
syn9770802   
syn9732885   
```   
Enter `pcawg-sanger-variant-caller.stage-files.json` in the field labeled `Get JSON file`.  
${image?fileName=synapse%5Fget%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
    - Drag and drop the synapse credentials file (e.g., `synapse_config.txt`) from the file system into the field called `Synapse config file`.
    - Drag and drop the working directory into the field called `Output directory`.
    - Run the tool by clicking `Quick Launch`.

#### **Run the workflow**
- Run the `Dockstore launch` tool.
    1. In the **Tools** tab, find and select the `Dockstore launch` tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore launch`.  
${image?fileName=dockstore%5Flaunch%2E2018%2D01%2D04%2Epng&align=None&scale=75&responsive=true}
    2. Drag and drop the `pcawg-sanger-variant-caller.cwl` and `pcawg-sanger-variant-caller.job.json` files from the working directory into the fields labeled `CWL file` and `JSON file`, respectively.  `Parent directory` can be left blank, since the directory containing the two input files will be used as the parent directory by default.   
    3. Click `Quick Launch`.

#### **Validate the results**
- Run the `Dockstore checker` tool.
  1. Edit the dates in the file names in `pcawg-sanger-variant-caller.checker.job.json` to match the dates in the actual output file names.
  2. In the **tools** tab, find and select the `Dockstore checker` tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore checker`.  
${image?fileName=dockstore%5Fchecker%2E2017%2D12%2D25%2Epng&align=None&scale=75&responsive=true}
  3. Drag and drop the `pcawg-sanger-variant-caller.checker.cwl` and `pcawg-sanger-variant-caller.checker.job.json` files from the working directory into the fields labeled `Checker CWL file` and `Checker JSON file`, respectively.  
  4. Click `Quick Launch`.
  5. Verify that the workflow ran successfully by opening the `results.json` file and confirming that the `Overall` field is equal to `true`.
${image?fileName=results%5Fjson%2E2017%2D12%2D25%2Epng&align=None&scale=75&responsive=true}

#### **Submit the results to Synapse**
- Run the `Dockstore submit` tool.
  1. In the **Tools** tab, find and select the `Dockstore submit` tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore submit`.  
${image?fileName=dockstore%5Fsubmit%2E2017%2D12%2D26%2Epng&align=None&scale=75&responsive=true}
  2. Drag and drop the `pcawg-sanger-variant-caller.submit.json` file into the field labeled `Submit JSON file`.  
  3. Enter a team name and the Synapse parent ID into the corresponding fields.  
  4. Drag and drop the synapse credentials file (e.g., `synapse_config.txt`) into the field labeled `Synapse config file`.
  5. Click `Quick Launch`.",9657926
pcawg-sanger-variant-caller,9657927_report.md,"### Workflow description

```YAML
contributor: ""Junjun Zhang""
workflow_handle: ""pcawg-sanger-variant-caller""
input_handle: ""Cell line HCC1143""
```

### Participant information
```YAML
name: ""Ben Ernest""
institution: ""Digicon Corporation""
```

### Submission overview
```YAML
date_accessed: ""2017-12-12"" 
platform: ""BioGenLink"" 
workflow_type: ""CWL"" 
runner_version: ""1.0.20170217172322"" 
docker_version: ""17.09.0-ce"" 
environment: ""BioGenLink"" 
env_cpus: ""1"" 
env_memory: ""8Gb"" 
env_disk: ""5Tb"" 
```

### Steps
#####This workflow was run using the [BioGenLink](http://digicon.com/biogenlink.html) platform from [Digicon](http://digicon.com/).  Click [here](http://digicon.com/biogenlink.html) or [email us](mailto:biogenlink@digiconasp.com) for more information. 

#### **Setup**

##### Create synapse credentials file.  
This only needs to be done once, and the credentials file can be used for each workflow.
1. Log into BioGenLink.  [Click here](http://digicon.com/biogenlink.html) or [email us](mailto:biogenlink@digiconasp.com) for more information.
${image?fileName=login%5Fscreen%5Fempty%2E2017%2D12%2D19%2Epng&align=None&scale=75&responsive=true}

2. In the **files** tab, right-click on any directory in the file system, select `Create File`, give the file a name (e.g., ""synapse_config.txt""), and click `Preview` to edit the file.  
${image?fileName=create%5Ffile%5Fpreview%2E2017%2D12%2D19%2Epng&align=None&scale=75&responsive=true}

Enter the following information in the file and save it by clicking **Save** (the disk button just above the text area).
```
[authentication]
username: email
password: password
[cache]
location: biodtfs/path/to/cache
```
**Note:** the cache directory is used by `synapseClient` for temporary files, and we must specify it in BioGenLink to avoid permissions errors. It can be any directory the user chooses, even a non-existing one as long as the parent directory is valid.  It is suggested to create a working directory for each workflow and keep this file in a parent directory outside of the working directories.  

#### **Provision workflow files**

1. Create a working directory.  
    - Right-click on any directory in the file system, select `Create Folder`, and enter a name for the working directory (e.g., `pcawg_sanger`).

2. Run the `Synapse get` tool.
    - In the **tools** tab, find and select the `Synapse get` tool.  It can be found by keyword search or browsing to `Synapse/All/Synapse get`.  Double-clicking (shown below) the tool will open it in the workspace for editing and browsing documentation and will display the menu for providing inputs and running the tool.
${image?fileName=synapse%5Fget%5Fopen%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
    - In the `Synapse IDs` field, enter the Synapse IDs for files to be downloaded.  In this case, the synapse IDs include the following, which correspond to `pcawg-sanger-variant-caller.stage-files.json`, `dockstore-tool-synapse-submit.cwl`, and `dockstore-tool-synapse-get.cwl`:
```shell
syn10519171
syn9732885
syn9770802
```
${image?fileName=synapse%5Fget%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
    - Drag and drop the synapse credentials file (e.g., `synapse_config.txt`) from the file system into the field called `Synapse config file`.
    - Drag and drop the working directory into the field called `Output directory`.
    - Run the tool by clicking `Quick Launch`.

#### **Import the workflow**
- If the workflow has not been imported yet, go to the **files** tab and find the `CWL` file corresponding to the workflow you want to build (e.g., `pcawg-sanger-variant-caller.cwl`).  Right-click on the file, and select `Import CWL File`.  This will automatically build a workflow which can be edited and run within the BioGenLink platform. 
${image?fileName=import%5Fcwl%5Ffile%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
The `pcawg-sanger-variant-caller` workflow is automatically created and placed in the **workflows** tab, under `CWL/Autogenerated`. 

#### **Run the workflow**
1. In the **workflows** tab, find and select the `pcawg-sanger-variant-caller` workflow.  The previous step automatically places it in the `CWL/Autogenerated` folder.  Double-clicking (shown below) opens the workflow in the workspace for editing and will display the menu for providing inputs and running the workflow.
${image?fileName=hello%5Fworld%5Fworkflow%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
If the run parameters aren't visible, right-click the orange ""play button"" at top right of the workspace to open them.
${image?fileName=hello%5Fworld%5Fworkflow%5Frun%2E2017%2D12%2D27%2Epng&align=None&scale=75&responsive=true}
The default inputs should already be set, but if they aren't then drag and drop the appropriate files from the working directory into the input fields.
2. Drag and drop a directory from the file system into the `Output Directory` field.
3. Run the workflow by clicking the `RUN WITH SKIPPING` button.


#### **Validate the results**
- Run the `Dockstore checker` tool.
  1. Edit the dates in the file names in `pcawg-sanger-variant-caller.checker.job.json` to match the dates in the actual output file names 
  2. In the **tools** tab, find and select the `Dockstore checker` tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore checker`.  
${image?fileName=dockstore%5Fchecker%2E2017%2D12%2D25%2Epng&align=None&scale=75&responsive=true}
  3. Drag and drop the `pcawg-sanger-variant-caller.checker.cwl` and `pcawg-sanger-variant-caller.checker.job.json` files from the working directory into the fields labeled `Checker CWL file` and `Checker JSON file`, respectively.  
  4. Click `Quick Launch`.
  5. Verify that the workflow ran successfully by opening the `results.json` file and confirming that the `Overall` field is equal to `true`.
${image?fileName=results%5Fjson%2E2017%2D12%2D25%2Epng&align=None&scale=75&responsive=true}

#### **Submit the results to Synapse**
- Run the `Dockstore submit` tool.
1. In the **tools** tab, find and select the `Dockstore submit` tool.  It can be found by keyword search or browsing to `Synapse/All/Dockstore submit`.  
${image?fileName=dockstore%5Fsubmit%2E2017%2D12%2D26%2Epng&align=None&scale=75&responsive=true}
2. Drag and drop the `pcawg-sanger-variant-caller.submit.json` file into the field labeled `Submit JSON file`.  
3. Enter a team name and the Synapse parent ID into the corresponding fields.  
4. Drag and drop the synapse credentials file (e.g., `synapse_config.txt`) into the field labeled `Synapse config file`.
5. Click `Quick Launch`.",9657927
